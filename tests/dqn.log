PreScan_Vissim_Python_0
waiting on port: 8031
Sending data to port: 8070
Enviroment is created
Model created!
[1]>> env.reset()
=========================
Retrying to reset environment!
Retrying to reset environment!
[1]>>[1]: env.step(1)
action:[0, 0.0]
reward:5.4910463017675065e-05
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00064063 0.1992    ]
done:False
-------------------------
[1]>>[2]: env.step(4)
action:[0, 0.0003203125]
reward:0.021008737688458266
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.245454 0.199629]
done:False
-------------------------
[1]>>[3]: env.step(1)
action:[0, 0.245454]
reward:0.04875217839604394
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.509761 0.201166]
done:False
-------------------------
[1]>>[4]: env.step(3)
action:[0, 5.509761]
reward:0.17848143217776524
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.737806 0.203917]
done:False
-------------------------
[1]>>[5]: env.step(3)
action:[0, 5.737806]
reward:0.21973869331559093
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.1799   0.207526]
done:False
-------------------------
[1]>>[6]: env.step(1)
action:[0, 1.1799]
reward:0.16952773305349111
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.71249  0.213293]
done:False
-------------------------
[1]>>[7]: env.step(2)
action:[3.5, 1.71249]
reward:-0.5386486960065336
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.08443  0.863334]
done:False
-------------------------
[1]>>[8]: env.step(1)
action:[0, 2.08443]
reward:-0.5205276864441601
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.2116  2.12497]
done:False
-------------------------
[1]>>[9]: env.step(3)
action:[0, 7.2116]
reward:0.36215411525103874
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.56794 2.66205]
done:False
-------------------------
[1]>>[10]: env.step(3)
action:[0, 7.56794]
reward:0.4623019602189097
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.74925 2.10968]
done:False
-------------------------
[1]>>[11]: env.step(0)
action:[-3.5, 3.74925]
reward:-0.2545756496452875
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      49.7089
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.13132  0.10637]
done:False
-------------------------
[1]>>[12]: env.step(1)
action:[0, 5.13132]
reward:-0.2100403811882905
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.808     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.36664   0.239697]
done:False
-------------------------
[1]>>[13]: env.step(3)
action:[0, 10.36664]
reward:0.6486755540307318
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.7608    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.5085    0.273955]
done:False
-------------------------
[1]>>[14]: env.step(0)
action:[-3.5, 5.5085]
reward:-0.15099335662455438
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.2038   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.05416 -1.80686]
done:False
-------------------------
[1]>>[15]: env.step(4)
action:[-3.5, 4.05416]
reward:0.5700259618365777
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      35.1212
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.03229 -4.0002 ]
done:False
-------------------------
[1]>>[16]: env.step(3)
action:[-3.5, 11.03229]
reward:0.6849272608062876
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 30.8485   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.83731 -3.11153]
done:False
-------------------------
[1]>>[17]: env.step(1)
action:[0, 5.83731]
reward:-0.1604637160207043
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      26.9971  49.5597   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.84562 -1.25221]
done:False
-------------------------
[1]>>[18]: env.step(1)
action:[0, 5.84562]
reward:0.5867167082690428
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      23.5793   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.806    1.29513]
done:False
-------------------------
[1]>>[19]: env.step(3)
action:[0, 10.806000000000001]
reward:0.6783477327124641
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       19.6597   42.3968    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.80354   0.271467]
done:False
-------------------------
[1]>>[20]: env.step(4)
action:[0, 3.80354]
reward:0.4613233734000567
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.9806    0.       38.672     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.67778   0.388184]
done:False
-------------------------
[1]>>[21]: env.step(4)
action:[0, 2.33889]
reward:0.3130863444794897
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.3329    0.       35.9774    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.17472   0.472397]
done:False
-------------------------
[1]>>[22]: env.step(2)
action:[3.5, 3.17472]
reward:-0.4268904442912882
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.0773   49.8125   33.6486    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.0901    0.484111]
done:False
-------------------------
[1]>>[23]: env.step(2)
action:[3.5, 3.0901]
reward:0.34463404355178057
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.80898 31.6132   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.37922  1.59343]
done:False
-------------------------
[1]>>[24]: env.step(2)
action:[3.5, 3.37922]
reward:0.34815745589331243
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.03002 30.2771
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.35093  3.79347]
done:False
-------------------------
[1]>>[25]: env.step(4)
action:[3.5, 1.675465]
reward:0.2397689063738603
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       5.18662 28.4914   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.4393   4.10963]
done:False
-------------------------
[1]>>[26]: env.step(1)
action:[0, 2.4393]
reward:-25.48230774557972
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.21849 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.58993 3.95021]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9882, 'y': 3.95021, 'z': 0.570766}
.........................
** Rewards description :
count    26.000000
mean     -0.823337
std       5.042650
min     -25.482308
25%      -0.158096
50%       0.199110
75%       0.436531
max       0.684927
dtype: float64
#########################
[2]>> env.reset()
=========================
[2]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.6600017298835412
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.0581   -0.498658]
done:False
-------------------------
[2]>>[2]: env.step(0)
action:[-3.5, 1.0581]
reward:-1.3935064731135096
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.989335 -1.09795 ]
done:False
-------------------------
[2]>>[3]: env.step(2)
action:[3.5, 0.989335]
reward:-1.4330909639792073
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.537724 -1.50951 ]
done:False
-------------------------
[2]>>[4]: env.step(1)
action:[0, 0.537724]
reward:-0.6693378573479811
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.813129 -1.94867 ]
done:False
-------------------------
[2]>>[5]: env.step(4)
action:[0, 0.4065645]
reward:0.09026941434859154
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.959672 -2.4088  ]
done:False
-------------------------
[2]>>[6]: env.step(2)
action:[3.5, 0.959672]
reward:-0.6635541020339226
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.7761  -2.53483]
done:False
-------------------------
[2]>>[7]: env.step(5)
action:[3.5, 0.7761]
reward:0.10795688424355177
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.07723 -2.86553]
done:False
-------------------------
[2]>>[8]: env.step(5)
action:[3.5, 1.07723]
reward:0.1282846792275562
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.24407 -2.99978]
done:False
-------------------------
[2]>>[9]: env.step(4)
action:[3.5, 0.622035]
reward:0.1404494192392427
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.5032  -2.92356]
done:False
-------------------------
[2]>>[10]: env.step(5)
action:[3.5, 1.5032]
reward:0.16606316379216274
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.59001 -2.48342]
done:False
-------------------------
[2]>>[11]: env.step(5)
action:[3.5, 1.59001]
reward:0.16764145020395205
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.58728 -1.70516]
done:False
-------------------------
[2]>>[12]: env.step(2)
action:[3.5, 1.58728]
reward:0.18204786395015812
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.76141  -0.633111]
done:False
-------------------------
[2]>>[13]: env.step(1)
action:[0, 1.76141]
reward:-0.5377845749969423
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.08268  0.113005]
done:False
-------------------------
[2]>>[14]: env.step(0)
action:[-3.5, 2.08268]
reward:-0.5251288782526655
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.15606 0.19525]
done:False
-------------------------
[2]>>[15]: env.step(3)
action:[-3.5, 7.15606]
reward:0.3532968505112226
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.47095  -0.439703]
done:False
-------------------------
[2]>>[16]: env.step(3)
action:[-3.5, 7.47095]
reward:0.4496468515426417
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.61119 -2.15746]
done:False
-------------------------
[2]>>[17]: env.step(4)
action:[-3.5, 1.805595]
reward:0.24938938585504594
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      48.5607   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.52423 -3.20057]
done:False
-------------------------
[2]>>[18]: env.step(1)
action:[0, 2.52423]
reward:-0.4703236866243081
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      46.7094   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.71592 -2.9446 ]
done:False
-------------------------
[2]>>[19]: env.step(5)
action:[0, 2.71592]
reward:0.2925319125036618
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      44.8802   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82635 -1.52196]
done:False
-------------------------
[2]>>[20]: env.step(2)
action:[3.5, 2.82635]
reward:-0.4551924064418453
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.        43.4223     0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.82682    0.0957068]
done:False
-------------------------
[2]>>[21]: env.step(1)
action:[0, 2.82682]
reward:-0.4489454373362504
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       41.2894    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.90385   0.355472]
done:False
-------------------------
[2]>>[22]: env.step(4)
action:[0, 1.451925]
reward:0.20469045554957987
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.5931    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.06885   0.348105]
done:False
-------------------------
[2]>>[23]: env.step(3)
action:[0, 7.068849999999999]
reward:0.34547190462051014
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.9583    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.39499   0.338122]
done:False
-------------------------
[2]>>[24]: env.step(4)
action:[0, 1.197495]
reward:0.18470165099661173
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.4379    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.89086   0.337706]
done:False
-------------------------
[2]>>[25]: env.step(0)
action:[-3.5, 1.89086]
reward:-0.5566873103870008
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.0628    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.82148   0.341388]
done:False
-------------------------
[2]>>[26]: env.step(5)
action:[-3.5, 1.82148]
reward:0.1911029564010645
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.7061    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.81213   0.347227]
done:False
-------------------------
[2]>>[27]: env.step(4)
action:[-3.5, 0.906065]
reward:0.14802035683506531
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       32.757     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.52281  -0.171069]
done:False
-------------------------
[2]>>[28]: env.step(3)
action:[-3.5, 6.52281]
reward:0.2814640840714167
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       32.0489
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.73827  -0.972648]
done:False
-------------------------
[2]>>[29]: env.step(5)
action:[-3.5, 1.73827]
reward:0.22636984579660385
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      31.3916   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26039 -2.36597]
done:False
-------------------------
[2]>>[30]: env.step(1)
action:[0, 2.26039]
reward:-0.4868463159607064
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      29.9183   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.579   -2.98447]
done:False
-------------------------
[2]>>[31]: env.step(2)
action:[3.5, 2.579]
reward:-0.4673514252761249
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      28.0148   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.7388  -2.57472]
done:False
-------------------------
[2]>>[32]: env.step(4)
action:[3.5, 1.3694]
reward:0.2007104611006049
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      26.6004  49.11     0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.0413  -1.43398]
done:False
-------------------------
[2]>>[33]: env.step(2)
action:[3.5, 2.0413]
reward:0.22610820339289162
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 2.56889e+01
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 2.18145e+00 1.61790e-02]
done:False
-------------------------
[2]>>[34]: env.step(0)
action:[-3.5, 2.18145]
reward:-1.2570899604492727
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       24.3314
 47.1648    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.35113   0.873588]
done:False
-------------------------
[2]>>[35]: env.step(0)
action:[-3.5, 2.35113]
reward:0.2552215712091717
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       22.66      0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.45917   0.942009]
done:False
-------------------------
[2]>>[36]: env.step(1)
action:[0, 2.45917]
reward:-0.4989046533262582
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.9702   43.7617    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.38169   0.546076]
done:False
-------------------------
[2]>>[37]: env.step(5)
action:[0, 2.38169]
reward:0.25665473434582453
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       19.2004   41.9517    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.46907   0.437732]
done:False
-------------------------
[2]>>[38]: env.step(1)
action:[0, 2.46907]
reward:0.2682711102927947
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.3285    0.       40.0479    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.58959   0.424418]
done:False
-------------------------
[2]>>[39]: env.step(2)
action:[3.5, 2.58959]
reward:-0.4695522475260311
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.2393   0.      37.9226   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.70907  0.44237]
done:False
-------------------------
[2]>>[40]: env.step(4)
action:[3.5, 1.354535]
reward:0.26379539983767586
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.2099    0.       35.847     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.81333   0.458377]
done:False
-------------------------
[2]>>[41]: env.step(5)
action:[3.5, 2.81333]
reward:0.3170285838578809
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.1446  33.9925   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10498  1.5842 ]
done:False
-------------------------
[2]>>[42]: env.step(3)
action:[3.5, 8.10498]
reward:0.4328214088216673
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      9.63471 0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.23771 3.5722 ]
done:False
-------------------------
[2]>>[43]: env.step(5)
action:[3.5, 3.23771]
reward:0.387486776706509
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      7.18746 0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.87981 4.20524]
done:False
-------------------------
[2]>>[44]: env.step(5)
action:[3.5, 3.87981]
reward:0.3895181209353482
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.39823 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.7449  4.03868]
done:False
-------------------------
[2]>>[45]: env.step(4)
action:[3.5, 1.87245]
reward:-24.65032901504343
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.2558   4.21148  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.74653  4.02371]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.941, 'y': 4.02371, 'z': 0.570794}
.........................
** Rewards description :
count    45.000000
mean     -0.638591
std       3.694513
min     -24.650329
25%      -0.486846
50%       0.166063
75%       0.256655
max       0.449647
dtype: float64
#########################
[3]>> env.reset()
=========================
Retrying to reset environment!
[3]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.0029240639350407755
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0341224 0.175843 ]
done:False
-------------------------
[3]>>[2]: env.step(0)
action:[-3.5, 0.0341224]
reward:-0.7270396196404538
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.259857 0.148753]
done:False
-------------------------
[3]>>[3]: env.step(0)
action:[-3.5, 0.259857]
reward:0.05069532743037338
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.529023  0.0396484]
done:False
-------------------------
[3]>>[4]: env.step(1)
action:[0, 0.529023]
reward:-0.6677917019716278
observation:
[ 0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.833598   -0.00454015]
done:False
-------------------------
[3]>>[5]: env.step(4)
action:[0, 0.416799]
reward:0.08927583634812361
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.94534  0.104393]
done:False
-------------------------
[3]>>[6]: env.step(0)
action:[-3.5, 0.94534]
reward:-0.615744003246322
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.34834 -0.15006]
done:False
-------------------------
[3]>>[7]: env.step(4)
action:[-3.5, 0.67417]
reward:0.1341528288670611
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.4149   -0.845791]
done:False
-------------------------
[3]>>[8]: env.step(3)
action:[-3.5, 6.4149]
reward:0.28106282022594087
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.76031 -1.82746]
done:False
-------------------------
[3]>>[9]: env.step(3)
action:[-3.5, 6.7603100000000005]
reward:0.4004973001036226
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.16344 -3.1867 ]
done:False
-------------------------
[3]>>[10]: env.step(5)
action:[-3.5, 3.16344]
reward:0.37275536846520374
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.71299 -3.31526]
done:False
-------------------------
[3]>>[11]: env.step(1)
action:[0, 3.71299]
reward:-0.3447414091341984
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.98552 -2.04678]
done:False
-------------------------
[3]>>[12]: env.step(0)
action:[-3.5, 3.98552]
reward:-0.33909891012205184
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.4792   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.98888 -1.47629]
done:False
-------------------------
[3]>>[13]: env.step(0)
action:[-3.5, 3.98888]
reward:0.4006327082541138
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      46.1802   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.85801 -3.09564]
done:False
-------------------------
[3]>>[14]: env.step(4)
action:[-3.5, 1.929005]
reward:0.3610895183746433
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 43.3573   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.87525 -3.27402]
done:False
-------------------------
[3]>>[15]: env.step(1)
action:[0, 3.87525]
reward:-0.33450483163898526
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      40.6521   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.07473 -1.91121]
done:False
-------------------------
[3]>>[16]: env.step(4)
action:[0, 2.037365]
reward:0.2683121633589694
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        39.127      0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.69802    0.0533399]
done:False
-------------------------
[3]>>[17]: env.step(3)
action:[0, 7.69802]
reward:0.40547321153517
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       37.1271    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.99198   0.456696]
done:False
-------------------------
[3]>>[18]: env.step(0)
action:[-3.5, 2.99198]
reward:-0.3942136751186178
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       34.9823    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.54311  -0.344413]
done:False
-------------------------
[3]>>[19]: env.step(2)
action:[3.5, 3.54311]
reward:-1.1332647057874037
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       32.4404    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.5425   -0.321689]
done:False
-------------------------
[3]>>[20]: env.step(2)
action:[3.5, 3.5425]
reward:0.3752370484215365
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      30.5027   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.64941  1.68625]
done:False
-------------------------
[3]>>[21]: env.step(4)
action:[3.5, 1.824705]
reward:0.2479808425809813
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      29.5071
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50224  3.60563]
done:False
-------------------------
[3]>>[22]: env.step(2)
action:[3.5, 2.50224]
reward:0.27349795076801897
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      27.7956   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.64547  4.27722]
done:False
-------------------------
[3]>>[23]: env.step(1)
action:[0, 2.64547]
reward:-0.4760065263774439
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.8342  49.0161   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.61575  4.00655]
done:False
-------------------------
[3]>>[24]: env.step(5)
action:[0, 2.61575]
reward:0.28214787949187836
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      23.8332  47.0176   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.72345  3.91598]
done:False
-------------------------
[3]>>[25]: env.step(4)
action:[0, 1.361725]
reward:0.2645456061295819
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.7515   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82073  3.91519]
done:False
-------------------------
[3]>>[26]: env.step(4)
action:[0, 1.410365]
reward:0.19102109206093787
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.4024
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.91392  3.07539]
done:False
-------------------------
[3]>>[27]: env.step(4)
action:[0, 0.95696]
reward:0.1535155148213282
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      19.7008   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.57594  2.067  ]
done:False
-------------------------
[3]>>[28]: env.step(1)
action:[0, 1.57594]
reward:0.16766328370945846
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      19.1425  42.0446   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.59106  1.08775]
done:False
-------------------------
[3]>>[29]: env.step(0)
action:[-3.5, 1.59106]
reward:-0.5512843899814381
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       18.0806
 40.8514    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.96175   0.430177]
done:False
-------------------------
[3]>>[30]: env.step(2)
action:[3.5, 1.96175]
reward:-1.2817988229138277
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       16.6864    0.       39.4089    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.10524   0.407889]
done:False
-------------------------
[3]>>[31]: env.step(1)
action:[0, 2.10524]
reward:-0.5244101899360916
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.197    37.8826    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.15916   0.416914]
done:False
-------------------------
[3]>>[32]: env.step(5)
action:[0, 2.15916]
reward:0.23466052807392956
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.5983    0.       36.248     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.2561    0.455011]
done:False
-------------------------
[3]>>[33]: env.step(0)
action:[-3.5, 2.2561]
reward:-0.4902081568119256
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       12.3031
  0.       34.6755    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.53888  -0.425572]
done:False
-------------------------
[3]>>[34]: env.step(2)
action:[3.5, 2.53888]
reward:-1.2332398513409404
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.6887
  0.      49.1643  32.925    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5536  -0.44342]
done:False
-------------------------
[3]>>[35]: env.step(0)
action:[-3.5, 2.5536]
reward:-1.231026249267801
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.53695  0.      47.619   31.3182
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.57708 -1.23652]
done:False
-------------------------
[3]>>[36]: env.step(2)
action:[3.5, 2.57708]
reward:-1.2311745508148613
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       9.18673  0.       0.       0.      30.0429   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.56939 -2.64254]
done:False
-------------------------
[3]>>[37]: env.step(0)
action:[-3.5, 2.56939]
reward:-1.2195189216461064
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       8.20634  0.       0.       0.      44.6106
 28.1756   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.71453 -3.01139]
done:False
-------------------------
[3]>>[38]: env.step(3)
action:[-3.5, 7.71453]
reward:0.40074992657240294
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.19278  0.       0.       0.       0.
 42.577   26.1238   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.92808 -3.01874]
done:False
-------------------------
[3]>>[39]: env.step(3)
action:[-3.5, 7.92808]
reward:0.5006667375351103
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.52549  0.       0.       0.       0.       0.       0.
  0.      23.2957   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.15461 -2.98371]
done:False
-------------------------
[3]>>[40]: env.step(1)
action:[0, 4.15461]
reward:-0.27054219905312593
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       5.55122  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.7777  20.3933   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.82348 -1.25929]
done:False
-------------------------
[3]>>[41]: env.step(3)
action:[0, 9.82348]
reward:0.6141006138180456
observation:
[ 0.       0.       0.       0.       0.       5.73428  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.9128   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.17755  1.11503]
done:False
-------------------------
[3]>>[42]: env.step(2)
action:[3.5, 5.17755]
reward:-0.21600539191826784
observation:
[ 0.       0.       0.       0.       0.       7.78616  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      31.2856
  0.      15.665    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.27686  3.54323]
done:False
-------------------------
[3]>>[43]: env.step(2)
action:[3.5, 5.27686]
reward:0.552194348648049
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.7405  48.5099  12.6966   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      11.4156   5.49112  4.79768]
done:False
-------------------------
[3]>>[44]: env.step(1)
action:[0, 5.49112]
reward:-0.21607847146017378
observation:
[15.1986   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.8933  44.6448   0.       9.02939  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.19751  4.19134]
done:False
-------------------------
[3]>>[45]: env.step(4)
action:[0, 3.1975100000000003]
reward:0.48390172902544437
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.0433  40.8609   0.       0.       0.       5.99848
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      19.0456   5.12014  4.18037]
done:False
-------------------------
[3]>>[46]: env.step(0)
action:[-3.5, 5.12014]
reward:-0.23262980051871684
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.2276  37.1278   0.       0.       0.       0.
  0.       0.       4.5042   0.       0.       0.       0.       0.
  0.       0.       0.      22.8612   5.07391  4.16972]
done:False
-------------------------
[3]>>[47]: env.step(3)
action:[-3.5, 10.07391]
reward:0.6395168736768624
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.0168   0.      33.5841   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       4.15843  0.       0.       0.      26.1302
  0.       0.       0.       0.       5.45753  2.34688]
done:False
-------------------------
[3]>>[48]: env.step(3)
action:[-3.5, 10.45753]
reward:0.695205466011011
observation:
[ 0.       0.       0.       0.       0.       0.       0.      13.1142
  0.       0.      32.0663   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      27.5895   0.       0.
  0.       0.       0.       0.       6.12255 -1.84108]
done:False
-------------------------
[3]>>[49]: env.step(1)
action:[0, 6.12255]
reward:-0.029193743396727423
observation:
[ 0.       9.17073  0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.4916   0.       0.       0.      28.5609
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      31.8662   7.56116 -5.61818]
done:False
-------------------------
[3]>>[50]: env.step(5)
action:[0, 7.56116]
reward:0.7885686875240661
observation:
[ 0.       0.       0.       0.       0.      36.4358   0.       0.
  0.       0.       0.       0.       0.       0.       0.       7.75309
  0.       0.       0.       0.       0.       0.      23.3093   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.1577  -3.4169 ]
done:False
-------------------------
[3]>>[51]: env.step(4)
action:[0, 6.1577]
reward:0.6897717039311679
observation:
[ 0.        0.        0.        0.       16.1133   39.1482    0.
  0.        0.        0.        0.        0.        0.        0.
  2.68972   0.        0.        0.        0.        0.        0.
  0.        0.       44.2774   20.6045    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.12261   0.984535]
done:False
-------------------------
[3]>>[52]: env.step(5)
action:[0, 7.12261]
reward:-24.29276310075605
observation:
[ 0.       0.       0.       0.      16.394   39.3952   0.       0.
  0.       0.       0.       0.       0.       2.47129  0.       0.
  0.       0.       0.       0.       0.       0.       0.      44.0417
 20.407    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.12264  1.22487]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 99.2144, 'y': 1.22487, 'z': 0.570057}
.........................
** Rewards description :
count    52.000000
mean     -0.533278
std       3.407778
min     -24.292763
25%      -0.479557
50%       0.111714
75%       0.373376
max       0.788569
dtype: float64
#########################
[4]>> env.reset()
=========================
[4]>>[1]: env.step(3)
action:[0, 12.06614]
reward:-24.21014212112406
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.0499  1.96048]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 100.81, 'y': 1.96048, 'z': 0.571714}
.........................
** Rewards description :
count     1.000000
mean    -24.210142
std            NaN
min     -24.210142
25%     -24.210142
50%     -24.210142
75%     -24.210142
max     -24.210142
dtype: float64
#########################
[5]>> env.reset()
=========================
[5]>>[1]: env.step(5)
action:[0, 1.9096]
reward:0.2009773729554889
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90948 -0.8575 ]
done:False
-------------------------
[5]>>[2]: env.step(2)
action:[3.5, 1.90948]
reward:-0.5532304114467593
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.85861  -0.764899]
done:False
-------------------------
[5]>>[3]: env.step(1)
action:[0, 1.85861]
reward:-0.5770488635853108
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.584    -0.449767]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.05971, 'y': -0.449767, 'z': 0.570057}
.........................
** Rewards description :
count    3.000000
mean    -0.309767
std      0.442478
min     -0.577049
25%     -0.565140
50%     -0.553230
75%     -0.176127
max      0.200977
dtype: float64
#########################
[6]>> env.reset()
=========================
[6]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.18582060979428483
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.953733 -0.628868]
done:False
-------------------------
[6]>>[2]: env.step(5)
action:[0, 0.953733]
reward:0.21261533924066583
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.28945  -0.713514]
done:False
-------------------------
[6]>>[3]: env.step(1)
action:[0, 2.28945]
reward:0.3362892959221264
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 3.47534    0.00492927]
done:False
-------------------------
[6]>>[4]: env.step(5)
action:[0, 3.47534]
reward:0.42026025351344415
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.23523  0.271942]
done:False
-------------------------
[6]>>[5]: env.step(0)
action:[-3.5, 4.23523]
reward:-0.28930715820560693
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.56176 -1.20138]
done:False
-------------------------
[6]>>[6]: env.step(0)
action:[-3.5, 4.56176]
reward:0.4696170078269632
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.59486 -3.58109]
done:False
-------------------------
[6]>>[7]: env.step(0)
action:[-3.5, 4.59486]
reward:0.4345293861504719
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.084    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.13702 -3.23009]
done:False
-------------------------
[6]>>[8]: env.step(1)
action:[0, 4.13702]
reward:-0.31563291035337115
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      44.3469   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24941 -1.75753]
done:False
-------------------------
[6]>>[9]: env.step(4)
action:[0, 2.124705]
reward:0.28032816342757527
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 42.6265    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.82382   0.269216]
done:False
-------------------------
[6]>>[10]: env.step(3)
action:[0, 7.8238199999999996]
reward:0.4064531749142648
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       40.6476    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.97294   0.433491]
done:False
-------------------------
[6]>>[11]: env.step(5)
action:[0, 2.97294]
reward:0.43772847067197623
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.813     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.58332   0.336612]
done:False
-------------------------
[6]>>[12]: env.step(1)
action:[0, 4.58332]
reward:0.5547393732742759
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.8551    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.69804   0.338617]
done:False
-------------------------
[6]>>[13]: env.step(5)
action:[0, 5.69804]
reward:0.6266002461014204
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.3104    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.37704   0.365941]
done:False
-------------------------
[6]>>[14]: env.step(5)
action:[0, 6.37704]
reward:0.6334948813053654
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.5845   47.3813    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.30032   0.393583]
done:False
-------------------------
[6]>>[15]: env.step(1)
action:[0, 6.30032]
reward:0.6246275054423838
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.9454   42.6998    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.19989   0.419663]
done:False
-------------------------
[6]>>[16]: env.step(4)
action:[0, 4.19989]
reward:0.5779024285329242
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.4066    0.       38.0936    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.10028   0.444839]
done:False
-------------------------
[6]>>[17]: env.step(5)
action:[0, 6.10028]
reward:0.6061397605422599
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.9968   49.7268   33.5621    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.00162   0.469418]
done:False
-------------------------
[6]>>[18]: env.step(5)
action:[0, 6.00162]
reward:0.589684733352801
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.87962   0.       45.3432   29.1728    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.80652   0.493192]
done:False
-------------------------
[6]>>[19]: env.step(2)
action:[3.5, 5.80652]
reward:-25.152484349595987
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.87265  0.       0.      42.3837  26.3142   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.95974  1.45882]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.7848, 'y': 1.45882, 'z': 0.569253}
.........................
** Rewards description :
count    19.000000
mean     -0.966347
std       5.863461
min     -25.152484
25%       0.246472
50%       0.434529
75%       0.583794
max       0.633495
dtype: float64
#########################
[7]>> env.reset()
=========================
[7]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.5908420963943924
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.88287 1.27451]
done:False
-------------------------
[7]>>[2]: env.step(1)
action:[0, 1.88287]
reward:-0.5875600387324117
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.45156 1.60273]
done:False
-------------------------
[7]>>[3]: env.step(3)
action:[0, 6.45156]
reward:0.24885598847374069
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.35622 1.95941]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02718, 'y': 1.95941, 'z': 0.5709}
.........................
** Rewards description :
count    3.000000
mean    -0.309849
std      0.483855
min     -0.590842
25%     -0.589201
50%     -0.587560
75%     -0.169352
max      0.248856
dtype: float64
#########################
[8]>> env.reset()
=========================
[8]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.1292628994186068
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.275052 0.388483]
done:False
-------------------------
[8]>>[2]: env.step(0)
action:[-3.5, 0.275052]
reward:-0.684468925885934
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.700035 0.541148]
done:False
-------------------------
[8]>>[3]: env.step(0)
action:[-3.5, 0.700035]
reward:0.11535420557031095
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.18425  0.206954]
done:False
-------------------------
[8]>>[4]: env.step(1)
action:[0, 1.18425]
reward:-0.6044910519930675
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.42319  0.230811]
done:False
-------------------------
[8]>>[5]: env.step(4)
action:[0, 0.711595]
reward:0.11981611792129396
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.2345   0.221994]
done:False
-------------------------
[8]>>[6]: env.step(3)
action:[0, 6.2345]
reward:0.28730437175971524
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.88226  0.211061]
done:False
-------------------------
[8]>>[7]: env.step(4)
action:[0, 0.94113]
reward:0.3171753323160448
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.57485  0.239629]
done:False
-------------------------
[8]>>[8]: env.step(5)
action:[0, 3.57485]
reward:0.44674322634684593
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.54805  0.251948]
done:False
-------------------------
[8]>>[9]: env.step(2)
action:[3.5, 4.54805]
reward:-0.24340190270031925
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      48.5458   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.07667  2.09001]
done:False
-------------------------
[8]>>[10]: env.step(2)
action:[3.5, 5.07667]
reward:0.5170881832796665
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.896    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.0811   4.39498]
done:False
-------------------------
[8]>>[11]: env.step(3)
action:[3.5, 10.0811]
reward:0.5855458759563145
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.3712   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73155  3.74367]
done:False
-------------------------
[8]>>[12]: env.step(4)
action:[3.5, 2.365775]
reward:0.3119717931330952
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.6715   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.15419  3.80779]
done:False
-------------------------
[8]>>[13]: env.step(4)
action:[3.5, 1.577095]
reward:0.28139917311123575
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.4052   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.9739   3.84138]
done:False
-------------------------
[8]>>[14]: env.step(3)
action:[3.5, 7.9739]
reward:0.42139788460800753
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.1751   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.12505  3.84059]
done:False
-------------------------
[8]>>[15]: env.step(3)
action:[3.5, 8.12505]
reward:0.5517750545283386
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.1713   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.77355  3.85057]
done:False
-------------------------
[8]>>[16]: env.step(2)
action:[3.5, 4.77355]
reward:0.5752505613285128
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.0442   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.92168  3.873  ]
done:False
-------------------------
[8]>>[17]: env.step(1)
action:[0, 5.92168]
reward:-0.09929367613202755
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      24.118   47.1049   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.64732  1.83094]
done:False
-------------------------
[8]>>[18]: env.step(1)
action:[0, 6.64732]
reward:0.6621425902150722
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.4495   43.0754    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.62158  -0.391077]
done:False
-------------------------
[8]>>[19]: env.step(2)
action:[3.5, 6.62158]
reward:-0.1088066571052444
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      16.3824
 39.4867   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.34331  2.90246]
done:False
-------------------------
[8]>>[20]: env.step(5)
action:[3.5, 6.34331]
reward:0.6410177810374622
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.6164   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.4105   5.06081]
done:False
-------------------------
[8]>>[21]: env.step(2)
action:[3.5, 6.4105]
reward:0.6334834068623422
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.11184 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.2918  3.91017]
done:False
-------------------------
[8]>>[22]: env.step(4)
action:[3.5, 4.2918]
reward:-24.498177057712727
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.15673 27.4695   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.07869  4.0076 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9312, 'y': 4.0076, 'z': 0.567709}
.........................
** Rewards description :
count    22.000000
mean     -0.892814
std       5.286174
min     -24.498177
25%      -0.045632
50%       0.299638
75%       0.543103
max       0.662143
dtype: float64
#########################
[9]>> env.reset()
=========================
Retrying to reset environment!
[9]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7359331959275727
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.164306  0.0867482]
done:False
-------------------------
[9]>>[2]: env.step(1)
action:[0, 0.164306]
reward:-0.7324216874635694
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.164306  -0.0355783]
done:False
-------------------------
[9]>>[3]: env.step(3)
action:[0, 5.164306]
reward:0.21256202057899948
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.23616  -0.137954]
done:False
-------------------------
[9]>>[4]: env.step(3)
action:[0, 6.23616]
reward:0.39567602324805584
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.23354 0.1221 ]
done:False
-------------------------
[9]>>[5]: env.step(1)
action:[0, 3.23354]
reward:0.38064732438920756
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.7947   0.218213]
done:False
-------------------------
[9]>>[6]: env.step(5)
action:[0, 3.7947]
reward:0.38390203725680294
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.69539  0.241231]
done:False
-------------------------
[9]>>[7]: env.step(4)
action:[0, 1.847695]
reward:0.24664229167724216
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.48014  0.253715]
done:False
-------------------------
[9]>>[8]: env.step(1)
action:[0, 2.48014]
reward:0.2512951178738407
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.398     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.37889   0.261714]
done:False
-------------------------
[9]>>[9]: env.step(2)
action:[3.5, 2.37889]
reward:-0.494786600856733
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      47.6777   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.45213  1.2068 ]
done:False
-------------------------
[9]>>[10]: env.step(4)
action:[3.5, 1.226065]
reward:0.1765919916675584
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      46.8302   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.78597  2.48166]
done:False
-------------------------
[9]>>[11]: env.step(5)
action:[3.5, 1.78597]
reward:0.19783571457235483
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      45.9364   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90238  3.52067]
done:False
-------------------------
[9]>>[12]: env.step(2)
action:[3.5, 1.90238]
reward:0.20908247727172583
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      44.55     0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00945  3.8541 ]
done:False
-------------------------
[9]>>[13]: env.step(0)
action:[-3.5, 2.00945]
reward:-1.284491906516423
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.092    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06062  3.60484]
done:False
-------------------------
[9]>>[14]: env.step(2)
action:[3.5, 2.06062]
reward:-1.2913745887908943
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.6918   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96435  3.86086]
done:False
-------------------------
[9]>>[15]: env.step(0)
action:[-3.5, 1.96435]
reward:-1.2948251811433504
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      40.2672   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.94661  3.886  ]
done:False
-------------------------
[9]>>[16]: env.step(3)
action:[-3.5, 6.94661]
reward:0.3487849053680865
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      38.8255
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.46692  3.14566]
done:False
-------------------------
[9]>>[17]: env.step(2)
action:[3.5, 2.46692]
reward:-1.2126164955399175
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.9825   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82513  3.24156]
done:False
-------------------------
[9]>>[18]: env.step(4)
action:[3.5, 1.412565]
reward:0.20102457686359085
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      35.382    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03431  3.72723]
done:False
-------------------------
[9]>>[19]: env.step(2)
action:[3.5, 2.03431]
reward:0.20749019611228392
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.8027   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95717  3.85306]
done:False
-------------------------
[9]>>[20]: env.step(2)
action:[3.5, 1.95717]
reward:0.20285712895071611
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.3554   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92034  3.87159]
done:False
-------------------------
[9]>>[21]: env.step(0)
action:[-3.5, 1.92034]
reward:-1.2838952160009698
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      31.0114
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09014  3.20601]
done:False
-------------------------
[9]>>[22]: env.step(2)
action:[3.5, 2.09014]
reward:-1.2750511660239265
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.5977   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15514  3.37238]
done:False
-------------------------
[9]>>[23]: env.step(3)
action:[3.5, 7.155139999999999]
reward:0.34621949330371415
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      28.0981   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.38275  3.76632]
done:False
-------------------------
[9]>>[24]: env.step(1)
action:[0, 2.38275]
reward:-0.3546297628293047
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.5614   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.19303  3.91397]
done:False
-------------------------
[9]>>[25]: env.step(1)
action:[0, 4.19303]
reward:0.4847785020022461
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      22.6287  45.6818   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.88259  2.38203]
done:False
-------------------------
[9]>>[26]: env.step(5)
action:[0, 4.88259]
reward:0.5031433452756109
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        20.4831    43.1839     0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.94814   -0.0734743]
done:False
-------------------------
[9]>>[27]: env.step(3)
action:[0, 9.94814]
reward:0.5654104696082884
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       17.07     39.7835    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.49772   0.469188]
done:False
-------------------------
[9]>>[28]: env.step(2)
action:[3.5, 4.49772]
reward:-0.23840993205182515
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      13.9394  36.9227   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.1542   2.08989]
done:False
-------------------------
[9]>>[29]: env.step(1)
action:[0, 5.1542]
reward:-0.22929523388124595
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.1061   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.1089   4.65472]
done:False
-------------------------
[9]>>[30]: env.step(3)
action:[0, 10.1089]
reward:0.589760550635605
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       7.53624 30.8206   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.78071  3.91973]
done:False
-------------------------
[9]>>[31]: env.step(3)
action:[0, 9.78071]
reward:0.5879781876999888
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       4.85457 43.7721  27.797    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.83902  2.15346]
done:False
-------------------------
[9]>>[32]: env.step(2)
action:[3.5, 4.83902]
reward:-0.2129204701839552
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        3.15376   0.        0.
  0.        0.       40.7204   24.5744    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.40193   0.719473]
done:False
-------------------------
[9]>>[33]: env.step(4)
action:[3.5, 3.40193]
reward:-24.56871565954183
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       1.97263  0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.7878  22.7427   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.39388  1.63183]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 60.4405, 'y': 1.63183, 'z': 0.565925}
.........................
** Rewards description :
count    33.000000
mean     -0.870233
std       4.303241
min     -24.568716
25%      -0.732422
50%       0.201025
75%       0.348785
max       0.589761
dtype: float64
#########################
[10]>> env.reset()
=========================
[10]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.12733117343416694
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.502   1.13077]
done:False
-------------------------
[10]>>[2]: env.step(1)
action:[0, 1.502]
reward:0.1089141849855394
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.907137 1.74625 ]
done:False
-------------------------
[10]>>[3]: env.step(5)
action:[0, 0.907137]
reward:0.15097068036264993
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.55789 2.27506]
done:False
-------------------------
[10]>>[4]: env.step(1)
action:[0, 1.55789]
reward:0.16897956989409912
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.6114  2.86696]
done:False
-------------------------
[10]>>[5]: env.step(4)
action:[0, 0.8057]
reward:0.1301386172815653
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.33408 3.06927]
done:False
-------------------------
[10]>>[6]: env.step(5)
action:[0, 1.33408]
reward:0.14101217606806873
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.33192 3.03454]
done:False
-------------------------
[10]>>[7]: env.step(3)
action:[0, 6.33192]
reward:0.24430819473470247
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.33058 2.73681]
done:False
-------------------------
[10]>>[8]: env.step(4)
action:[0, 0.66529]
reward:0.11478665237358701
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.18618 2.22287]
done:False
-------------------------
[10]>>[9]: env.step(3)
action:[0, 6.18618]
reward:0.22881397432015507
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17815 1.51849]
done:False
-------------------------
[10]>>[10]: env.step(1)
action:[0, 1.17815]
reward:0.14318510040706933
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     1.3969 0.8207]
done:False
-------------------------
[10]>>[11]: env.step(5)
action:[0, 1.3969]
reward:0.17524494629283133
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.72704  0.327115]
done:False
-------------------------
[10]>>[12]: env.step(3)
action:[0, 6.72704]
reward:0.32721107414479866
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.25298  0.194338]
done:False
-------------------------
[10]>>[13]: env.step(2)
action:[3.5, 2.25298]
reward:-0.38121589392301
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.89074 0.22058]
done:False
-------------------------
[10]>>[14]: env.step(0)
action:[-3.5, 3.89074]
reward:-1.0549772020440882
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      48.1891   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44707 -1.25209]
done:False
-------------------------
[10]>>[15]: env.step(3)
action:[-3.5, 9.44707]
reward:0.5608073417379763
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      46.3349   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.56216 -3.56704]
done:False
-------------------------
[10]>>[16]: env.step(5)
action:[-3.5, 4.56216]
reward:0.49314282615699917
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.9088   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.89853 -3.17502]
done:False
-------------------------
[10]>>[17]: env.step(4)
action:[-3.5, 2.449265]
reward:0.31375724210091605
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      40.1795   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.15544 -3.15344]
done:False
-------------------------
[10]>>[18]: env.step(4)
action:[-3.5, 1.57772]
reward:0.2840270855025402
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 37.9298   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.00609 -3.17854]
done:False
-------------------------
[10]>>[19]: env.step(0)
action:[-3.5, 3.00609]
reward:0.3045010013748435
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.6106   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.90164 -3.16763]
done:False
-------------------------
[10]>>[20]: env.step(0)
action:[-3.5, 2.90164]
reward:0.29480050344235664
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.512    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.80791 -3.14776]
done:False
-------------------------
[10]>>[21]: env.step(2)
action:[3.5, 2.80791]
reward:-1.214498395674556
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.4872   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.7167  -3.13683]
done:False
-------------------------
[10]>>[22]: env.step(5)
action:[3.5, 2.7167]
reward:0.28279928049296443
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.6247   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.70623 -2.1312 ]
done:False
-------------------------
[10]>>[23]: env.step(1)
action:[0, 2.70623]
reward:-0.48861946715106264
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.2927   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.44581 -0.44593]
done:False
-------------------------
[10]>>[24]: env.step(3)
action:[0, 7.44581]
reward:0.3992948368992436
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       26.5778
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.97686   0.485317]
done:False
-------------------------
[10]>>[25]: env.step(5)
action:[0, 2.97686]
reward:0.3471597538053288
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.1588   46.9554    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.43906   0.438499]
done:False
-------------------------
[10]>>[26]: env.step(2)
action:[3.5, 3.43906]
reward:-0.3827778662419272
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      21.8688  44.8271   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.57462  1.7901 ]
done:False
-------------------------
[10]>>[27]: env.step(4)
action:[3.5, 1.78731]
reward:0.24546192471940387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      20.621   43.7681
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.48082  3.58161]
done:False
-------------------------
[10]>>[28]: env.step(2)
action:[3.5, 2.48082]
reward:0.2580321326299079
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.9143   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.46115  4.04618]
done:False
-------------------------
[10]>>[29]: env.step(2)
action:[3.5, 2.46115]
reward:0.23942876150278636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.0897  40.3081   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.23873  4.0018 ]
done:False
-------------------------
[10]>>[30]: env.step(0)
action:[-3.5, 2.23873]
reward:-1.267150089371696
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.6189
 38.7874   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.21415  3.27506]
done:False
-------------------------
[10]>>[31]: env.step(2)
action:[3.5, 2.21415]
reward:-1.2734706681303145
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.67    37.6858   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.14336  1.9836 ]
done:False
-------------------------
[10]>>[32]: env.step(1)
action:[0, 2.14336]
reward:-0.5391651378154818
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       14.4101   37.1502    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.97045   0.474405]
done:False
-------------------------
[10]>>[33]: env.step(2)
action:[3.5, 1.97045]
reward:-0.5316987717975825
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       13.6514   36.1239
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.10428  -0.451343]
done:False
-------------------------
[10]>>[34]: env.step(5)
action:[3.5, 2.10428]
reward:0.21973527696162393
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       12.4802
  0.       34.7494    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.08824  -0.808794]
done:False
-------------------------
[10]>>[35]: env.step(3)
action:[3.5, 7.08824]
reward:0.31876405930536045
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.0503   49.5292   33.2854    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.05778  -0.504695]
done:False
-------------------------
[10]>>[36]: env.step(1)
action:[0, 2.05778]
reward:-0.5460094926113146
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        9.59417   0.       31.9485    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90891   0.193081]
done:False
-------------------------
[10]>>[37]: env.step(0)
action:[-3.5, 1.90891]
reward:-0.5359154389033269
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  8.37054   0.        0.       30.5477    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.06848  -0.054462]
done:False
-------------------------
[10]>>[38]: env.step(5)
action:[-3.5, 2.06848]
reward:0.2172625329593471
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        7.67271   0.        0.
 45.5942   29.3077    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.06716  -0.942242]
done:False
-------------------------
[10]>>[39]: env.step(1)
action:[0, 2.06716]
reward:-0.5256807116252872
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       6.60895  0.       0.
  0.      27.8286   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15323 -1.03036]
done:False
-------------------------
[10]>>[40]: env.step(1)
action:[0, 2.15323]
reward:0.22266650096186374
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.27777   0.        0.        0.       26.4753    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.11162  -0.356423]
done:False
-------------------------
[10]>>[41]: env.step(2)
action:[3.5, 2.11162]
reward:-0.5453034547843847
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  4.00568   0.        0.        0.        0.       41.4024   25.1917
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.904     0.314322]
done:False
-------------------------
[10]>>[42]: env.step(2)
action:[3.5, 1.904]
reward:-24.776942513256852
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       2.85311
  0.       0.       0.       0.       0.      40.4557  24.3335   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.17868  1.17703]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 58.8685, 'y': 1.17703, 'z': 0.573955}
.........................
** Rewards description :
count    42.000000
mean     -0.642878
std       3.846836
min     -24.776943
25%      -0.516415
50%       0.159975
75%       0.276607
max       0.560807
dtype: float64
#########################
[11]>> env.reset()
=========================
[11]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.19360688914534713
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.04775  0.817461]
done:False
-------------------------
[11]>>[2]: env.step(3)
action:[0, 6.04775]
reward:0.37722248971084404
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.04806  0.432836]
done:False
-------------------------
[11]>>[3]: env.step(2)
action:[3.5, 3.04806]
reward:-0.3987924146221776
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.47183 1.48735]
done:False
-------------------------
[11]>>[4]: env.step(4)
action:[3.5, 1.735915]
reward:0.2331238141768822
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.34319 3.17962]
done:False
-------------------------
[11]>>[5]: env.step(3)
action:[3.5, 7.34319]
reward:0.3829859633870094
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.79673 3.80318]
done:False
-------------------------
[11]>>[6]: env.step(2)
action:[3.5, 2.79673]
reward:0.3355313691397982
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.33908 3.79704]
done:False
-------------------------
[11]>>[7]: env.step(1)
action:[0, 3.33908]
reward:-0.4119691341374556
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.2611   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.23463  3.76927]
done:False
-------------------------
[11]>>[8]: env.step(4)
action:[0, 1.617315]
reward:0.2100058660135622
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      47.7177
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09191  2.88786]
done:False
-------------------------
[11]>>[9]: env.step(4)
action:[0, 1.045955]
reward:0.16248252718419082
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      46.9361   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.6613   1.70284]
done:False
-------------------------
[11]>>[10]: env.step(0)
action:[-3.5, 1.6613]
reward:-0.5610439619786498
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      46.5608   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.82625  0.45719]
done:False
-------------------------
[11]>>[11]: env.step(0)
action:[-3.5, 1.82625]
reward:0.19429142636665958
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.       46.3611    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.84946  -0.879176]
done:False
-------------------------
[11]>>[12]: env.step(2)
action:[3.5, 1.84946]
reward:-1.2861620750384564
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.5592   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.08035 -1.91944]
done:False
-------------------------
[11]>>[13]: env.step(3)
action:[3.5, 7.08035]
reward:0.35783841462858973
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      44.2379   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5467  -2.48319]
done:False
-------------------------
[11]>>[14]: env.step(1)
action:[0, 2.5467]
reward:-0.34210534339927684
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.7131   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.31048 -2.09868]
done:False
-------------------------
[11]>>[15]: env.step(4)
action:[0, 2.15524]
reward:0.2919700620176103
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 39.6847    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.95959  -0.196005]
done:False
-------------------------
[11]>>[16]: env.step(0)
action:[-3.5, 2.95959]
reward:-0.4378737250517515
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       37.5327    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.00765   0.122794]
done:False
-------------------------
[11]>>[17]: env.step(3)
action:[-3.5, 8.00765]
reward:0.42786247300524094
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 35.6714    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.19886  -0.933647]
done:False
-------------------------
[11]>>[18]: env.step(2)
action:[3.5, 3.19886]
reward:-1.1321522111619742
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.3953   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.64252 -1.21045]
done:False
-------------------------
[11]>>[19]: env.step(2)
action:[3.5, 3.64252]
reward:0.36967919081650735
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       31.096     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.55459   0.667087]
done:False
-------------------------
[11]>>[20]: env.step(3)
action:[3.5, 8.554590000000001]
reward:0.4400648063638177
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 30.0844   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.21774  3.0846 ]
done:False
-------------------------
[11]>>[21]: env.step(2)
action:[3.5, 3.21774]
reward:0.33551872253280224
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      28.3355   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.23367  4.50494]
done:False
-------------------------
[11]>>[22]: env.step(3)
action:[3.5, 8.23367]
reward:0.44773218042728075
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      26.0326  49.2369   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.396    4.38589]
done:False
-------------------------
[11]>>[23]: env.step(0)
action:[-3.5, 3.396]
reward:-1.0930087750814634
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      23.8416  46.923    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.08671  2.62958]
done:False
-------------------------
[11]>>[24]: env.step(1)
action:[0, 4.08671]
reward:-0.3563584265056675
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.       23.3226   46.0438    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.74521  -0.242282]
done:False
-------------------------
[11]>>[25]: env.step(5)
action:[0, 3.74521]
reward:0.39535717395711395
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.0825  44.3792   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.85225 -2.28811]
done:False
-------------------------
[11]>>[26]: env.step(1)
action:[0, 3.85225]
reward:0.3895688620264523
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 19.56     0.      41.7086   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.75243 -2.33769]
done:False
-------------------------
[11]>>[27]: env.step(1)
action:[0, 3.75243]
reward:0.3696479238077211
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       17.1602
  0.       39.6225    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.52672  -0.560186]
done:False
-------------------------
[11]>>[28]: env.step(3)
action:[0, 8.526720000000001]
reward:0.4603581640570721
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.7865  37.4366   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.48459  0.46331]
done:False
-------------------------
[11]>>[29]: env.step(1)
action:[0, 3.48459]
reward:0.32646425459880646
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.3371    0.       34.9484    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.05431   0.474475]
done:False
-------------------------
[11]>>[30]: env.step(1)
action:[0, 3.05431]
reward:0.30180643846147226
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.2401  48.9406  32.7756   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.85627  0.48051]
done:False
-------------------------
[11]>>[31]: env.step(1)
action:[0, 2.85627]
reward:0.28268249410528923
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.31831   0.       46.9108   30.7431    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.6699    0.491559]
done:False
-------------------------
[11]>>[32]: env.step(5)
action:[0, 2.6699]
reward:0.27172584860890175
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.52751   0.       44.95     28.7791    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.58179   0.497524]
done:False
-------------------------
[11]>>[33]: env.step(1)
action:[0, 2.58179]
reward:0.25499969463699607
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  4.97736   0.        0.       43.1237   26.95      0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.39879   0.504865]
done:False
-------------------------
[11]>>[34]: env.step(2)
action:[3.5, 2.39879]
reward:-0.5054954366334251
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        3.72992   0.
  0.        0.        0.       41.3637   25.1873    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.31626   0.514921]
done:False
-------------------------
[11]>>[35]: env.step(4)
action:[3.5, 1.15813]
reward:0.1818863304962477
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       2.5943   0.       0.
  0.       0.       0.       0.      23.9775   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.86675  1.22914]
done:False
-------------------------
[11]>>[36]: env.step(5)
action:[3.5, 1.86675]
reward:-24.80714809189774
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       2.51717  0.       0.
  0.       0.       0.       0.      23.9172   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.82194  1.3002 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 59.3328, 'y': 1.3002, 'z': 0.569029}
.........................
** Rewards description :
count    36.000000
mean     -0.648269
std       4.169544
min     -24.807148
25%      -0.366967
50%       0.263363
75%       0.369656
max       0.460358
dtype: float64
#########################
[12]>> env.reset()
=========================
[12]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.05150236641379381
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.603485 0.60318 ]
done:False
-------------------------
[12]>>[2]: env.step(0)
action:[-3.5, 0.603485]
reward:-0.677380360302356
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.701613 1.01826 ]
done:False
-------------------------
[12]>>[3]: env.step(4)
action:[-3.5, 0.3508065]
reward:0.09999869396714978
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.08901  0.770162]
done:False
-------------------------
[12]>>[4]: env.step(1)
action:[0, 1.08901]
reward:-0.6083247148824668
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.40112  0.556544]
done:False
-------------------------
[12]>>[5]: env.step(3)
action:[0, 6.40112]
reward:0.297304452899486
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.96395  0.342157]
done:False
-------------------------
[12]>>[6]: env.step(4)
action:[0, 0.981975]
reward:0.3266111947245831
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.68179  0.221592]
done:False
-------------------------
[12]>>[7]: env.step(4)
action:[0, 1.840895]
reward:0.2535886159291295
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.56675  0.226417]
done:False
-------------------------
[12]>>[8]: env.step(4)
action:[0, 1.283375]
reward:0.1855090286085532
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.87913  0.241072]
done:False
-------------------------
[12]>>[9]: env.step(5)
action:[0, 1.87913]
reward:0.19531733430177617
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.84864  0.254016]
done:False
-------------------------
[12]>>[10]: env.step(0)
action:[-3.5, 1.84864]
reward:-0.5374426373599106
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       49.5021    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.06502  -0.458721]
done:False
-------------------------
[12]>>[11]: env.step(5)
action:[-3.5, 2.06502]
reward:0.216042996814938
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      48.6627   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05322 -1.68657]
done:False
-------------------------
[12]>>[12]: env.step(2)
action:[3.5, 2.05322]
reward:-1.2781474498408145
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      47.3934
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.12673 -2.11536]
done:False
-------------------------
[12]>>[13]: env.step(5)
action:[3.5, 2.12673]
reward:0.22156104194670845
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.9422   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.10481 -1.8714 ]
done:False
-------------------------
[12]>>[14]: env.step(0)
action:[-3.5, 2.10481]
reward:-1.273004160103469
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      44.7191   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.17637 -2.42713]
done:False
-------------------------
[12]>>[15]: env.step(2)
action:[3.5, 2.17637]
reward:-1.2953036612136195
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.5293   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.88781 -3.04525]
done:False
-------------------------
[12]>>[16]: env.step(5)
action:[3.5, 1.88781]
reward:0.20761026925336878
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.1223   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99525 -2.82182]
done:False
-------------------------
[12]>>[17]: env.step(2)
action:[3.5, 1.99525]
reward:0.21462559283418084
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.759    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05346 -2.01737]
done:False
-------------------------
[12]>>[18]: env.step(2)
action:[3.5, 2.05346]
reward:0.21608913131876428
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       39.7203    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.05667  -0.737713]
done:False
-------------------------
[12]>>[19]: env.step(3)
action:[3.5, 7.05667]
reward:0.3494328739395094
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.0741    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.4475    0.922097]
done:False
-------------------------
[12]>>[20]: env.step(5)
action:[3.5, 2.4475]
reward:0.3052692828278438
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.5429   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.05079  3.00816]
done:False
-------------------------
[12]>>[21]: env.step(3)
action:[3.5, 8.05079]
reward:0.4566997158508543
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      37.1091   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.55662  4.77292]
done:False
-------------------------
[12]>>[22]: env.step(3)
action:[3.5, 8.55662]
reward:0.5931472439760237
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.0021   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.21392  5.13202]
done:False
-------------------------
[12]>>[23]: env.step(5)
action:[3.5, 5.21392]
reward:0.5846178539106628
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.1135   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.936    3.67894]
done:False
-------------------------
[12]>>[24]: env.step(0)
action:[-3.5, 5.936]
reward:-0.9137097174988301
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      26.5479   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.77773  2.14824]
done:False
-------------------------
[12]>>[25]: env.step(4)
action:[-3.5, 3.77773]
reward:0.5191417308767835
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 26.1396  48.6032   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.43262 -1.94856]
done:False
-------------------------
[12]>>[26]: env.step(2)
action:[3.5, 5.43262]
reward:-0.945723802915789
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      24.8046   0.      46.5534   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.47961 -4.99622]
done:False
-------------------------
[12]>>[27]: env.step(4)
action:[3.5, 3.47961]
reward:0.42009953500812847
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.6917   0.      43.3205   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.23212 -4.55593]
done:False
-------------------------
[12]>>[28]: env.step(0)
action:[-3.5, 4.23212]
reward:-1.0664197906298791
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      18.7996   0.      40.6497   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.2156  -3.05636]
done:False
-------------------------
[12]>>[29]: env.step(5)
action:[-3.5, 4.2156]
reward:0.3969733318835103
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.9477
  0.      37.6056   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.75507 -3.05826]
done:False
-------------------------
[12]>>[30]: env.step(1)
action:[0, 3.75507]
reward:-0.37205713807555796
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.4747
  0.      34.8546   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.63029 -3.04914]
done:False
-------------------------
[12]>>[31]: env.step(1)
action:[0, 3.63029]
reward:0.3729681014927265
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.9292   0.       0.      32.5606   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.59895 -1.68961]
done:False
-------------------------
[12]>>[32]: env.step(2)
action:[3.5, 3.59895]
reward:-0.3994091095547646
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.15382  47.8228   31.6638    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.3264    0.804387]
done:False
-------------------------
[12]>>[33]: env.step(4)
action:[3.5, 1.6632]
reward:0.2355533779224562
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       8.39177 31.4491   0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.39097  2.79775]
done:False
-------------------------
[12]>>[34]: env.step(3)
action:[3.5, 7.390969999999999]
reward:0.3516393993134199
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.66628 30.9554   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.3915   4.35821]
done:False
-------------------------
[12]>>[35]: env.step(2)
action:[3.5, 2.3915]
reward:0.23099508867237262
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      45.4255   6.48302  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15337  5.13302]
done:False
-------------------------
[12]>>[36]: env.step(2)
action:[3.5, 2.15337]
reward:0.21627016389505171
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      43.9821  28.408    5.13463  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03389  5.22388]
done:False
-------------------------
[12]>>[37]: env.step(3)
action:[3.5, 7.0338899999999995]
reward:-24.682622291731267
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.0122  27.424    4.15814  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05417  4.93635]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.2959, 'y': 4.93635, 'z': 0.569024}
.........................
** Rewards description :
count    37.000000
mean     -0.717053
std       4.089749
min     -24.682622
25%      -0.537443
50%       0.216043
75%       0.326611
max       0.593147
dtype: float64
#########################
[13]>> env.reset()
=========================
[13]>>[1]: env.step(3)
action:[0, 7.05006]
reward:-24.683096196439426
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.04425 4.63913]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.8339, 'y': 4.63913, 'z': 0.56915}
.........................
** Rewards description :
count     1.000000
mean    -24.683096
std            NaN
min     -24.683096
25%     -24.683096
50%     -24.683096
75%     -24.683096
max     -24.683096
dtype: float64
#########################
[14]>> env.reset()
=========================
[14]>>[1]: env.step(0)
action:[-3.5, 0.748383]
reward:-0.6651353628997566
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.810199 -0.299778]
done:False
-------------------------
[14]>>[2]: env.step(0)
action:[-3.5, 0.810199]
reward:0.12033570760853987
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.21604  -0.770891]
done:False
-------------------------
[14]>>[3]: env.step(3)
action:[-3.5, 6.21604]
reward:0.2881625845963866
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.89745 -1.7171 ]
done:False
-------------------------
[14]>>[4]: env.step(5)
action:[-3.5, 1.89745]
reward:0.2485583238302697
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.49111 -3.06074]
done:False
-------------------------
[14]>>[5]: env.step(0)
action:[-3.5, 2.49111]
reward:0.24187800739281862
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26112 -3.35532]
done:False
-------------------------
[14]>>[6]: env.step(4)
action:[-3.5, 1.13056]
reward:0.16732682956227787
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.69836 -3.34311]
done:False
-------------------------
[14]>>[7]: env.step(2)
action:[3.5, 1.69836]
reward:-1.2988879369803563
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96392 -2.84618]
done:False
-------------------------
[14]>>[8]: env.step(0)
action:[-3.5, 1.96392]
reward:-1.2871697637152484
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03951 -3.0515 ]
done:False
-------------------------
[14]>>[9]: env.step(2)
action:[3.5, 2.03951]
reward:-1.2910765423063228
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.97324 -2.34538]
done:False
-------------------------
[14]>>[10]: env.step(2)
action:[3.5, 1.97324]
reward:0.21571551184745047
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07219 -1.17922]
done:False
-------------------------
[14]>>[11]: env.step(5)
action:[3.5, 2.07219]
reward:0.2096659180336941
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.97407  0.289026]
done:False
-------------------------
[14]>>[12]: env.step(2)
action:[3.5, 1.97407]
reward:0.20269233512822865
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.7113   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.91412  1.71446]
done:False
-------------------------
[14]>>[13]: env.step(3)
action:[3.5, 6.9141200000000005]
reward:0.3396307565909521
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.3616   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.36081  3.19783]
done:False
-------------------------
[14]>>[14]: env.step(2)
action:[3.5, 2.36081]
reward:0.3971080653938405
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      47.7219   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.22047  4.92218]
done:False
-------------------------
[14]>>[15]: env.step(5)
action:[3.5, 4.22047]
reward:0.48216846682741454
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.4598   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.84201  4.98989]
done:False
-------------------------
[14]>>[16]: env.step(0)
action:[-3.5, 4.84201]
reward:-1.017312398499366
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      41.2613   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.69333  3.80624]
done:False
-------------------------
[14]>>[17]: env.step(0)
action:[-3.5, 4.69333]
reward:0.45302976871807976
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.9821   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.34893  3.84819]
done:False
-------------------------
[14]>>[18]: env.step(5)
action:[-3.5, 4.34893]
reward:0.45925462909678716
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      35.2129   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.51487  2.30813]
done:False
-------------------------
[14]>>[19]: env.step(0)
action:[-3.5, 4.51487]
reward:0.436308131420283
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.5082   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.17971 -1.05766]
done:False
-------------------------
[14]>>[20]: env.step(4)
action:[-3.5, 2.089855]
reward:0.27927763883901924
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.281    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.81961 -3.38263]
done:False
-------------------------
[14]>>[21]: env.step(2)
action:[3.5, 2.81961]
reward:-1.2260704224701078
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      32.9968   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.57143 -4.38965]
done:False
-------------------------
[14]>>[22]: env.step(2)
action:[3.5, 2.57143]
reward:0.2620546208654113
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      31.2919
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.48777 -4.43131]
done:False
-------------------------
[14]>>[23]: env.step(1)
action:[0, 2.48777]
reward:-0.5050118183756866
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.6321   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29992 -3.62018]
done:False
-------------------------
[14]>>[24]: env.step(3)
action:[0, 7.29992]
reward:0.33598722483149096
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      28.3409   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.21896 -2.24902]
done:False
-------------------------
[14]>>[25]: env.step(2)
action:[3.5, 2.21896]
reward:-0.5377542757737296
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       27.6548    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.96866  -0.728614]
done:False
-------------------------
[14]>>[26]: env.step(2)
action:[3.5, 1.96866]
reward:0.19919094165326
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       27.2279    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.8731    0.664006]
done:False
-------------------------
[14]>>[27]: env.step(0)
action:[-3.5, 1.8731]
reward:-1.2840616312444106
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      26.3272
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09993  1.78156]
done:False
-------------------------
[14]>>[28]: env.step(4)
action:[-3.5, 1.049965]
reward:0.16531690308321728
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      25.2056   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.69435  2.36518]
done:False
-------------------------
[14]>>[29]: env.step(0)
action:[-3.5, 1.69435]
reward:0.17672411325209605
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      23.931    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.67049  2.4537 ]
done:False
-------------------------
[14]>>[30]: env.step(4)
action:[-3.5, 0.835245]
reward:0.14106912770435798
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      22.892   45.9082   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.45731  2.13591]
done:False
-------------------------
[14]>>[31]: env.step(2)
action:[3.5, 1.45731]
reward:-1.3104681176814592
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      21.8366  44.8923   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8842   2.52617]
done:False
-------------------------
[14]>>[32]: env.step(5)
action:[3.5, 1.8842]
reward:0.1845371963600775
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.7996  43.9334   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.7172   3.36528]
done:False
-------------------------
[14]>>[33]: env.step(2)
action:[3.5, 1.7172]
reward:0.18663170472820642
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      19.6158   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.78422  3.82615]
done:False
-------------------------
[14]>>[34]: env.step(1)
action:[0, 1.78422]
reward:-0.5430307732600771
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.2263   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01338  3.653  ]
done:False
-------------------------
[14]>>[35]: env.step(4)
action:[0, 1.00669]
reward:0.158361594802255
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      17.1313
 40.2641   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.62164  2.99482]
done:False
-------------------------
[14]>>[36]: env.step(5)
action:[0, 1.62164]
reward:0.18579301023586708
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      16.3173  39.3382   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.79799  2.01575]
done:False
-------------------------
[14]>>[37]: env.step(5)
action:[0, 1.79799]
reward:0.1896983493924415
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       15.5993   38.445
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.80104   0.948599]
done:False
-------------------------
[14]>>[38]: env.step(5)
action:[0, 1.80104]
reward:0.21042826823110264
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 14.4256   37.1373    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.0511    0.467739]
done:False
-------------------------
[14]>>[39]: env.step(2)
action:[3.5, 2.0511]
reward:-0.5326357496662766
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.9012    0.       35.5911    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.07274   0.650386]
done:False
-------------------------
[14]>>[40]: env.step(2)
action:[3.5, 2.07274]
reward:0.2167127286994615
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      11.4825  34.3104   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05942  1.46112]
done:False
-------------------------
[14]>>[41]: env.step(2)
action:[3.5, 2.05942]
reward:0.21063074463182652
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.3935  33.4562
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.98896  2.72329]
done:False
-------------------------
[14]>>[42]: env.step(2)
action:[3.5, 1.98896]
reward:0.20637040580617466
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       9.35931 32.5808
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95494  3.75332]
done:False
-------------------------
[14]>>[43]: env.step(2)
action:[3.5, 1.95494]
reward:0.2070707426657911
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      47.004    7.94046  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.97193  4.00206]
done:False
-------------------------
[14]>>[44]: env.step(3)
action:[3.5, 6.97193]
reward:0.3417514721508828
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.468    6.4127   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.3728   4.04067]
done:False
-------------------------
[14]>>[45]: env.step(1)
action:[0, 2.3728]
reward:-0.45021725443562133
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       4.52495
 27.7521   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.00164  3.23697]
done:False
-------------------------
[14]>>[46]: env.step(1)
action:[0, 3.00164]
reward:-24.68920157430088
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       4.22297 27.3908
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.98069  2.92097]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9651, 'y': 2.92097, 'z': 0.569836}
.........................
** Rewards description :
count    46.000000
mean     -0.619969
std       3.672506
min     -24.689202
25%      -0.525730
50%       0.188165
75%       0.246888
max       0.482168
dtype: float64
#########################
[15]>> env.reset()
=========================
[15]>>[1]: env.step(1)
action:[0, 2.98235]
reward:0.1329894259023625
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.823958 -0.448208]
done:False
-------------------------
[15]>>[2]: env.step(5)
action:[0, 0.823958]
reward:0.13382778467248915
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.37357   0.0898895]
done:False
-------------------------
[15]>>[3]: env.step(4)
action:[0, 0.686785]
reward:0.12459364472743444
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.29765  0.170294]
done:False
-------------------------
[15]>>[4]: env.step(5)
action:[0, 1.29765]
reward:0.11333815175868749
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.01085  -0.438656]
done:False
-------------------------
[15]>>[5]: env.step(2)
action:[3.5, 1.01085]
reward:-0.6189000004610548
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.29427  0.417333]
done:False
-------------------------
[15]>>[6]: env.step(1)
action:[0, 1.29427]
reward:-0.5791518836454888
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.69978  0.367582]
done:False
-------------------------
[15]>>[7]: env.step(3)
action:[0, 6.6997800000000005]
reward:0.3053662940944987
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.98892 0.33989]
done:False
-------------------------
[15]>>[8]: env.step(5)
action:[0, 1.98892]
reward:0.35706527598797877
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.80988  0.238494]
done:False
-------------------------
[15]>>[9]: env.step(4)
action:[0, 1.90494]
reward:0.44239387558603127
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.90991  0.238306]
done:False
-------------------------
[15]>>[10]: env.step(1)
action:[0, 4.90991]
reward:0.5293962027430832
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.1539    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.28356   0.267483]
done:False
-------------------------
[15]>>[11]: env.step(2)
action:[3.5, 5.28356]
reward:-0.14407010523498343
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.7609    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.20299   0.294569]
done:False
-------------------------
[15]>>[12]: env.step(4)
action:[3.5, 4.20299]
reward:0.5889889706401057
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.0728    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.24691   0.321308]
done:False
-------------------------
[15]>>[13]: env.step(1)
action:[0, 6.24691]
reward:-0.13809718164924945
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.5223    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.0422    0.346383]
done:False
-------------------------
[15]>>[14]: env.step(4)
action:[0, 4.0422]
reward:0.5631557621202098
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.0531   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.9444   0.37067]
done:False
-------------------------
[15]>>[15]: env.step(1)
action:[0, 5.9444]
reward:0.5843524413937278
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.7332   47.5312    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.74985   0.394146]
done:False
-------------------------
[15]>>[16]: env.step(2)
action:[3.5, 5.74985]
reward:-0.1643618625033061
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      21.0173  44.0516
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.81559  2.35167]
done:False
-------------------------
[15]>>[17]: env.step(5)
action:[3.5, 5.81559]
reward:0.5822597765337275
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      17.8837  41.148    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.75423  4.78781]
done:False
-------------------------
[15]>>[18]: env.step(1)
action:[0, 5.75423]
reward:-0.18145925339685198
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      13.8577  37.0891   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.58761  3.82948]
done:False
-------------------------
[15]>>[19]: env.step(0)
action:[-3.5, 5.58761]
reward:-0.1946300728809821
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.3741  33.3774   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.45528  2.12464]
done:False
-------------------------
[15]>>[20]: env.step(4)
action:[-3.5, 3.45528]
reward:0.41306625918318013
observation:
[ 0.       0.       0.       0.       0.       0.       0.      10.5686
  0.      48.8274  32.5412   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.1489  -1.21317]
done:False
-------------------------
[15]>>[21]: env.step(0)
action:[-3.5, 4.1489]
reward:0.44756789323861
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 11.2057   0.       0.      31.6354   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.41509 -4.0371 ]
done:False
-------------------------
[15]>>[22]: env.step(2)
action:[3.5, 4.41509]
reward:-1.0638105963015378
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.99971  0.       0.       0.       0.
 28.9141   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.20314 -4.84889]
done:False
-------------------------
[15]>>[23]: env.step(1)
action:[0, 4.20314]
reward:-0.33529723265422035
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       7.58607
  0.       0.       0.       0.      26.2329   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.9827  -3.30907]
done:False
-------------------------
[15]>>[24]: env.step(2)
action:[3.5, 3.9827]
reward:-0.37059073697793865
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        4.87815   0.
  0.        0.        0.       41.4663   25.1583    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.59183  -0.605459]
done:False
-------------------------
[15]>>[25]: env.step(0)
action:[-3.5, 3.59183]
reward:-26.13683909745015
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.57991  0.       0.       0.
  0.      41.1559  24.9834   0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.4855   0.79539]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.9694, 'y': 0.79539, 'z': 0.569892}
.........................
** Rewards description :
count    25.000000
mean     -0.984354
std       5.258423
min     -26.136839
25%      -0.194630
50%       0.124594
75%       0.442394
max       0.588989
dtype: float64
#########################
[16]>> env.reset()
=========================
[16]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.02670696923650086
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.312281 0.410631]
done:False
-------------------------
[16]>>[2]: env.step(2)
action:[3.5, 0.312281]
reward:-0.6828296849716509
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.710071 0.676932]
done:False
-------------------------
[16]>>[3]: env.step(1)
action:[0, 0.710071]
reward:-0.6307345791028085
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.22832  0.687584]
done:False
-------------------------
[16]>>[4]: env.step(5)
action:[0, 1.22832]
reward:0.12906667476645012
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.21563  0.438719]
done:False
-------------------------
[16]>>[5]: env.step(1)
action:[0, 1.21563]
reward:0.15146323437967293
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.48667  0.297116]
done:False
-------------------------
[16]>>[6]: env.step(4)
action:[0, 0.743335]
reward:0.12295211569504565
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.26394  0.236918]
done:False
-------------------------
[16]>>[7]: env.step(1)
action:[0, 1.26394]
reward:0.15386870720973686
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.50343  0.217968]
done:False
-------------------------
[16]>>[8]: env.step(3)
action:[0, 6.50343]
reward:0.30774585363366136
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.06745  0.220857]
done:False
-------------------------
[16]>>[9]: env.step(1)
action:[0, 2.06745]
reward:0.2624915841823149
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.61912  0.240432]
done:False
-------------------------
[16]>>[10]: env.step(3)
action:[0, 7.619120000000001]
reward:0.3681438468664988
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.54117  0.252304]
done:False
-------------------------
[16]>>[11]: env.step(0)
action:[-3.5, 2.54117]
reward:-0.47762047568967325
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 49.4428    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.622    -0.729916]
done:False
-------------------------
[16]>>[12]: env.step(3)
action:[-3.5, 7.622]
reward:0.3849994721188266
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      48.4957   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.75239 -2.40113]
done:False
-------------------------
[16]>>[13]: env.step(3)
action:[-3.5, 7.75239]
reward:0.5382607055875073
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      46.2701
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.68908 -3.56791]
done:False
-------------------------
[16]>>[14]: env.step(5)
action:[-3.5, 4.68908]
reward:0.5208809690288931
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.5791   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.22748 -3.22098]
done:False
-------------------------
[16]>>[15]: env.step(0)
action:[-3.5, 5.22748]
reward:0.5254958876356763
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 38.7363   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.15316 -3.19848]
done:False
-------------------------
[16]>>[16]: env.step(1)
action:[0, 5.15316]
reward:-0.21502306940357996
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      35.2745   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.29583 -1.37053]
done:False
-------------------------
[16]>>[17]: env.step(1)
action:[0, 5.29583]
reward:0.535481815421242
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      32.3111   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.26678  1.04709]
done:False
-------------------------
[16]>>[18]: env.step(5)
action:[0, 5.26678]
reward:0.5107201094919682
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       28.7322    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.95061   0.288947]
done:False
-------------------------
[16]>>[19]: env.step(0)
action:[-3.5, 4.95061]
reward:-0.24897869748361656
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      25.8667  48.4075   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.90358 -1.43058]
done:False
-------------------------
[16]>>[20]: env.step(1)
action:[0, 4.90358]
reward:-0.2563056188521721
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      23.2557
  0.      45.4597   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.82032 -2.76886]
done:False
-------------------------
[16]>>[21]: env.step(5)
action:[0, 4.82032]
reward:0.48264714954335225
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      20.0662  42.5621   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.69823 -0.82041]
done:False
-------------------------
[16]>>[22]: env.step(3)
action:[0, 9.698229999999999]
reward:0.5729636554724752
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       17.0455   39.8032    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.66019   0.748669]
done:False
-------------------------
[16]>>[23]: env.step(5)
action:[0, 4.66019]
reward:0.4412734428342497
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.9366    0.       36.6028    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.20678   0.503356]
done:False
-------------------------
[16]>>[24]: env.step(2)
action:[3.5, 4.20678]
reward:-0.3240721250869064
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.9221   49.6499   33.4854    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.12445   0.476188]
done:False
-------------------------
[16]>>[25]: env.step(1)
action:[0, 4.12445]
reward:-0.3322216698390261
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.03032   0.       46.5985   30.4295    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.04142   0.482785]
done:False
-------------------------
[16]>>[26]: env.step(5)
action:[0, 4.04142]
reward:0.4098239859045109
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.37166   0.        0.       43.6076   27.4345    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.96125   0.500215]
done:False
-------------------------
[16]>>[27]: env.step(2)
action:[3.5, 3.96125]
reward:-25.33221064703288
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  3.22287  0.       0.       0.      41.4718  25.3881   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.08236  1.38055]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.7853, 'y': 1.38055, 'z': 0.569769}
.........................
** Rewards description :
count    27.000000
mean     -0.816852
std       4.914742
min     -25.332211
25%      -0.252642
50%       0.153869
75%       0.461960
max       0.572964
dtype: float64
#########################
[17]>> env.reset()
=========================
Retrying to reset environment!
[17]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.11251605689504984
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.32548  -0.643296]
done:False
-------------------------
[17]>>[2]: env.step(4)
action:[0, 0.66274]
reward:0.12642297516768888
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.32548 -1.09919]
done:False
-------------------------
[17]>>[3]: env.step(4)
action:[0, 0.66274]
reward:0.12642297516768888
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.32548  -0.834694]
done:False
-------------------------
[17]>>[4]: env.step(2)
action:[3.5, 1.32548]
reward:-0.6097059894936196
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.32548 -0.49185]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.01641, 'y': -0.49185, 'z': 0.570198}
.........................
** Rewards description :
count    4.000000
mean    -0.061086
std      0.365805
min     -0.609706
25%     -0.068039
50%      0.119470
75%      0.126423
max      0.126423
dtype: float64
#########################
[18]>> env.reset()
=========================
[18]>>[1]: env.step(2)
action:[3.5, 1.32548]
reward:-0.6532954666128512
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.806247 -0.621153]
done:False
-------------------------
[18]>>[2]: env.step(4)
action:[3.5, 0.4031235]
reward:0.10821980750859339
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.1736  -0.15343]
done:False
-------------------------
[18]>>[3]: env.step(4)
action:[3.5, 0.5868]
reward:0.11207312887040669
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.17351  0.702497]
done:False
-------------------------
[18]>>[4]: env.step(3)
action:[3.5, 6.17351]
reward:0.2281723933124269
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17351 1.33274]
done:False
-------------------------
[18]>>[5]: env.step(5)
action:[3.5, 1.17351]
reward:0.12438745890815765
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17351 1.51998]
done:False
-------------------------
[18]>>[6]: env.step(4)
action:[3.5, 0.586755]
reward:0.11181582325495018
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17046 1.20284]
done:False
-------------------------
[18]>>[7]: env.step(4)
action:[3.5, 0.58523]
reward:0.11178377740063336
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17046 0.75655]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.00172, 'y': 0.75655, 'z': 0.570029}
.........................
** Rewards description :
count    7.000000
mean     0.020451
std      0.300187
min     -0.653295
25%      0.110002
50%      0.111816
75%      0.118230
max      0.228172
dtype: float64
#########################
[19]>> env.reset()
=========================
[19]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.6505279433119304
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.17046  0.960777]
done:False
-------------------------
[19]>>[2]: env.step(0)
action:[-3.5, 1.17046]
reward:-1.4138049861216804
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.720432 1.64985 ]
done:False
-------------------------
[19]>>[3]: env.step(1)
action:[0, 0.720432]
reward:-0.6096175303268274
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.4778  1.44534]
done:False
-------------------------
[19]>>[4]: env.step(2)
action:[3.5, 1.4778]
reward:-0.6489140631286566
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.82017  0.586004]
done:False
-------------------------
[19]>>[5]: env.step(4)
action:[3.5, 0.410085]
reward:0.10893809012524713
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     1.1804 1.1338]
done:False
-------------------------
[19]>>[6]: env.step(0)
action:[-3.5, 1.1804]
reward:-1.4088634454894087
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.77649 1.89028]
done:False
-------------------------
[19]>>[7]: env.step(1)
action:[0, 0.77649]
reward:-0.6051860523416863
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.51681 1.66733]
done:False
-------------------------
[19]>>[8]: env.step(0)
action:[-3.5, 1.51681]
reward:-0.6130688223000982
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.23744  0.646502]
done:False
-------------------------
[19]>>[9]: env.step(0)
action:[-3.5, 1.23744]
reward:0.13101100930174325
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.23656   0.0523925]
done:False
-------------------------
[19]>>[10]: env.step(1)
action:[0, 1.23656]
reward:-0.5790718775647188
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.71517  -0.135521]
done:False
-------------------------
[19]>>[11]: env.step(2)
action:[3.5, 1.71517]
reward:-0.579134012049725
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.59477  0.254149]
done:False
-------------------------
[19]>>[12]: env.step(3)
action:[3.5, 6.5947700000000005]
reward:0.3213644958614678
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.21342 1.08409]
done:False
-------------------------
[19]>>[13]: env.step(2)
action:[3.5, 2.21342]
reward:0.272251076408887
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.70236 2.72195]
done:False
-------------------------
[19]>>[14]: env.step(5)
action:[3.5, 2.70236]
reward:0.2857445715229928
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.74608 3.80425]
done:False
-------------------------
[19]>>[15]: env.step(0)
action:[-3.5, 2.74608]
reward:-1.2269880586390727
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.57854 3.63437]
done:False
-------------------------
[19]>>[16]: env.step(5)
action:[-3.5, 2.57854]
reward:0.2531317214246105
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      49.7615
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.37675  2.60272]
done:False
-------------------------
[19]>>[17]: env.step(5)
action:[-3.5, 2.37675]
reward:0.24202141531750598
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      48.9276   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29146  1.0609 ]
done:False
-------------------------
[19]>>[18]: env.step(1)
action:[0, 2.29146]
reward:-0.5279228131027922
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.6243    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.0699   -0.533063]
done:False
-------------------------
[19]>>[19]: env.step(0)
action:[-3.5, 2.0699]
reward:-0.5409125727840338
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.4701   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96763 -2.12362]
done:False
-------------------------
[19]>>[20]: env.step(5)
action:[-3.5, 1.96763]
reward:0.21632659362703444
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.1021   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.08101 -3.39771]
done:False
-------------------------
[19]>>[21]: env.step(4)
action:[-3.5, 1.040505]
reward:0.15905345097832704
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      47.2293   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.62149 -4.07076]
done:False
-------------------------
[19]>>[22]: env.step(2)
action:[3.5, 1.62149]
reward:-1.3129918807850827
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      46.1179   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.81269 -4.35892]
done:False
-------------------------
[19]>>[23]: env.step(0)
action:[-3.5, 1.81269]
reward:-1.2971924325308617
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.7637   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95586 -4.16691]
done:False
-------------------------
[19]>>[24]: env.step(2)
action:[3.5, 1.95586]
reward:-1.2887161087164911
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      43.3903   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02277 -3.40882]
done:False
-------------------------
[19]>>[25]: env.step(2)
action:[3.5, 2.02277]
reward:0.2148728077634916
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      42.2862   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04958 -2.17392]
done:False
-------------------------
[19]>>[26]: env.step(0)
action:[-3.5, 2.04958]
reward:-1.272248593703732
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.9575   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.19937 -1.65642]
done:False
-------------------------
[19]>>[27]: env.step(2)
action:[3.5, 2.19937]
reward:-1.2712799053087225
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       39.8894    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.17371  -0.608853]
done:False
-------------------------
[19]>>[28]: env.step(1)
action:[0, 2.17371]
reward:-0.5370883579449812
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.2701    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.98805   0.827026]
done:False
-------------------------
[19]>>[29]: env.step(2)
action:[3.5, 1.98805]
reward:-0.5511746463820493
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.8448   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.86383  2.28574]
done:False
-------------------------
[19]>>[30]: env.step(5)
action:[3.5, 1.86383]
reward:0.20383297716033333
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.3983   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95549  3.63367]
done:False
-------------------------
[19]>>[31]: env.step(4)
action:[3.5, 0.977745]
reward:0.1483885280873939
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      37.4941   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.5093   4.29535]
done:False
-------------------------
[19]>>[32]: env.step(5)
action:[3.5, 1.5093]
reward:0.16192352257134196
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.4931   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.53875  4.65966]
done:False
-------------------------
[19]>>[33]: env.step(2)
action:[3.5, 1.53875]
reward:0.18010145029516725
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      35.3262   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.75008  4.66361]
done:False
-------------------------
[19]>>[34]: env.step(3)
action:[3.5, 6.7500800000000005]
reward:0.3250320117194586
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.956    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.22014  4.1855 ]
done:False
-------------------------
[19]>>[35]: env.step(2)
action:[3.5, 2.22014]
reward:0.28187059494274336
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      32.0156   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.81894  3.87477]
done:False
-------------------------
[19]>>[36]: env.step(2)
action:[3.5, 2.81894]
reward:0.28714123236418665
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.9387   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.73414  3.85195]
done:False
-------------------------
[19]>>[37]: env.step(5)
action:[3.5, 2.73414]
reward:0.274044549169656
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.9623   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.59421  3.87206]
done:False
-------------------------
[19]>>[38]: env.step(5)
action:[3.5, 2.59421]
reward:0.26412320919682586
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.054    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50743  3.88535]
done:False
-------------------------
[19]>>[39]: env.step(2)
action:[3.5, 2.50743]
reward:0.2470805695953143
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.1613   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.32056  3.89593]
done:False
-------------------------
[19]>>[40]: env.step(1)
action:[0, 2.32056]
reward:-0.5071663617628013
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      22.6801
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.31542  3.05477]
done:False
-------------------------
[19]>>[41]: env.step(3)
action:[0, 7.31542]
reward:0.329453790764359
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.7713  44.7552   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.13377  1.64225]
done:False
-------------------------
[19]>>[42]: env.step(3)
action:[0, 7.13377]
reward:0.366792291009592
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       20.7486
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.64555   0.495469]
done:False
-------------------------
[19]>>[43]: env.step(4)
action:[0, 1.322775]
reward:0.38176100748567904
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       18.2529   40.9761    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.28641   0.321748]
done:False
-------------------------
[19]>>[44]: env.step(3)
action:[0, 9.28641]
reward:0.6325451326125238
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       14.6178    0.       37.2897    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.56015   0.454195]
done:False
-------------------------
[19]>>[45]: env.step(0)
action:[-3.5, 5.56015]
reward:-0.1309332534851403
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.6786   0.      33.5394   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.3101  -1.56839]
done:False
-------------------------
[19]>>[46]: env.step(4)
action:[-3.5, 4.3101]
reward:0.49955293565271297
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2448   0.       0.      47.0227
 30.5713   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.04465 -3.63265]
done:False
-------------------------
[19]>>[47]: env.step(1)
action:[0, 5.04465]
reward:-0.2593544903715862
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.64162  0.       0.       0.
  0.      27.0192   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.74557 -3.00644]
done:False
-------------------------
[19]>>[48]: env.step(0)
action:[-3.5, 4.74557]
reward:-0.27693879286139655
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.54907  0.       0.       0.       0.       0.       0.
 40.0358  23.5647   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.59326 -2.99704]
done:False
-------------------------
[19]>>[49]: env.step(0)
action:[-3.5, 4.59326]
reward:0.4630172513687185
observation:
[ 0.       0.       0.       0.       0.       0.       7.25194  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      19.9554   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.50211 -2.96492]
done:False
-------------------------
[19]>>[50]: env.step(1)
action:[0, 4.50211]
reward:-0.279272373453055
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.70464  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      33.4497  17.04     0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.62407 -1.21547]
done:False
-------------------------
[19]>>[51]: env.step(4)
action:[0, 2.312035]
reward:0.3069201105460737
observation:
[ 0.       0.       0.       0.       0.       8.27994  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      31.554   15.3387   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10508  0.6391 ]
done:False
-------------------------
[19]>>[52]: env.step(1)
action:[0, 3.10508]
reward:0.28902834497288077
observation:
[ 0.        0.       10.1768    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.4824   13.286    49.5411    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.68586   0.635317]
done:False
-------------------------
[19]>>[53]: env.step(1)
action:[0, 2.68586]
reward:0.2708609264812965
observation:
[ 0.       12.0564    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.5371   11.3387    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.56718   0.611153]
done:False
-------------------------
[19]>>[54]: env.step(5)
action:[0, 2.56718]
reward:0.26137135120455235
observation:
[ 0.       13.8949    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       25.6605    9.45884   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.48046   0.612762]
done:False
-------------------------
[19]>>[55]: env.step(5)
action:[0, 2.48046]
reward:0.2494553532123392
observation:
[ 0.       15.6548    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       23.8778    7.67441   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.35632   0.613657]
done:False
-------------------------
[19]>>[56]: env.step(1)
action:[0, 2.35632]
reward:0.23497567030688288
observation:
[17.314     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.2041    6.00492   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.21065   0.618151]
done:False
-------------------------
[19]>>[57]: env.step(2)
action:[3.5, 2.21065]
reward:-0.5140098994501496
observation:
[ 0.       0.       0.      18.6431   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.6935   0.      40.9058   4.77133  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.25943  1.37832]
done:False
-------------------------
[19]>>[58]: env.step(1)
action:[0, 2.25943]
reward:-0.5253609943348369
observation:
[ 0.       0.       0.       0.       0.      19.4919   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      19.6362  40.1359
  0.       0.       4.52941  0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.10905  2.72071]
done:False
-------------------------
[19]>>[59]: env.step(3)
action:[0, 7.10905]
reward:0.3620848861335426
observation:
[ 0.       0.      21.0033   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.0743  38.7435   0.       0.
  0.       0.       4.05228  0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.59271  3.33445]
done:False
-------------------------
[19]>>[60]: env.step(0)
action:[-3.5, 2.59271]
reward:-0.3345367373825874
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.5502  36.1719   0.       0.       0.       0.       0.       0.
  0.       0.       3.16979  0.       0.       0.       0.       0.
  0.       0.      23.553    0.       4.39496  2.78131]
done:False
-------------------------
[19]>>[61]: env.step(1)
action:[0, 4.39496]
reward:-25.264593839095443
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.1823   0.      34.4439   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       2.70913  0.       0.       0.       0.
 25.1446   0.       0.       0.       4.84022  1.31702]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 85.1033, 'y': 1.31702, 'z': 0.570292}
.........................
** Rewards description :
count    61.000000
mean     -0.586898
std       3.263347
min     -25.264594
25%      -0.579072
50%       0.148389
75%       0.272251
max       0.632545
dtype: float64
#########################
[20]>> env.reset()
=========================
[20]>>[1]: env.step(4)
action:[0, 2.4101]
reward:0.09020510251829375
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.458026 -0.114634]
done:False
-------------------------
[20]>>[2]: env.step(2)
action:[3.5, 0.458026]
reward:-0.7011286440430443
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.45802  -0.439685]
done:False
-------------------------
[20]>>[3]: env.step(0)
action:[-3.5, 0.45802]
reward:-1.4511288565543314
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.458019 -0.731193]
done:False
-------------------------
[20]>>[4]: env.step(1)
action:[0, 0.458019]
reward:-0.6807497544550338
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.698188 -1.07399 ]
done:False
-------------------------
[20]>>[5]: env.step(3)
action:[0, 5.698188]
reward:0.25482639489178127
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.61757 -1.2139 ]
done:False
-------------------------
[20]>>[6]: env.step(3)
action:[0, 6.61757]
reward:0.4173121951533485
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.41222 -1.14396]
done:False
-------------------------
[20]>>[7]: env.step(2)
action:[3.5, 3.41222]
reward:-0.3623595390246684
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.83812  0.511105]
done:False
-------------------------
[20]>>[8]: env.step(1)
action:[0, 3.83812]
reward:-0.3622885487335995
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.73254 1.49388]
done:False
-------------------------
[20]>>[9]: env.step(5)
action:[0, 3.73254]
reward:0.36008074435594195
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.41173  0.366663]
done:False
-------------------------
[20]>>[10]: env.step(0)
action:[-3.5, 3.41173]
reward:-0.4046042032547208
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      49.7396   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.30832 -1.28731]
done:False
-------------------------
[20]>>[11]: env.step(1)
action:[0, 3.30832]
reward:-0.41025613391755456
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      48.6763   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.26367 -3.24316]
done:False
-------------------------
[20]>>[12]: env.step(5)
action:[0, 3.26367]
reward:0.32111356325746854
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 46.5941   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.04308 -3.59313]
done:False
-------------------------
[20]>>[13]: env.step(1)
action:[0, 3.04308]
reward:0.3011771530082447
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      44.5796   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.8513  -2.65387]
done:False
-------------------------
[20]>>[14]: env.step(2)
action:[3.5, 2.8513]
reward:-0.46837481065158015
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       43.2756    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.65813  -0.930444]
done:False
-------------------------
[20]>>[15]: env.step(5)
action:[3.5, 2.65813]
reward:0.24933814546624763
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.709     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.31047   0.871015]
done:False
-------------------------
[20]>>[16]: env.step(3)
action:[3.5, 7.3104700000000005]
reward:0.36718965296013195
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.344    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.60636  2.60852]
done:False
-------------------------
[20]>>[17]: env.step(5)
action:[3.5, 2.60636]
reward:0.3279623924782507
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      41.3701
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.29249  4.53058]
done:False
-------------------------
[20]>>[18]: env.step(0)
action:[-3.5, 3.29249]
reward:-1.1731290319066794
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      39.3408   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10739  5.29163]
done:False
-------------------------
[20]>>[19]: env.step(1)
action:[0, 3.10739]
reward:-0.4363596609672347
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 37.0857   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.98946  4.56507]
done:False
-------------------------
[20]>>[20]: env.step(1)
action:[0, 2.98946]
reward:0.287364431574602
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.133    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.69426  3.89192]
done:False
-------------------------
[20]>>[21]: env.step(4)
action:[0, 1.34713]
reward:0.24654476606892017
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.1513   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.60409  3.81358]
done:False
-------------------------
[20]>>[22]: env.step(4)
action:[0, 1.302045]
reward:0.17910680310694843
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      32.0338   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.79727  2.9383 ]
done:False
-------------------------
[20]>>[23]: env.step(4)
action:[0, 0.898635]
reward:0.17130454998108874
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      31.3595   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.80418  1.86825]
done:False
-------------------------
[20]>>[24]: env.step(2)
action:[3.5, 1.80418]
reward:-0.5599167681913022
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       30.6727    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.80414   0.771743]
done:False
-------------------------
[20]>>[25]: env.step(5)
action:[3.5, 1.80414]
reward:0.2067670140635458
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 29.4342    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.00595   0.284504]
done:False
-------------------------
[20]>>[26]: env.step(2)
action:[3.5, 2.00595]
reward:0.21523001152365473
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       27.9897    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.05812   0.391355]
done:False
-------------------------
[20]>>[27]: env.step(5)
action:[3.5, 2.05812]
reward:0.2162872576410102
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.5904  49.4856   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05791  1.12095]
done:False
-------------------------
[20]>>[28]: env.step(4)
action:[3.5, 1.028955]
reward:0.19403460649141757
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      25.5237   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04568  2.33887]
done:False
-------------------------
[20]>>[29]: env.step(3)
action:[3.5, 7.04568]
reward:0.35069271220018905
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      24.4277  47.5678
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.46599  3.63079]
done:False
-------------------------
[20]>>[30]: env.step(5)
action:[3.5, 2.46599]
reward:0.3106997144440038
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      22.3609   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.11338  3.98493]
done:False
-------------------------
[20]>>[31]: env.step(2)
action:[3.5, 3.11338]
reward:0.30626678265611296
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.1569   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.89666  3.9423 ]
done:False
-------------------------
[20]>>[32]: env.step(1)
action:[0, 2.89666]
reward:-0.45614642965846564
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.0294   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.79747  3.9331 ]
done:False
-------------------------
[20]>>[33]: env.step(1)
action:[0, 2.79747]
reward:0.291406318136767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      16.2554  39.386
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.79208  2.92704]
done:False
-------------------------
[20]>>[34]: env.step(3)
action:[0, 7.79208]
reward:0.3966068976412832
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      15.2386   0.      38.1181   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.85632  1.16731]
done:False
-------------------------
[20]>>[35]: env.step(2)
action:[3.5, 2.85632]
reward:-0.3970690175548159
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       13.2687   35.9105    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.54131   0.347191]
done:False
-------------------------
[20]>>[36]: env.step(2)
action:[3.5, 3.54131]
reward:0.36159206998315924
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      10.7801  33.5605   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.47847  1.28557]
done:False
-------------------------
[20]>>[37]: env.step(3)
action:[3.5, 8.47847]
reward:0.43288356930643673
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       9.05383 32.2302
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.14513  3.37442]
done:False
-------------------------
[20]>>[38]: env.step(0)
action:[-3.5, 3.14513]
reward:-1.1733921241976732
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.94573 30.2332   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.14096  4.07891]
done:False
-------------------------
[20]>>[39]: env.step(3)
action:[-3.5, 8.14096]
reward:0.4424224348742601
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       4.66214
 27.8705   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.35127  3.15826]
done:False
-------------------------
[20]>>[40]: env.step(2)
action:[3.5, 3.35127]
reward:-1.0211183585959533
observation:
[ 0.        0.        0.        0.        0.        0.        4.1867
  0.        0.        0.       42.1849   26.0228    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.01688   0.489939]
done:False
-------------------------
[20]>>[41]: env.step(3)
action:[3.5, 10.01688]
reward:0.6839121120665076
observation:
[ 0.       0.       0.       7.26217  0.       0.       0.       0.
  0.       0.      25.2863   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.07721 -3.54049]
done:False
-------------------------
[20]>>[42]: env.step(4)
action:[3.5, 4.07721]
reward:0.674372867679029
observation:
[ 0.       0.       0.       0.       0.       0.       0.       9.34629
  0.       0.       0.       0.       0.       0.       0.       0.
 21.3719   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.43126 -5.5941 ]
done:False
-------------------------
[20]>>[43]: env.step(3)
action:[3.5, 12.43126]
reward:0.8714300520113463
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       8.33902  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      33.2365
 16.7746   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.14711 -1.93298]
done:False
-------------------------
[20]>>[44]: env.step(1)
action:[0, 8.14711]
reward:0.09211857616026486
observation:
[ 0.       0.       0.       9.27271  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      29.8053   0.      14.1805   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.78604  3.26264]
done:False
-------------------------
[20]>>[45]: env.step(3)
action:[0, 13.78604]
reward:0.9303173383840123
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      23.9807  44.2959   8.12643
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.2545   0.       0.       0.       8.69562  1.83341]
done:False
-------------------------
[20]>>[46]: env.step(2)
action:[3.5, 8.69562]
reward:-24.85682763920498
observation:
[19.4143    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.3229    3.92659  40.1844    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.4055   -0.109794]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.9182, 'y': -0.109794, 'z': 0.57089}
.........................
** Rewards description :
count    46.000000
mean     -0.529658
std       3.706979
min     -24.856828
25%      -0.408843
50%       0.215759
75%       0.345010
max       0.930317
dtype: float64
#########################
[21]>> env.reset()
=========================
[21]>>[1]: env.step(5)
action:[0, 10.7325]
reward:0.4728541512429705
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.09386  0.269063]
done:False
-------------------------
[21]>>[2]: env.step(4)
action:[0, 1.54693]
reward:0.5109181252224704
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.88315  0.207918]
done:False
-------------------------
[21]>>[3]: env.step(2)
action:[3.5, 5.88315]
reward:-0.012290486346530738
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       7.85717  0.243777]
done:False
-------------------------
[21]>>[4]: env.step(4)
action:[3.5, 5.85717]
reward:0.8073498981172804
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.7092    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.8534    0.283334]
done:False
-------------------------
[21]>>[5]: env.step(3)
action:[3.5, 13.8534]
reward:0.9913321049685289
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      38.6693   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.62859  3.2076 ]
done:False
-------------------------
[21]>>[6]: env.step(3)
action:[3.5, 14.62859]
reward:1.0779028845703702
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.4347   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.8474   4.00232]
done:False
-------------------------
[21]>>[7]: env.step(0)
action:[-3.5, 10.8474]
reward:-0.4376254362968637
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        24.9104    47.6198
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 11.5329    -0.0697821]
done:False
-------------------------
[21]>>[8]: env.step(4)
action:[-3.5, 9.5329]
reward:1.0404654622927576
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.6755
 41.898    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.5     -5.53832]
done:False
-------------------------
[21]>>[9]: env.step(1)
action:[0, 11.5]
reward:0.30926572253603957
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       12.5067   34.9437    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.3181   -0.261728]
done:False
-------------------------
[21]>>[10]: env.step(2)
action:[3.5, 11.3181]
reward:0.29600666098508177
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.0345   5.72942  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.1446   4.9118 ]
done:False
-------------------------
[21]>>[11]: env.step(0)
action:[-3.5, 11.1446]
reward:-25.462480012982887
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 42.4647  26.8576   3.58747  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.0489   4.80124]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.391, 'y': 4.80124, 'z': 0.56867}
.........................
** Rewards description :
count    11.000000
mean     -1.855118
std       7.843598
min     -25.462480
25%       0.141858
50%       0.472854
75%       0.899341
max       1.077903
dtype: float64
#########################
[22]>> env.reset()
=========================
[22]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.634789330957924
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.35755  -0.482283]
done:False
-------------------------
[22]>>[2]: env.step(2)
action:[3.5, 1.35755]
reward:-1.3518050508130033
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.41203  -0.178232]
done:False
-------------------------
[22]>>[3]: env.step(5)
action:[3.5, 1.41203]
reward:0.09490046814536413
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.763209 0.574405]
done:False
-------------------------
[22]>>[4]: env.step(1)
action:[0, 0.763209]
reward:-0.6560155307096525
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.914551 0.480309]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.00285, 'y': 0.480309, 'z': 0.570224}
.........................
** Rewards description :
count    4.000000
mean    -0.636927
std      0.590760
min     -1.351805
25%     -0.829963
50%     -0.645402
75%     -0.452367
max      0.094900
dtype: float64
#########################
[23]>> env.reset()
=========================
[23]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.03810038318723841
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.445934 0.499596]
done:False
-------------------------
[23]>>[2]: env.step(1)
action:[0, 0.445934]
reward:0.04614317030449325
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.428956 0.82691 ]
done:False
-------------------------
[23]>>[3]: env.step(1)
action:[0, 0.428956]
reward:0.08835658660349921
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.93141  0.752034]
done:False
-------------------------
[23]>>[4]: env.step(2)
action:[3.5, 0.93141]
reward:-0.6126212419459072
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.38914 1.04036]
done:False
-------------------------
[23]>>[5]: env.step(3)
action:[3.5, 6.38914]
reward:0.2647987406775089
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.56698 1.91444]
done:False
-------------------------
[23]>>[6]: env.step(0)
action:[-3.5, 1.56698]
reward:-1.1975724527594624
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.23578 3.38665]
done:False
-------------------------
[23]>>[7]: env.step(0)
action:[-3.5, 3.23578]
reward:0.38588554333294744
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.86011 3.88728]
done:False
-------------------------
[23]>>[8]: env.step(2)
action:[3.5, 3.86011]
reward:-1.120165360317637
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.62783 3.79167]
done:False
-------------------------
[23]>>[9]: env.step(1)
action:[0, 3.62783]
reward:-0.38904169157204493
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.4489  3.73153]
done:False
-------------------------
[23]>>[10]: env.step(3)
action:[0, 8.4489]
reward:0.47724741352717565
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      47.8758   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.72139  2.43704]
done:False
-------------------------
[23]>>[11]: env.step(5)
action:[0, 3.72139]
reward:0.42572534638869974
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       46.1597
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.24322   0.145826]
done:False
-------------------------
[23]>>[12]: env.step(2)
action:[3.5, 4.24322]
reward:-0.3397105878821624
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.2184    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.9167    0.207755]
done:False
-------------------------
[23]>>[13]: env.step(5)
action:[3.5, 3.9167]
reward:0.389299491061404
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      40.3871   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.73292  0.33429]
done:False
-------------------------
[23]>>[14]: env.step(4)
action:[3.5, 1.86646]
reward:0.33958703617882335
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.6448    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.62218   0.331896]
done:False
-------------------------
[23]>>[15]: env.step(0)
action:[-3.5, 3.62218]
reward:-1.1196538133593057
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       35.4692
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.69375  -0.954893]
done:False
-------------------------
[23]>>[16]: env.step(4)
action:[-3.5, 1.846875]
reward:0.25103369604425274
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      34.5248   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.53401 -2.79277]
done:False
-------------------------
[23]>>[17]: env.step(5)
action:[-3.5, 2.53401]
reward:0.24860251439022996
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.0042   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.33251 -3.24564]
done:False
-------------------------
[23]>>[18]: env.step(2)
action:[3.5, 2.33251]
reward:-1.2725524912000743
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.4228   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.12494 -3.20776]
done:False
-------------------------
[23]>>[19]: env.step(5)
action:[3.5, 2.12494]
reward:0.2154728706332834
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 29.8061   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03132 -3.15912]
done:False
-------------------------
[23]>>[20]: env.step(3)
action:[3.5, 7.03132]
reward:0.3620783023260046
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      28.2168   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.61206 -2.37327]
done:False
-------------------------
[23]>>[21]: env.step(4)
action:[3.5, 1.30603]
reward:0.2040509993295918
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       27.032    49.6231    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09758  -0.911453]
done:False
-------------------------
[23]>>[22]: env.step(1)
action:[0, 2.09758]
reward:-0.5447510806918164
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.4406   49.2321    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.9142    0.551731]
done:False
-------------------------
[23]>>[23]: env.step(1)
action:[0, 1.9142]
reward:0.20069310720660688
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      26.0413   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90489  1.97099]
done:False
-------------------------
[23]>>[24]: env.step(2)
action:[3.5, 1.90489]
reward:-0.5494273387355008
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.7193  48.8263   0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90576  3.37744]
done:False
-------------------------
[23]>>[25]: env.step(1)
action:[0, 1.90576]
reward:-0.5353828538940282
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.8412
 48.0416   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07573  4.50126]
done:False
-------------------------
[23]>>[26]: env.step(2)
action:[3.5, 2.07573]
reward:-0.5320948708163518
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      23.5736   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07315  5.10286]
done:False
-------------------------
[23]>>[27]: env.step(4)
action:[3.5, 1.036575]
reward:0.1659569777074696
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      22.3053   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.70539  5.07946]
done:False
-------------------------
[23]>>[28]: env.step(5)
action:[3.5, 1.70539]
reward:0.1923412129732165
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.0567   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.85611  4.59822]
done:False
-------------------------
[23]>>[29]: env.step(5)
action:[3.5, 1.85611]
reward:0.19343372314054236
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 19.6764  42.8976   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.83163  4.09029]
done:False
-------------------------
[23]>>[30]: env.step(2)
action:[3.5, 1.83163]
reward:0.19741193739866475
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      18.2835   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.88584  3.94117]
done:False
-------------------------
[23]>>[31]: env.step(2)
action:[3.5, 1.88584]
reward:0.19965011064236138
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.8614  40.079    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.89936  3.91758]
done:False
-------------------------
[23]>>[32]: env.step(3)
action:[3.5, 6.89936]
reward:0.3407296394720313
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.3266   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.3782   3.92796]
done:False
-------------------------
[23]>>[33]: env.step(0)
action:[-3.5, 2.3782]
reward:-1.1118253570562766
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.8178   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.10336  3.95304]
done:False
-------------------------
[23]>>[34]: env.step(4)
action:[-3.5, 2.05168]
reward:0.28417815244228706
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.7655  33.8976
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88946  2.79149]
done:False
-------------------------
[23]>>[35]: env.step(4)
action:[-3.5, 1.44473]
reward:0.21020330768993056
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.2302  49.1233  33.0445   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.13745  1.1398 ]
done:False
-------------------------
[23]>>[36]: env.step(3)
action:[-3.5, 7.137449999999999]
reward:0.31260694072804107
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.       10.3058    0.       32.6555    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.96914  -0.354622]
done:False
-------------------------
[23]>>[37]: env.step(2)
action:[3.5, 1.96914]
reward:-1.278372096844109
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       9.91819  0.      31.7348   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.14502 -1.44025]
done:False
-------------------------
[23]>>[38]: env.step(5)
action:[3.5, 2.14502]
reward:0.22132918080386155
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.10113  0.       0.      46.7692  30.4185
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09742 -1.95325]
done:False
-------------------------
[23]>>[39]: env.step(1)
action:[0, 2.09742]
reward:-0.5324866777862562
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       7.8473   0.       0.
  0.      28.8456   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06297 -1.76972]
done:False
-------------------------
[23]>>[40]: env.step(2)
action:[3.5, 2.06297]
reward:-0.5337248933289571
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.43738   0.        0.        0.       43.8178   27.5034
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.05655  -0.970361]
done:False
-------------------------
[23]>>[41]: env.step(1)
action:[0, 2.05655]
reward:-0.5468954839905105
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         5.01549    0.
  0.         0.        42.6445    26.406      0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.89849    0.0563402]
done:False
-------------------------
[23]>>[42]: env.step(1)
action:[0, 1.89849]
reward:0.20831827059574715
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  3.80566   0.        0.        0.        0.       41.2594   25.0643
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.00116   0.481699]
done:False
-------------------------
[23]>>[43]: env.step(5)
action:[0, 2.00116]
reward:0.20504952673492816
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        3.10945   0.        0.
  0.        0.        0.        0.       39.8231   23.6412    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.93589   0.561511]
done:False
-------------------------
[23]>>[44]: env.step(1)
action:[0, 1.93589]
reward:0.20105690663622205
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  3.10496   0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.4033   22.2228    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90387   0.561355]
done:False
-------------------------
[23]>>[45]: env.step(4)
action:[0, 0.951935]
reward:0.18053507627813176
observation:
[ 0.        0.        0.        0.        0.        3.72372   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.9821   20.7992    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90201   0.552734]
done:False
-------------------------
[23]>>[46]: env.step(1)
action:[0, 1.90201]
reward:0.20022225663038307
observation:
[ 0.        0.        0.        4.71084   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.5604   19.3743    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90224   0.551115]
done:False
-------------------------
[23]>>[47]: env.step(0)
action:[-3.5, 1.90224]
reward:-0.5322136655453215
observation:
[ 0.        6.11149   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       18.0338    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.11508  -0.115679]
done:False
-------------------------
[23]>>[48]: env.step(0)
action:[-3.5, 2.11508]
reward:0.21834301849995544
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      33.4797  17.0872   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.54624  2.06863 -1.34044]
done:False
-------------------------
[23]>>[49]: env.step(0)
action:[-3.5, 2.06863]
reward:0.2058617023514111
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.2584   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.03404  1.92886 -2.59422]
done:False
-------------------------
[23]>>[50]: env.step(2)
action:[3.5, 1.92886]
reward:-1.2880737666882227
observation:
[ 0.      10.4214   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      14.9522   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03731 -2.98536]
done:False
-------------------------
[23]>>[51]: env.step(0)
action:[-3.5, 2.03731]
reward:-1.296216574658057
observation:
[ 0.       0.      11.6452   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      30.0981
 13.5576  49.3925   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.91152 -2.98456]
done:False
-------------------------
[23]>>[52]: env.step(2)
action:[3.5, 1.91152]
reward:-1.299530019634654
observation:
[ 0.       0.      12.8621   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.1612  47.9648   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90286 -2.95303]
done:False
-------------------------
[23]>>[53]: env.step(4)
action:[3.5, 0.95143]
reward:0.1596017258421971
observation:
[ 0.       0.       0.       0.      13.6022   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.001    0.      46.8897   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.65034 -2.39366]
done:False
-------------------------
[23]>>[54]: env.step(1)
action:[0, 1.65034]
reward:-0.5616544572943363
observation:
[ 0.       0.       0.       0.       0.      14.0933   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.98044  0.      46.026    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.82162 -1.48069]
done:False
-------------------------
[23]>>[55]: env.step(1)
action:[0, 1.82162]
reward:0.18955155222022008
observation:
[ 0.        0.        0.        0.        0.        0.       14.4141
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.17026  45.3744    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.79336  -0.282014]
done:False
-------------------------
[23]>>[56]: env.step(1)
action:[0, 1.79336]
reward:0.2128491967354346
observation:
[ 0.        0.        0.        0.       15.2501    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 24.3835    8.11422   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.08238   0.553045]
done:False
-------------------------
[23]>>[57]: env.step(0)
action:[-3.5, 2.08238]
reward:-0.5344101327960374
observation:
[ 0.        0.       16.6275    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       22.9176   42.9542    6.69688
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04338   0.654256]
done:False
-------------------------
[23]>>[58]: env.step(2)
action:[3.5, 2.04338]
reward:-1.2669659801536497
observation:
[ 0.       0.       0.       0.      17.6642   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      21.6651  41.8843   5.71563
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26523  1.47002]
done:False
-------------------------
[23]>>[59]: env.step(2)
action:[3.5, 2.26523]
reward:0.21074888641923017
observation:
[ 0.       0.       0.       0.       0.      18.3403   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.7724
 41.2908   0.       5.55003  0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.93894  2.91132]
done:False
-------------------------
[23]>>[60]: env.step(4)
action:[3.5, 0.96947]
reward:0.1642114078894651
observation:
[ 0.       0.       0.       0.       0.      19.1068   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      19.9637
 40.6877   0.       0.       5.56039  0.       0.       0.       0.
  0.       0.       0.       0.       1.70119  3.91523]
done:False
-------------------------
[23]>>[61]: env.step(1)
action:[0, 1.70119]
reward:-0.5594975508348308
observation:
[ 0.       0.      20.328    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.7569  39.5891   0.       0.
  0.       0.       5.1828   0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.83495  4.28046]
done:False
-------------------------
[23]>>[62]: env.step(0)
action:[-3.5, 1.83495]
reward:-0.544832611889936
observation:
[21.714    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.3716  38.236    0.       0.       0.       0.
  0.       4.63423  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.97887  4.17446]
done:False
-------------------------
[23]>>[63]: env.step(4)
action:[-3.5, 0.989435]
reward:0.1642148411457257
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 16.2026  37.0017   0.       0.       0.       0.       0.       0.
  0.       3.98314  0.       0.       0.       0.       0.       0.
  0.       0.      22.8679   0.       1.69624  3.57653]
done:False
-------------------------
[23]>>[64]: env.step(3)
action:[-3.5, 6.6962399999999995]
reward:0.3285527392629936
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      15.2077   0.      35.8209
  0.       0.       0.       0.       0.       0.       0.       0.
  3.19159  0.       0.       0.       0.       0.       0.       0.
 23.9009   0.       0.       0.       2.27736  2.5632 ]
done:False
-------------------------
[23]>>[65]: env.step(2)
action:[3.5, 2.27736]
reward:-1.2196373921724275
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.5285   0.      34.0376   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       3.67077  0.
  0.       0.       0.      25.6426   2.78608  2.13969]
done:False
-------------------------
[23]>>[66]: env.step(0)
action:[-3.5, 2.78608]
reward:-1.2139055132443408
observation:
[ 0.       0.      27.4618   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      11.6383   0.      32.357    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       5.498    0.       2.72946  2.93415]
done:False
-------------------------
[23]>>[67]: env.step(5)
action:[-3.5, 2.72946]
reward:0.2772512174500148
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.84169  0.      30.5835   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.01626  0.       0.      29.2674   2.63479  2.8183 ]
done:False
-------------------------
[23]>>[68]: env.step(0)
action:[-3.5, 2.63479]
reward:0.2649506352678104
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.55885  0.      28.9449
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.99638  0.
 30.7582   0.       0.       0.       2.50743  1.62317]
done:False
-------------------------
[23]>>[69]: env.step(1)
action:[0, 2.50743]
reward:-0.5128617671583928
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        7.31843
  0.        0.       27.2826    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        9.33871   0.       32.3454
  0.        2.19923   0.815844]
done:False
-------------------------
[23]>>[70]: env.step(2)
action:[3.5, 2.19923]
reward:-0.5210699625507069
observation:
[33.8722    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.88827   0.        0.       49.5427   25.7848    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 10.8679    2.1763    0.974648]
done:False
-------------------------
[23]>>[71]: env.step(4)
action:[3.5, 1.08815]
reward:0.177595013465796
observation:
[ 0.      12.136   35.0215   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       4.54639  0.       0.      48.422   24.751    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.83253  1.72259]
done:False
-------------------------
[23]>>[72]: env.step(5)
action:[3.5, 1.83253]
reward:-24.807205614945993
observation:
[ 0.      12.2852  35.1471   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.37772  0.       0.      24.6495   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8298   1.85551]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 95.3093, 'y': 1.85551, 'z': 0.570054}
.........................
** Rewards description :
count    72.000000
mean     -0.535424
std       2.955371
min     -24.807206
25%      -0.545348
50%       0.165086
75%       0.213505
max       0.477247
dtype: float64
#########################
[24]>> env.reset()
=========================
[24]>>[1]: env.step(0)
action:[-3.5, 1.83877]
reward:-25.555953498622532
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.84337 2.06483]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 95.4883, 'y': 2.06483, 'z': 0.570037}
.........................
** Rewards description :
count     1.000000
mean    -25.555953
std            NaN
min     -25.555953
25%     -25.555953
50%     -25.555953
75%     -25.555953
max     -25.555953
dtype: float64
#########################
[25]>> env.reset()
=========================
[25]>>[1]: env.step(4)
action:[0, 0.3495055]
reward:0.06310416103085892
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.652794 0.628307]
done:False
-------------------------
[25]>>[2]: env.step(1)
action:[0, 0.652794]
reward:0.10126603708929391
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.02856  0.248779]
done:False
-------------------------
[25]>>[3]: env.step(3)
action:[0, 6.02856]
reward:0.2760492804940162
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.79524  0.291423]
done:False
-------------------------
[25]>>[4]: env.step(4)
action:[0, 0.89762]
reward:0.15043585457387237
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.55386  0.246246]
done:False
-------------------------
[25]>>[5]: env.step(1)
action:[0, 1.55386]
reward:0.17650138314765534
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.70293  0.232949]
done:False
-------------------------
[25]>>[6]: env.step(5)
action:[0, 1.70293]
reward:0.18897653845508625
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.81609  0.228507]
done:False
-------------------------
[25]>>[7]: env.step(3)
action:[0, 6.81609]
reward:0.33147053758604095
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.28369  0.232014]
done:False
-------------------------
[25]>>[8]: env.step(1)
action:[0, 2.28369]
reward:0.2882934327798452
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.88215  0.243021]
done:False
-------------------------
[25]>>[9]: env.step(1)
action:[0, 2.88215]
reward:0.2938116284626273
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.7056    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.80058   0.260487]
done:False
-------------------------
[25]>>[10]: env.step(0)
action:[-3.5, 2.80058]
reward:-0.4541490639060185
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 47.9825    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.84614  -0.801652]
done:False
-------------------------
[25]>>[11]: env.step(2)
action:[3.5, 2.84614]
reward:-1.2165857608679902
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.1173    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.68144  -0.930328]
done:False
-------------------------
[25]>>[12]: env.step(5)
action:[3.5, 2.68144]
reward:0.27551959764293266
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       44.3896
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.62551   0.122581]
done:False
-------------------------
[25]>>[13]: env.step(3)
action:[3.5, 7.62551]
reward:0.39299996961572115
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      43.3082
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.85241  1.87965]
done:False
-------------------------
[25]>>[14]: env.step(4)
action:[3.5, 1.426205]
reward:0.2166176907863877
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      42.4435
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.2199   3.53954]
done:False
-------------------------
[25]>>[15]: env.step(4)
action:[3.5, 1.10995]
reward:0.1686881071838603
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.2562   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.71988  4.03625]
done:False
-------------------------
[25]>>[16]: env.step(0)
action:[-3.5, 1.71988]
reward:-1.317038189359865
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.0205   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.73928  4.09378]
done:False
-------------------------
[25]>>[17]: env.step(0)
action:[-3.5, 1.73928]
reward:0.19707392368143545
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.7456   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90484  3.68633]
done:False
-------------------------
[25]>>[18]: env.step(2)
action:[3.5, 1.90484]
reward:-1.3070071838871378
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.4299   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.81412  3.90413]
done:False
-------------------------
[25]>>[19]: env.step(5)
action:[3.5, 1.81412]
reward:0.19559838838918736
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.9611   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.86829  3.92415]
done:False
-------------------------
[25]>>[20]: env.step(3)
action:[3.5, 6.86829]
reward:0.34019326683189965
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.4374   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.37928  3.89963]
done:False
-------------------------
[25]>>[21]: env.step(3)
action:[3.5, 7.37928]
reward:0.4921923665786486
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.9168   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.18194  3.8681 ]
done:False
-------------------------
[25]>>[22]: env.step(2)
action:[3.5, 4.18194]
reward:0.4853670924880138
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.4164   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.89297  3.8685 ]
done:False
-------------------------
[25]>>[23]: env.step(1)
action:[0, 4.89297]
reward:-0.25590213701919823
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.7694   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.8282   3.88837]
done:False
-------------------------
[25]>>[24]: env.step(2)
action:[3.5, 4.8282]
reward:-0.2639780825474932
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.1869   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73987  3.91063]
done:False
-------------------------
[25]>>[25]: env.step(1)
action:[0, 4.73987]
reward:-0.2554340689360706
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      18.2384   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.87254  2.24273]
done:False
-------------------------
[25]>>[26]: env.step(5)
action:[0, 4.87254]
reward:0.49776304921406095
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        16.1262    38.744      0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.88082   -0.0750102]
done:False
-------------------------
[25]>>[27]: env.step(4)
action:[0, 2.44041]
reward:0.4190473280363203
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       12.7567   35.3779    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.47855   0.495176]
done:False
-------------------------
[25]>>[28]: env.step(0)
action:[-3.5, 4.47855]
reward:-0.2991716977247335
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.57804  48.2473   32.0815    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.37442   0.499716]
done:False
-------------------------
[25]>>[29]: env.step(4)
action:[-3.5, 2.18721]
reward:0.2785148484908202
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        8.03591   0.       46.1378
 29.8705    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.78589  -0.754401]
done:False
-------------------------
[25]>>[30]: env.step(5)
action:[-3.5, 2.78589]
reward:0.2720293886109266
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  8.14462  0.       0.       0.      28.806    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.55652 -2.46337]
done:False
-------------------------
[25]>>[31]: env.step(0)
action:[-3.5, 2.55652]
reward:0.2744340072746948
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       7.63698  0.       0.       0.       0.      27.1251
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.6434  -3.11005]
done:False
-------------------------
[25]>>[32]: env.step(2)
action:[3.5, 2.6434]
reward:-1.2302962176844952
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.58112  0.       0.       0.       0.
  0.       0.      25.2762   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.56359 -2.66814]
done:False
-------------------------
[25]>>[33]: env.step(2)
action:[3.5, 2.56359]
reward:0.2579833332051256
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       5.15741  0.       0.
  0.       0.       0.       0.       0.      23.8243   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.43986 -1.40008]
done:False
-------------------------
[25]>>[34]: env.step(3)
action:[3.5, 7.4398599999999995]
reward:0.3449168873320969
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.52366   0.        0.        0.        0.        0.
  0.        0.       39.3662   23.1304    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.29531   0.287028]
done:False
-------------------------
[25]>>[35]: env.step(5)
action:[3.5, 2.29531]
reward:-24.777522730056077
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.90943   0.        0.        0.        0.        0.
  0.        0.        0.       39.1658   22.9981    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.0738    0.924147]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 60.0292, 'y': 0.924147, 'z': 0.569544}
.........................
** Rewards description :
count    35.000000
mean     -0.697092
std       4.222217
min     -24.777523
25%      -0.255668
50%       0.197074
75%       0.291053
max       0.497763
dtype: float64
#########################
[26]>> env.reset()
=========================
[26]>>[1]: env.step(4)
action:[0, 1.03292]
reward:0.07567367467394678
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.630342 0.360009]
done:False
-------------------------
[26]>>[2]: env.step(4)
action:[0, 0.315171]
reward:0.07907603148571063
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.850006 0.230824]
done:False
-------------------------
[26]>>[3]: env.step(2)
action:[3.5, 0.850006]
reward:-0.6193448407961868
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.32917  0.579683]
done:False
-------------------------
[26]>>[4]: env.step(1)
action:[0, 1.32917]
reward:-0.575599978851185
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.7338   0.440168]
done:False
-------------------------
[26]>>[5]: env.step(1)
action:[0, 1.7338]
reward:0.17694683369100822
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.66331  0.347326]
done:False
-------------------------
[26]>>[6]: env.step(3)
action:[0, 6.66331]
reward:0.2862736964003543
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.76236  0.276846]
done:False
-------------------------
[26]>>[7]: env.step(5)
action:[0, 1.76236]
reward:0.1928256296686252
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.84772  0.245317]
done:False
-------------------------
[26]>>[8]: env.step(1)
action:[0, 1.84772]
reward:0.19797028219814017
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.88857  0.235929]
done:False
-------------------------
[26]>>[9]: env.step(1)
action:[0, 1.88857]
reward:0.19969412418687402
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.89921  0.235689]
done:False
-------------------------
[26]>>[10]: env.step(2)
action:[3.5, 1.89921]
reward:-0.5354411573135103
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.07666  0.970209]
done:False
-------------------------
[26]>>[11]: env.step(3)
action:[3.5, 7.07666]
reward:0.3549142937677454
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      49.5204   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.51103  2.27505]
done:False
-------------------------
[26]>>[12]: env.step(2)
action:[3.5, 2.51103]
reward:0.31129073843017224
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      48.0604   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10944  3.78262]
done:False
-------------------------
[26]>>[13]: env.step(0)
action:[-3.5, 3.10944]
reward:-1.1931799989759324
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.9486   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.90449  3.77987]
done:False
-------------------------
[26]>>[14]: env.step(0)
action:[-3.5, 2.90449]
reward:0.28681392160354613
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      44.2287
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.70872  2.66272]
done:False
-------------------------
[26]>>[15]: env.step(5)
action:[-3.5, 2.70872]
reward:0.26675362693583793
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       43.3717    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.51106   0.940472]
done:False
-------------------------
[26]>>[16]: env.step(4)
action:[-3.5, 1.25553]
reward:0.2175757086948289
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.0952    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.2742   -0.800988]
done:False
-------------------------
[26]>>[17]: env.step(2)
action:[3.5, 2.2742]
reward:-1.2615049920858945
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      42.2243   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.27408 -1.98445]
done:False
-------------------------
[26]>>[18]: env.step(1)
action:[0, 2.27408]
reward:-0.5195778214790185
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      40.8806   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.17575 -2.47032]
done:False
-------------------------
[26]>>[19]: env.step(2)
action:[3.5, 2.17575]
reward:-0.5308469784487644
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.3061   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.0633  -2.20579]
done:False
-------------------------
[26]>>[20]: env.step(2)
action:[3.5, 2.0633]
reward:0.21354120356582612
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      37.9655   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02329 -1.36393]
done:False
-------------------------
[26]>>[21]: env.step(2)
action:[3.5, 2.02329]
reward:0.21486539149526201
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        36.9542     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.04936   -0.0765307]
done:False
-------------------------
[26]>>[22]: env.step(5)
action:[3.5, 2.04936]
reward:0.20522538892178388
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.3857   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92597  1.38467]
done:False
-------------------------
[26]>>[23]: env.step(4)
action:[3.5, 0.962985]
reward:0.1512044787502698
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      36.0254   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.54673  2.58655]
done:False
-------------------------
[26]>>[24]: env.step(1)
action:[0, 1.54673]
reward:-0.5860536879628783
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.5916   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.55369  3.65513]
done:False
-------------------------
[26]>>[25]: env.step(1)
action:[0, 1.55369]
reward:0.17678679975845213
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      34.6763   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.70641  4.3463 ]
done:False
-------------------------
[26]>>[26]: env.step(5)
action:[0, 1.70641]
reward:0.19644145663888146
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      33.4566   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90541  4.72072]
done:False
-------------------------
[26]>>[27]: env.step(3)
action:[0, 6.90541]
reward:0.3420866179173918
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.9657   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.39361  4.56134]
done:False
-------------------------
[26]>>[28]: env.step(4)
action:[0, 1.196805]
reward:0.1876004442839585
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      30.6054
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92601  3.7008 ]
done:False
-------------------------
[26]>>[29]: env.step(5)
action:[0, 1.92601]
reward:0.2093256374628457
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.6848   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00649  2.40346]
done:False
-------------------------
[26]>>[30]: env.step(5)
action:[0, 2.00649]
reward:0.2016055513774749
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.064    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.89286  1.10335]
done:False
-------------------------
[26]>>[31]: env.step(2)
action:[3.5, 1.89286]
reward:-0.5324924429134114
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       27.9861
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.11404   0.299294]
done:False
-------------------------
[26]>>[32]: env.step(5)
action:[3.5, 2.11404]
reward:0.21844347845630296
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       26.5724   49.3693    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.07011   0.172218]
done:False
-------------------------
[26]>>[33]: env.step(4)
action:[3.5, 1.035055]
reward:0.16132635896186465
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.3361   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.65014  0.58601]
done:False
-------------------------
[26]>>[34]: env.step(3)
action:[3.5, 6.65014]
reward:0.3247201120527399
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      24.141   47.0593   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.24125  1.42237]
done:False
-------------------------
[26]>>[35]: env.step(3)
action:[3.5, 7.24125]
reward:0.47007710277022596
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      22.6335
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.93091  3.39638]
done:False
-------------------------
[26]>>[36]: env.step(2)
action:[3.5, 3.93091]
reward:0.4600121632065961
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.641   42.8592   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.6291   4.20759]
done:False
-------------------------
[26]>>[37]: env.step(1)
action:[0, 4.6291]
reward:-0.2972868511118684
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.3508   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.36093  3.96868]
done:False
-------------------------
[26]>>[38]: env.step(0)
action:[-3.5, 4.36093]
reward:-0.2888987315628637
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      13.5996  36.6627   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.53558  2.40516]
done:False
-------------------------
[26]>>[39]: env.step(5)
action:[-3.5, 4.53558]
reward:0.4375106835119831
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.       13.3194    0.       35.5991    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.18988  -0.972025]
done:False
-------------------------
[26]>>[40]: env.step(2)
action:[3.5, 4.18988]
reward:-1.0646533529876836
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.5436   0.      33.791    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24869 -3.19493]
done:False
-------------------------
[26]>>[41]: env.step(1)
action:[0, 4.24869]
reward:-0.3208395531574218
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.1227   0.
  0.       0.      30.8288   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.15513 -3.02704]
done:False
-------------------------
[26]>>[42]: env.step(1)
action:[0, 4.15513]
reward:0.4075755776050727
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        7.2784    0.
  0.       45.0336   28.7351    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.90433  -0.778935]
done:False
-------------------------
[26]>>[43]: env.step(2)
action:[3.5, 3.90433]
reward:-0.3763394464032598
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.34199
  0.      44.1096  28.0614   0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.53914  1.88781]
done:False
-------------------------
[26]>>[44]: env.step(4)
action:[3.5, 1.76957]
reward:0.3437932156161343
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 43.3459   4.31502  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.69886  4.39153]
done:False
-------------------------
[26]>>[45]: env.step(5)
action:[3.5, 3.69886]
reward:0.36261893866965067
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      41.1795  25.704    0.       0.
  2.75677  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.45195  5.51294]
done:False
-------------------------
[26]>>[46]: env.step(5)
action:[3.5, 3.45195]
reward:-24.64624315957021
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      40.8553  25.3948   0.       0.
  2.54891  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.40273  5.53399]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 58.3759, 'y': 5.53399, 'z': 0.570569}
.........................
** Rewards description :
count    46.000000
mean     -0.552559
std       3.659038
min     -24.646243
25%      -0.362464
50%       0.194634
75%       0.281394
max       0.470077
dtype: float64
#########################
[27]>> env.reset()
=========================
[27]>>[1]: env.step(1)
action:[0, 3.35393]
reward:0.14737898033953176
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.903162 -0.600525]
done:False
-------------------------
[27]>>[2]: env.step(3)
action:[0, 5.903162]
reward:0.28485793315274804
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.93496  -0.438964]
done:False
-------------------------
[27]>>[3]: env.step(0)
action:[-3.5, 1.93496]
reward:-0.49816388560674674
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        2.5218    0.0641764]
done:False
-------------------------
[27]>>[4]: env.step(3)
action:[-3.5, 7.5218]
reward:0.44137773278914566
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.49271 -0.74432]
done:False
-------------------------
[27]>>[5]: env.step(3)
action:[-3.5, 8.49271]
reward:0.5614645879109129
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.80943 -3.21728]
done:False
-------------------------
[27]>>[6]: env.step(3)
action:[-3.5, 9.809429999999999]
reward:0.6435031241117206
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.57764 -3.34927]
done:False
-------------------------
[27]>>[7]: env.step(2)
action:[3.5, 5.57764]
reward:-0.8889722938482403
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       46.9435    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.19778  -0.974563]
done:False
-------------------------
[27]>>[8]: env.step(4)
action:[3.5, 4.19778]
reward:0.5602603590111666
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.9204   0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.86726  3.46692]
done:False
-------------------------
[27]>>[9]: env.step(5)
action:[3.5, 5.86726]
reward:0.6028217338108488
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      42.6336   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.01547  6.31202]
done:False
-------------------------
[27]>>[10]: env.step(2)
action:[3.5, 6.01547]
reward:0.5904235008882629
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      38.7343   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.8129   4.46379]
done:False
-------------------------
[27]>>[11]: env.step(3)
action:[3.5, 10.812899999999999]
reward:0.667014825120265
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.7853   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.64669  3.76962]
done:False
-------------------------
[27]>>[12]: env.step(0)
action:[-3.5, 5.64669]
reward:-0.8654635302207146
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.3982   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.49698  3.88746]
done:False
-------------------------
[27]>>[13]: env.step(5)
action:[-3.5, 6.49698]
reward:0.7097602110549432
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      26.1275   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.31403  1.54949]
done:False
-------------------------
[27]>>[14]: env.step(2)
action:[3.5, 7.31403]
reward:-0.7805662594611422
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      22.869
 45.2837   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.24418 -1.73155]
done:False
-------------------------
[27]>>[15]: env.step(2)
action:[3.5, 7.24418]
reward:0.709485506214367
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       18.2015   41.0219    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.12342   0.928833]
done:False
-------------------------
[27]>>[16]: env.step(0)
action:[-3.5, 7.12342]
reward:-0.7981350069603251
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      15.5273   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.04807  5.29234]
done:False
-------------------------
[27]>>[17]: env.step(3)
action:[-3.5, 12.04807]
reward:0.7784372454659285
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.6979
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.89136  4.66507]
done:False
-------------------------
[27]>>[18]: env.step(5)
action:[-3.5, 6.89136]
reward:0.7016816934967243
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         9.61385    0.        31.9389     0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  7.10355   -0.0489715]
done:False
-------------------------
[27]>>[19]: env.step(3)
action:[-3.5, 12.10355]
reward:0.9702113792259881
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 11.7369   0.       0.       0.      30.196    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.73343 -6.13117]
done:False
-------------------------
[27]>>[20]: env.step(1)
action:[0, 9.73343]
reward:0.2384411231818957
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.26187  0.       0.       0.
  0.       0.       0.       0.      23.1831   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6128  -5.80707]
done:False
-------------------------
[27]>>[21]: env.step(2)
action:[3.5, 10.6128]
reward:0.27929227544225754
observation:
[ 0.       0.       0.       8.85679  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.4882  16.0259   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.0478  -1.79777]
done:False
-------------------------
[27]>>[22]: env.step(3)
action:[3.5, 16.047800000000002]
reward:1.1303159220434056
observation:
[ 0.       0.      16.6013   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.10649 24.6371  43.7779   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.3938  -2.90427]
done:False
-------------------------
[27]>>[23]: env.step(2)
action:[3.5, 11.3938]
reward:1.0697491487510877
observation:
[ 0.      24.7419   0.       0.       0.       0.       0.       2.68329
  0.       0.       0.       0.       0.       0.       0.      16.4858
  0.       0.      35.1858   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.5193  -2.86536]
done:False
-------------------------
[27]>>[24]: env.step(2)
action:[3.5, 11.5193]
reward:1.0645837124432371
observation:
[ 0.        0.        0.        0.        0.        8.02061  31.0104
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.57184   0.        0.       28.6029    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.4017    0.841515]
done:False
-------------------------
[27]>>[25]: env.step(4)
action:[3.5, 9.4017]
reward:0.9699178808216635
observation:
[36.1635   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      48.1376  25.2828   0.       4.14967
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.7051   0.      10.4043   6.4485 ]
done:False
-------------------------
[27]>>[26]: env.step(0)
action:[-3.5, 10.4043]
reward:-25.518410667712843
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.1192  21.3386   0.       0.       0.       0.       0.       0.
  0.       0.       2.05667  0.       0.       0.      17.9131   0.
 39.9919   0.       0.       0.      10.3369   5.52885]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 99.7785, 'y': 5.52885, 'z': 0.570846}
.........................
** Rewards description :
count    26.000000
mean     -0.624182
std       5.115736
min     -25.518411
25%       0.170145
50%       0.575944
75%       0.709692
max       1.130316
dtype: float64
#########################
[28]>> env.reset()
=========================
[28]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.12679641537037536
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.49562  -0.564735]
done:False
-------------------------
[28]>>[2]: env.step(5)
action:[0, 1.49562]
reward:0.16179612231431914
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.54064  -0.254773]
done:False
-------------------------
[28]>>[3]: env.step(5)
action:[0, 1.54064]
reward:0.11658510383153164
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.988754 0.363182]
done:False
-------------------------
[28]>>[4]: env.step(4)
action:[0, 0.494377]
reward:0.08436106808074838
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.867739  0.0705835]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.0081, 'y': 0.0705835, 'z': 0.569748}
.........................
** Rewards description :
count    4.000000
mean     0.122385
std      0.031896
min      0.084361
25%      0.108529
50%      0.121691
75%      0.135546
max      0.161796
dtype: float64
#########################
[29]>> env.reset()
=========================
[29]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7230842336263061
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.314728 0.410514]
done:False
-------------------------
[29]>>[2]: env.step(1)
action:[0, 0.314728]
reward:-0.7053317367427088
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.444417 0.675385]
done:False
-------------------------
[29]>>[3]: env.step(5)
action:[0, 0.444417]
reward:0.0881375505035033
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.92495  0.687676]
done:False
-------------------------
[29]>>[4]: env.step(5)
action:[0, 0.92495]
reward:0.10037806945915839
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.949978 0.607729]
done:False
-------------------------
[29]>>[5]: env.step(2)
action:[3.5, 0.949978]
reward:-0.649418518300287
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.946136 0.415965]
done:False
-------------------------
[29]>>[6]: env.step(0)
action:[-3.5, 0.946136]
reward:-1.3650485405013855
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.35645 0.16667]
done:False
-------------------------
[29]>>[7]: env.step(0)
action:[-3.5, 1.35645]
reward:0.1596979413550889
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.55024  -0.534762]
done:False
-------------------------
[29]>>[8]: env.step(0)
action:[-3.5, 1.55024]
reward:0.18464579711868748
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.802   -1.60399]
done:False
-------------------------
[29]>>[9]: env.step(4)
action:[-3.5, 0.901]
reward:0.13864579192896542
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.41189 -2.63843]
done:False
-------------------------
[29]>>[10]: env.step(1)
action:[0, 1.41189]
reward:-0.5678830867227629
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.80609 -3.1158 ]
done:False
-------------------------
[29]>>[11]: env.step(3)
action:[0, 6.80609]
reward:0.3318562971761797
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29099 -3.17403]
done:False
-------------------------
[29]>>[12]: env.step(3)
action:[0, 7.29099]
reward:0.46081743797793806
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.79942 -2.25562]
done:False
-------------------------
[29]>>[13]: env.step(2)
action:[3.5, 3.79942]
reward:-0.3203298636050721
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.27394  0.422563]
done:False
-------------------------
[29]>>[14]: env.step(2)
action:[3.5, 4.27394]
reward:0.42106119219680743
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.403    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.04576  3.47369]
done:False
-------------------------
[29]>>[15]: env.step(1)
action:[0, 4.04576]
reward:-0.3227668403034044
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      47.1782   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.18132  5.3478 ]
done:False
-------------------------
[29]>>[16]: env.step(2)
action:[3.5, 4.18132]
reward:-0.3296166054742127
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.2867   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.0603   4.83724]
done:False
-------------------------
[29]>>[17]: env.step(1)
action:[0, 4.0603]
reward:-0.3527010202588866
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      41.6384   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.79801  3.85661]
done:False
-------------------------
[29]>>[18]: env.step(2)
action:[3.5, 3.79801]
reward:-0.3733838798498376
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.9019   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.60287  3.8245 ]
done:False
-------------------------
[29]>>[19]: env.step(3)
action:[3.5, 8.60287]
reward:0.47615966353130146
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.0452   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.66887  3.82441]
done:False
-------------------------
[29]>>[20]: env.step(1)
action:[0, 3.66887]
reward:-0.249121597833591
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.668    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.22216  3.84514]
done:False
-------------------------
[29]>>[21]: env.step(0)
action:[-3.5, 5.22216]
reward:-0.13779062381245388
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.2426   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.3025   3.87138]
done:False
-------------------------
[29]>>[22]: env.step(2)
action:[3.5, 6.3025]
reward:-0.7678716092288629
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      22.8906   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.67419  3.90148]
done:False
-------------------------
[29]>>[23]: env.step(0)
action:[-3.5, 7.67419]
reward:-0.7229216079846482
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.9642   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.96548  3.9341 ]
done:False
-------------------------
[29]>>[24]: env.step(1)
action:[0, 7.96548]
reward:0.03140951407976422
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.1243   0.      34.9692   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.95437  1.38191]
done:False
-------------------------
[29]>>[25]: env.step(0)
action:[-3.5, 7.95437]
reward:0.03245775642352644
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.1396   0.       0.      31.8024   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.9721  -3.52778]
done:False
-------------------------
[29]>>[26]: env.step(5)
action:[-3.5, 7.9721]
reward:0.7787424447337197
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.06094  0.       0.
  0.       0.       0.      26.392    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.9147  -3.91135]
done:False
-------------------------
[29]>>[27]: env.step(2)
action:[3.5, 7.9147]
reward:-0.7418504046856332
observation:
[ 0.       0.       0.       0.       0.       0.       7.02005  0.
  0.       0.       0.       0.       0.       0.       0.       0.
 20.8262   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.63691 -3.09394]
done:False
-------------------------
[29]>>[28]: env.step(4)
action:[3.5, 5.63691]
reward:0.6291172171302907
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        7.66145   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       32.9608   16.6094    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.42626  -0.637472]
done:False
-------------------------
[29]>>[29]: env.step(2)
action:[3.5, 6.42626]
reward:0.6198786406473302
observation:
[ 0.       0.       0.       0.       0.       0.       0.       7.33645
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.7615   0.      16.3026   0.       0.       0.       0.
  0.       0.       0.       0.       6.10449  4.24276]
done:False
-------------------------
[29]>>[30]: env.step(5)
action:[3.5, 6.10449]
reward:0.6216565556327356
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      28.3263  49.315    0.      13.9205   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      11.3088   6.20885  6.64449]
done:False
-------------------------
[29]>>[31]: env.step(0)
action:[-3.5, 6.20885]
reward:-0.8833026582914982
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      24.4366  45.2188   0.
  9.62137  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      14.6771   0.
  0.       0.       0.       0.       6.11608  4.39785]
done:False
-------------------------
[29]>>[32]: env.step(5)
action:[-3.5, 6.11608]
reward:0.5854417732389506
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.        23.9424     7.64017   43.8965     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        15.7341     0.
  0.         0.         0.         0.         0.         0.
  5.72142    0.0471208]
done:False
-------------------------
[29]>>[33]: env.step(3)
action:[-3.5, 10.72142]
reward:0.6802184280815662
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.93852 24.3343  43.1184   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      17.6371
  0.       0.       0.       0.       5.85035 -4.14517]
done:False
-------------------------
[29]>>[34]: env.step(2)
action:[3.5, 5.85035]
reward:-0.8788670309006377
observation:
[ 0.      21.8498   0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.47806  0.       0.      21.5773   0.
 39.4124   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.26534 -5.99764]
done:False
-------------------------
[29]>>[35]: env.step(1)
action:[0, 6.26534]
reward:-0.12561119412246002
observation:
[ 0.       0.       0.       0.       0.       0.       0.      24.3498
  0.       0.       0.       0.       0.       3.1642   0.       0.
  0.       0.       0.       0.       0.      17.2707   0.      35.7552
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.20542 -3.42694]
done:False
-------------------------
[29]>>[36]: env.step(2)
action:[3.5, 6.20542]
reward:-25.128370754893655
observation:
[ 0.       0.       0.       0.       0.       0.       0.      24.3954
  0.       0.       0.       0.       0.       0.       2.63479  0.
  0.       0.       0.       0.       0.       0.      16.8515   0.
 35.5577   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.18325 -2.841  ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 83.5289, 'y': -2.841, 'z': 0.570733}
.........................
** Rewards description :
count    36.000000
mean     -0.805693
std       4.205400
min     -25.128371
25%      -0.663397
50%      -0.131701
75%       0.354158
max       0.778742
dtype: float64
#########################
[30]>> env.reset()
=========================
[30]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.1436691280304928
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.69723 1.18347]
done:False
-------------------------
[30]>>[2]: env.step(0)
action:[-3.5, 1.69723]
reward:-0.6038349787058479
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.3028  1.58546]
done:False
-------------------------
[30]>>[3]: env.step(0)
action:[-3.5, 1.3028]
reward:0.12523542223648373
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.1513  2.10945]
done:False
-------------------------
[30]>>[4]: env.step(1)
action:[0, 1.1513]
reward:-0.6030100958165325
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.44916 2.3385 ]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.03125, 'y': 2.3385, 'z': 0.570208}
.........................
** Rewards description :
count    4.000000
mean    -0.234485
std      0.426079
min     -0.603835
25%     -0.603216
50%     -0.238887
75%      0.129844
max      0.143669
dtype: float64
#########################
[31]>> env.reset()
=========================
[31]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.06594619921470876
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.773696 0.71322 ]
done:False
-------------------------
[31]>>[2]: env.step(3)
action:[0, 5.773696]
reward:0.18692993833415755
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.773695 1.19818 ]
done:False
-------------------------
[31]>>[3]: env.step(1)
action:[0, 0.773695]
reward:0.07453238455596153
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.68166 1.66984]
done:False
-------------------------
[31]>>[4]: env.step(4)
action:[0, 0.34083]
reward:0.10078589710846993
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.10085 1.4589 ]
done:False
-------------------------
[31]>>[5]: env.step(3)
action:[0, 6.10085]
reward:0.23999896969720935
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.33576  0.866082]
done:False
-------------------------
[31]>>[6]: env.step(0)
action:[-3.5, 1.33576]
reward:-0.5549021014487084
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.98183  0.389275]
done:False
-------------------------
[31]>>[7]: env.step(0)
action:[-3.5, 1.98183]
reward:0.2112519369270101
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.01589  -0.661046]
done:False
-------------------------
[31]>>[8]: env.step(2)
action:[3.5, 2.01589]
reward:-1.27173762002463
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.21401  -0.993496]
done:False
-------------------------
[31]>>[9]: env.step(1)
action:[0, 2.21401]
reward:-0.5281089810995228
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.087    -0.513245]
done:False
-------------------------
[31]>>[10]: env.step(4)
action:[0, 1.0435]
reward:0.15797766515616551
observation:
[ 0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  1.60783    -0.00926062]
done:False
-------------------------
[31]>>[11]: env.step(1)
action:[0, 1.60783]
reward:0.1682531693695718
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.59018  0.181051]
done:False
-------------------------
[31]>>[12]: env.step(2)
action:[3.5, 1.59018]
reward:-0.5825172093688435
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.58533  0.244977]
done:False
-------------------------
[31]>>[13]: env.step(4)
action:[3.5, 0.792665]
reward:0.13254823847455174
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.36611  0.806104]
done:False
-------------------------
[31]>>[14]: env.step(1)
action:[0, 1.36611]
reward:-0.5696031697743711
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.7968   0.836758]
done:False
-------------------------
[31]>>[15]: env.step(3)
action:[0, 6.7968]
reward:0.2729997294182573
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.0344    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.56571   0.520758]
done:False
-------------------------
[31]>>[16]: env.step(1)
action:[0, 1.56571]
reward:0.1782209075965542
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.8174    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.72068   0.354848]
done:False
-------------------------
[31]>>[17]: env.step(0)
action:[-3.5, 1.72068]
reward:-0.5427381984122364
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      46.6706   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03281 -0.37396]
done:False
-------------------------
[31]>>[18]: env.step(0)
action:[-3.5, 2.03281]
reward:0.21251387459232318
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.9074   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01845 -1.62494]
done:False
-------------------------
[31]>>[19]: env.step(5)
action:[-3.5, 2.01845]
reward:0.2051100058614342
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.     45.1651  0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  1.9323 -2.8854]
done:False
-------------------------
[31]>>[20]: env.step(1)
action:[0, 1.9323]
reward:-0.541205452955876
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.9024   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99848 -3.29784]
done:False
-------------------------
[31]>>[21]: env.step(1)
action:[0, 1.99848]
reward:0.21477289321621815
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 42.4521   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05444 -3.11643]
done:False
-------------------------
[31]>>[22]: env.step(0)
action:[-3.5, 2.05444]
reward:-0.5391115325756888
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 41.0682   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99333 -3.2143 ]
done:False
-------------------------
[31]>>[23]: env.step(2)
action:[3.5, 1.99333]
reward:-1.292438419850372
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 39.6642   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96828 -3.20794]
done:False
-------------------------
[31]>>[24]: env.step(4)
action:[3.5, 0.98414]
reward:0.15085141998877788
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.5291   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.53721 -2.68427]
done:False
-------------------------
[31]>>[25]: env.step(1)
action:[0, 1.53721]
reward:-0.573293738012296
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      37.5556   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.70956 -1.83402]
done:False
-------------------------
[31]>>[26]: env.step(3)
action:[0, 6.70956]
reward:0.3176459833661008
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       36.6454    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.13858  -0.620584]
done:False
-------------------------
[31]>>[27]: env.step(4)
action:[0, 1.06929]
reward:0.3632155538895359
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       34.6047
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.11682   0.556554]
done:False
-------------------------
[31]>>[28]: env.step(2)
action:[3.5, 4.11682]
reward:-0.27383587703621437
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.2539    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.79044   0.364823]
done:False
-------------------------
[31]>>[29]: env.step(2)
action:[3.5, 4.79044]
reward:0.5328177074905207
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.7961   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.35822  2.34955]
done:False
-------------------------
[31]>>[30]: env.step(5)
action:[3.5, 5.35822]
reward:0.5419716274970298
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      24.9072   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.33633  4.61976]
done:False
-------------------------
[31]>>[31]: env.step(1)
action:[0, 5.33633]
reward:-0.2179517769431525
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      21.4742   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.21167  3.06617]
done:False
-------------------------
[31]>>[32]: env.step(2)
action:[3.5, 5.21167]
reward:-0.23355760490998556
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      18.2681  41.2722   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.03893  2.01532]
done:False
-------------------------
[31]>>[33]: env.step(3)
action:[3.5, 10.03893]
reward:0.5948780436694823
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.1606  38.386    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.86643  4.05559]
done:False
-------------------------
[31]>>[34]: env.step(4)
action:[3.5, 2.433215]
reward:0.32135331898817426
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.3859  35.637    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.25367  4.05641]
done:False
-------------------------
[31]>>[35]: env.step(0)
action:[-3.5, 3.25367]
reward:-1.1594036955978941
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.2911  33.4308
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.28796  2.86128]
done:False
-------------------------
[31]>>[36]: env.step(0)
action:[-3.5, 3.28796]
reward:0.3268949030829718
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.65842  48.4296   32.3001    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.10882   0.641565]
done:False
-------------------------
[31]>>[37]: env.step(0)
action:[-3.5, 3.10882]
reward:0.3052830262171611
observation:
[ 0.       0.       0.       0.       0.       0.       0.      10.0868
  0.      31.8667   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88563 -1.55107]
done:False
-------------------------
[31]>>[38]: env.step(4)
action:[-3.5, 1.442815]
reward:0.2140875486771662
observation:
[ 0.       0.       0.       0.       0.       0.       0.      10.4967
  0.       0.      31.3941   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.18504 -3.20696]
done:False
-------------------------
[31]>>[39]: env.step(0)
action:[-3.5, 2.18504]
reward:0.21610684355853366
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      10.1629   0.       0.       0.      30.2246   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02399 -4.03489]
done:False
-------------------------
[31]>>[40]: env.step(0)
action:[-3.5, 2.02399]
reward:0.214375481167894
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.46618  0.       0.       0.      28.833
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04324 -4.22005]
done:False
-------------------------
[31]>>[41]: env.step(2)
action:[3.5, 2.04324]
reward:-1.2843042615241365
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.42494  0.       0.       0.
  0.      43.8483  27.3652   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05445 -3.77946]
done:False
-------------------------
[31]>>[42]: env.step(2)
action:[3.5, 2.05445]
reward:0.21330690474414865
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.14298  0.
  0.       0.       0.       0.      26.1128   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02266 -2.80678]
done:False
-------------------------
[31]>>[43]: env.step(2)
action:[3.5, 2.02266]
reward:0.21484582073407665
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  5.68851  0.       0.       0.       0.       0.      41.6534  25.2778
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04928 -1.43732]
done:False
-------------------------
[31]>>[44]: env.step(5)
action:[3.5, 2.04928]
reward:0.2053062999611822
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 4.26273e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 4.11664e+01 2.49091e+01 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 1.92697e+00 3.72003e-02]
done:False
-------------------------
[31]>>[45]: env.step(5)
action:[3.5, 1.92697]
reward:-24.802218030800226
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        3.39125   0.
  0.        0.        0.        0.       40.9506   24.7885    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86648   0.969184]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 58.1934, 'y': 0.969184, 'z': 0.569595}
.........................
** Rewards description :
count    45.000000
mean     -0.618048
std       3.720664
min     -24.802218
25%      -0.539112
50%       0.168253
75%       0.214846
max       0.594878
dtype: float64
#########################
[32]>> env.reset()
=========================
[32]>>[1]: env.step(1)
action:[0, 1.86819]
reward:0.10466060267176706
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.765031 0.28259 ]
done:False
-------------------------
[32]>>[2]: env.step(5)
action:[0, 0.765031]
reward:0.13451654433811505
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.39653  0.243784]
done:False
-------------------------
[32]>>[3]: env.step(5)
action:[0, 1.39653]
reward:0.1586807161359532
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.52801 0.22616]
done:False
-------------------------
[32]>>[4]: env.step(1)
action:[0, 1.52801]
reward:0.17659998340756417
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.71058  0.222545]
done:False
-------------------------
[32]>>[5]: env.step(3)
action:[0, 6.71058]
reward:0.3239159133362135
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.21615 0.22647]
done:False
-------------------------
[32]>>[6]: env.step(4)
action:[0, 1.108075]
reward:0.1762085811089794
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.81085  0.234052]
done:False
-------------------------
[32]>>[7]: env.step(1)
action:[0, 1.81085]
reward:0.19529499820567583
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.86544  0.240932]
done:False
-------------------------
[32]>>[8]: env.step(1)
action:[0, 1.86544]
reward:0.19880861322376756
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.89428  0.248226]
done:False
-------------------------
[32]>>[9]: env.step(1)
action:[0, 1.89428]
reward:0.19995509798325908
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.90094  0.256059]
done:False
-------------------------
[32]>>[10]: env.step(2)
action:[3.5, 1.90094]
reward:-0.549805636299119
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.9379    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90217   0.263767]
done:False
-------------------------
[32]>>[11]: env.step(1)
action:[0, 1.90217]
reward:-0.5497570820402868
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.5139    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90245   0.271536]
done:False
-------------------------
[32]>>[12]: env.step(0)
action:[-3.5, 1.90245]
reward:-0.5340519509963614
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       46.2507    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09271  -0.434997]
done:False
-------------------------
[32]>>[13]: env.step(3)
action:[-3.5, 7.09271]
reward:0.3544044611299224
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.3545   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50064 -1.72808]
done:False
-------------------------
[32]>>[14]: env.step(1)
action:[0, 2.50064]
reward:-0.45359700508149814
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      43.6619
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.92794 -2.36586]
done:False
-------------------------
[32]>>[15]: env.step(3)
action:[0, 7.9279399999999995]
reward:0.42984911072945764
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.5261   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.24409 -1.68912]
done:False
-------------------------
[32]>>[16]: env.step(1)
action:[0, 3.24409]
reward:0.46191565480748187
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       39.0449
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.82525   0.348827]
done:False
-------------------------
[32]>>[17]: env.step(2)
action:[3.5, 4.82525]
reward:-0.22191202163418255
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.3812   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.28761  2.88008]
done:False
-------------------------
[32]>>[18]: env.step(4)
action:[3.5, 3.28761]
reward:0.5027395174650248
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      33.3104   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.34164  4.88609]
done:False
-------------------------
[32]>>[19]: env.step(5)
action:[3.5, 5.34164]
reward:0.5337559013436068
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.3638   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.23271  3.75791]
done:False
-------------------------
[32]>>[20]: env.step(4)
action:[3.5, 3.23271]
reward:0.4702445020152289
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.6609   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.9352   3.85569]
done:False
-------------------------
[32]>>[21]: env.step(2)
action:[3.5, 4.9352]
reward:0.4862415846591401
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      22.0985   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.71596  3.91648]
done:False
-------------------------
[32]>>[22]: env.step(4)
action:[3.5, 2.35798]
reward:0.3095471153801755
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.43     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.12611  3.93293]
done:False
-------------------------
[32]>>[23]: env.step(0)
action:[-3.5, 3.12611]
reward:-1.1847969019930387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.1449   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.00415  3.9352 ]
done:False
-------------------------
[32]>>[24]: env.step(1)
action:[0, 3.00415]
reward:-0.4283870021762589
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      15.1873  38.3094
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.11416  2.83175]
done:False
-------------------------
[32]>>[25]: env.step(3)
action:[0, 8.11416]
reward:0.40132924792780295
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       14.1206    0.       36.9435
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.8355    0.938552]
done:False
-------------------------
[32]>>[26]: env.step(0)
action:[-3.5, 2.8355]
reward:-0.44789037863919234
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 12.3436    0.       34.9503    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.91472   0.314172]
done:False
-------------------------
[32]>>[27]: env.step(5)
action:[-3.5, 2.91472]
reward:0.2824405845784485
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.3952   32.9231    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.65231   0.410133]
done:False
-------------------------
[32]>>[28]: env.step(3)
action:[-3.5, 7.65231]
reward:0.36941928921839384
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.55029   0.       47.1541   30.9853    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.54888   0.473451]
done:False
-------------------------
[32]>>[29]: env.step(2)
action:[3.5, 2.54888]
reward:-1.2409776946217845
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.71666   0.       45.1609   28.9901    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.45626   0.496125]
done:False
-------------------------
[32]>>[30]: env.step(5)
action:[3.5, 2.45626]
reward:0.25304587637123
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.99327  0.      43.5868  27.4978   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.40627  1.4024 ]
done:False
-------------------------
[32]>>[31]: env.step(4)
action:[3.5, 1.203135]
reward:-24.805483414480122
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       4.42952  0.      43.1575  27.1215   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00796  1.91528]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.1207, 'y': 1.91528, 'z': 0.569423}
.........................
** Rewards description :
count    31.000000
mean     -0.770745
std       4.486143
min     -24.805483
25%      -0.438139
50%       0.195295
75%       0.361912
max       0.533756
dtype: float64
#########################
[33]>> env.reset()
=========================
[33]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.16889978309073073
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.749913 0.700436]
done:False
-------------------------
[33]>>[2]: env.step(3)
action:[0, 5.749913]
reward:0.1844649258319251
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.7499  1.16607]
done:False
-------------------------
[33]>>[3]: env.step(2)
action:[3.5, 0.7499]
reward:-0.6701988605951212
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.7499  1.47015]
done:False
-------------------------
[33]>>[4]: env.step(2)
action:[3.5, 0.7499]
reward:0.07527999349462153
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.696444 1.80002 ]
done:False
-------------------------
[33]>>[5]: env.step(5)
action:[3.5, 0.696444]
reward:0.1119404115424868
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.14452 2.47559]
done:False
-------------------------
[33]>>[6]: env.step(1)
action:[0, 1.14452]
reward:-0.5895809153479559
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.61188 3.33101]
done:False
-------------------------
[33]>>[7]: env.step(1)
action:[0, 1.61188]
reward:0.17965274716980495
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.72639 4.0958 ]
done:False
-------------------------
[33]>>[8]: env.step(1)
action:[0, 1.72639]
reward:0.1946517589273411
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.87878 4.53924]
done:False
-------------------------
[33]>>[9]: env.step(0)
action:[-3.5, 1.87878]
reward:-0.5427757493717645
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.99283 4.45459]
done:False
-------------------------
[33]>>[10]: env.step(4)
action:[-3.5, 0.996415]
reward:0.14969549517716502
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.52029 3.90183]
done:False
-------------------------
[33]>>[11]: env.step(2)
action:[3.5, 1.52029]
reward:-1.3304092849152136
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.62815 3.82111]
done:False
-------------------------
[33]>>[12]: env.step(2)
action:[3.5, 1.62815]
reward:0.1837933018428447
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.77224 3.77338]
done:False
-------------------------
[33]>>[13]: env.step(3)
action:[3.5, 6.77224]
reward:0.3302662277512446
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.27967 3.75749]
done:False
-------------------------
[33]>>[14]: env.step(4)
action:[3.5, 1.139835]
reward:0.1755782890933139
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.79532 3.75593]
done:False
-------------------------
[33]>>[15]: env.step(3)
action:[3.5, 6.79532]
reward:0.3304824771730548
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.9202   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.27659  3.75769]
done:False
-------------------------
[33]>>[16]: env.step(3)
action:[3.5, 7.276590000000001]
reward:0.47206793346040954
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      47.5128   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.94771  3.76639]
done:False
-------------------------
[33]>>[17]: env.step(5)
action:[3.5, 3.94771]
reward:0.4557672559391768
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      44.238    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.57043  3.78617]
done:False
-------------------------
[33]>>[18]: env.step(3)
action:[3.5, 9.57043]
reward:0.5588492295354011
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      40.8345   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.50547  3.80621]
done:False
-------------------------
[33]>>[19]: env.step(4)
action:[3.5, 2.252735]
reward:0.3015302392104119
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.0049   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.05325  3.82247]
done:False
-------------------------
[33]>>[20]: env.step(1)
action:[0, 3.05325]
reward:-0.4457803908475841
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.8038   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88637  3.8341 ]
done:False
-------------------------
[33]>>[21]: env.step(0)
action:[-3.5, 2.88637]
reward:-0.441126733542267
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.9236   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.98567  2.74896]
done:False
-------------------------
[33]>>[22]: env.step(2)
action:[3.5, 2.98567]
reward:-1.199603152586087
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       33.0796    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.85601   0.741565]
done:False
-------------------------
[33]>>[23]: env.step(5)
action:[3.5, 2.85601]
reward:0.2908950169173585
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 31.6684    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.77114  -0.427183]
done:False
-------------------------
[33]>>[24]: env.step(2)
action:[3.5, 2.77114]
reward:0.2819201620441252
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.7693    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.6818   -0.402484]
done:False
-------------------------
[33]>>[25]: env.step(2)
action:[3.5, 2.6818]
reward:0.2691603432729013
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       28.0513
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.54732   0.634455]
done:False
-------------------------
[33]>>[26]: env.step(4)
action:[3.5, 1.27366]
reward:0.18974866112650646
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.127    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.93273  2.02715]
done:False
-------------------------
[33]>>[27]: env.step(0)
action:[-3.5, 1.93273]
reward:-1.2780999296747322
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      25.8738  48.9258   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15743  2.66722]
done:False
-------------------------
[33]>>[28]: env.step(2)
action:[3.5, 2.15743]
reward:-1.2782114279327985
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.4176   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.0999   2.63359]
done:False
-------------------------
[33]>>[29]: env.step(1)
action:[0, 2.0999]
reward:-0.5325410349669519
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      23.0026
 45.9981   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06169  1.8789 ]
done:False
-------------------------
[33]>>[30]: env.step(3)
action:[0, 7.0616900000000005]
reward:0.3180613647615651
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       22.1164   44.963
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.0557    0.664335]
done:False
-------------------------
[33]>>[31]: env.step(5)
action:[0, 2.0557]
reward:0.2253386100559998
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       20.8511   43.6147    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.16849   0.270523]
done:False
-------------------------
[33]>>[32]: env.step(2)
action:[3.5, 2.16849]
reward:-0.5264783480453108
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      19.3999  42.1769   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.1182   0.56727]
done:False
-------------------------
[33]>>[33]: env.step(1)
action:[0, 2.1182]
reward:-0.5405516526178276
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       18.0476   40.7722    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.95993   0.331977]
done:False
-------------------------
[33]>>[34]: env.step(2)
action:[3.5, 1.95993]
reward:-0.5454721103118637
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      16.6698  39.5118   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.93988  1.20533]
done:False
-------------------------
[33]>>[35]: env.step(2)
action:[3.5, 1.93988]
reward:0.21023691839014824
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      15.6032   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01407  2.42628]
done:False
-------------------------
[33]>>[36]: env.step(0)
action:[-3.5, 2.01407]
reward:-1.2759687834459037
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      14.2469  37.3449   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.163    2.89709]
done:False
-------------------------
[33]>>[37]: env.step(2)
action:[3.5, 2.163]
reward:-1.2889045393094236
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      13.0549   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.9687   3.74926]
done:False
-------------------------
[33]>>[38]: env.step(2)
action:[3.5, 1.9687]
reward:0.19825180835124762
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.6901   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.86173  3.98806]
done:False
-------------------------
[33]>>[39]: env.step(4)
action:[3.5, 0.930865]
reward:0.1807468458043507
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.2411  10.179    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90983  4.04034]
done:False
-------------------------
[33]>>[40]: env.step(1)
action:[0, 1.90983]
reward:-0.5399711416803155
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.80333 32.0223   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01906  3.40193]
done:False
-------------------------
[33]>>[41]: env.step(1)
action:[0, 2.01906]
reward:0.2153954206768725
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       7.81749 30.8604   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05685  2.26857]
done:False
-------------------------
[33]>>[42]: env.step(2)
action:[3.5, 2.05685]
reward:-0.5239421535840822
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.54769
 45.4757  29.4725   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.17695  1.94681]
done:False
-------------------------
[33]>>[43]: env.step(2)
action:[3.5, 2.17695]
reward:0.22318232414713077
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       5.09484 44.0378  28.0712   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.11196  2.33872]
done:False
-------------------------
[33]>>[44]: env.step(0)
action:[-3.5, 2.11196]
reward:-26.277089772001197
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       4.4353  43.3893  27.4433   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.1249   2.56571]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9015, 'y': 2.56571, 'z': 0.571391}
.........................
** Rewards description :
count    44.000000
mean     -0.757974
std       3.976970
min     -26.277090
25%      -0.541108
50%       0.172239
75%       0.223721
max       0.558849
dtype: float64
#########################
[34]>> env.reset()
=========================
[34]>>[1]: env.step(0)
action:[-3.5, 2.50978]
reward:-0.5282206852819409
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.52557  0.       0.       0.      41.8581  25.7718
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.0117   1.16207]
done:False
-------------------------
[34]>>[2]: env.step(1)
action:[0, 2.0117]
reward:-0.5455288805883565
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        3.09216   0.        0.        0.
  0.       40.6704   24.5294    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.92625   0.713996]
done:False
-------------------------
[34]>>[3]: env.step(1)
action:[0, 1.92625]
reward:0.2048945069277376
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        2.90142   0.        0.        0.        0.        0.
  0.        0.       39.3444   23.1784    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.95274   0.576919]
done:False
-------------------------
[34]>>[4]: env.step(3)
action:[0, 6.95274]
reward:0.30420202155767684
observation:
[ 0.        0.        0.        0.        0.        0.        3.21282
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.9529   21.7759    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.91128   0.552643]
done:False
-------------------------
[34]>>[5]: env.step(4)
action:[0, 0.95564]
reward:0.1461326580367273
observation:
[ 0.        0.        0.        0.        0.        3.83031   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.7899   20.6081    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.48781   0.552071]
done:False
-------------------------
[34]>>[6]: env.step(1)
action:[0, 1.48781]
reward:0.17194731209616976
observation:
[ 0.        0.        0.        0.        4.66693   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.6135   19.4281    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.66462   0.552151]
done:False
-------------------------
[34]>>[7]: env.step(1)
action:[0, 1.66462]
reward:0.1862393090551525
observation:
[ 0.        0.        0.        5.72811   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.3134   18.1252    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.79263   0.560937]
done:False
-------------------------
[34]>>[8]: env.step(1)
action:[0, 1.79263]
reward:0.19472704904863442
observation:
[ 0.        0.        6.93863   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.9411   16.75      0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86313   0.568255]
done:False
-------------------------
[34]>>[9]: env.step(5)
action:[0, 1.86313]
reward:0.1988112999574549
observation:
[ 0.        0.        8.32344   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.4403   15.2457    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.89489   0.572594]
done:False
-------------------------
[34]>>[10]: env.step(0)
action:[-3.5, 1.89489]
reward:-0.5341211548883429
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 30.1978   13.9071    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  9.7665    2.09376  -0.124651]
done:False
-------------------------
[34]>>[11]: env.step(1)
action:[0, 2.09376]
reward:-0.5328264199842201
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      29.4101  12.9755   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.0823   0.       0.       2.05976 -1.35505]
done:False
-------------------------
[34]>>[12]: env.step(3)
action:[0, 7.05976]
reward:0.3564132623998396
observation:
[12.6118   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.0899  11.5928
 47.644    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.53401 -1.82293]
done:False
-------------------------
[34]>>[13]: env.step(2)
action:[3.5, 2.53401]
reward:-0.35056437634253534
observation:
[ 0.       0.       0.      14.6883   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.6362   9.14642  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.20659 -1.22679]
done:False
-------------------------
[34]>>[14]: env.step(1)
action:[0, 4.20659]
reward:-0.23187358605608943
observation:
[ 0.        0.        0.       16.9839    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       22.5061   42.5831
  6.33486   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.31216   0.849854]
done:False
-------------------------
[34]>>[15]: env.step(0)
action:[-3.5, 5.31216]
reward:-25.21753045794619
observation:
[19.3247    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.1985    0.       40.2337    4.00426   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.22323   0.571875]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.1463, 'y': 0.571875, 'z': 0.571838}
.........................
** Rewards description :
count    15.000000
mean     -1.745153
std       6.502678
min     -25.217530
25%      -0.530524
50%       0.146133
75%       0.196769
max       0.356413
dtype: float64
#########################
[35]>> env.reset()
=========================
[35]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.032436845614065186
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.379464 0.455135]
done:False
-------------------------
[35]>>[2]: env.step(2)
action:[3.5, 0.379464]
reward:-0.6758238651608042
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.776008 0.832919]
done:False
-------------------------
[35]>>[3]: env.step(0)
action:[-3.5, 0.776008]
reward:-1.3742831533703421
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.28874 0.98504]
done:False
-------------------------
[35]>>[4]: env.step(5)
action:[-3.5, 1.28874]
reward:0.14802609666361832
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.42721  0.802787]
done:False
-------------------------
[35]>>[5]: env.step(1)
action:[0, 1.42721]
reward:-0.5852671793221942
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.59302  0.424337]
done:False
-------------------------
[35]>>[6]: env.step(3)
action:[0, 6.59302]
reward:0.31664253982558016
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.15527  0.265029]
done:False
-------------------------
[35]>>[7]: env.step(3)
action:[0, 7.15527]
reward:0.4587961407854233
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.8074   0.226871]
done:False
-------------------------
[35]>>[8]: env.step(0)
action:[-3.5, 3.8074]
reward:-0.27990988565287395
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.78954  0.252201]
done:False
-------------------------
[35]>>[9]: env.step(1)
action:[0, 4.78954]
reward:-0.2234434892247642
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.0979    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.27651   0.273407]
done:False
-------------------------
[35]>>[10]: env.step(2)
action:[3.5, 5.27651]
reward:-0.20062097959244063
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.7351   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.45414  2.23848]
done:False
-------------------------
[35]>>[11]: env.step(4)
action:[3.5, 3.4541399999999998]
reward:0.5111188186562932
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.8303   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.40896  4.5776 ]
done:False
-------------------------
[35]>>[12]: env.step(2)
action:[3.5, 5.40896]
reward:0.5302720922168732
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      37.0665   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.17026  3.72759]
done:False
-------------------------
[35]>>[13]: env.step(3)
action:[3.5, 10.170259999999999]
reward:0.6026632366573076
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.3491   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.9376   3.81689]
done:False
-------------------------
[35]>>[14]: env.step(1)
action:[0, 4.9376]
reward:-0.19852279145379825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      30.1518   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.56649  2.09442]
done:False
-------------------------
[35]>>[15]: env.step(2)
action:[3.5, 5.56649]
reward:-0.18963531170540926
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       26.9659   49.7848    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.52646   0.350183]
done:False
-------------------------
[35]>>[16]: env.step(5)
action:[3.5, 5.52646]
reward:0.550878400460286
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      23.6375  46.7053
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.41139  2.69565]
done:False
-------------------------
[35]>>[17]: env.step(1)
action:[0, 5.41139]
reward:-0.2053404820539766
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.5132   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.35835  4.60606]
done:False
-------------------------
[35]>>[18]: env.step(4)
action:[0, 3.3583499999999997]
reward:0.4050935207003481
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      17.7267  40.8543   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.07209  2.9548 ]
done:False
-------------------------
[35]>>[19]: env.step(2)
action:[3.5, 4.07209]
reward:-0.343272264600365
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      15.1052   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.91435  2.00658]
done:False
-------------------------
[35]>>[20]: env.step(4)
action:[3.5, 1.957175]
reward:0.2577984421282769
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1971  36.3442   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5892   3.20599]
done:False
-------------------------
[35]>>[21]: env.step(0)
action:[-3.5, 2.5892]
reward:-1.2406976255459838
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.5159   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.44961  3.92012]
done:False
-------------------------
[35]>>[22]: env.step(5)
action:[-3.5, 2.44961]
reward:0.25924134040275093
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      9.73674
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.48376 3.51363]
done:False
-------------------------
[35]>>[23]: env.step(0)
action:[-3.5, 2.48376]
reward:0.2539716950029336
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.44015 31.4833   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.41072  2.28338]
done:False
-------------------------
[35]>>[24]: env.step(0)
action:[-3.5, 2.41072]
reward:0.24093653089838285
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        8.12839   0.       30.703     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.26973   0.626677]
done:False
-------------------------
[35]>>[25]: env.step(2)
action:[3.5, 2.26973]
reward:-1.276867445903647
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  8.4379    0.        0.       30.3151    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.08816  -0.958943]
done:False
-------------------------
[35]>>[26]: env.step(5)
action:[3.5, 2.08816]
reward:0.22448624302672165
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  8.33327  0.       0.       0.      29.4257   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15001 -2.0782 ]
done:False
-------------------------
[35]>>[27]: env.step(5)
action:[3.5, 2.15001]
reward:0.2214746353451973
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       7.81956  0.       0.       0.      28.1299   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09794 -2.60841]
done:False
-------------------------
[35]>>[28]: env.step(0)
action:[-3.5, 2.09794]
reward:-1.283255146222219
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       7.3599   0.       0.       0.       0.      26.7938
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05351 -2.9677 ]
done:False
-------------------------
[35]>>[29]: env.step(2)
action:[3.5, 2.05351]
reward:-1.2831017312612152
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.45545  0.       0.       0.       0.
  0.      41.6637  25.2298   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06648 -2.54765]
done:False
-------------------------
[35]>>[30]: env.step(4)
action:[3.5, 1.03324]
reward:0.16495730750019177
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.48501  0.       0.       0.
  0.       0.       0.       0.      24.1395   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.69421 -1.69867]
done:False
-------------------------
[35]>>[31]: env.step(1)
action:[0, 1.69421]
reward:-0.5657892416118417
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  4.36847   0.        0.        0.        0.        0.        0.
  0.       23.3231    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.76076  -0.583773]
done:False
-------------------------
[35]>>[32]: env.step(0)
action:[-3.5, 1.76076]
reward:-0.5418090054442626
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        3.97015   0.        0.        0.        0.
  0.        0.        0.        0.        0.       38.3297   22.0539
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.03405  -0.152207]
done:False
-------------------------
[35]>>[33]: env.step(1)
action:[0, 2.03405]
reward:-0.5303764761641975
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  3.95674   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       37.0128   20.7947
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.10444   0.422468]
done:False
-------------------------
[35]>>[34]: env.step(2)
action:[3.5, 2.10444]
reward:-0.5179188257723857
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  3.90914  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      35.9919  19.9005
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.23836  1.44341]
done:False
-------------------------
[35]>>[35]: env.step(1)
action:[0, 2.23836]
reward:-0.5208010764508748
observation:
[ 0.       0.       0.       0.       4.77334  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.685   18.6803   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.16979  1.93426]
done:False
-------------------------
[35]>>[36]: env.step(0)
action:[-3.5, 2.16979]
reward:-0.5269287336841015
observation:
[ 0.       6.15688  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.2448  17.2374   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.1124   1.7529 ]
done:False
-------------------------
[35]>>[37]: env.step(1)
action:[0, 2.1124]
reward:-0.5445318818918656
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       31.9664   15.8564    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  7.60768   1.91315   0.985609]
done:False
-------------------------
[35]>>[38]: env.step(4)
action:[0, 0.956575]
reward:0.15618148716943103
observation:
[ 8.84584   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       30.8022   14.6372    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.60801   0.657593]
done:False
-------------------------
[35]>>[39]: env.step(2)
action:[3.5, 1.60801]
reward:-0.5814270687724579
observation:
[10.091     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       29.5582   13.3677    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.59398   0.563676]
done:False
-------------------------
[35]>>[40]: env.step(1)
action:[0, 1.59398]
reward:-0.5824149014596607
observation:
[ 0.       11.2423    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       28.3821    0.       12.1816    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.58561   0.556117]
done:False
-------------------------
[35]>>[41]: env.step(0)
action:[-3.5, 1.58561]
reward:-0.5832036811831485
observation:
[ 0.       12.3901    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.2052   11.0007    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.57822   0.569409]
done:False
-------------------------
[35]>>[42]: env.step(1)
action:[0, 1.57822]
reward:-0.571027331902648
observation:
[ 0.       13.5993    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       25.9687    9.76276   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.72661   0.585673]
done:False
-------------------------
[35]>>[43]: env.step(0)
action:[-3.5, 1.72661]
reward:-0.5593754150191373
observation:
[ 0.       14.9108    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.634     8.42818   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.83007   0.599926]
done:False
-------------------------
[35]>>[44]: env.step(0)
action:[-3.5, 1.83007]
reward:0.21404335290601675
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        23.4299     0.         7.09125    0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        16.295      0.
  2.08769   -0.0611071]
done:False
-------------------------
[35]>>[45]: env.step(3)
action:[-3.5, 7.08769]
reward:0.353963529990616
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.10551 42.2232   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.5757   0.       0.       0.       2.49638 -1.33101]
done:False
-------------------------
[35]>>[46]: env.step(3)
action:[-3.5, 7.49638]
reward:0.5137412029069256
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       4.98863 21.3693   0.      40.3767   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.7778   0.       4.43255 -3.05872]
done:False
-------------------------
[35]>>[47]: env.step(5)
action:[-3.5, 4.43255]
reward:0.4983938880710027
observation:
[ 0.       0.      23.1499   0.       0.       0.       0.       0.
  0.       0.       0.       2.61255  0.       0.       0.       0.
 18.005    0.      36.8319   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.999   -2.82153]
done:False
-------------------------
[35]>>[48]: env.step(1)
action:[0, 4.999]
reward:-25.2126539700079
observation:
[ 0.       0.       0.       0.      25.4224   0.       0.       2.46656
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.3174   0.       0.      34.3148   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.36543 -1.98843]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 84.886, 'y': -1.98843, 'z': 0.569269}
.........................
** Rewards description :
count    48.000000
mean     -0.714233
std       3.653063
min     -25.212654
25%      -0.567099
50%      -0.202981
75%       0.254928
max       0.602663
dtype: float64
#########################
[36]>> env.reset()
=========================
[36]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.20735010712524393
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.21405 1.35214]
done:False
-------------------------
[36]>>[2]: env.step(3)
action:[0, 6.21405]
reward:0.35199857791781547
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.69022 1.60065]
done:False
-------------------------
[36]>>[3]: env.step(1)
action:[0, 2.69022]
reward:0.3220864019376768
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.19852 1.01675]
done:False
-------------------------
[36]>>[4]: env.step(1)
action:[0, 3.19852]
reward:0.30770484781840757
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.89317  0.290625]
done:False
-------------------------
[36]>>[5]: env.step(4)
action:[0, 1.446585]
reward:0.2640664177297616
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.79364  0.211233]
done:False
-------------------------
[36]>>[6]: env.step(3)
action:[0, 7.79364]
reward:0.4080813170059936
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.00111  0.232372]
done:False
-------------------------
[36]>>[7]: env.step(1)
action:[0, 3.00111]
reward:0.36161441753666296
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.7068    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.6138    0.262516]
done:False
-------------------------
[36]>>[8]: env.step(2)
action:[3.5, 3.6138]
reward:-0.3636935101812333
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      46.292    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.77091  1.54525]
done:False
-------------------------
[36]>>[9]: env.step(5)
action:[3.5, 3.77091]
reward:0.3824467452430803
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      44.5042   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.68301  3.81583]
done:False
-------------------------
[36]>>[10]: env.step(0)
action:[-3.5, 3.68301]
reward:-1.1352744322996395
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.9848   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.48232  3.85486]
done:False
-------------------------
[36]>>[11]: env.step(4)
action:[-3.5, 1.74116]
reward:0.2378061081510252
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      40.393    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.39894  2.62348]
done:False
-------------------------
[36]>>[12]: env.step(5)
action:[-3.5, 2.39894]
reward:0.24346816250478373
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      39.6658   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30357  1.01294]
done:False
-------------------------
[36]>>[13]: env.step(5)
action:[-3.5, 2.30357]
reward:0.22007875274132335
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.4216    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04259  -0.553498]
done:False
-------------------------
[36]>>[14]: env.step(1)
action:[0, 2.04259]
reward:-0.542806079199387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.328    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95151 -2.0286 ]
done:False
-------------------------
[36]>>[15]: env.step(1)
action:[0, 1.95151]
reward:0.2218864931818325
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.009    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15257 -3.37381]
done:False
-------------------------
[36]>>[16]: env.step(5)
action:[0, 2.15257]
reward:0.21348989368931243
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.023    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00035 -4.17   ]
done:False
-------------------------
[36]>>[17]: env.step(1)
action:[0, 2.00035]
reward:0.20901915880073446
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      36.7459   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.98419 -4.40138]
done:False
-------------------------
[36]>>[18]: env.step(2)
action:[3.5, 1.98419]
reward:-0.5367792342825004
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.2966   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03918 -4.03738]
done:False
-------------------------
[36]>>[19]: env.step(1)
action:[0, 2.03918]
reward:-0.5344010697969023
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      33.8457   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05429 -3.02121]
done:False
-------------------------
[36]>>[20]: env.step(3)
action:[0, 7.05429]
reward:0.35446721917974977
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      32.7829   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.51103 -1.57931]
done:False
-------------------------
[36]>>[21]: env.step(3)
action:[0, 7.51103]
reward:0.5165467108565923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      31.1532   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.46545  0.55226]
done:False
-------------------------
[36]>>[22]: env.step(0)
action:[-3.5, 4.46545]
reward:-0.20411911421334494
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       27.4588    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.61089   0.986717]
done:False
-------------------------
[36]>>[23]: env.step(4)
action:[-3.5, 3.6108900000000004]
reward:0.44104920019482946
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      25.382   47.8957   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.46624 -1.5797 ]
done:False
-------------------------
[36]>>[24]: env.step(4)
action:[-3.5, 2.23312]
reward:0.298579796453847
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.     24.1687  0.     46.3066  0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  3.0217 -3.341 ]
done:False
-------------------------
[36]>>[25]: env.step(1)
action:[0, 3.0217]
reward:-0.4499926474328372
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.2547  44.2806   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84219 -3.31687]
done:False
-------------------------
[36]>>[26]: env.step(1)
action:[0, 2.84219]
reward:0.280372971579287
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.3764  42.5561   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.645   -2.20928]
done:False
-------------------------
[36]>>[27]: env.step(2)
action:[3.5, 2.645]
reward:-0.4896509833383238
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       19.1153   41.6186    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.44848  -0.529999]
done:False
-------------------------
[36]>>[28]: env.step(2)
action:[3.5, 2.44848]
reward:0.2372869081751427
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 18.4429  41.2615   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.21578  1.17623]
done:False
-------------------------
[36]>>[29]: env.step(1)
action:[0, 2.21578]
reward:-0.520342217195883
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      17.2558  40.268
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.18102  2.39839]
done:False
-------------------------
[36]>>[30]: env.step(3)
action:[0, 7.18102]
reward:0.3682255281401119
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.7016   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.65172  2.901  ]
done:False
-------------------------
[36]>>[31]: env.step(2)
action:[3.5, 2.65172]
reward:-0.4142159071151019
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.831   37.049    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.37848  3.93547]
done:False
-------------------------
[36]>>[32]: env.step(5)
action:[3.5, 3.37848]
reward:0.3174041132196455
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.7545  35.002    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.96835  4.0041 ]
done:False
-------------------------
[36]>>[33]: env.step(0)
action:[-3.5, 2.96835]
reward:-1.2044947928383585
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       9.91618
 33.0915   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.79993  3.11343]
done:False
-------------------------
[36]>>[34]: env.step(4)
action:[-3.5, 1.399965]
reward:0.21452330404627698
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.08484 48.0263  31.9926   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.20104  1.6194 ]
done:False
-------------------------
[36]>>[35]: env.step(5)
action:[-3.5, 2.20104]
reward:0.21344682595316403
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         9.07524    0.        47.6825    31.5054
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.98771    0.0751524]
done:False
-------------------------
[36]>>[36]: env.step(4)
action:[-3.5, 0.993855]
reward:0.18340576627791322
observation:
[ 0.       0.       0.       0.       0.       0.       0.       9.41809
  0.      47.5166  31.2207   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92614 -1.37243]
done:False
-------------------------
[36]>>[37]: env.step(1)
action:[0, 1.92614]
reward:-0.5332320821922516
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  9.36271  0.       0.      46.8309  30.4529   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09674 -2.48226]
done:False
-------------------------
[36]>>[38]: env.step(2)
action:[3.5, 2.09674]
reward:-0.5312358044761383
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       8.88409  0.       0.      45.6621  29.2354   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07833 -3.09517]
done:False
-------------------------
[36]>>[39]: env.step(0)
action:[-3.5, 2.07833]
reward:-1.2912889888392012
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.98842  0.       0.       0.       0.
 27.6914   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96096 -3.0812 ]
done:False
-------------------------
[36]>>[40]: env.step(2)
action:[3.5, 1.96096]
reward:-1.284005197724739
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       6.94686  0.       0.
  0.       0.      26.2882   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07865 -2.58958]
done:False
-------------------------
[36]>>[41]: env.step(4)
action:[3.5, 1.039325]
reward:0.17713291096975325
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       5.74463  0.
  0.       0.       0.       0.      41.5945  25.2118   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.83917 -1.61196]
done:False
-------------------------
[36]>>[42]: env.step(4)
action:[3.5, 0.919585]
reward:0.16392498309351541
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        4.51433   0.        0.        0.        0.
  0.       40.8863   24.5885    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.71022  -0.420417]
done:False
-------------------------
[36]>>[43]: env.step(4)
action:[3.5, 0.85511]
reward:0.15573914578933568
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        3.32576   0.        0.
  0.        0.        0.       40.4774   24.2947    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.62807   0.787389]
done:False
-------------------------
[36]>>[44]: env.step(5)
action:[3.5, 1.62807]
reward:-24.828070555753367
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        3.24601   0.        0.
  0.        0.        0.       40.453    24.2789    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.62934   0.867345]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 58.7519, 'y': 0.867345, 'z': 0.57074}
.........................
** Rewards description :
count    44.000000
mean     -0.613418
std       3.769098
min     -24.828071
25%      -0.497324
50%       0.211233
75%       0.300861
max       0.516547
dtype: float64
#########################
[37]>> env.reset()
=========================
[37]>>[1]: env.step(0)
action:[-3.5, 1.63278]
reward:-0.6881106648048478
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.31765  0.669681]
done:False
-------------------------
[37]>>[2]: env.step(1)
action:[0, 0.31765]
reward:-0.6520569750730927
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.0729   0.841628]
done:False
-------------------------
[37]>>[3]: env.step(3)
action:[0, 6.0729]
reward:0.2464180719200133
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.4211   0.594326]
done:False
-------------------------
[37]>>[4]: env.step(1)
action:[0, 1.4211]
reward:0.15853511423978134
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.52012  0.364183]
done:False
-------------------------
[37]>>[5]: env.step(0)
action:[-3.5, 1.52012]
reward:-0.5575526293760489
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90371 -0.28404]
done:False
-------------------------
[37]>>[6]: env.step(0)
action:[-3.5, 1.90371]
reward:0.2068555347032388
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.98213 -1.43897]
done:False
-------------------------
[37]>>[7]: env.step(0)
action:[-3.5, 1.98213]
reward:0.19969825689424803
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.87587 -2.67437]
done:False
-------------------------
[37]>>[8]: env.step(2)
action:[3.5, 1.87587]
reward:-1.2867874773300303
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06616 -3.33805]
done:False
-------------------------
[37]>>[9]: env.step(5)
action:[3.5, 2.06616]
reward:0.20793189422200445
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95456 -3.3243 ]
done:False
-------------------------
[37]>>[10]: env.step(2)
action:[3.5, 1.95456]
reward:0.2186756813439667
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.1128  -2.84401]
done:False
-------------------------
[37]>>[11]: env.step(2)
action:[3.5, 2.1128]
reward:0.21895562773411367
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07664 -1.75899]
done:False
-------------------------
[37]>>[12]: env.step(1)
action:[0, 2.07664]
reward:-0.5461453440734743
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       49.8649    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90255  -0.474004]
done:False
-------------------------
[37]>>[13]: env.step(2)
action:[3.5, 1.90255]
reward:-0.5308642681022797
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       48.595
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.13139   0.252865]
done:False
-------------------------
[37]>>[14]: env.step(0)
action:[-3.5, 2.13139]
reward:-1.281608604011557
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       47.119     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.06514   0.238389]
done:False
-------------------------
[37]>>[15]: env.step(1)
action:[0, 2.06514]
reward:-0.5424167572666696
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.7077   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.95059  0.31054]
done:False
-------------------------
[37]>>[16]: env.step(5)
action:[0, 1.95059]
reward:0.20470088022759447
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.2853    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.94431   0.316288]
done:False
-------------------------
[37]>>[17]: env.step(5)
action:[0, 1.94431]
reward:0.20014580897237572
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.8987    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.89074   0.309273]
done:False
-------------------------
[37]>>[18]: env.step(2)
action:[3.5, 1.89074]
reward:-0.5363598873279771
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      41.4891   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06763  1.03915]
done:False
-------------------------
[37]>>[19]: env.step(0)
action:[-3.5, 2.06763]
reward:-1.2841487543297228
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      40.5143   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05024  2.28408]
done:False
-------------------------
[37]>>[20]: env.step(1)
action:[0, 2.05024]
reward:-0.5448357080376088
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      39.6234   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92501  3.45922]
done:False
-------------------------
[37]>>[21]: env.step(0)
action:[-3.5, 1.92501]
reward:-0.5380731482988441
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.2422   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03828  3.87997]
done:False
-------------------------
[37]>>[22]: env.step(5)
action:[-3.5, 2.03828]
reward:0.21659864179732122
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.7748   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06665  3.68135]
done:False
-------------------------
[37]>>[23]: env.step(1)
action:[0, 2.06665]
reward:-0.5333698501848123
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      35.4709
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05994  2.86739]
done:False
-------------------------
[37]>>[24]: env.step(5)
action:[0, 2.05994]
reward:0.21046826931439178
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      34.5777   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.98686  1.60417]
done:False
-------------------------
[37]>>[25]: env.step(2)
action:[3.5, 1.98686]
reward:-0.5293679085718396
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      33.3032
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.12849  1.11303]
done:False
-------------------------
[37]>>[26]: env.step(5)
action:[3.5, 2.12849]
reward:0.22075781348794954
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.844    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09461  1.31195]
done:False
-------------------------
[37]>>[27]: env.step(2)
action:[3.5, 2.09461]
reward:0.2171960243124076
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      30.5044   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05982  2.14486]
done:False
-------------------------
[37]>>[28]: env.step(5)
action:[3.5, 2.05982]
reward:0.2040053723702991
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.3627   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90858  3.34117]
done:False
-------------------------
[37]>>[29]: env.step(5)
action:[3.5, 1.90858]
reward:0.2079290060850223
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      28.0801   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99392  3.83645]
done:False
-------------------------
[37]>>[30]: env.step(2)
action:[3.5, 1.99392]
reward:0.20515603555921708
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.6627   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.93899  3.93043]
done:False
-------------------------
[37]>>[31]: env.step(5)
action:[3.5, 1.93899]
reward:0.20125315317993703
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.2449   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90547  3.92972]
done:False
-------------------------
[37]>>[32]: env.step(3)
action:[3.5, 6.90547]
reward:0.3025547517988042
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.8204   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90273  3.9171 ]
done:False
-------------------------
[37]>>[33]: env.step(1)
action:[0, 1.90273]
reward:-0.5324185262576049
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      22.4877
 45.6295   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.11247  3.26707]
done:False
-------------------------
[37]>>[34]: env.step(5)
action:[0, 2.11247]
reward:0.2185988991521834
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      21.5471   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07239  2.05438]
done:False
-------------------------
[37]>>[35]: env.step(5)
action:[0, 2.07239]
reward:0.20452582532574248
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       20.797    43.6714
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.91174   0.853056]
done:False
-------------------------
[37]>>[36]: env.step(0)
action:[-3.5, 1.91174]
reward:-0.5378049807005065
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.4441   43.1042    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04485  -0.428948]
done:False
-------------------------
[37]>>[37]: env.step(4)
action:[-3.5, 1.022425]
reward:0.18116745504960996
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.3666  42.7464   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.89201 -1.79229]
done:False
-------------------------
[37]>>[38]: env.step(1)
action:[0, 1.89201]
reward:-0.5361705231102116
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      19.7287  41.7931   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06961 -2.90778]
done:False
-------------------------
[37]>>[39]: env.step(1)
action:[0, 2.06961]
reward:0.2182592316846867
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      18.6549  40.4853   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07898 -3.38977]
done:False
-------------------------
[37]>>[40]: env.step(0)
action:[-3.5, 2.07898]
reward:-0.5384382175628721
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      17.2808
  0.      39.015    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99536 -3.23134]
done:False
-------------------------
[37]>>[41]: env.step(3)
action:[-3.5, 6.99536]
reward:0.34026124443790706
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.8511
  0.      37.4868   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.34836 -3.09893]
done:False
-------------------------
[37]>>[42]: env.step(3)
action:[-3.5, 7.34836]
reward:0.4814639767455383
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.6164
  0.      35.0184   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.05094 -3.03176]
done:False
-------------------------
[37]>>[43]: env.step(1)
action:[0, 4.05094]
reward:-0.2847723468974994
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.     10.4872  0.     32.1575  0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  4.6661 -1.5154]
done:False
-------------------------
[37]>>[44]: env.step(2)
action:[3.5, 4.6661]
reward:-0.29415106678098235
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.40369 47.2843  31.2242   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.39188  1.7739 ]
done:False
-------------------------
[37]>>[45]: env.step(0)
action:[-3.5, 4.39188]
reward:-1.044482075215342
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      45.398    6.3464   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.45619  4.22278]
done:False
-------------------------
[37]>>[46]: env.step(5)
action:[-3.5, 4.45619]
reward:-24.547775975626223
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.1043   4.11037  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.39789  4.43028]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.0711, 'y': 4.43028, 'z': 0.569442}
.........................
** Rewards description :
count    46.000000
mean     -0.714687
std       3.625004
min     -24.547776
25%      -0.538347
50%       0.169851
75%       0.209834
max       0.481464
dtype: float64
#########################
[38]>> env.reset()
=========================
[38]>>[1]: env.step(2)
action:[3.5, 4.33836]
reward:-25.30514883725497
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.33297 3.21693]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 58.0987, 'y': 3.21693, 'z': 0.569566}
.........................
** Rewards description :
count     1.000000
mean    -25.305149
std            NaN
min     -25.305149
25%     -25.305149
50%     -25.305149
75%     -25.305149
max     -25.305149
dtype: float64
#########################
[39]>> env.reset()
=========================
[39]>>[1]: env.step(3)
action:[0, 6.4706600000000005]
reward:0.24092956390208947
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.25466  -0.720528]
done:False
-------------------------
[39]>>[2]: env.step(3)
action:[0, 6.25466]
reward:0.43136143371121605
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.68168  -0.548683]
done:False
-------------------------
[39]>>[3]: env.step(0)
action:[-3.5, 3.68168]
reward:-0.3510098881261796
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.91404 -1.48217]
done:False
-------------------------
[39]>>[4]: env.step(4)
action:[-3.5, 1.95702]
reward:0.3659569920140111
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.92926 -3.34719]
done:False
-------------------------
[39]>>[5]: env.step(1)
action:[0, 3.92926]
reward:-0.380836644839498
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.47643 -3.31162]
done:False
-------------------------
[39]>>[6]: env.step(4)
action:[0, 1.738215]
reward:0.22636460486450943
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26034 -2.41956]
done:False
-------------------------
[39]>>[7]: env.step(5)
action:[0, 2.26034]
reward:0.22539699156683848
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      49.088    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.11804 -1.03923]
done:False
-------------------------
[39]>>[8]: env.step(5)
action:[0, 2.11804]
reward:0.21284177743727972
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        48.0326     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.00112    0.0670181]
done:False
-------------------------
[39]>>[9]: env.step(4)
action:[0, 1.00056]
reward:0.15442867895363754
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       46.7531    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.57599   0.291644]
done:False
-------------------------
[39]>>[10]: env.step(0)
action:[-3.5, 1.57599]
reward:-0.5594048101497686
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.4997    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86737   0.142897]
done:False
-------------------------
[39]>>[11]: env.step(2)
action:[3.5, 1.86737]
reward:-1.2940800985215497
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       44.2959    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.97988  -0.544497]
done:False
-------------------------
[39]>>[12]: env.step(3)
action:[3.5, 6.97988]
reward:0.31302561476732244
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      43.4374   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01372 -1.72523]
done:False
-------------------------
[39]>>[13]: env.step(5)
action:[3.5, 2.01372]
reward:0.2228723842563079
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      42.1767
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.149   -2.12694]
done:False
-------------------------
[39]>>[14]: env.step(0)
action:[-3.5, 2.149]
reward:-1.2925723173380774
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.1329   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92774 -2.96584]
done:False
-------------------------
[39]>>[15]: env.step(0)
action:[-3.5, 1.92774]
reward:0.2025302206253181
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      39.783
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92374 -3.21231]
done:False
-------------------------
[39]>>[16]: env.step(3)
action:[-3.5, 6.9237400000000004]
reward:0.3032817109567636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 38.3783   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90715 -3.23994]
done:False
-------------------------
[39]>>[17]: env.step(0)
action:[-3.5, 1.90715]
reward:0.19672885752436184
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 37.022    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8587  -3.22398]
done:False
-------------------------
[39]>>[18]: env.step(5)
action:[-3.5, 1.8587]
reward:0.1989098814234198
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.6345   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.89719 -3.19654]
done:False
-------------------------
[39]>>[19]: env.step(5)
action:[-3.5, 1.89719]
reward:0.20049787176310652
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.1403   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90678 -3.16223]
done:False
-------------------------
[39]>>[20]: env.step(1)
action:[0, 1.90678]
reward:-0.5326349260523651
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      32.7332   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.10883 -2.47084]
done:False
-------------------------
[39]>>[21]: env.step(4)
action:[0, 1.054415]
reward:0.16214490432403394
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      31.7597   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.65513 -1.41866]
done:False
-------------------------
[39]>>[22]: env.step(0)
action:[-3.5, 1.65513]
reward:-0.5464639281582101
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      30.6162   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00407 -1.0159 ]
done:False
-------------------------
[39]>>[23]: env.step(3)
action:[-3.5, 7.0040700000000005]
reward:0.33940513049393267
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.2469   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.33551 -1.19171]
done:False
-------------------------
[39]>>[24]: env.step(5)
action:[-3.5, 2.33551]
reward:0.2949396702760121
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      27.7213   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.95116 -2.32185]
done:False
-------------------------
[39]>>[25]: env.step(5)
action:[-3.5, 2.95116]
reward:0.2915938350305708
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      26.0413  48.2783
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.75597 -3.08592]
done:False
-------------------------
[39]>>[26]: env.step(5)
action:[-3.5, 2.75597]
reward:0.26972761234652687
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.2076
  0.      46.3538   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.53574 -3.14216]
done:False
-------------------------
[39]>>[27]: env.step(3)
action:[-3.5, 7.5357400000000005]
reward:0.3835717578226368
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.3704  44.4412   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.75597 -3.10838]
done:False
-------------------------
[39]>>[28]: env.step(1)
action:[0, 2.75597]
reward:-0.4108680431155816
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.1367  42.346    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.39413 -2.06627]
done:False
-------------------------
[39]>>[29]: env.step(1)
action:[0, 3.39413]
reward:0.3323577340619282
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 18.194     0.       40.8196    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.15022   0.119797]
done:False
-------------------------
[39]>>[30]: env.step(2)
action:[3.5, 3.15022]
reward:-0.4442602319622334
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.0533  40.0273   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88093  2.14402]
done:False
-------------------------
[39]>>[31]: env.step(1)
action:[0, 2.88093]
reward:-0.45022352740305444
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      15.4671  38.629    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.87453  3.50315]
done:False
-------------------------
[39]>>[32]: env.step(4)
action:[0, 1.437265]
reward:0.26481026037172306
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      13.4609  36.6634   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.80509  3.65306]
done:False
-------------------------
[39]>>[33]: env.step(0)
action:[-3.5, 2.80509]
reward:-0.4672683536993204
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      11.7213
 34.8265   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.6833   2.67532]
done:False
-------------------------
[39]>>[34]: env.step(0)
action:[-3.5, 2.6833]
reward:0.26734013824374947
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      10.9122  33.697    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.52461  1.01562]
done:False
-------------------------
[39]>>[35]: env.step(3)
action:[-3.5, 7.52461]
reward:0.3455432044702693
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.       10.9665    0.       33.2086    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.28194  -0.736607]
done:False
-------------------------
[39]>>[36]: env.step(3)
action:[-3.5, 7.2819400000000005]
reward:0.36478558225087226
observation:
[ 0.       0.       0.       0.       0.       0.       0.      11.3585
  0.      49.2354  32.8734   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.58334 -2.43299]
done:False
-------------------------
[39]>>[37]: env.step(1)
action:[0, 2.58334]
reward:-0.4217251321212103
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.0597   0.       0.      47.9561  31.5005   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.30213 -3.95672]
done:False
-------------------------
[39]>>[38]: env.step(4)
action:[0, 1.651065]
reward:0.23581482134537626
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.97189  0.       0.       0.       0.
 29.672    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.39719 -4.16405]
done:False
-------------------------
[39]>>[39]: env.step(2)
action:[3.5, 2.39719]
reward:-0.5068896431896746
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       8.46153  0.
  0.       0.      44.3989  27.9349   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29964 -3.38486]
done:False
-------------------------
[39]>>[40]: env.step(2)
action:[3.5, 2.29964]
reward:0.23459405014628998
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  6.86358  0.       0.       0.       0.      43.1599  26.7555   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.22017 -2.04479]
done:False
-------------------------
[39]>>[41]: env.step(1)
action:[0, 2.22017]
reward:-0.5364276810650119
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        5.34533   0.        0.
  0.        0.       26.0454    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.98445  -0.575251]
done:False
-------------------------
[39]>>[42]: env.step(0)
action:[-3.5, 1.98445]
reward:-0.532128635405111
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.02282   0.        0.        0.        0.        0.
 24.8906    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09556   0.219094]
done:False
-------------------------
[39]>>[43]: env.step(3)
action:[-3.5, 7.09556]
reward:0.35750788549347334
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.26636  0.       0.       0.       0.       0.
  0.       0.      39.568   23.3628   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.53876  0.40497]
done:False
-------------------------
[39]>>[44]: env.step(0)
action:[-3.5, 2.53876]
reward:0.41039077325473317
observation:
[ 0.        0.        0.        4.5554    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 37.2624   20.9581    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.3441   -0.570523]
done:False
-------------------------
[39]>>[45]: env.step(1)
action:[0, 4.3441]
reward:-0.22007976550631758
observation:
[ 0.       8.05741  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      18.6732   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.43187 -3.27411]
done:False
-------------------------
[39]>>[46]: env.step(3)
action:[0, 10.43187]
reward:0.71788945062087
observation:
[ 0.       0.       0.       0.       0.       0.      10.6035   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      14.525    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.44323 -2.61164]
done:False
-------------------------
[39]>>[47]: env.step(3)
action:[0, 11.44323]
reward:0.8684694566057727
observation:
[ 0.       0.       0.       0.      12.4982   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      26.8597  47.0693  10.8217   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.3502   1.39869]
done:False
-------------------------
[39]>>[48]: env.step(3)
action:[0, 13.3502]
reward:0.9940924193524374
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       20.3181    0.        4.11318   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 19.2126    9.79818   0.551318]
done:False
-------------------------
[39]>>[49]: env.step(2)
action:[3.5, 9.79818]
reward:-24.80437252453115
observation:
[20.1992    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       19.3744    0.        3.13074   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.9278    0.397403]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.7703, 'y': 0.397403, 'z': 0.570262}
.........................
** Rewards description :
count    49.000000
mean     -0.471860
std       3.580468
min     -24.804373
25%      -0.421725
50%       0.222872
75%       0.313026
max       0.994092
dtype: float64
#########################
[40]>> env.reset()
=========================
[40]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.09740853263096001
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.14597  0.825688]
done:False
-------------------------
[40]>>[2]: env.step(1)
action:[0, 1.14597]
reward:0.1426807621469831
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.39891  0.958611]
done:False
-------------------------
[40]>>[3]: env.step(2)
action:[3.5, 1.39891]
reward:-0.6033280498308916
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.38345 1.62769]
done:False
-------------------------
[40]>>[4]: env.step(0)
action:[-3.5, 1.38345]
reward:-1.341336780872908
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.53107 2.59906]
done:False
-------------------------
[40]>>[5]: env.step(5)
action:[-3.5, 1.53107]
reward:0.1857157223876284
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.8197  3.66116]
done:False
-------------------------
[40]>>[6]: env.step(2)
action:[3.5, 1.8197]
reward:-1.30621726136962
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.84495 3.71874]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.00787, 'y': 3.71874, 'z': 0.569932}
.........................
** Rewards description :
count    6.000000
mean    -0.470846
std      0.721603
min     -1.341337
25%     -1.130495
50%     -0.252960
75%      0.131363
max      0.185716
dtype: float64
#########################
[41]>> env.reset()
=========================
[41]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.6793361576194099
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.829384 0.756583]
done:False
-------------------------
[41]>>[2]: env.step(3)
action:[3.5, 5.829384]
reward:0.22947629824059185
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.27541 1.41672]
done:False
-------------------------
[41]>>[3]: env.step(3)
action:[3.5, 6.27541]
reward:0.4116512642969652
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.42592 3.02863]
done:False
-------------------------
[41]>>[4]: env.step(5)
action:[3.5, 3.42592]
reward:0.3969092280413786
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.95168 4.20601]
done:False
-------------------------
[41]>>[5]: env.step(1)
action:[0, 3.95168]
reward:-0.3491893900561158
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.86956 3.18359]
done:False
-------------------------
[41]>>[6]: env.step(4)
action:[0, 1.93478]
reward:0.25195346533508967
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.52328 1.23459]
done:False
-------------------------
[41]>>[7]: env.step(5)
action:[0, 2.52328]
reward:0.2626382495492915
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.50696  0.189023]
done:False
-------------------------
[41]>>[8]: env.step(3)
action:[0, 7.506959999999999]
reward:0.3714743650569695
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.61102  0.173585]
done:False
-------------------------
[41]>>[9]: env.step(3)
action:[0, 7.61102]
reward:0.5165748985997681
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.8391    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.44082   0.261948]
done:False
-------------------------
[41]>>[10]: env.step(1)
action:[0, 4.44082]
reward:0.5079002251213343
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.1641    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.12041   0.290797]
done:False
-------------------------
[41]>>[11]: env.step(2)
action:[3.5, 5.12041]
reward:-0.21399220578245326
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      40.8364   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.31753  2.10933]
done:False
-------------------------
[41]>>[12]: env.step(2)
action:[3.5, 5.31753]
reward:0.5374346682158809
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.0833   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.28696  4.52446]
done:False
-------------------------
[41]>>[13]: env.step(1)
action:[0, 5.28696]
reward:-0.2367589366443903
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.4103   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.97839  3.75459]
done:False
-------------------------
[41]>>[14]: env.step(0)
action:[-3.5, 4.97839]
reward:-0.2556578697809737
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.7883   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.81001  3.8277 ]
done:False
-------------------------
[41]>>[15]: env.step(3)
action:[-3.5, 9.81001]
reward:0.5968215760787565
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     27.7264  0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  4.9496  2.2959]
done:False
-------------------------
[41]>>[16]: env.step(3)
action:[-3.5, 9.9496]
reward:0.666654292888863
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 27.1212  49.6744   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.85759 -1.5097 ]
done:False
-------------------------
[41]>>[17]: env.step(0)
action:[-3.5, 5.85759]
reward:0.6527156649612171
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      25.9112  47.6135   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.69065 -5.39478]
done:False
-------------------------
[41]>>[18]: env.step(3)
action:[-3.5, 11.69065]
reward:0.7516284891607514
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.4435   0.      42.9923   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.60091 -4.77282]
done:False
-------------------------
[41]>>[19]: env.step(4)
action:[-3.5, 4.60091]
reward:0.5447318003267383
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.1371  38.9845   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.56192 -2.74729]
done:False
-------------------------
[41]>>[20]: env.step(4)
action:[-3.5, 3.5619199999999998]
reward:0.43609594716987693
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.0611
  0.      35.5352   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.41524 -2.9972 ]
done:False
-------------------------
[41]>>[21]: env.step(3)
action:[-3.5, 9.41524]
reward:0.5399222848405295
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.302    0.
  0.      32.3009   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.29517 -3.02842]
done:False
-------------------------
[41]>>[22]: env.step(0)
action:[-3.5, 4.29517]
reward:0.48905452794359966
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.73106  0.       0.
  0.      28.8868   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.91235 -3.01425]
done:False
-------------------------
[41]>>[23]: env.step(3)
action:[-3.5, 9.91235]
reward:0.5935463381230064
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.853    0.       0.       0.       0.       0.
  0.      25.2163   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.88031 -2.98891]
done:False
-------------------------
[41]>>[24]: env.step(0)
action:[-3.5, 4.88031]
reward:0.4910159186885907
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.68602
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.6148   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.79145 -2.96589]
done:False
-------------------------
[41]>>[25]: env.step(0)
action:[-3.5, 4.79145]
reward:0.48017061206099143
observation:
[ 0.       0.       0.       0.       0.       8.23532  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.6183  18.1084   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.67347 -2.94566]
done:False
-------------------------
[41]>>[26]: env.step(3)
action:[-3.5, 9.67347]
reward:0.5670233115532548
observation:
[ 0.       0.       0.      10.7148   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.215   14.6812   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.58772 -2.92688]
done:False
-------------------------
[41]>>[27]: env.step(4)
action:[-3.5, 2.29386]
reward:0.31495524709726525
observation:
[ 0.       0.       0.      12.9852   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.0048   0.      47.8102   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.20914 -2.912  ]
done:False
-------------------------
[41]>>[28]: env.step(0)
action:[-3.5, 3.20914]
reward:0.3240415035280354
observation:
[ 0.       0.      15.0666   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.71677  0.      45.4586   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.09307 -2.89938]
done:False
-------------------------
[41]>>[29]: env.step(2)
action:[3.5, 3.09307]
reward:-1.174808022455046
observation:
[ 0.       0.       0.       0.       0.      16.622    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.41453 43.3904   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.13638 -1.7137 ]
done:False
-------------------------
[41]>>[30]: env.step(1)
action:[0, 3.13638]
reward:-0.44462804697919317
observation:
[ 0.        0.        0.        0.        0.        0.       17.3553
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       22.3795    6.01732   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.87984   0.200396]
done:False
-------------------------
[41]>>[31]: env.step(5)
action:[0, 2.87984]
reward:0.29690355692702525
observation:
[ 0.        0.       19.1566    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       20.348     0.       40.4002
  4.17489   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.83932   0.768399]
done:False
-------------------------
[41]>>[32]: env.step(4)
action:[0, 1.41966]
reward:-24.73935181028643
observation:
[ 0.       19.6936    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       19.8108   39.8608    3.6493
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.75848   0.724686]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.6483, 'y': 0.724686, 'z': 0.570041}
.........................
** Rewards description :
count    32.000000
mean     -0.526951
std       4.440245
min     -24.739352
25%       0.118609
50%       0.404280
75%       0.538057
max       0.751628
dtype: float64
#########################
[42]>> env.reset()
=========================
[42]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.20024684360267053
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.12804  -0.135547]
done:False
-------------------------
[42]>>[2]: env.step(2)
action:[3.5, 1.12804]
reward:-0.5812609584188737
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.71597  0.418382]
done:False
-------------------------
[42]>>[3]: env.step(5)
action:[3.5, 1.71597]
reward:0.17855084091286294
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.68709 1.2784 ]
done:False
-------------------------
[42]>>[4]: env.step(5)
action:[3.5, 1.68709]
reward:0.17589500181451864
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.66232 2.38276]
done:False
-------------------------
[42]>>[5]: env.step(2)
action:[3.5, 1.66232]
reward:0.1767716471300681
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.67907 3.37502]
done:False
-------------------------
[42]>>[6]: env.step(0)
action:[-3.5, 1.67907]
reward:-1.3071861646334066
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.8684  3.77447]
done:False
-------------------------
[42]>>[7]: env.step(3)
action:[-3.5, 6.8684]
reward:0.3393403485784131
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.36862 3.67721]
done:False
-------------------------
[42]>>[8]: env.step(5)
action:[-3.5, 2.36862]
reward:0.29719228656733143
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.97069 2.63455]
done:False
-------------------------
[42]>>[9]: env.step(3)
action:[-3.5, 7.970689999999999]
reward:0.43037794032549825
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.24014  0.494076]
done:False
-------------------------
[42]>>[10]: env.step(2)
action:[3.5, 3.24014]
reward:-1.1316469725368261
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      49.8639   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.63854 -0.97323]
done:False
-------------------------
[42]>>[11]: env.step(2)
action:[3.5, 3.63854]
reward:0.3721515381479547
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       47.2956    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.58663  -0.585823]
done:False
-------------------------
[42]>>[12]: env.step(0)
action:[-3.5, 3.58663]
reward:-1.137649774945103
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       44.9847    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.47664  -0.906381]
done:False
-------------------------
[42]>>[13]: env.step(0)
action:[-3.5, 3.47664]
reward:0.32947349041420715
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      43.5356   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.09371 -2.76989]
done:False
-------------------------
[42]>>[14]: env.step(3)
action:[-3.5, 8.09371]
reward:0.41630926983222594
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      41.412
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.03045 -3.20257]
done:False
-------------------------
[42]>>[15]: env.step(1)
action:[0, 3.03045]
reward:-0.4376844391008594
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      39.2987   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.99228 -2.51661]
done:False
-------------------------
[42]>>[16]: env.step(5)
action:[0, 2.99228]
reward:0.2925902826299005
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       37.7523    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.75798  -0.756985]
done:False
-------------------------
[42]>>[17]: env.step(4)
action:[0, 1.37899]
reward:0.2024172536591625
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 36.4069    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.05956   0.275049]
done:False
-------------------------
[42]>>[18]: env.step(2)
action:[3.5, 2.05956]
reward:-0.5178046879378976
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      35.5463
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.25097  1.39609]
done:False
-------------------------
[42]>>[19]: env.step(4)
action:[3.5, 1.125485]
reward:0.17054252327179192
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.9939   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.7383   2.73233]
done:False
-------------------------
[42]>>[20]: env.step(1)
action:[0, 1.7383]
reward:-0.544831167021679
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.9512   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00305  3.56638]
done:False
-------------------------
[42]>>[21]: env.step(1)
action:[0, 2.00305]
reward:0.21495520999609474
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      32.5924   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05551  3.90163]
done:False
-------------------------
[42]>>[22]: env.step(0)
action:[-3.5, 2.05551]
reward:-0.5340820216161369
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.1372   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05408  3.59371]
done:False
-------------------------
[42]>>[23]: env.step(2)
action:[3.5, 2.05408]
reward:-1.2840224984433235
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      29.8836
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05516  2.6991 ]
done:False
-------------------------
[42]>>[24]: env.step(5)
action:[3.5, 2.05516]
reward:0.21610107678976145
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      29.0963   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05639  1.37498]
done:False
-------------------------
[42]>>[25]: env.step(3)
action:[3.5, 7.05639]
reward:0.359940421147765
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 27.888     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.57901   0.636235]
done:False
-------------------------
[42]>>[26]: env.step(1)
action:[0, 2.57901]
reward:-0.3504647212319192
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       25.4692    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.1966    0.861961]
done:False
-------------------------
[42]>>[27]: env.step(4)
action:[0, 2.0983]
reward:0.25511717201147655
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       23.3266   46.1525    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.5211    0.578113]
done:False
-------------------------
[42]>>[28]: env.step(4)
action:[0, 1.26055]
reward:0.17873800118625283
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       21.9013   44.6807    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.8032    0.356466]
done:False
-------------------------
[42]>>[29]: env.step(4)
action:[0, 0.9016]
reward:0.1473326801530546
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.7739   43.5391    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.51569   0.394314]
done:False
-------------------------
[42]>>[30]: env.step(5)
action:[0, 1.51569]
reward:0.17683495575984892
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       19.6522   42.4098    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.71649   0.466576]
done:False
-------------------------
[42]>>[31]: env.step(2)
action:[3.5, 1.71649]
reward:-0.5619023625479301
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       18.4026   41.1415    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.80209   0.456456]
done:False
-------------------------
[42]>>[32]: env.step(3)
action:[3.5, 6.80209]
reward:0.3428490184349522
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      16.9885  39.815    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.42895  1.08992]
done:False
-------------------------
[42]>>[33]: env.step(3)
action:[3.5, 7.42895]
reward:0.4844713068558108
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.2893
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.06964  3.05388]
done:False
-------------------------
[42]>>[34]: env.step(1)
action:[0, 4.06964]
reward:-0.2708585526954139
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.3762   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.84064  4.30047]
done:False
-------------------------
[42]>>[35]: env.step(4)
action:[0, 2.42032]
reward:0.4431031010643459
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.43827 32.5098   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.79013  2.476  ]
done:False
-------------------------
[42]>>[36]: env.step(4)
action:[0, 2.395065]
reward:0.3217039170726722
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        8.20536   0.
 30.6713    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.26756   0.393857]
done:False
-------------------------
[42]>>[37]: env.step(4)
action:[0, 1.63378]
reward:0.2733322899241679
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  6.30157   0.        0.       28.5023    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.86055   0.416652]
done:False
-------------------------
[42]>>[38]: env.step(0)
action:[-3.5, 2.86055]
reward:-0.4657294636236041
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        4.60414
  0.        0.        0.       42.6342   26.4584    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.68838   0.500517]
done:False
-------------------------
[42]>>[39]: env.step(0)
action:[-3.5, 2.68838]
reward:0.28785462023724406
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        4.25247   0.        0.        0.        0.        0.
 24.5487    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.77557  -0.528406]
done:False
-------------------------
[42]>>[40]: env.step(0)
action:[-3.5, 2.77557]
reward:0.26782001227302615
observation:
[ 0.       0.       0.       0.       5.56081  0.       0.       0.
  0.       0.       0.       0.      23.4824   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50743 -2.23699]
done:False
-------------------------
[42]>>[41]: env.step(1)
action:[0, 2.50743]
reward:-0.487986180760314
observation:
[ 0.       0.       0.       0.       0.       6.39125  0.       0.
  0.       0.       0.       0.       0.       0.      38.3779  21.9086
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50327 -2.88799]
done:False
-------------------------
[42]>>[42]: env.step(0)
action:[-3.5, 2.50327]
reward:-0.493585866339606
observation:
[ 0.       0.       0.       0.       0.       0.       6.75727  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.1507   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.43573 -2.54438]
done:False
-------------------------
[42]>>[43]: env.step(1)
action:[0, 2.43573]
reward:-0.5039554803766462
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.69677  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.6917   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.32583 -1.42118]
done:False
-------------------------
[42]>>[44]: env.step(3)
action:[0, 7.32583]
reward:0.3250720540216062
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         6.55288    0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        17.6726     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.0767    -0.0476216]
done:False
-------------------------
[42]>>[45]: env.step(4)
action:[0, 1.03835]
reward:0.2080975467055747
observation:
[ 0.        0.        0.        0.        0.        7.41565   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       16.301
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.21352   0.556056]
done:False
-------------------------
[42]>>[46]: env.step(3)
action:[0, 7.21352]
reward:0.3530717353750243
observation:
[ 0.        0.        8.81415   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       30.9221   14.7251    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.45377   0.635359]
done:False
-------------------------
[42]>>[47]: env.step(3)
action:[0, 7.4537700000000005]
reward:0.4966570347944107
observation:
[ 0.       11.2433    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       28.3773   12.1787    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.22117   0.603846]
done:False
-------------------------
[42]>>[48]: env.step(0)
action:[-3.5, 4.22117]
reward:-0.22859104933455776
observation:
[ 0.       14.857     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.6873    8.48243   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.35135   0.602819]
done:False
-------------------------
[42]>>[49]: env.step(0)
action:[-3.5, 5.35135]
reward:-24.39787567531271
observation:
[19.3484    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.1603   40.208     3.98527   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.13512   0.628501]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.132, 'y': 0.628501, 'z': 0.570678}
.........................
** Rewards description :
count    49.000000
mean     -0.536780
std       3.514374
min     -24.397876
25%      -0.487986
50%       0.178738
75%       0.321704
max       0.496657
dtype: float64
#########################
[43]>> env.reset()
=========================
[43]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.3383903708100541
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.82388  0.205344]
done:False
-------------------------
[43]>>[2]: env.step(5)
action:[0, 2.82388]
reward:0.33621122107276746
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.34076 0.21756]
done:False
-------------------------
[43]>>[3]: env.step(3)
action:[0, 8.34076]
reward:0.45622201444404425
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.478    0.231156]
done:False
-------------------------
[43]>>[4]: env.step(4)
action:[0, 1.739]
reward:0.24523038196377986
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.49007  0.243034]
done:False
-------------------------
[43]>>[5]: env.step(5)
action:[0, 2.49007]
reward:0.25522524863424856
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.42448  0.252918]
done:False
-------------------------
[43]>>[6]: env.step(1)
action:[0, 2.42448]
reward:0.24499289062301216
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.1936    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.3158    0.262465]
done:False
-------------------------
[43]>>[7]: env.step(5)
action:[0, 2.3158]
reward:0.2309872860474417
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.5376    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.1722    0.271473]
done:False
-------------------------
[43]>>[8]: env.step(1)
action:[0, 2.1722]
reward:0.22163736651513005
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.9449    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09437   0.280116]
done:False
-------------------------
[43]>>[9]: env.step(4)
action:[0, 1.047185]
reward:0.16164217617602564
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.551     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.6509    0.287778]
done:False
-------------------------
[43]>>[10]: env.step(3)
action:[0, 6.6509]
reward:0.32183752371315855
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.1711    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.20526   0.295087]
done:False
-------------------------
[43]>>[11]: env.step(0)
action:[-3.5, 2.20526]
reward:-0.4681822230441414
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 41.5496    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.82201  -0.592662]
done:False
-------------------------
[43]>>[12]: env.step(3)
action:[-3.5, 7.822010000000001]
reward:0.3748661031881669
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.5793   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.57487 -2.34354]
done:False
-------------------------
[43]>>[13]: env.step(2)
action:[3.5, 2.57487]
reward:-1.2232195550703546
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      38.9938   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.66765 -3.06864]
done:False
-------------------------
[43]>>[14]: env.step(5)
action:[3.5, 2.66765]
reward:0.2728297765707569
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      37.1218   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.59591 -2.66557]
done:False
-------------------------
[43]>>[15]: env.step(2)
action:[3.5, 2.59591]
reward:0.26412932672877204
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      35.5405   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50708 -1.38444]
done:False
-------------------------
[43]>>[16]: env.step(1)
action:[0, 2.50708]
reward:-0.500607239048785
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       34.6643    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.3489    0.346314]
done:False
-------------------------
[43]>>[17]: env.step(4)
action:[0, 1.17445]
reward:0.18153297121598932
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      33.682    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.85841  1.00675]
done:False
-------------------------
[43]>>[18]: env.step(4)
action:[0, 0.929205]
reward:0.12976718980337942
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       32.7835    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.29877   0.984872]
done:False
-------------------------
[43]>>[19]: env.step(3)
action:[0, 6.29877]
reward:0.25835207290874024
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.6826    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.51058   0.688762]
done:False
-------------------------
[43]>>[20]: env.step(0)
action:[-3.5, 1.51058]
reward:-0.5625715807642288
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      30.621
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.84549  0.13628]
done:False
-------------------------
[43]>>[21]: env.step(5)
action:[-3.5, 1.84549]
reward:0.2026076645138719
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       29.797
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.94524  -0.930993]
done:False
-------------------------
[43]>>[22]: env.step(5)
action:[-3.5, 1.94524]
reward:0.19799508689751658
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.2906   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.86449 -2.21478]
done:False
-------------------------
[43]>>[23]: env.step(4)
action:[-3.5, 0.932245]
reward:0.15361820160193673
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      28.6036   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.58335 -3.00696]
done:False
-------------------------
[43]>>[24]: env.step(5)
action:[-3.5, 1.58335]
reward:0.1640208065871102
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.6347  49.9036
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.54543 -3.22185]
done:False
-------------------------
[43]>>[25]: env.step(4)
action:[-3.5, 0.772715]
reward:0.13266315961614744
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      26.6512
 48.8811   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.37247 -3.17805]
done:False
-------------------------
[43]>>[26]: env.step(2)
action:[3.5, 1.37247]
reward:-1.3551689268358804
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 25.6651  47.8604   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.36802 -3.14705]
done:False
-------------------------
[43]>>[27]: env.step(0)
action:[-3.5, 1.36802]
reward:-1.3555442387429737
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.6762  46.8374   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.36464 -3.12367]
done:False
-------------------------
[43]>>[28]: env.step(0)
action:[-3.5, 1.36464]
reward:0.1618698150001211
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 23.6114  45.7338   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.57427 -3.10579]
done:False
-------------------------
[43]>>[29]: env.step(2)
action:[3.5, 1.57427]
reward:-1.3016008204388076
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      22.2615  44.4491   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96212 -2.51714]
done:False
-------------------------
[43]>>[30]: env.step(0)
action:[-3.5, 1.96212]
reward:-1.2891197794980125
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.0735   0.      43.4519   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01631 -1.39114]
done:False
-------------------------
[43]>>[31]: env.step(0)
action:[-3.5, 2.01631]
reward:0.22397199626761527
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       19.7188   42.1567    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.16172  -0.990994]
done:False
-------------------------
[43]>>[32]: env.step(3)
action:[-3.5, 7.16172]
reward:0.3226102893375923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 18.3951  40.7503   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.08715 -1.28411]
done:False
-------------------------
[43]>>[33]: env.step(0)
action:[-3.5, 2.08715]
reward:0.21433674775371592
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      17.4292   0.      39.5308
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02698 -2.19805]
done:False
-------------------------
[43]>>[34]: env.step(2)
action:[3.5, 2.02698]
reward:-1.2959326906818842
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      16.4807   0.      38.307
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.91754 -2.88689]
done:False
-------------------------
[43]>>[35]: env.step(5)
action:[3.5, 1.91754]
reward:0.21041795862137821
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.1853
  0.      36.9015   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02185 -2.77979]
done:False
-------------------------
[43]>>[36]: env.step(2)
action:[3.5, 2.02185]
reward:0.21544135523883767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      13.7345   0.      35.5474   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05671 -2.05104]
done:False
-------------------------
[43]>>[37]: env.step(3)
action:[3.5, 7.05671]
reward:0.35133819415923007
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       12.3271
  0.       34.475     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.4713   -0.772424]
done:False
-------------------------
[43]>>[38]: env.step(1)
action:[0, 2.4713]
reward:-0.4408462369796212
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       10.4651   49.1287
 32.9476    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.09291   0.482839]
done:False
-------------------------
[43]>>[39]: env.step(2)
action:[3.5, 3.09291]
reward:-0.4555295029711459
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       8.74901 47.6978
 31.6736   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.75602  2.16134]
done:False
-------------------------
[43]>>[40]: env.step(1)
action:[0, 2.75602]
reward:-0.4701377247419991
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.00356 30.1471   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.66026  3.10118]
done:False
-------------------------
[43]>>[41]: env.step(0)
action:[-3.5, 2.66026]
reward:-0.48091339656052895
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       5.17777 28.3129   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5518   2.91937]
done:False
-------------------------
[43]>>[42]: env.step(3)
action:[-3.5, 7.5518]
reward:0.3908805803226323
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.90546  0.      42.6513  26.637
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84409  1.80153]
done:False
-------------------------
[43]>>[43]: env.step(0)
action:[-3.5, 2.84409]
reward:0.34447198098015747
observation:
[ 0.        0.        0.        0.        0.        4.48213   0.
  0.        0.        0.       41.722    25.4743    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.4387   -0.409521]
done:False
-------------------------
[43]>>[44]: env.step(1)
action:[0, 3.4387]
reward:-0.3925963712888867
observation:
[ 0.       0.       0.       0.       0.       0.       5.3885   0.
  0.       0.       0.       0.       0.       0.      23.7474   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.45167 -1.98071]
done:False
-------------------------
[43]>>[45]: env.step(5)
action:[0, 3.45167]
reward:0.3504588586555725
observation:
[ 0.       0.       0.       0.       0.       0.       0.       5.57189
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      37.7496  21.3395   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.36157 -1.79094]
done:False
-------------------------
[43]>>[46]: env.step(1)
action:[0, 3.36157]
reward:0.3243238672037419
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        5.2312    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 35.7618   19.4705    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.05847  -0.169741]
done:False
-------------------------
[43]>>[47]: env.step(4)
action:[0, 1.529235]
reward:0.21731431848364785
observation:
[ 0.        0.        0.        0.        0.        6.02868   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       34.0823   17.87
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.2026    0.530735]
done:False
-------------------------
[43]>>[48]: env.step(0)
action:[-3.5, 2.2026]
reward:-0.5172315758325412
observation:
[ 0.        0.        7.49561   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       16.2666    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.22219   0.277547]
done:False
-------------------------
[43]>>[49]: env.step(5)
action:[-3.5, 2.22219]
reward:0.2264471232027009
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 14.8559    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  9.14285   2.14035  -0.749876]
done:False
-------------------------
[43]>>[50]: env.step(0)
action:[-3.5, 2.14035]
reward:0.20607055564156518
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.045    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.4886   0.       1.91346 -2.04158]
done:False
-------------------------
[43]>>[51]: env.step(4)
action:[-3.5, 0.95673]
reward:0.1598353890081804
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      29.7156  13.185   49.0915   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      11.707    1.65182 -2.79201]
done:False
-------------------------
[43]>>[52]: env.step(3)
action:[-3.5, 6.65182]
reward:0.31594011622428453
observation:
[ 0.      12.9531   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.9792   0.
 47.8033   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.13186 -2.95687]
done:False
-------------------------
[43]>>[53]: env.step(4)
action:[-3.5, 1.06593]
reward:0.18055903301609355
observation:
[ 0.       0.      14.2988   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.5547
  0.      46.3202   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8738  -2.96367]
done:False
-------------------------
[43]>>[54]: env.step(5)
action:[-3.5, 1.8738]
reward:0.18812642573430796
observation:
[ 0.       0.      15.5077   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.26275 44.981    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.76311 -2.93727]
done:False
-------------------------
[43]>>[55]: env.step(1)
action:[0, 1.76311]
reward:-0.5651380445213781
observation:
[ 0.       0.      16.7074   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.00352  0.      43.6663   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.75139 -2.91152]
done:False
-------------------------
[43]>>[56]: env.step(5)
action:[0, 1.75139]
reward:0.18397653921356902
observation:
[ 0.       0.      17.918    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.77032
 23.267    0.      42.357    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.74364 -2.89282]
done:False
-------------------------
[43]>>[57]: env.step(2)
action:[3.5, 1.74364]
reward:-0.5406753937257691
observation:
[ 0.       0.       0.      18.9233   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       5.41345 21.919    0.      41.1224   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05207 -2.29106]
done:False
-------------------------
[43]>>[58]: env.step(1)
action:[0, 2.05207]
reward:-25.536191540326833
observation:
[ 0.       0.       0.       0.       0.      19.4727   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.37647  0.      40.3486   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02934 -1.38755]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.9602, 'y': -1.38755, 'z': 0.568606}
.........................
** Rewards description :
count    58.000000
mean     -0.496863
std       3.385648
min     -25.536192
25%      -0.465019
50%       0.193061
75%       0.257570
max       0.456222
dtype: float64
#########################
[44]>> env.reset()
=========================
[44]>>[1]: env.step(4)
action:[0, 1.020465]
reward:0.07810480435991302
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.662197 0.71485 ]
done:False
-------------------------
[44]>>[2]: env.step(0)
action:[-3.5, 0.662197]
reward:-0.6266448047717648
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.28903  0.405283]
done:False
-------------------------
[44]>>[3]: env.step(3)
action:[-3.5, 6.28903]
reward:0.2561281747275219
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.48579  0.323416]
done:False
-------------------------
[44]>>[4]: env.step(5)
action:[-3.5, 1.48579]
reward:0.18829770228356604
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86218  -0.230483]
done:False
-------------------------
[44]>>[5]: env.step(3)
action:[-3.5, 6.86218]
reward:0.3349927519482395
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.31601 -1.36506]
done:False
-------------------------
[44]>>[6]: env.step(3)
action:[-3.5, 7.31601]
reward:0.4777162638336354
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.01066 -3.23377]
done:False
-------------------------
[44]>>[7]: env.step(3)
action:[-3.5, 9.01066]
reward:0.61537085790342
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.39781 -3.42901]
done:False
-------------------------
[44]>>[8]: env.step(0)
action:[-3.5, 5.39781]
reward:0.6242349221187408
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.117    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.42023 -3.25166]
done:False
-------------------------
[44]>>[9]: env.step(0)
action:[-3.5, 6.42023]
reward:0.7524440766608345
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.3453   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.93001 -3.19874]
done:False
-------------------------
[44]>>[10]: env.step(3)
action:[-3.5, 12.93001]
reward:0.9178631729024923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.1803   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.71973 -3.16745]
done:False
-------------------------
[44]>>[11]: env.step(3)
action:[-3.5, 13.71973]
reward:1.0104905187972584
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 29.2655   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.96752 -3.12967]
done:False
-------------------------
[44]>>[12]: env.step(2)
action:[3.5, 9.96752]
reward:-0.5042677669918609
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       22.3175   45.0738    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.6699    0.157817]
done:False
-------------------------
[44]>>[13]: env.step(3)
action:[3.5, 15.6699]
reward:1.0781362282308555
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.7446   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.591    6.29641]
done:False
-------------------------
[44]>>[14]: env.step(3)
action:[3.5, 15.591]
reward:1.0666304180793769
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.3917
 33.6531   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4179   3.99726]
done:False
-------------------------
[44]>>[15]: env.step(0)
action:[-3.5, 10.4179]
reward:-25.522076847972688
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.6555   3.33854  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2758   4.16513]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.5182, 'y': 4.16513, 'z': 0.569817}
.........................
** Rewards description :
count    15.000000
mean     -1.283505
std       6.725529
min     -25.522077
25%       0.133201
50%       0.477716
75%       0.835154
max       1.078136
dtype: float64
#########################
[45]>> env.reset()
=========================
[45]>>[1]: env.step(5)
action:[0, 10.1372]
reward:0.22357869785365758
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.126716 0.112677]
done:False
-------------------------
[45]>>[2]: env.step(0)
action:[-3.5, 0.126716]
reward:-0.7364386811682174
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.126716 0.02006 ]
done:False
-------------------------
[45]>>[3]: env.step(2)
action:[3.5, 0.126716]
reward:-1.4650143496374073
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.377691 -0.106254]
done:False
-------------------------
[45]>>[4]: env.step(5)
action:[3.5, 0.377691]
reward:0.0640159022982445
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.656501  -0.0260204]
done:False
-------------------------
[45]>>[5]: env.step(3)
action:[3.5, 5.6565010000000004]
reward:0.17377380655460303
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.644429 0.128303]
done:False
-------------------------
[45]>>[6]: env.step(3)
action:[3.5, 5.644429]
reward:0.17469222023347214
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.658503 0.284367]
done:False
-------------------------
[45]>>[7]: env.step(3)
action:[3.5, 5.658503]
reward:0.2162613698605469
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.1575   0.570547]
done:False
-------------------------
[45]>>[8]: env.step(0)
action:[-3.5, 1.1575]
reward:-1.2345716932618718
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.88261 1.53294]
done:False
-------------------------
[45]>>[9]: env.step(4)
action:[-3.5, 1.441305]
reward:0.26261428159830835
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.77716 1.41425]
done:False
-------------------------
[45]>>[10]: env.step(2)
action:[3.5, 2.77716]
reward:-1.2102082658920212
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.77725   -0.0861957]
done:False
-------------------------
[45]>>[11]: env.step(3)
action:[3.5, 7.77725]
reward:0.3480067343641434
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.24954  0.451809]
done:False
-------------------------
[45]>>[12]: env.step(1)
action:[0, 2.24954]
reward:-0.5118572208411657
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.27595  0.409124]
done:False
-------------------------
[45]>>[13]: env.step(3)
action:[0, 7.27595]
reward:0.3812251063442975
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.79137  0.160406]
done:False
-------------------------
[45]>>[14]: env.step(0)
action:[-3.5, 2.79137]
reward:-0.4332907316413992
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        3.10651   0.0735529]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.04321, 'y': 0.0735529, 'z': 0.571461}
.........................
** Rewards description :
count    14.000000
mean     -0.267658
std       0.657567
min      -1.465014
25%      -0.680293
50%       0.118895
75%       0.221749
max       0.381225
dtype: float64
#########################
[46]>> env.reset()
=========================
[46]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.1094509636701529
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.28902  0.999245]
done:False
-------------------------
[46]>>[2]: env.step(0)
action:[-3.5, 1.28902]
reward:-0.6135179045113911
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.28902 1.40038]
done:False
-------------------------
[46]>>[3]: env.step(4)
action:[-3.5, 0.64451]
reward:0.12298346647404099
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.28902 1.0692 ]
done:False
-------------------------
[46]>>[4]: env.step(1)
action:[0, 1.28902]
reward:-0.6141889837848754
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.281    0.547604]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02533, 'y': 0.547604, 'z': 0.569934}
.........................
** Rewards description :
count    4.000000
mean    -0.248818
std      0.421543
min     -0.614189
25%     -0.613686
50%     -0.252033
75%      0.112834
max      0.122983
dtype: float64
#########################
[47]>> env.reset()
=========================
Retrying to reset environment!
[47]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.16472204340165014
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.699693 0.164864]
done:False
-------------------------
[47]>>[2]: env.step(2)
action:[3.5, 0.699693]
reward:-0.6235872308855532
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.31612 0.44528]
done:False
-------------------------
[47]>>[3]: env.step(4)
action:[3.5, 0.65806]
reward:0.1219816193614329
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.27369 1.07965]
done:False
-------------------------
[47]>>[4]: env.step(3)
action:[3.5, 6.27369]
reward:0.28037581652668764
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.78716 1.97297]
done:False
-------------------------
[47]>>[5]: env.step(4)
action:[3.5, 0.89358]
reward:0.290817363890045
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.26079 3.4708 ]
done:False
-------------------------
[47]>>[6]: env.step(0)
action:[-3.5, 3.26079]
reward:-1.1088842303934408
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.91981 3.86719]
done:False
-------------------------
[47]>>[7]: env.step(4)
action:[-3.5, 1.959905]
reward:0.3602532976508273
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.85705 2.23713]
done:False
-------------------------
[47]>>[8]: env.step(3)
action:[-3.5, 8.857050000000001]
reward:0.47906724657231897
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.64283  -0.458911]
done:False
-------------------------
[47]>>[9]: env.step(3)
action:[-3.5, 8.64283]
reward:0.6075306098732869
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.38461 -3.83336]
done:False
-------------------------
[47]>>[10]: env.step(3)
action:[-3.5, 10.38461]
reward:0.7470913652535314
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 47.5574   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.86354 -5.58762]
done:False
-------------------------
[47]>>[11]: env.step(5)
action:[-3.5, 6.86354]
reward:0.7430989636777569
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      42.4133   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.68769 -2.93352]
done:False
-------------------------
[47]>>[12]: env.step(1)
action:[0, 7.68769]
reward:-0.011153116974716548
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      36.9806   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.42198 -3.22408]
done:False
-------------------------
[47]>>[13]: env.step(2)
action:[3.5, 7.42198]
reward:-0.010045648509144134
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       32.1876    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.50394  -0.435938]
done:False
-------------------------
[47]>>[14]: env.step(2)
action:[3.5, 7.50394]
reward:0.730839676428209
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 30.4771   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.35581  4.81637]
done:False
-------------------------
[47]>>[15]: env.step(5)
action:[3.5, 7.35581]
reward:0.7219193388881074
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.7272   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.26835  6.21887]
done:False
-------------------------
[47]>>[16]: env.step(0)
action:[-3.5, 7.26835]
reward:-0.7944287906239528
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      22.6157  45.6391   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.06313  2.13305]
done:False
-------------------------
[47]>>[17]: env.step(1)
action:[0, 7.06313]
reward:-0.05578477100291579
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.0124   0.      43.2888   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.95749 -2.12475]
done:False
-------------------------
[47]>>[18]: env.step(2)
action:[3.5, 6.95749]
reward:-0.0695638957781759
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      16.3119  38.5588   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.79432 -1.39223]
done:False
-------------------------
[47]>>[19]: env.step(4)
action:[3.5, 4.79432]
reward:0.6148171678390426
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      13.6531  36.8346   0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.44446  3.48724]
done:False
-------------------------
[47]>>[20]: env.step(0)
action:[-3.5, 6.44446]
reward:-0.8541818631798268
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      49.1817  10.3584   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.45027  6.13482]
done:False
-------------------------
[47]>>[21]: env.step(3)
action:[-3.5, 11.45027]
reward:0.7283887054736338
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.2329   6.17169  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.33498  3.8325 ]
done:False
-------------------------
[47]>>[22]: env.step(3)
action:[-3.5, 11.33498]
reward:0.7571952884668249
observation:
[ 0.        0.        0.        0.        0.        6.90539   0.
  0.       44.6876   28.4026    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.76836  -0.836518]
done:False
-------------------------
[47]>>[23]: env.step(0)
action:[-3.5, 6.76836]
reward:0.7442788115553124
observation:
[ 0.       0.       0.       0.       0.       0.       9.88023  0.
  0.       0.       0.       0.      27.0166   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.72806 -5.78173]
done:False
-------------------------
[47]>>[24]: env.step(0)
action:[-3.5, 7.72806]
reward:0.7580639489520804
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       9.39981  0.       0.       0.       0.       0.
  0.       0.       0.      21.8061   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.68236 -5.71169]
done:False
-------------------------
[47]>>[25]: env.step(3)
action:[-3.5, 12.68236]
reward:0.8392975602959032
observation:
[ 0.       0.       0.       0.       0.       0.       8.36738  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.5157  17.036    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.61095 -2.14627]
done:False
-------------------------
[47]>>[26]: env.step(3)
action:[-3.5, 12.610949999999999]
reward:0.8230054989651316
observation:
[ 0.       0.       0.      13.1952   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 11.8263   0.      47.609    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.39144 -3.02471]
done:False
-------------------------
[47]>>[27]: env.step(0)
action:[-3.5, 7.39144]
reward:0.7899497627886722
observation:
[ 0.       0.      18.4102   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.30726
 22.7801   0.      41.8406   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.21989 -2.92839]
done:False
-------------------------
[47]>>[28]: env.step(3)
action:[-3.5, 13.21989]
reward:0.9848646701672568
observation:
[ 0.      24.8606   0.       0.       0.       0.       2.72407  0.
  0.       0.       0.       0.       0.       0.       0.      16.3703
  0.       0.      35.0621   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.68466 -2.86182]
done:False
-------------------------
[47]>>[29]: env.step(3)
action:[-3.5, 14.68466]
reward:1.0922907344087056
observation:
[ 0.      33.0158   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.23664  0.       0.
  0.       0.      26.6927   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.0769  -2.80423]
done:False
-------------------------
[47]>>[30]: env.step(2)
action:[3.5, 11.0769]
reward:-0.41944519174744377
observation:
[ 0.        0.        0.        0.        0.       16.511    39.5207
  0.        0.        0.        0.        0.        0.        0.
  2.54135   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       20.2748    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.78      0.921947]
done:False
-------------------------
[47]>>[31]: env.step(2)
action:[3.5, 11.78]
reward:-23.90967678111536
observation:
[ 0.       0.       0.       0.       0.       0.      16.8071  39.7337
  0.       0.       0.       0.       0.       0.       2.07158  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.7354  20.1828   0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.7696   1.45914]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 99.5035, 'y': 1.45914, 'z': 0.571037}
.........................
** Rewards description :
count    31.000000
mean     -0.466997
std       4.389206
min     -23.909677
25%      -0.033469
50%       0.479067
75%       0.745685
max       1.092291
dtype: float64
#########################
[48]>> env.reset()
=========================
[48]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.008468783520125558
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0988724 0.131957 ]
done:False
-------------------------
[48]>>[2]: env.step(4)
action:[0, 0.0494362]
reward:0.023049985649260814
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.257078  0.0931593]
done:False
-------------------------
[48]>>[3]: env.step(3)
action:[0, 5.257078]
reward:0.17509266652895306
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.760162 0.159925]
done:False
-------------------------
[48]>>[4]: env.step(3)
action:[0, 5.760162]
reward:0.2896084430452702
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.02924  0.237115]
done:False
-------------------------
[48]>>[5]: env.step(5)
action:[0, 2.02924]
reward:0.26308698872155795
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.63597  0.242982]
done:False
-------------------------
[48]>>[6]: env.step(3)
action:[0, 7.63597]
reward:0.3980140875438621
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.91313  0.234877]
done:False
-------------------------
[48]>>[7]: env.step(3)
action:[0, 7.913130000000001]
reward:0.4910472028320082
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.03365  0.241986]
done:False
-------------------------
[48]>>[8]: env.step(3)
action:[0, 9.03365]
reward:0.6135062785141847
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.4133    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.36703   0.260685]
done:False
-------------------------
[48]>>[9]: env.step(4)
action:[0, 3.3670299999999997]
reward:0.41492752336602734
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.7215   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.19458  0.28094]
done:False
-------------------------
[48]>>[10]: env.step(0)
action:[-3.5, 4.19458]
reward:-0.29928432207767663
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      43.1538   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44397 -1.2385 ]
done:False
-------------------------
[48]>>[11]: env.step(5)
action:[-3.5, 4.44397]
reward:0.46650673967567535
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.3244   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.58429 -3.54812]
done:False
-------------------------
[48]>>[12]: env.step(0)
action:[-3.5, 4.58429]
reward:0.44219571530029045
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.1379   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.23754 -3.17419]
done:False
-------------------------
[48]>>[13]: env.step(4)
action:[-3.5, 2.11877]
reward:0.28688697499773874
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.7125   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.90605 -3.144  ]
done:False
-------------------------
[48]>>[14]: env.step(0)
action:[-3.5, 2.90605]
reward:0.3061615058914767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.5742   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.94719 -3.15872]
done:False
-------------------------
[48]>>[15]: env.step(2)
action:[3.5, 2.94719]
reward:-1.1685145939696577
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      31.4209   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.2511  -2.05331]
done:False
-------------------------
[48]>>[16]: env.step(0)
action:[-3.5, 3.2511]
reward:-1.1563636688078054
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.1943   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.32652 -1.59482]
done:False
-------------------------
[48]>>[17]: env.step(0)
action:[-3.5, 3.32652]
reward:0.3333538085429742
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.3053  49.6307
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.17952 -2.82905]
done:False
-------------------------
[48]>>[18]: env.step(4)
action:[-3.5, 1.58976]
reward:0.23091008045360062
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      25.5402
 47.7438   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.35277 -3.14422]
done:False
-------------------------
[48]>>[19]: env.step(2)
action:[3.5, 2.35277]
reward:-1.2371583847321759
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.6652  45.9234   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.55208 -2.45876]
done:False
-------------------------
[48]>>[20]: env.step(3)
action:[3.5, 7.55208]
reward:0.3939435283416466
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 22.0902   44.6011    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.88268  -0.898195]
done:False
-------------------------
[48]>>[21]: env.step(2)
action:[3.5, 2.88268]
reward:0.32778060768349604
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.1466  44.0186   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.22115  1.32114]
done:False
-------------------------
[48]>>[22]: env.step(4)
action:[3.5, 1.610575]
reward:0.23454183150619987
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.651   43.7658   0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.3918   3.30526]
done:False
-------------------------
[48]>>[23]: env.step(5)
action:[3.5, 2.3918]
reward:0.24041028945603293
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      19.6252
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26804  4.57092]
done:False
-------------------------
[48]>>[24]: env.step(0)
action:[-3.5, 2.26804]
reward:-1.2483405307914983
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.1232  41.4015   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.43637  5.13153]
done:False
-------------------------
[48]>>[25]: env.step(2)
action:[3.5, 2.43637]
reward:-1.2336986358645636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.3304   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5736   4.81721]
done:False
-------------------------
[48]>>[26]: env.step(2)
action:[3.5, 2.5736]
reward:0.26499243090671676
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 14.5382  37.7894   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.52324  4.11251]
done:False
-------------------------
[48]>>[27]: env.step(4)
action:[3.5, 1.26162]
reward:0.19543087459395
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.9469   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.00439  3.96715]
done:False
-------------------------
[48]>>[28]: env.step(3)
action:[3.5, 7.00439]
reward:0.33733404019340923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.3617  34.6154   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30962  3.94905]
done:False
-------------------------
[48]>>[29]: env.step(2)
action:[3.5, 2.30962]
reward:0.29093658000832967
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.27121 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.90825 3.96532]
done:False
-------------------------
[48]>>[30]: env.step(5)
action:[3.5, 2.90825]
reward:0.3126521392282682
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.03625 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.027   3.98765]
done:False
-------------------------
[48]>>[31]: env.step(5)
action:[3.5, 3.027]
reward:0.32207713972919777
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.73711 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.11421 4.00258]
done:False
-------------------------
[48]>>[32]: env.step(3)
action:[3.5, 8.11421]
reward:-24.57536585322413
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.27061 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.13113 4.00459]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9098, 'y': 4.00459, 'z': 0.569701}
.........................
** Rewards description :
count    32.000000
mean     -0.726744
std       4.389212
min     -24.575366
25%       0.019405
50%       0.275940
75%       0.334349
max       0.613506
dtype: float64
#########################
[49]>> env.reset()
=========================
[49]>>[1]: env.step(2)
action:[3.5, 3.13695]
reward:-25.42335551561723
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.14346 4.00562]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.2235, 'y': 4.00562, 'z': 0.569736}
.........................
** Rewards description :
count     1.000000
mean    -25.423356
std            NaN
min     -25.423356
25%     -25.423356
50%     -25.423356
75%     -25.423356
max     -25.423356
dtype: float64
#########################
[50]>> env.reset()
=========================
[50]>>[1]: env.step(5)
action:[0, 0.00558157]
reward:0.029572599475922296
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.344477 0.198127]
done:False
-------------------------
[50]>>[2]: env.step(3)
action:[0, 5.344477]
reward:0.1564320994266648
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.514041 0.201264]
done:False
-------------------------
[50]>>[3]: env.step(2)
action:[3.5, 0.514041]
reward:-0.6948979833081886
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.517354 0.202889]
done:False
-------------------------
[50]>>[4]: env.step(3)
action:[3.5, 5.517354]
reward:0.20179690189655886
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.01746  0.337094]
done:False
-------------------------
[50]>>[5]: env.step(5)
action:[3.5, 1.01746]
reward:0.15253837821031244
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.5491   0.895916]
done:False
-------------------------
[50]>>[6]: env.step(2)
action:[3.5, 1.5491]
reward:0.1649352545446181
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.56498 1.83547]
done:False
-------------------------
[50]>>[7]: env.step(3)
action:[3.5, 6.56498]
reward:0.26734095335795643
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.5542  2.85184]
done:False
-------------------------
[50]>>[8]: env.step(4)
action:[3.5, 0.7771]
reward:0.13026845898732578
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.34278 3.53172]
done:False
-------------------------
[50]>>[9]: env.step(3)
action:[3.5, 6.34278]
reward:0.27611721548949447
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.71752 3.77169]
done:False
-------------------------
[50]>>[10]: env.step(2)
action:[3.5, 1.71752]
reward:0.22285675306017771
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.22286 3.80016]
done:False
-------------------------
[50]>>[11]: env.step(2)
action:[3.5, 2.22286]
reward:0.24445357791277772
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.35962 3.78212]
done:False
-------------------------
[50]>>[12]: env.step(3)
action:[3.5, 7.35962]
reward:0.3737554584062036
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.67651 3.76498]
done:False
-------------------------
[50]>>[13]: env.step(0)
action:[-3.5, 2.67651]
reward:-1.176255370045845
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      48.575    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.22254  2.74237]
done:False
-------------------------
[50]>>[14]: env.step(2)
action:[3.5, 3.22254]
reward:-1.1645543474668754
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.602     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.23156   0.525181]
done:False
-------------------------
[50]>>[15]: env.step(2)
action:[3.5, 3.23156]
reward:0.34541562497832623
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 46.0686    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.35361  -0.999886]
done:False
-------------------------
[50]>>[16]: env.step(3)
action:[3.5, 8.35361]
reward:0.4545268729311943
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.6684    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.45305  -0.910017]
done:False
-------------------------
[50]>>[17]: env.step(4)
action:[3.5, 1.726525]
reward:0.2373272035310594
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 42.0166    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.39676   0.424316]
done:False
-------------------------
[50]>>[18]: env.step(3)
action:[3.5, 7.3967600000000004]
reward:0.34202227674316554
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      41.1733
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26997  2.04697]
done:False
-------------------------
[50]>>[19]: env.step(1)
action:[0, 2.26997]
reward:-0.49213386913736684
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      39.6882   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.51183  3.08424]
done:False
-------------------------
[50]>>[20]: env.step(3)
action:[0, 7.51183]
reward:0.3916483137976939
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.8018   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.86377  3.08823]
done:False
-------------------------
[50]>>[21]: env.step(2)
action:[3.5, 2.86377]
reward:-0.4328682079322481
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      35.8554   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.09365  3.79438]
done:False
-------------------------
[50]>>[22]: env.step(2)
action:[3.5, 3.09365]
reward:0.3276585422344644
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.6245   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.16689  3.87786]
done:False
-------------------------
[50]>>[23]: env.step(3)
action:[3.5, 8.16689]
reward:0.43826955660664496
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.2921   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.29174  3.8404 ]
done:False
-------------------------
[50]>>[24]: env.step(3)
action:[3.5, 8.29174]
reward:0.5286966710911
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.3892   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.42895  3.85716]
done:False
-------------------------
[50]>>[25]: env.step(1)
action:[0, 4.42895]
reward:-0.23838400937873816
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      25.3401  48.3792   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.17173  2.26699]
done:False
-------------------------
[50]>>[26]: env.step(3)
action:[0, 10.17173]
reward:0.6173001872723071
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 22.9882   45.6945    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.13346  -0.224513]
done:False
-------------------------
[50]>>[27]: env.step(2)
action:[3.5, 5.13346]
reward:-0.2525538569921729
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.3862   42.1354    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.81148   0.488477]
done:False
-------------------------
[50]>>[28]: env.step(0)
action:[-3.5, 4.81148]
reward:-0.9924907674812506
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.6181  38.9678   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.02266 -1.1324 ]
done:False
-------------------------
[50]>>[29]: env.step(3)
action:[-3.5, 10.02266]
reward:0.62256323996601
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.9197   0.      36.2866
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.24151 -3.6246 ]
done:False
-------------------------
[50]>>[30]: env.step(1)
action:[0, 5.24151]
reward:-0.19423454319464917
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.2286   0.      49.0134  32.6408   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.54702 -2.27053]
done:False
-------------------------
[50]>>[31]: env.step(0)
action:[-3.5, 5.54702]
reward:-0.18904594039257538
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.57059  0.
  0.      29.0744   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.53911 -0.91927]
done:False
-------------------------
[50]>>[32]: env.step(0)
action:[-3.5, 5.53911]
reward:0.5493243123907333
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.16724  0.       0.       0.       0.       0.      25.8878   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.38777 -3.2081 ]
done:False
-------------------------
[50]>>[33]: env.step(3)
action:[-3.5, 10.38777]
reward:0.637781259869133
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.62394
  0.       0.       0.       0.       0.       0.       0.       0.
 38.4374  21.9554   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.35558 -2.9598 ]
done:False
-------------------------
[50]>>[34]: env.step(0)
action:[-3.5, 5.35558]
reward:0.5676315398215281
observation:
[ 0.       0.       0.       0.       8.38519  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.405   17.8928   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.67524 -2.96232]
done:False
-------------------------
[50]>>[35]: env.step(3)
action:[-3.5, 10.675239999999999]
reward:0.6643480269093227
observation:
[ 0.       0.       0.      11.5395   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.6912   0.      49.5264   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.64469 -2.93855]
done:False
-------------------------
[50]>>[36]: env.step(0)
action:[-3.5, 5.64469]
reward:0.564438381694946
observation:
[ 0.       0.      15.185    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.59514  0.      45.3306   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.56073 -2.90861]
done:False
-------------------------
[50]>>[37]: env.step(5)
action:[-3.5, 5.56073]
reward:0.5544247162392837
observation:
[ 0.       0.      18.9826   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.72455
 22.1701   0.      41.2172   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.44954 -2.8804 ]
done:False
-------------------------
[50]>>[38]: env.step(1)
action:[0, 5.44954]
reward:-25.180607321607077
observation:
[ 0.       0.       0.       0.      21.1981   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.15697 19.519    0.      38.6935   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.67506 -2.16178]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 80.4748, 'y': -2.16178, 'z': 0.569619}
.........................
** Rewards description :
count    38.000000
mean     -0.551173
std       4.132857
min     -25.180607
25%      -0.192937
50%       0.240890
75%       0.450463
max       0.664348
dtype: float64
#########################
[51]>> env.reset()
=========================
Retrying to reset environment!
[51]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.5826881429474935
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.98082  -0.921225]
done:False
-------------------------
[51]>>[2]: env.step(3)
action:[-3.5, 6.98082]
reward:0.31038862860508715
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.98082  -0.832562]
done:False
-------------------------
[51]>>[3]: env.step(3)
action:[-3.5, 6.98082]
reward:0.3095422693589432
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.97034  -0.385484]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.04636, 'y': -0.385484, 'z': 0.570228}
.........................
** Rewards description :
count    3.000000
mean     0.012414
std      0.515374
min     -0.582688
25%     -0.136573
50%      0.309542
75%      0.309965
max      0.310389
dtype: float64
#########################
[52]>> env.reset()
=========================
[52]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.75
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.1992]
done:False
-------------------------
[52]>>[2]: env.step(5)
action:[3.5, 0.0]
reward:0.16524606774125036
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.95599  -0.890262]
done:False
-------------------------
[52]>>[3]: env.step(4)
action:[3.5, 0.977995]
reward:0.18555171492887926
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.95599  -0.861511]
done:False
-------------------------
[52]>>[4]: env.step(3)
action:[3.5, 6.95599]
reward:0.307192344688074
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.94746  -0.438245]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.00259, 'y': -0.438245, 'z': 0.570165}
.........................
** Rewards description :
count    4.000000
mean    -0.023002
std      0.488701
min     -0.750000
25%     -0.063565
50%      0.175399
75%      0.215962
max      0.307192
dtype: float64
#########################
[53]>> env.reset()
=========================
[53]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.16360316552489962
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.93625  -0.906175]
done:False
-------------------------
[53]>>[2]: env.step(3)
action:[0, 6.93625]
reward:0.2998727920464803
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86189  -0.962078]
done:False
-------------------------
[53]>>[3]: env.step(0)
action:[-3.5, 1.86189]
reward:-0.5700192787154956
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.66784  -0.806709]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.05561, 'y': -0.806709, 'z': 0.570921}
.........................
** Rewards description :
count    3.000000
mean    -0.035514
std      0.467882
min     -0.570019
25%     -0.203208
50%      0.163603
75%      0.231738
max      0.299873
dtype: float64
#########################
[54]>> env.reset()
=========================
Retrying to reset environment!
[54]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.14784809645374153
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.497263 0.201525]
done:False
-------------------------
[54]>>[2]: env.step(5)
action:[0, 0.497263]
reward:0.10035955983547089
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.05668  0.203757]
done:False
-------------------------
[54]>>[3]: env.step(2)
action:[3.5, 1.05668]
reward:-0.6031090499041147
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.47163 0.55601]
done:False
-------------------------
[54]>>[4]: env.step(4)
action:[3.5, 0.735815]
reward:0.12615377617074433
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     1.304  1.2429]
done:False
-------------------------
[54]>>[5]: env.step(5)
action:[3.5, 1.304]
reward:0.13637541459589414
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.284   2.08662]
done:False
-------------------------
[54]>>[6]: env.step(1)
action:[0, 1.284]
reward:-0.6141383570272527
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.28286 2.90769]
done:False
-------------------------
[54]>>[7]: env.step(4)
action:[0, 0.64143]
reward:0.1161369221297921
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.20822 3.27598]
done:False
-------------------------
[54]>>[8]: env.step(2)
action:[3.5, 1.20822]
reward:-0.6279353232310737
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.13714 3.59184]
done:False
-------------------------
[54]>>[9]: env.step(3)
action:[3.5, 6.1371400000000005]
reward:0.25874916084876987
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.55585 3.69465]
done:False
-------------------------
[54]>>[10]: env.step(4)
action:[3.5, 0.777925]
reward:0.24912612101964293
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.77793 3.7751 ]
done:False
-------------------------
[54]>>[11]: env.step(4)
action:[3.5, 1.388965]
reward:0.36393582880699327
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.04593 3.77558]
done:False
-------------------------
[54]>>[12]: env.step(3)
action:[3.5, 9.04593]
reward:0.5954048765794965
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      47.2399   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.12171  3.77673]
done:False
-------------------------
[54]>>[13]: env.step(5)
action:[3.5, 5.12171]
reward:0.5687734394827346
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.1253   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.74882  3.79518]
done:False
-------------------------
[54]>>[14]: env.step(1)
action:[0, 5.74882]
reward:-0.1524016024455701
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      39.4859   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.97527  1.85083]
done:False
-------------------------
[54]>>[15]: env.step(0)
action:[-3.5, 5.97527]
reward:-0.15245308515003075
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       36.3559    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.91797  -0.525019]
done:False
-------------------------
[54]>>[16]: env.step(3)
action:[-3.5, 10.91797]
reward:0.6872708431675437
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      33.0236   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.89812 -2.22574]
done:False
-------------------------
[54]>>[17]: env.step(0)
action:[-3.5, 5.89812]
reward:0.62404910051411
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 29.4677   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.29265 -3.60718]
done:False
-------------------------
[54]>>[18]: env.step(5)
action:[-3.5, 6.29265]
reward:0.6116281022170402
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 25.0357  47.1957   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.02708 -3.19847]
done:False
-------------------------
[54]>>[19]: env.step(4)
action:[-3.5, 4.02708]
reward:0.4765522670985958
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.0376  43.0483   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.81788 -3.09025]
done:False
-------------------------
[54]>>[20]: env.step(2)
action:[3.5, 4.81788]
reward:-0.990542762013368
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.6308   0.      39.9328   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.0464  -1.31152]
done:False
-------------------------
[54]>>[21]: env.step(3)
action:[3.5, 10.0464]
reward:0.5881391004855703
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.1164  39.1215   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.77474  2.27847]
done:False
-------------------------
[54]>>[22]: env.step(4)
action:[3.5, 2.38737]
reward:0.46558912294983096
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.6598
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.08664  5.42365]
done:False
-------------------------
[54]>>[23]: env.step(3)
action:[3.5, 10.08664]
reward:0.606415328294088
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.2916   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.00872  5.82257]
done:False
-------------------------
[54]>>[24]: env.step(0)
action:[-3.5, 5.00872]
reward:-0.990754116434784
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       8.5749  31.7726   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.99594  3.16932]
done:False
-------------------------
[54]>>[25]: env.step(1)
action:[0, 4.99594]
reward:-0.23964560494996023
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        8.0953    0.       46.4924   30.28      0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.01356  -0.177711]
done:False
-------------------------
[54]>>[26]: env.step(5)
action:[0, 5.01356]
reward:0.5077883525205716
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        5.87662
  0.        0.        0.       26.8758    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.97577  -0.940507]
done:False
-------------------------
[54]>>[27]: env.step(4)
action:[0, 2.487885]
reward:0.4611354317879375
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        3.07221   0.        0.
  0.        0.        0.        0.        0.       23.6279    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.00428   0.644596]
done:False
-------------------------
[54]>>[28]: env.step(0)
action:[-3.5, 5.00428]
reward:-0.24302446211055517
observation:
[ 0.        0.        5.15477   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       36.7759
 20.4298    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.96752  -0.990517]
done:False
-------------------------
[54]>>[29]: env.step(1)
action:[0, 4.96752]
reward:-0.24678255394130466
observation:
[ 0.       0.       0.       0.       8.20491  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      17.209    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.92787 -2.23649]
done:False
-------------------------
[54]>>[30]: env.step(3)
action:[0, 9.92787]
reward:0.5955603619681195
observation:
[ 0.         0.         0.         0.         0.         0.
  9.3988     0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        14.3032     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.9033     0.0878954]
done:False
-------------------------
[54]>>[31]: env.step(1)
action:[0, 4.9033]
reward:0.5849580465789939
observation:
[12.8333    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       26.706    10.528     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.01818   0.743314]
done:False
-------------------------
[54]>>[32]: env.step(5)
action:[0, 6.01818]
reward:0.6863434226362801
observation:
[17.6801    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.8293    5.63887   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.11031   0.647065]
done:False
-------------------------
[54]>>[33]: env.step(1)
action:[0, 7.11031]
reward:-24.26464811825452
observation:
[19.8723    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.6444   39.6827    3.4703    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.51735   0.594593]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.5891, 'y': 0.594593, 'z': 0.57119}
.........................
** Rewards description :
count    33.000000
mean     -0.592944
std       4.277645
min     -24.264648
25%      -0.239646
50%       0.249126
75%       0.584958
max       0.687271
dtype: float64
#########################
[55]>> env.reset()
=========================
[55]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7323863491625647
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.205796 0.339654]
done:False
-------------------------
[55]>>[2]: env.step(5)
action:[3.5, 0.205796]
reward:0.032543316676395255
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.329264 0.511389]
done:False
-------------------------
[55]>>[3]: env.step(5)
action:[3.5, 0.329264]
reward:0.05299603778862888
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.538751 0.699503]
done:False
-------------------------
[55]>>[4]: env.step(3)
action:[3.5, 5.5387509999999995]
reward:0.20260975031937511
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.02195 1.09185]
done:False
-------------------------
[55]>>[5]: env.step(4)
action:[3.5, 0.510975]
reward:0.10531328117905606
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.11209 1.7662 ]
done:False
-------------------------
[55]>>[6]: env.step(3)
action:[3.5, 6.11209]
reward:0.2463883934856145
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.41094 2.56197]
done:False
-------------------------
[55]>>[7]: env.step(1)
action:[0, 1.41094]
reward:-0.4826680129060948
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.8426  3.63983]
done:False
-------------------------
[55]>>[8]: env.step(3)
action:[0, 7.8426]
reward:0.4963051296450419
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.1194  3.84868]
done:False
-------------------------
[55]>>[9]: env.step(5)
action:[0, 4.1194]
reward:0.4681615806152773
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.68672 2.2281 ]
done:False
-------------------------
[55]>>[10]: env.step(3)
action:[0, 9.686720000000001]
reward:0.5958093102547957
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.96691  -0.194311]
done:False
-------------------------
[55]>>[11]: env.step(1)
action:[0, 4.96691]
reward:0.5085193059408013
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       46.7633    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.99694   0.328481]
done:False
-------------------------
[55]>>[12]: env.step(4)
action:[0, 2.49847]
reward:0.3273146494408764
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.94      0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.31141   0.325988]
done:False
-------------------------
[55]>>[13]: env.step(4)
action:[0, 1.655705]
reward:0.30211943047585166
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.5291    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.20979   0.296986]
done:False
-------------------------
[55]>>[14]: env.step(5)
action:[0, 3.20979]
reward:0.3387352029406464
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.1045    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.27573   0.307835]
done:False
-------------------------
[55]>>[15]: env.step(0)
action:[-3.5, 3.27573]
reward:-0.3855472001478701
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       37.0089
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.58072  -0.849328]
done:False
-------------------------
[55]>>[16]: env.step(3)
action:[-3.5, 8.58072]
reward:0.46630360006428717
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      35.7876   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.54749 -3.01459]
done:False
-------------------------
[55]>>[17]: env.step(0)
action:[-3.5, 3.54749]
reward:0.3767147357324759
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.3202   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.66674 -3.3036 ]
done:False
-------------------------
[55]>>[18]: env.step(1)
action:[0, 3.66674]
reward:-0.3596366058601195
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      30.7607   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.80883 -2.05954]
done:False
-------------------------
[55]>>[19]: env.step(3)
action:[0, 8.80883]
reward:0.5078196848882899
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 28.6378    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.02736   0.378242]
done:False
-------------------------
[55]>>[20]: env.step(4)
action:[0, 2.01368]
reward:0.28049266107316106
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.3176   49.1372    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.8536    0.524108]
done:False
-------------------------
[55]>>[21]: env.step(4)
action:[0, 1.4268]
reward:0.26042330150363846
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.263    47.0609    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.75394   0.418426]
done:False
-------------------------
[55]>>[22]: env.step(4)
action:[0, 1.37697]
reward:0.2586207489011887
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.2216   45.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.74432   0.409394]
done:False
-------------------------
[55]>>[23]: env.step(4)
action:[0, 1.37216]
reward:0.2079104394501634
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.5075   43.2685    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.1278    0.419735]
done:False
-------------------------
[55]>>[24]: env.step(2)
action:[3.5, 2.1278]
reward:-0.49998544377759857
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      18.9257  41.7834   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.45132  1.17796]
done:False
-------------------------
[55]>>[25]: env.step(3)
action:[3.5, 7.45132]
reward:0.37217820881643227
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      17.6901  40.7555
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.63377  2.74108]
done:False
-------------------------
[55]>>[26]: env.step(2)
action:[3.5, 2.63377]
reward:0.38955696963913367
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      15.8111   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.0569   4.15557]
done:False
-------------------------
[55]>>[27]: env.step(2)
action:[3.5, 4.0569]
reward:0.4964921738679666
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.3835   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.06825  3.9328 ]
done:False
-------------------------
[55]>>[28]: env.step(5)
action:[3.5, 5.06825]
reward:0.5534412960703631
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.37138 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.5597  3.96634]
done:False
-------------------------
[55]>>[29]: env.step(5)
action:[3.5, 5.5597]
reward:-24.440966083636408
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.22899 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.51059 4.00464]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8331, 'y': 4.00464, 'z': 0.5688}
.........................
** Rewards description :
count    29.000000
mean     -0.657049
std       4.587889
min     -24.440966
25%       0.052996
50%       0.280493
75%       0.466304
max       0.595809
dtype: float64
#########################
[56]>> env.reset()
=========================
[56]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7475512743820926
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0285743 0.219058 ]
done:False
-------------------------
[56]>>[2]: env.step(1)
action:[0, 0.0285743]
reward:-0.7276221385096961
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.254422 0.235991]
done:False
-------------------------
[56]>>[3]: env.step(1)
action:[0, 0.254422]
reward:0.049656829062365515
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.518162 0.224719]
done:False
-------------------------
[56]>>[4]: env.step(3)
action:[0, 5.518162]
reward:0.1965992603638441
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.95438  0.223884]
done:False
-------------------------
[56]>>[5]: env.step(1)
action:[0, 0.95438]
reward:0.2059828465790487
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.20889  0.217085]
done:False
-------------------------
[56]>>[6]: env.step(1)
action:[0, 2.20889]
reward:0.33856951038815963
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.52389  0.221816]
done:False
-------------------------
[56]>>[7]: env.step(2)
action:[3.5, 3.52389]
reward:-0.34278358900410516
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.05759 1.53325]
done:False
-------------------------
[56]>>[8]: env.step(3)
action:[3.5, 9.057590000000001]
reward:0.5176019689965354
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.09257 3.87166]
done:False
-------------------------
[56]>>[9]: env.step(3)
action:[3.5, 9.09257]
reward:0.49690383020848294
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.2228   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.81467  3.80595]
done:False
-------------------------
[56]>>[10]: env.step(4)
action:[3.5, 1.907335]
reward:0.25601756528301095
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.0399   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.57986  3.76373]
done:False
-------------------------
[56]>>[11]: env.step(4)
action:[3.5, 1.28993]
reward:0.23773823801629237
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.1472   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.51092  3.79017]
done:False
-------------------------
[56]>>[12]: env.step(3)
action:[3.5, 7.5109200000000005]
reward:0.38575262487156714
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.1891   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.78965  3.79914]
done:False
-------------------------
[56]>>[13]: env.step(1)
action:[0, 2.78965]
reward:-0.41305003386614203
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      41.2087   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.35852  2.75132]
done:False
-------------------------
[56]>>[14]: env.step(4)
action:[0, 1.67926]
reward:0.23300035937286978
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      40.1729   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.35585  1.01858]
done:False
-------------------------
[56]>>[15]: env.step(1)
action:[0, 2.35585]
reward:0.2423536955679939
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      38.7812   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30074  0.2807 ]
done:False
-------------------------
[56]>>[16]: env.step(4)
action:[0, 1.15037]
reward:0.17577043670220302
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       37.398     0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.795     0.257842]
done:False
-------------------------
[56]>>[17]: env.step(5)
action:[0, 1.795]
reward:0.1984233620821357
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.0255    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.90723   0.287107]
done:False
-------------------------
[56]>>[18]: env.step(2)
action:[3.5, 1.90723]
reward:-0.51960595536078
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       34.5699    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.26712   0.910662]
done:False
-------------------------
[56]>>[19]: env.step(3)
action:[3.5, 7.26712]
reward:0.3644685522732574
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.2968   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.58307  2.39888]
done:False
-------------------------
[56]>>[20]: env.step(5)
action:[3.5, 2.58307]
reward:0.3787449848361253
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      31.6225   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.93338  3.98112]
done:False
-------------------------
[56]>>[21]: env.step(0)
action:[-3.5, 3.93338]
reward:-1.0417105197322636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.5441   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.60637  3.68718]
done:False
-------------------------
[56]>>[22]: env.step(1)
action:[0, 4.60637]
reward:-0.2767455251253378
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       26.5718    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.63055   0.994767]
done:False
-------------------------
[56]>>[23]: env.step(2)
action:[3.5, 4.63055]
reward:-0.27529788617787887
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      24.6164  47.1902
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.64316 -1.14961]
done:False
-------------------------
[56]>>[24]: env.step(0)
action:[-3.5, 4.64316]
reward:-1.023546219206032
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       21.3364   43.9742
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.66259  -0.313068]
done:False
-------------------------
[56]>>[25]: env.step(3)
action:[-3.5, 9.66259]
reward:0.5846499951783688
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.        18.1693    40.8266     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.82426    0.0735152]
done:False
-------------------------
[56]>>[26]: env.step(1)
action:[0, 4.82426]
reward:-0.24271415596768875
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       14.7954    0.       37.4332
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.01656   0.336218]
done:False
-------------------------
[56]>>[27]: env.step(0)
action:[-3.5, 5.01656]
reward:-0.2218930999242108
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       11.7564    0.
 33.9523    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.24003  -0.763049]
done:False
-------------------------
[56]>>[28]: env.step(3)
action:[-3.5, 10.24003]
reward:0.644126536865997
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.906    0.       0.       0.      31.5392   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.47844 -3.57013]
done:False
-------------------------
[56]>>[29]: env.step(2)
action:[3.5, 5.47844]
reward:-0.9247718701183815
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       7.45151
  0.       0.       0.       0.      27.4316   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.74516 -2.48957]
done:False
-------------------------
[56]>>[30]: env.step(1)
action:[0, 5.74516]
reward:-0.18951205205412824
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       3.67637  0.
  0.      42.0475  25.9606   0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.48342  1.44337]
done:False
-------------------------
[56]>>[31]: env.step(2)
action:[3.5, 5.48342]
reward:-25.19612823284625
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       3.49473  0.
  0.      42.0057  25.9512   0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.46158  1.71615]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.0401, 'y': 1.71615, 'z': 0.569903}
.........................
** Rewards description :
count    31.000000
mean     -0.859244
std       4.542718
min     -25.196128
25%      -0.377917
50%       0.175770
75%       0.297294
max       0.644127
dtype: float64
#########################
[57]>> env.reset()
=========================
[57]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.7248990629941827
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.293462 0.398071]
done:False
-------------------------
[57]>>[2]: env.step(4)
action:[-3.5, 0.146731]
reward:0.0282310728561393
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.293462 0.612889]
done:False
-------------------------
[57]>>[3]: env.step(3)
action:[-3.5, 5.293462]
reward:0.1369466554056429
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.293462 0.818342]
done:False
-------------------------
[57]>>[4]: env.step(3)
action:[-3.5, 5.293462]
reward:0.15205641563464692
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.474322 1.04838 ]
done:False
-------------------------
[57]>>[5]: env.step(5)
action:[-3.5, 0.474322]
reward:0.0998006409602356
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.05578 1.09309]
done:False
-------------------------
[57]>>[6]: env.step(5)
action:[-3.5, 1.05578]
reward:0.11117329414692659
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.04556 1.00768]
done:False
-------------------------
[57]>>[7]: env.step(3)
action:[-3.5, 6.04556]
reward:0.24655192961232353
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.42957  0.724949]
done:False
-------------------------
[57]>>[8]: env.step(2)
action:[3.5, 1.42957]
reward:-1.3002281814835488
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.0149   0.976142]
done:False
-------------------------
[57]>>[9]: env.step(0)
action:[-3.5, 2.0149]
reward:-1.2897024592036428
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.99605 2.02624]
done:False
-------------------------
[57]>>[10]: env.step(3)
action:[-3.5, 6.99605]
reward:0.3090784406049273
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.96079 3.2046 ]
done:False
-------------------------
[57]>>[11]: env.step(5)
action:[-3.5, 1.96079]
reward:0.2330736321782792
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.28636 3.62547]
done:False
-------------------------
[57]>>[12]: env.step(0)
action:[-3.5, 2.28636]
reward:0.25246495089718324
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.44164 3.24108]
done:False
-------------------------
[57]>>[13]: env.step(5)
action:[-3.5, 2.44164]
reward:0.26685634302605876
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.57909 2.01318]
done:False
-------------------------
[57]>>[14]: env.step(5)
action:[-3.5, 2.57909]
reward:0.27364630788837985
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.62808  0.167195]
done:False
-------------------------
[57]>>[15]: env.step(3)
action:[-3.5, 7.628080000000001]
reward:0.37614030712865415
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.63937 -1.75607]
done:False
-------------------------
[57]>>[16]: env.step(3)
action:[-3.5, 7.6393699999999995]
reward:0.4235949297523658
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      49.5638   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.23662 -3.6278 ]
done:False
-------------------------
[57]>>[17]: env.step(0)
action:[-3.5, 3.23662]
reward:0.36723887223150825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      47.5826   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.62544 -4.56286]
done:False
-------------------------
[57]>>[18]: env.step(4)
action:[-3.5, 1.81272]
reward:0.24841163279822456
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.5489   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5105  -3.98441]
done:False
-------------------------
[57]>>[19]: env.step(2)
action:[3.5, 2.5105]
reward:-1.2445633042049034
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.6764   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.42196 -3.30299]
done:False
-------------------------
[57]>>[20]: env.step(2)
action:[3.5, 2.42196]
reward:0.2544188030177913
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      41.8646   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.43164 -3.16993]
done:False
-------------------------
[57]>>[21]: env.step(3)
action:[3.5, 7.43164]
reward:0.3924804744383441
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      40.1227   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.89432 -2.05282]
done:False
-------------------------
[57]>>[22]: env.step(2)
action:[3.5, 2.89432]
reward:0.33490401328319713
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 38.9939     0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  3.30687    0.0952041]
done:False
-------------------------
[57]>>[23]: env.step(4)
action:[3.5, 1.653435]
reward:0.23254171220950223
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.5261   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.35672  2.07244]
done:False
-------------------------
[57]>>[24]: env.step(2)
action:[3.5, 2.35672]
reward:0.2641189269197406
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.0774   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.56675  3.82006]
done:False
-------------------------
[57]>>[25]: env.step(3)
action:[3.5, 7.56675]
reward:0.3835894236726989
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      36.5936   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.74844  4.99713]
done:False
-------------------------
[57]>>[26]: env.step(5)
action:[3.5, 2.74844]
reward:0.29809804195757905
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.6      0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88692  5.15351]
done:False
-------------------------
[57]>>[27]: env.step(4)
action:[3.5, 1.44346]
reward:0.20667622203196373
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.0216   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09502  4.3425 ]
done:False
-------------------------
[57]>>[28]: env.step(5)
action:[3.5, 2.09502]
reward:0.23026076586903677
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.4697   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.21855  3.91586]
done:False
-------------------------
[57]>>[29]: env.step(5)
action:[3.5, 2.21855]
reward:0.2444505064826336
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.6404   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.36066  3.84297]
done:False
-------------------------
[57]>>[30]: env.step(0)
action:[-3.5, 2.36066]
reward:-1.2316158163722517
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.0993   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.61808  2.8102 ]
done:False
-------------------------
[57]>>[31]: env.step(2)
action:[3.5, 2.61808]
reward:-1.2170459566961673
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       27.3256    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.73279   0.975689]
done:False
-------------------------
[57]>>[32]: env.step(1)
action:[0, 2.73279]
reward:-0.45949873601132296
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       25.9853
 48.7378    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.79709  -0.192109]
done:False
-------------------------
[57]>>[33]: env.step(3)
action:[0, 7.79709]
reward:0.40304301149144883
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       23.9863   46.6974    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.93645  -0.186682]
done:False
-------------------------
[57]>>[34]: env.step(2)
action:[3.5, 2.93645]
reward:-0.43529503776212486
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.0162  44.875    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.04539  1.05695]
done:False
-------------------------
[57]>>[35]: env.step(2)
action:[3.5, 3.04539]
reward:0.30750910556363387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.7534
 43.8516   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.92903  3.08245]
done:False
-------------------------
[57]>>[36]: env.step(5)
action:[3.5, 2.92903]
reward:0.33193947215394126
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.8746  42.0907   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.26129  4.21957]
done:False
-------------------------
[57]>>[37]: env.step(0)
action:[-3.5, 3.26129]
reward:-1.1553140736655054
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.5435   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.33707  3.78914]
done:False
-------------------------
[57]>>[38]: env.step(3)
action:[-3.5, 8.33707]
reward:0.45164487673463016
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.8999  37.901    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.42025  1.93346]
done:False
-------------------------
[57]>>[39]: env.step(3)
action:[-3.5, 8.42025]
reward:0.4599331062687665
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.       14.7274    0.       37.156     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.50575  -0.733938]
done:False
-------------------------
[57]>>[40]: env.step(0)
action:[-3.5, 3.50575]
reward:0.4085301743823252
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 15.0793   0.      36.6041   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.07877 -3.40734]
done:False
-------------------------
[57]>>[41]: env.step(3)
action:[-3.5, 9.078769999999999]
reward:0.5346528272502356
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.6544   0.       0.      34.1893
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.31018 -4.78549]
done:False
-------------------------
[57]>>[42]: env.step(1)
action:[0, 4.31018]
reward:-0.2749900779469157
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.7216   0.       0.      47.5053  31.047    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.72722 -3.70907]
done:False
-------------------------
[57]>>[43]: env.step(4)
action:[0, 2.36361]
reward:0.4211978785839481
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  7.62163   0.        0.       29.3086    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.52508  -0.553059]
done:False
-------------------------
[57]>>[44]: env.step(2)
action:[3.5, 4.52508]
reward:-0.2875801125486852
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       5.75482 28.8159   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.51148  2.77435]
done:False
-------------------------
[57]>>[45]: env.step(5)
action:[3.5, 4.51148]
reward:0.4857852191567166
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.1754  27.6715
  0.       4.49341  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.81599  5.63468]
done:False
-------------------------
[57]>>[46]: env.step(5)
action:[3.5, 4.81599]
reward:0.48915152102056175
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.8502  24.5017   0.       0.       0.       0.       0.
  2.40986  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.7834   5.87962]
done:False
-------------------------
[57]>>[47]: env.step(4)
action:[3.5, 2.3917]
reward:-24.604891232938385
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 39.0663  23.6637   0.       0.       0.       0.       0.       0.
  0.       1.90858  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.18749  5.42943]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 60.1742, 'y': 5.42943, 'z': 0.569731}
.........................
** Rewards description :
count    47.000000
mean     -0.501392
std       3.634504
min     -24.604891
25%      -0.123380
50%       0.248412
75%       0.371690
max       0.534653
dtype: float64
#########################
[58]>> env.reset()
=========================
[58]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.13255022711276052
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.5643   -0.763931]
done:False
-------------------------
[58]>>[2]: env.step(4)
action:[0, 0.78215]
reward:0.14889701710880565
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.56429 -1.18364]
done:False
-------------------------
[58]>>[3]: env.step(3)
action:[0, 6.56429]
reward:0.26814927327362703
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.56429  -0.723752]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.01925, 'y': -0.723752, 'z': 0.572092}
.........................
** Rewards description :
count    3.000000
mean     0.183199
std      0.074022
min      0.132550
25%      0.140724
50%      0.148897
75%      0.208523
max      0.268149
dtype: float64
#########################
[59]>> env.reset()
=========================
[59]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.1325493897914998
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.56429  -0.763931]
done:False
-------------------------
[59]>>[2]: env.step(2)
action:[3.5, 1.56429]
reward:-0.5977471234867477
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.40897 -1.26504]
done:False
-------------------------
[59]>>[3]: env.step(3)
action:[3.5, 6.40897]
reward:0.203253768331709
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.812192 -1.37903 ]
done:False
-------------------------
[59]>>[4]: env.step(0)
action:[-3.5, 0.812192]
reward:-1.3720077447348813
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.30684 -1.85942]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.00149, 'y': -1.85942, 'z': 0.570548}
.........................
** Rewards description :
count    4.000000
mean    -0.408488
std      0.737369
min     -1.372008
25%     -0.791312
50%     -0.232599
75%      0.150225
max      0.203254
dtype: float64
#########################
[60]>> env.reset()
=========================
[60]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.02888817825998962
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.337848 0.432924]
done:False
-------------------------
[60]>>[2]: env.step(3)
action:[0, 5.337848]
reward:0.15538937265182085
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.50319  0.684065]
done:False
-------------------------
[60]>>[3]: env.step(0)
action:[-3.5, 0.50319]
reward:-0.5675194008744285
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.03765  0.571539]
done:False
-------------------------
[60]>>[4]: env.step(0)
action:[-3.5, 2.03765]
reward:0.31811134497276455
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.31233  0.271276]
done:False
-------------------------
[60]>>[5]: env.step(3)
action:[-3.5, 8.31233]
reward:0.5475728131683236
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.67142 -1.28922]
done:False
-------------------------
[60]>>[6]: env.step(3)
action:[-3.5, 9.671420000000001]
reward:0.675273901307384
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.04505 -3.99895]
done:False
-------------------------
[60]>>[7]: env.step(3)
action:[-3.5, 11.04505]
reward:0.7773372292493486
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.3562   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.12645 -3.09237]
done:False
-------------------------
[60]>>[8]: env.step(3)
action:[-3.5, 12.12645]
reward:0.8810164095149959
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.5707   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.36595 -3.15447]
done:False
-------------------------
[60]>>[9]: env.step(4)
action:[-3.5, 6.36595]
reward:0.7047508058641129
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      36.5171   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.27737 -3.15126]
done:False
-------------------------
[60]>>[10]: env.step(4)
action:[-3.5, 5.27737]
reward:0.6749569200616722
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.2316   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.13922 -3.1332 ]
done:False
-------------------------
[60]>>[11]: env.step(3)
action:[-3.5, 12.13922]
reward:0.7907933230086159
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 26.0583  48.2687   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.04502 -3.1081 ]
done:False
-------------------------
[60]>>[12]: env.step(3)
action:[-3.5, 12.045020000000001]
reward:0.785309604790241
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.019   43.0295   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.99015 -3.08098]
done:False
-------------------------
[60]>>[13]: env.step(2)
action:[3.5, 6.99015]
reward:-0.7342478191408025
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.7968
  0.      37.4474   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.97562 -3.05145]
done:False
-------------------------
[60]>>[14]: env.step(4)
action:[3.5, 5.97562]
reward:0.6778879803250821
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 10.7022   49.0824   32.82      0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.00483  -0.677038]
done:False
-------------------------
[60]>>[15]: env.step(3)
action:[3.5, 12.00483]
reward:0.780966140345963
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       8.72393 32.0181   0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.93821  4.32714]
done:False
-------------------------
[60]>>[16]: env.step(3)
action:[3.5, 11.93821]
reward:0.8670553383496534
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.1853  27.9026   0.       5.11183  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.2055   6.77909]
done:False
-------------------------
[60]>>[17]: env.step(1)
action:[0, 8.2055]
reward:-24.921086323356093
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      40.4895   0.
 25.0728   0.       0.       0.       2.46013  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.57868  5.63139]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 58.5491, 'y': 5.63139, 'z': 0.569598}
.........................
** Rewards description :
count    17.000000
mean     -1.032797
std       6.174880
min     -24.921086
25%       0.155389
50%       0.675274
75%       0.780966
max       0.881016
dtype: float64
#########################
[61]>> env.reset()
=========================
[61]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.14628215374824244
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.72851  -0.723032]
done:False
-------------------------
[61]>>[2]: env.step(3)
action:[0, 6.72851]
reward:0.29120602135497414
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.80685  -0.555273]
done:False
-------------------------
[61]>>[3]: env.step(2)
action:[3.5, 1.80685]
reward:-0.5932618098086715
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.40212  -0.318917]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.06666, 'y': -0.318917, 'z': 0.570612}
.........................
** Rewards description :
count    3.000000
mean    -0.051925
std      0.474379
min     -0.593262
25%     -0.223490
50%      0.146282
75%      0.218744
max      0.291206
dtype: float64
#########################
[62]>> env.reset()
=========================
Retrying to reset environment!
[62]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.01792557589249455
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.209446 0.341272]
done:False
-------------------------
[62]>>[2]: env.step(3)
action:[0, 5.209446]
reward:0.16974727303231443
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.707744 0.494456]
done:False
-------------------------
[62]>>[3]: env.step(1)
action:[0, 0.707744]
reward:0.125012889336248
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.29741  0.310106]
done:False
-------------------------
[62]>>[4]: env.step(5)
action:[0, 1.29741]
reward:0.15787745966519395
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.54315  0.248877]
done:False
-------------------------
[62]>>[5]: env.step(4)
action:[0, 0.771575]
reward:0.1303579851047298
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.34523 0.22418]
done:False
-------------------------
[62]>>[6]: env.step(1)
action:[0, 1.34523]
reward:0.15999157512490747
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.55657  0.220132]
done:False
-------------------------
[62]>>[7]: env.step(3)
action:[0, 6.55657]
reward:0.28556615324995477
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.78033 0.22259]
done:False
-------------------------
[62]>>[8]: env.step(4)
action:[0, 0.890165]
reward:0.14259791989116366
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.46187  0.229099]
done:False
-------------------------
[62]>>[9]: env.step(1)
action:[0, 1.46187]
reward:0.17224440795971546
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.67468  0.237344]
done:False
-------------------------
[62]>>[10]: env.step(5)
action:[0, 1.67468]
reward:0.19383445790193954
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.88183 0.24618]
done:False
-------------------------
[62]>>[11]: env.step(0)
action:[-3.5, 1.88183]
reward:-0.523055535459727
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.23149  -0.471276]
done:False
-------------------------
[62]>>[12]: env.step(1)
action:[0, 2.23149]
reward:-0.5099469234603367
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.9527   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30376 -0.37222]
done:False
-------------------------
[62]>>[13]: env.step(3)
action:[0, 7.3037600000000005]
reward:0.3364849786926707
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       47.353     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.2242    0.131047]
done:False
-------------------------
[62]>>[14]: env.step(4)
action:[0, 1.1121]
reward:0.16486368581678412
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       45.993     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.67337   0.269512]
done:False
-------------------------
[62]>>[15]: env.step(2)
action:[3.5, 1.67337]
reward:-0.5425861405501053
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       44.8122
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04648   0.969702]
done:False
-------------------------
[62]>>[16]: env.step(3)
action:[3.5, 7.04648]
reward:0.3428424051251065
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.8517   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.36777  2.2868 ]
done:False
-------------------------
[62]>>[17]: env.step(1)
action:[0, 2.36777]
reward:-0.46582651756386617
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      42.2377   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.81038  3.07614]
done:False
-------------------------
[62]>>[18]: env.step(3)
action:[0, 7.81038]
reward:0.423416655509589
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 40.1403   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.1916   2.67502]
done:False
-------------------------
[62]>>[19]: env.step(3)
action:[0, 8.191600000000001]
reward:0.5289003732207023
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       37.9338
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.45665   0.564818]
done:False
-------------------------
[62]>>[20]: env.step(5)
action:[0, 4.45665]
reward:0.49830176504369106
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.4367    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.99178   0.369898]
done:False
-------------------------
[62]>>[21]: env.step(4)
action:[0, 2.49589]
reward:0.3214377993431441
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.6315   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.23905  0.36644]
done:False
-------------------------
[62]>>[22]: env.step(5)
action:[0, 3.23905]
reward:0.32617740053412575
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.2775    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.11213   0.362098]
done:False
-------------------------
[62]>>[23]: env.step(3)
action:[0, 8.11213]
reward:0.4154029955207972
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.9981   49.8108    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.01434   0.377942]
done:False
-------------------------
[62]>>[24]: env.step(0)
action:[-3.5, 3.01434]
reward:-0.43578778283767683
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       25.2356
 47.8912    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.01981  -0.687783]
done:False
-------------------------
[62]>>[25]: env.step(5)
action:[-3.5, 3.01981]
reward:0.2917910742566274
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      24.3921  46.7161   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.74124 -2.534  ]
done:False
-------------------------
[62]>>[26]: env.step(3)
action:[-3.5, 7.7412399999999995]
reward:0.4151853568046541
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      22.7564  44.8428
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.1043  -3.24159]
done:False
-------------------------
[62]>>[27]: env.step(1)
action:[0, 3.1043]
reward:-0.37267672228249993
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.2426  42.3655   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.78519 -2.48638]
done:False
-------------------------
[62]>>[28]: env.step(3)
action:[0, 8.78519]
reward:0.48594901444588096
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       18.0609   40.6207    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.74968  -0.208738]
done:False
-------------------------
[62]>>[29]: env.step(2)
action:[3.5, 3.74968]
reward:-0.31010959228394475
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.4825   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.41674  2.83269]
done:False
-------------------------
[62]>>[30]: env.step(3)
action:[3.5, 9.41674]
reward:0.5735081835542979
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      14.4818   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73778  5.29854]
done:False
-------------------------
[62]>>[31]: env.step(3)
action:[3.5, 9.73778]
reward:0.687809563093354
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.6086   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.20058  4.90225]
done:False
-------------------------
[62]>>[32]: env.step(1)
action:[0, 6.20058]
reward:-0.01823556072234056
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      44.6983   5.65032  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.69458  4.0638 ]
done:False
-------------------------
[62]>>[33]: env.step(1)
action:[0, 7.69458]
reward:-24.22172019539522
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.1256   4.08864  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.97749  4.11082]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8626, 'y': 4.11082, 'z': 0.572372}
.........................
** Rewards description :
count    33.000000
mean     -0.607052
std       4.253402
min     -24.221720
25%      -0.018236
50%       0.169747
75%       0.342842
max       0.687810
dtype: float64
#########################
[63]>> env.reset()
=========================
[63]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.6207481600207202
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.52492 -0.66236]
done:False
-------------------------
[63]>>[2]: env.step(3)
action:[3.5, 6.52492]
reward:0.26413605600474654
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.52491  -0.616993]
done:False
-------------------------
[63]>>[3]: env.step(3)
action:[3.5, 6.52491]
reward:0.27267874741775977
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.62974  0.348839]
done:False
-------------------------
[63]>>[4]: env.step(3)
action:[3.5, 6.62974]
reward:0.27160532290526185
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.59035  0.828123]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.03609, 'y': 0.828123, 'z': 0.570564}
.........................
** Rewards description :
count    4.000000
mean     0.046918
std      0.445127
min     -0.620748
25%      0.042915
50%      0.267871
75%      0.271874
max      0.272679
dtype: float64
#########################
[64]>> env.reset()
=========================
Retrying to reset environment!
[64]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.7487339621988028
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.014772 0.189081]
done:False
-------------------------
[64]>>[2]: env.step(4)
action:[-3.5, 0.007386]
reward:0.045413270028499805
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.530011 0.156325]
done:False
-------------------------
[64]>>[3]: env.step(2)
action:[3.5, 0.530011]
reward:-1.4002640339609247
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.04109  0.184187]
done:False
-------------------------
[64]>>[4]: env.step(2)
action:[3.5, 1.04109]
reward:0.11037945858729589
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.03979  0.741101]
done:False
-------------------------
[64]>>[5]: env.step(3)
action:[3.5, 6.03979]
reward:0.2822754451218249
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.86901 1.43186]
done:False
-------------------------
[64]>>[6]: env.step(2)
action:[3.5, 1.86901]
reward:0.2420832842761586
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.41915 2.89577]
done:False
-------------------------
[64]>>[7]: env.step(0)
action:[-3.5, 2.41915]
reward:-1.2373227900410368
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.53347 3.59653]
done:False
-------------------------
[64]>>[8]: env.step(3)
action:[-3.5, 7.5334699999999994]
reward:0.38821568525395866
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.81506 3.27757]
done:False
-------------------------
[64]>>[9]: env.step(3)
action:[-3.5, 7.81506]
reward:0.5381492191914327
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.67195 1.27373]
done:False
-------------------------
[64]>>[10]: env.step(3)
action:[-3.5, 9.671949999999999]
reward:0.664993254823637
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.90432 -2.59324]
done:False
-------------------------
[64]>>[11]: env.step(4)
action:[-3.5, 3.9043200000000002]
reward:0.6936023167317334
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      48.6275
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.73874 -5.84852]
done:False
-------------------------
[64]>>[12]: env.step(2)
action:[3.5, 7.73874]
reward:-0.693174345006401
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.1679   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.37545 -3.37744]
done:False
-------------------------
[64]>>[13]: env.step(2)
action:[3.5, 8.37545]
reward:0.799063420781887
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.7935   0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.10457  2.69214]
done:False
-------------------------
[64]>>[14]: env.step(2)
action:[3.5, 8.10457]
reward:0.7944943063963708
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      38.8249   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.10671  7.37871]
done:False
-------------------------
[64]>>[15]: env.step(5)
action:[3.5, 8.10671]
reward:0.7859579595466626
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      33.4185   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.98399  5.59863]
done:False
-------------------------
[64]>>[16]: env.step(3)
action:[3.5, 12.98399]
reward:0.8652389636035659
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.4918   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.91716  3.05054]
done:False
-------------------------
[64]>>[17]: env.step(5)
action:[3.5, 7.91716]
reward:0.7491561911560404
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      22.9376  46.1175   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.50946  3.81754]
done:False
-------------------------
[64]>>[18]: env.step(0)
action:[-3.5, 7.50946]
reward:-0.7661590671261822
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.361    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.39641  3.90837]
done:False
-------------------------
[64]>>[19]: env.step(2)
action:[3.5, 7.39641]
reward:-0.7857160159583491
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.5936   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.15197  3.95306]
done:False
-------------------------
[64]>>[20]: env.step(4)
action:[3.5, 5.15197]
reward:0.5821149383967799
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.91003 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.91821 3.98558]
done:False
-------------------------
[64]>>[21]: env.step(5)
action:[3.5, 5.91821]
reward:-24.40914761469642
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.98768 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.84293 4.00525]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.059, 'y': 4.00525, 'z': 0.570319}
.........................
** Rewards description :
count    21.000000
mean     -1.071399
std       5.396713
min     -24.409148
25%      -0.748734
50%       0.282275
75%       0.693602
max       0.865239
dtype: float64
#########################
[65]>> env.reset()
=========================
[65]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.7495776937211185
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00492708 0.195997  ]
done:False
-------------------------
[65]>>[2]: env.step(5)
action:[-3.5, 0.00492708]
reward:0.0005063632008468488
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00467605 0.19249   ]
done:False
-------------------------
[65]>>[3]: env.step(2)
action:[3.5, 0.00467605]
reward:-1.4544121551049602
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.532741 0.222632]
done:False
-------------------------
[65]>>[4]: env.step(0)
action:[-3.5, 0.532741]
reward:-1.399999315956916
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.04355  0.203443]
done:False
-------------------------
[65]>>[5]: env.step(3)
action:[-3.5, 6.04355]
reward:0.21464990284957658
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.04168  -0.352789]
done:False
-------------------------
[65]>>[6]: env.step(3)
action:[-3.5, 6.0416799999999995]
reward:0.2799764907752392
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.84025 -1.03133]
done:False
-------------------------
[65]>>[7]: env.step(3)
action:[-3.5, 6.84025]
reward:0.43082685023893524
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.52847 -2.74803]
done:False
-------------------------
[65]>>[8]: env.step(3)
action:[-3.5, 8.52847]
reward:0.597436083821558
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.27819 -3.61821]
done:False
-------------------------
[65]>>[9]: env.step(5)
action:[-3.5, 5.27819]
reward:0.5817044661469031
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.8812  -3.30696]
done:False
-------------------------
[65]>>[10]: env.step(1)
action:[0, 5.8812]
reward:-0.16313339850915376
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      46.1756   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.7991  -3.23708]
done:False
-------------------------
[65]>>[11]: env.step(1)
action:[0, 5.7991]
reward:0.5777963872891543
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      41.9169   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.69907 -3.19675]
done:False
-------------------------
[65]>>[12]: env.step(4)
action:[0, 3.69907]
reward:0.43079114336611746
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      38.836    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.31331 -1.53038]
done:False
-------------------------
[65]>>[13]: env.step(3)
action:[0, 9.313310000000001]
reward:0.5356237116693122
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      36.5592   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.26427  0.64091]
done:False
-------------------------
[65]>>[14]: env.step(0)
action:[-3.5, 4.26427]
reward:-0.34763308121977204
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.6493    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.8111    0.365681]
done:False
-------------------------
[65]>>[15]: env.step(1)
action:[0, 3.8111]
reward:-0.36199706504807516
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.8405    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.74297   0.349035]
done:False
-------------------------
[65]>>[16]: env.step(4)
action:[0, 1.871485]
reward:0.24975122351951842
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       28.6949    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.51218   0.380766]
done:False
-------------------------
[65]>>[17]: env.step(0)
action:[-3.5, 2.51218]
reward:-0.4802664810833152
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.1466  49.8493
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.59676 -0.52689]
done:False
-------------------------
[65]>>[18]: env.step(5)
action:[-3.5, 2.59676]
reward:0.25076714760044055
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.3621  48.814    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.34328 -2.12705]
done:False
-------------------------
[65]>>[19]: env.step(4)
action:[-3.5, 1.17164]
reward:0.17708797491092199
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      25.4459  47.6985   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.80555 -3.04594]
done:False
-------------------------
[65]>>[20]: env.step(3)
action:[-3.5, 6.80555]
reward:0.2881388489458566
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      24.3023  46.4671
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.74978 -3.16072]
done:False
-------------------------
[65]>>[21]: env.step(2)
action:[3.5, 1.74978]
reward:-1.2992717718796327
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.9829   0.      45.14     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.94642 -2.8623 ]
done:False
-------------------------
[65]>>[22]: env.step(0)
action:[-3.5, 1.94642]
reward:-1.3057505658406876
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      21.7862
 43.833    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.81891 -3.1594 ]
done:False
-------------------------
[65]>>[23]: env.step(3)
action:[-3.5, 6.81891]
reward:0.298323744211083
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.4794
 42.4514   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.87209 -3.16299]
done:False
-------------------------
[65]>>[24]: env.step(2)
action:[3.5, 1.87209]
reward:-1.2954597241553976
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.0502  41.1186   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96199 -2.41137]
done:False
-------------------------
[65]>>[25]: env.step(5)
action:[3.5, 1.96199]
reward:0.21345815960422548
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.7911   0.      40.0905   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04761 -1.23264]
done:False
-------------------------
[65]>>[26]: env.step(4)
action:[3.5, 1.023805]
reward:0.15706730789635515
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.70900e+01
 3.96523e+01 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 1.60183e+00 2.32137e-02]
done:False
-------------------------
[65]>>[27]: env.step(3)
action:[3.5, 6.60183]
reward:0.3130722213639867
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 16.5495  39.3702   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.10881  1.30268]
done:False
-------------------------
[65]>>[28]: env.step(4)
action:[3.5, 1.054405]
reward:0.3385597812716742
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      15.9389  39.0956   0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.81239  3.48489]
done:False
-------------------------
[65]>>[29]: env.step(3)
action:[3.5, 8.81239]
reward:0.6167103673803328
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      13.4259   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.46537  5.79766]
done:False
-------------------------
[65]>>[30]: env.step(3)
action:[3.5, 10.46537]
reward:0.7416259798986459
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      48.0738   9.05358
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.76655  4.55898]
done:False
-------------------------
[65]>>[31]: env.step(2)
action:[3.5, 6.76655]
reward:0.8031224251530871
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      42.4818   3.45737  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.56516  4.12894]
done:False
-------------------------
[65]>>[32]: env.step(0)
action:[-3.5, 8.56516]
reward:-25.659049472844522
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      42.0483   3.0355   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.66443  4.15735]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.9026, 'y': 4.15735, 'z': 0.57321}
.........................
** Rewards description :
count    32.000000
mean     -0.825611
std       4.581839
min     -25.659049
25%      -0.391564
50%       0.232201
75%       0.430800
max       0.803122
dtype: float64
#########################
[66]>> env.reset()
=========================
[66]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.0
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.1992]
done:False
-------------------------
[66]>>[2]: env.step(4)
action:[0, 0.0]
reward:0.0
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.1992]
done:False
-------------------------
[66]>>[3]: env.step(4)
action:[0, 0.0]
reward:0.06209856114399109
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.728312 -0.253813]
done:False
-------------------------
[66]>>[4]: env.step(5)
action:[0, 0.728312]
reward:0.07751928514925385
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.728312 -0.546636]
done:False
-------------------------
[66]>>[5]: env.step(5)
action:[0, 0.728312]
reward:0.10076656766999419
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.00375 -0.69928]
done:False
-------------------------
[66]>>[6]: env.step(0)
action:[-3.5, 1.00375]
reward:-0.6267934135139911
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.20187 -1.21713]
done:False
-------------------------
[66]>>[7]: env.step(3)
action:[-3.5, 6.2018699999999995]
reward:0.23448797082739073
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.24332 -1.55328]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.04975, 'y': -1.55328, 'z': 0.570018}
.........................
** Rewards description :
count    7.000000
mean    -0.021703
std      0.278262
min     -0.626793
25%      0.000000
50%      0.062099
75%      0.089143
max      0.234488
dtype: float64
#########################
[67]>> env.reset()
=========================
Retrying to reset environment!
[67]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.7449973433185636
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0583887 0.238893 ]
done:False
-------------------------
[67]>>[2]: env.step(4)
action:[-3.5, 0.02919435]
reward:0.047377980520103335
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.547662 0.25208 ]
done:False
-------------------------
[67]>>[3]: env.step(2)
action:[3.5, 0.547662]
reward:-1.4384705734779872
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.584686  -0.0291387]
done:False
-------------------------
[67]>>[4]: env.step(3)
action:[3.5, 5.584686]
reward:0.24773655064375205
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.55926   -0.0437657]
done:False
-------------------------
[67]>>[5]: env.step(0)
action:[-3.5, 1.55926]
reward:-1.2905627891915206
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09953  -0.574197]
done:False
-------------------------
[67]>>[6]: env.step(0)
action:[-3.5, 2.09953]
reward:0.21164815641528656
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99127 -1.72553]
done:False
-------------------------
[67]>>[7]: env.step(4)
action:[-3.5, 0.995635]
reward:0.17972068787284481
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.88127 -2.87652]
done:False
-------------------------
[67]>>[8]: env.step(5)
action:[-3.5, 1.88127]
reward:0.21167413015779957
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04615 -3.31617]
done:False
-------------------------
[67]>>[9]: env.step(3)
action:[-3.5, 7.04615]
reward:0.30692000952850307
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92155 -3.32562]
done:False
-------------------------
[67]>>[10]: env.step(2)
action:[3.5, 1.92155]
reward:-1.2991583536666034
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90485 -3.29481]
done:False
-------------------------
[67]>>[11]: env.step(4)
action:[3.5, 0.952425]
reward:0.14850957650827162
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.51708 -2.76524]
done:False
-------------------------
[67]>>[12]: env.step(3)
action:[3.5, 6.51708]
reward:0.3104439432992121
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09744 -1.90643]
done:False
-------------------------
[67]>>[13]: env.step(5)
action:[3.5, 2.09744]
reward:0.27027811344383834
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      49.993
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.70713 -0.15694]
done:False
-------------------------
[67]>>[14]: env.step(3)
action:[3.5, 7.707129999999999]
reward:0.3940007487611852
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.4858   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84464  1.79634]
done:False
-------------------------
[67]>>[15]: env.step(3)
action:[3.5, 7.84464]
reward:0.5495136971725285
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 48.6272   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.81388  4.41237]
done:False
-------------------------
[67]>>[16]: env.step(4)
action:[3.5, 2.40694]
reward:0.32129058700684965
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      46.1936   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.25946  5.48809]
done:False
-------------------------
[67]>>[17]: env.step(2)
action:[3.5, 3.25946]
reward:0.32807540093499327
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 43.9996   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.13062  4.71452]
done:False
-------------------------
[67]>>[18]: env.step(1)
action:[0, 3.13062]
reward:-0.4478685356903332
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 41.9991   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84121  3.87475]
done:False
-------------------------
[67]>>[19]: env.step(3)
action:[0, 7.84121]
reward:0.42566837723903994
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      40.3284   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.21254  2.31256]
done:False
-------------------------
[67]>>[20]: env.step(3)
action:[0, 8.21254]
reward:0.5680894800772516
observation:
[ 0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
  0.00000e+00  0.00000e+00  0.00000e+00  3.86792e+01  0.00000e+00
  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00
  0.00000e+00  4.96706e+00 -2.25609e-02]
done:False
-------------------------
[67]>>[21]: env.step(3)
action:[0, 9.96706]
reward:0.6652465085189212
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       34.7525    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.834     0.101451]
done:False
-------------------------
[67]>>[22]: env.step(3)
action:[0, 10.834]
reward:0.7510250563903794
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.1342    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.80657   0.315639]
done:False
-------------------------
[67]>>[23]: env.step(5)
action:[0, 6.80657]
reward:0.6932036068813606
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.9453   47.7434    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.00768   0.378828]
done:False
-------------------------
[67]>>[24]: env.step(0)
action:[-3.5, 7.00768]
reward:-0.04916301540489121
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.9679  43.3047   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.06279 -1.78329]
done:False
-------------------------
[67]>>[25]: env.step(2)
action:[3.5, 7.06279]
reward:-0.8004560715524127
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      17.4509
  0.      39.018    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.03114 -3.75635]
done:False
-------------------------
[67]>>[26]: env.step(5)
action:[3.5, 7.03114]
reward:0.6900454667098825
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.0732    0.       35.522     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.90802  -0.136665]
done:False
-------------------------
[67]>>[27]: env.step(4)
action:[3.5, 4.90802]
reward:0.6398188508445735
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.7035   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.75309  4.79567]
done:False
-------------------------
[67]>>[28]: env.step(2)
action:[3.5, 6.75309]
reward:0.6649701807254819
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      46.6097  31.2263   8.06683  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.63372  6.73058]
done:False
-------------------------
[67]>>[29]: env.step(5)
action:[3.5, 6.63372]
reward:-24.36548591628056
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      42.9157   3.89996  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.24992  4.1205 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.114, 'y': 4.1205, 'z': 0.569951}
.........................
** Rewards description :
count    29.000000
mean     -0.752100
std       4.584727
min     -24.365486
25%      -0.049163
50%       0.270278
75%       0.549514
max       0.751025
dtype: float64
#########################
[68]>> env.reset()
=========================
[68]>>[1]: env.step(2)
action:[3.5, 6.30416]
reward:-0.5214378818870442
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.14559  0.902786]
done:False
-------------------------
[68]>>[2]: env.step(3)
action:[3.5, 6.14559]
reward:0.23523806805147376
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.26653 1.46799]
done:False
-------------------------
[68]>>[3]: env.step(4)
action:[3.5, 0.633265]
reward:0.29907091091081484
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.42773 3.20492]
done:False
-------------------------
[68]>>[4]: env.step(2)
action:[3.5, 3.42773]
reward:0.4596713888473068
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.75052 5.72487]
done:False
-------------------------
[68]>>[5]: env.step(1)
action:[0, 4.75052]
reward:-0.24452138201507545
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.0115  5.97644]
done:False
-------------------------
[68]>>[6]: env.step(0)
action:[-3.5, 5.0115]
reward:-0.2378619474910053
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.03289 3.52476]
done:False
-------------------------
[68]>>[7]: env.step(0)
action:[-3.5, 5.03289]
reward:0.4958124054244535
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.81544 1.36439]
done:False
-------------------------
[68]>>[8]: env.step(4)
action:[-3.5, 2.40772]
reward:0.3093738668810447
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.11153 -1.39821]
done:False
-------------------------
[68]>>[9]: env.step(3)
action:[-3.5, 8.11153]
reward:0.4563220033922611
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.53659 -3.75245]
done:False
-------------------------
[68]>>[10]: env.step(1)
action:[0, 3.53659]
reward:-0.34185258438596655
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      48.2313   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.06621 -4.99551]
done:False
-------------------------
[68]>>[11]: env.step(3)
action:[0, 9.06621]
reward:0.5076732085313544
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      45.3965   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.96111 -4.13727]
done:False
-------------------------
[68]>>[12]: env.step(4)
action:[0, 1.980555]
reward:0.26558517546885113
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      43.9386
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.67877 -2.13524]
done:False
-------------------------
[68]>>[13]: env.step(2)
action:[3.5, 2.67877]
reward:-0.48758593203769174
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       43.3186    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.46534  -0.238265]
done:False
-------------------------
[68]>>[14]: env.step(0)
action:[-3.5, 2.46534]
reward:-1.250089752473348
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.9825   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.36566  1.56567]
done:False
-------------------------
[68]>>[15]: env.step(0)
action:[-3.5, 2.36566]
reward:0.24989224893331702
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      42.0576
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.39036  2.97662]
done:False
-------------------------
[68]>>[16]: env.step(4)
action:[-3.5, 1.19518]
reward:0.18373671250025836
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      40.8254   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8798   3.62064]
done:False
-------------------------
[68]>>[17]: env.step(4)
action:[-3.5, 0.9399]
reward:0.15668088679557812
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      39.6324   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.61817  3.67526]
done:False
-------------------------
[68]>>[18]: env.step(4)
action:[-3.5, 0.809085]
reward:0.1422393745367333
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.5744   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.47785  3.34677]
done:False
-------------------------
[68]>>[19]: env.step(0)
action:[-3.5, 1.47785]
reward:0.1554394369545289
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      37.5996
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.46879  2.67843]
done:False
-------------------------
[68]>>[20]: env.step(2)
action:[3.5, 1.46879]
reward:-1.3086381084720533
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      36.4968   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90343  2.70667]
done:False
-------------------------
[68]>>[21]: env.step(0)
action:[-3.5, 1.90343]
reward:-1.3030503304906664
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      35.3008   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8623   3.29142]
done:False
-------------------------
[68]>>[22]: env.step(2)
action:[3.5, 1.8623]
reward:-1.306839589165881
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.0206   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.82678  3.71385]
done:False
-------------------------
[68]>>[23]: env.step(3)
action:[3.5, 6.82678]
reward:0.33182354910841433
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.5466   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.28541  3.85821]
done:False
-------------------------
[68]>>[24]: env.step(3)
action:[3.5, 7.285410000000001]
reward:0.4753851927542535
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.1228   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.98825  3.88811]
done:False
-------------------------
[68]>>[25]: env.step(1)
action:[0, 3.98825]
reward:-0.28285728034649926
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     27.3116  0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  4.7064  2.4201]
done:False
-------------------------
[68]>>[26]: env.step(0)
action:[-3.5, 4.7064]
reward:-0.2906848015882816
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.       26.6024   49.2583    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.42628  -0.882686]
done:False
-------------------------
[68]>>[27]: env.step(0)
action:[-3.5, 4.42628]
reward:0.47235383223292793
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.3021  48.3805   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.66397 -3.98124]
done:False
-------------------------
[68]>>[28]: env.step(0)
action:[-3.5, 4.66397]
reward:0.4644993587173126
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      23.7959   0.
 45.4708   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.50348 -4.99594]
done:False
-------------------------
[68]>>[29]: env.step(0)
action:[-3.5, 4.50348]
reward:0.4278936906237273
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.5012  42.3934   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.0753  -3.28144]
done:False
-------------------------
[68]>>[30]: env.step(5)
action:[-3.5, 4.0753]
reward:0.403486500506792
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.6306   0.      39.4425   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.87251 -3.00307]
done:False
-------------------------
[68]>>[31]: env.step(4)
action:[-3.5, 1.936255]
reward:0.3549309807195734
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.9966
  0.      36.5757   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.79634 -3.01119]
done:False
-------------------------
[68]>>[32]: env.step(2)
action:[3.5, 3.79634]
reward:-1.1159828474713778
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      12.5377   0.
  0.      33.7787   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.69643 -3.02634]
done:False
-------------------------
[68]>>[33]: env.step(0)
action:[-3.5, 3.69643]
reward:-1.1345355746939063
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.3647   0.
  0.      31.1327   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.48823 -3.02057]
done:False
-------------------------
[68]>>[34]: env.step(5)
action:[-3.5, 3.48823]
reward:0.3451510407843154
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.56229  0.       0.
  0.      28.6379   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.28614 -3.00463]
done:False
-------------------------
[68]>>[35]: env.step(5)
action:[-3.5, 3.28614]
reward:0.32520706836234603
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.25832  0.       0.       0.       0.
  0.      26.2944   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.0883  -2.98944]
done:False
-------------------------
[68]>>[36]: env.step(4)
action:[-3.5, 1.54415]
reward:0.22552053606165656
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.64519  0.       0.       0.       0.       0.
  0.      24.4158   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29859 -2.97891]
done:False
-------------------------
[68]>>[37]: env.step(3)
action:[-3.5, 7.29859]
reward:0.36501067910248913
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.52965  0.       0.       0.       0.       0.       0.       0.
  0.      22.6657   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.582   -2.97009]
done:False
-------------------------
[68]>>[38]: env.step(3)
action:[-3.5, 7.582]
reward:0.50945493236914
observation:
[ 0.       0.       0.       0.       0.       0.       7.21476  0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.5252  20.0295   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.35534 -2.95643]
done:False
-------------------------
[68]>>[39]: env.step(1)
action:[0, 4.35534]
reward:-0.23910242488298628
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.92006  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      33.0633  16.6618   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.18078 -1.10393]
done:False
-------------------------
[68]>>[40]: env.step(2)
action:[3.5, 5.18078]
reward:-0.24602546564680416
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.36575  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.8163  15.9536   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.88439  2.56737]
done:False
-------------------------
[68]>>[41]: env.step(0)
action:[-3.5, 4.88439]
reward:-0.996671886765977
observation:
[ 0.       0.       9.54839  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.682    0.      14.6062
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.95009  5.22107]
done:False
-------------------------
[68]>>[42]: env.step(2)
action:[3.5, 4.95009]
reward:-1.0013914242147886
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 26.2276  47.0298  11.3491   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.931    0.       0.       4.8724   4.79068]
done:False
-------------------------
[68]>>[43]: env.step(2)
action:[3.5, 4.8724]
reward:0.4866561322501419
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.4075  44.746    8.58166  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.806    0.       0.
  0.       0.       0.       0.       4.73702  1.77214]
done:False
-------------------------
[68]>>[44]: env.step(3)
action:[3.5, 9.737020000000001]
reward:0.5750558362093492
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  6.10246  42.3283    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       17.3481
  0.        4.67823  -0.561023]
done:False
-------------------------
[68]>>[45]: env.step(5)
action:[3.5, 4.67823]
reward:-24.500408339459078
observation:
[19.1553   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 20.7697   4.28383 40.5006   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.95312 -0.61303]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.784, 'y': -0.61303, 'z': 0.570022}
.........................
** Rewards description :
count    45.000000
mean     -0.602897
std       3.692838
min     -24.500408
25%      -0.341853
50%       0.225521
75%       0.403487
max       0.575056
dtype: float64
#########################
[69]>> env.reset()
=========================
[69]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.13054195396177548
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54032 1.13701]
done:False
-------------------------
[69]>>[2]: env.step(3)
action:[0, 6.5403199999999995]
reward:0.2657067731698779
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54032 1.42093]
done:False
-------------------------
[69]>>[3]: env.step(5)
action:[0, 1.54032]
reward:0.15694468558274924
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.47123 1.01877]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02399, 'y': 1.01877, 'z': 0.570325}
.........................
** Rewards description :
count    3.000000
mean     0.184398
std      0.071642
min      0.130542
25%      0.143743
50%      0.156945
75%      0.211326
max      0.265707
dtype: float64
#########################
[70]>> env.reset()
=========================
[70]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.10693017750335747
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.25905 1.01095]
done:False
-------------------------
[70]>>[2]: env.step(3)
action:[0, 6.25905]
reward:0.23077558374491375
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.18381 1.78299]
done:False
-------------------------
[70]>>[3]: env.step(0)
action:[-3.5, 1.18381]
reward:-0.5728180022841443
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.80364 2.0794 ]
done:False
-------------------------
[70]>>[4]: env.step(5)
action:[-3.5, 1.80364]
reward:0.18577726267300043
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.7523  2.11844]
done:False
-------------------------
[70]>>[5]: env.step(3)
action:[-3.5, 6.7523]
reward:0.28685227477989605
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.74724 1.67785]
done:False
-------------------------
[70]>>[6]: env.step(3)
action:[-3.5, 6.74724]
reward:0.32466094925157357
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.21624  0.772391]
done:False
-------------------------
[70]>>[7]: env.step(1)
action:[0, 2.21624]
reward:-0.3827599321657785
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.88055 -1.30006]
done:False
-------------------------
[70]>>[8]: env.step(1)
action:[0, 3.88055]
reward:0.4456234613921544
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.4573  -3.17187]
done:False
-------------------------
[70]>>[9]: env.step(4)
action:[0, 2.22865]
reward:0.41217403656298757
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44424 -2.27632]
done:False
-------------------------
[70]>>[10]: env.step(5)
action:[0, 4.44424]
reward:0.4442568318404988
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 48.0617    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.2989    0.278465]
done:False
-------------------------
[70]>>[11]: env.step(2)
action:[3.5, 4.2989]
reward:-0.3376617733259654
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 46.4262   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.92876  2.72668]
done:False
-------------------------
[70]>>[12]: env.step(5)
action:[3.5, 3.92876]
reward:0.41043257905232117
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      44.373    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.99713  4.57849]
done:False
-------------------------
[70]>>[13]: env.step(1)
action:[0, 3.99713]
reward:-0.3489551646607814
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 41.61     0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.86116  4.21125]
done:False
-------------------------
[70]>>[14]: env.step(5)
action:[0, 3.86116]
reward:0.38087733449427263
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      39.8382   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.64069  2.08551]
done:False
-------------------------
[70]>>[15]: env.step(3)
action:[0, 8.64069]
reward:0.4865403188337498
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.        38.3775     0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  3.79345    0.0834583]
done:False
-------------------------
[70]>>[16]: env.step(3)
action:[0, 8.79345]
reward:0.6002487315839254
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 35.1808     0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  5.24952    0.0623511]
done:False
-------------------------
[70]>>[17]: env.step(4)
action:[0, 3.2495200000000004]
reward:0.40766931090183123
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.8316    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.13192   0.349062]
done:False
-------------------------
[70]>>[18]: env.step(2)
action:[3.5, 4.13192]
reward:-0.3394120333827174
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       28.8472    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.94831   0.393689]
done:False
-------------------------
[70]>>[19]: env.step(3)
action:[3.5, 8.94831]
reward:0.5189435963201188
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      26.0222  48.9962   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.13739  1.83282]
done:False
-------------------------
[70]>>[20]: env.step(0)
action:[-3.5, 4.13739]
reward:-1.0299030885783358
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.166    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.70713  2.82105]
done:False
-------------------------
[70]>>[21]: env.step(5)
action:[-3.5, 4.70713]
reward:0.48269302086810917
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       20.5492   43.3869
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.72712   0.780972]
done:False
-------------------------
[70]>>[22]: env.step(0)
action:[-3.5, 4.72712]
reward:0.45612689582818433
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.2537  42.4279   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.38019 -2.5102 ]
done:False
-------------------------
[70]>>[23]: env.step(3)
action:[-3.5, 9.380189999999999]
reward:0.5576351593068254
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.6621   0.      40.1158   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.53701 -4.46493]
done:False
-------------------------
[70]>>[24]: env.step(2)
action:[3.5, 4.53701]
reward:-0.9387424913498279
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      15.0974   0.       0.      36.4767   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.79562 -3.50174]
done:False
-------------------------
[70]>>[25]: env.step(3)
action:[3.5, 10.79562]
reward:0.7618466029133961
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.9476   0.
  0.      31.7954   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.96895 -3.15697]
done:False
-------------------------
[70]>>[26]: env.step(3)
action:[3.5, 11.96895]
reward:0.8827164365780342
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.12208  0.       0.       0.       0.
  0.      25.8797   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.43069 -3.03765]
done:False
-------------------------
[70]>>[27]: env.step(4)
action:[3.5, 6.43069]
reward:0.8073609956036913
observation:
[ 0.       0.       0.       0.       0.       0.       7.49918  0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.9409  19.4404   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.71018 -2.96648]
done:False
-------------------------
[70]>>[28]: env.step(2)
action:[3.5, 8.71018]
reward:0.8483976121683485
observation:
[ 0.       0.       0.      12.1404   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.9748   0.      48.7995   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.73734 -2.92169]
done:False
-------------------------
[70]>>[29]: env.step(2)
action:[3.5, 8.73734]
reward:0.8624140251246908
observation:
[ 0.        0.        0.        0.        0.        0.        0.
 16.267     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       23.3724    7.0853    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.93704   0.225905]
done:False
-------------------------
[70]>>[30]: env.step(3)
action:[3.5, 13.93704]
reward:0.9437069680769417
observation:
[ 0.       0.       0.      18.889    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      20.4842  41.565
  0.       0.       0.       7.63918  0.       0.       0.       0.
  0.       0.       0.       0.       8.86347  6.03012]
done:False
-------------------------
[70]>>[31]: env.step(5)
action:[3.5, 8.86347]
reward:0.8767095613521823
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.2782
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.00637  0.       0.       0.       0.       0.      24.9681
  0.       0.       0.       0.       9.11753  5.39812]
done:False
-------------------------
[70]>>[32]: env.step(1)
action:[0, 9.11753]
reward:0.12666756579550498
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       10.3951    0.        0.
 30.1421    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        6.26173  29.413     0.        0.
  0.        9.05339   0.233263]
done:False
-------------------------
[70]>>[33]: env.step(1)
action:[0, 9.05339]
reward:0.8619419024917304
observation:
[ 0.        0.       12.5325   35.6543    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        4.83486   0.        0.        0.        0.
 23.9548    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.85105   0.308083]
done:False
-------------------------
[70]>>[34]: env.step(0)
action:[-3.5, 8.85105]
reward:0.10185696249742526
observation:
[42.0803    0.        0.        0.        4.13797   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       41.3454   17.7132    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 19.0131    8.75296   0.632962]
done:False
-------------------------
[70]>>[35]: env.step(3)
action:[-3.5, 13.75296]
reward:0.9277100782331447
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      35.4639  11.6326   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      47.9666
  0.       0.      10.0574   0.       8.66403 -1.57536]
done:False
-------------------------
[70]>>[36]: env.step(1)
action:[0, 8.66403]
reward:0.11535314549704889
observation:
[ 0.       0.      30.6663   0.      15.9077   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.61557  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.99884 -3.07462]
done:False
-------------------------
[70]>>[37]: env.step(1)
action:[0, 8.99884]
reward:0.8656053032793493
observation:
[ 0.       0.      35.3095  19.2946   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      25.3964   0.
  0.       0.       0.       0.       0.       5.61272  0.       0.
  0.       0.       0.       0.       8.91887  1.55491]
done:False
-------------------------
[70]>>[38]: env.step(2)
action:[3.5, 8.91887]
reward:0.10126160503730208
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       19.0614    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        7.30477   0.        0.        0.       41.5995
 25.6645    8.72725   0.734099]
done:False
-------------------------
[70]>>[39]: env.step(4)
action:[3.5, 6.72725]
reward:0.7363675013805694
observation:
[ 0.      13.2128   0.       0.      46.9597  30.7093   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.275    0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.62734  3.73421]
done:False
-------------------------
[70]>>[40]: env.step(1)
action:[0, 7.62734]
reward:7.978841462885633e-05
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.5393   0.       0.       0.      11.8637   0.       0.
  0.       0.       0.       0.       0.       0.       0.      18.1774
  0.       0.      35.8902   0.       7.59492  4.85373]
done:False
-------------------------
[70]>>[41]: env.step(5)
action:[0, 7.59492]
reward:0.7321952408358796
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.2193   0.       0.       0.
  0.       6.5224   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      20.6959   0.      40.0485
  0.       0.       0.       0.       7.35202  1.27406]
done:False
-------------------------
[70]>>[42]: env.step(4)
action:[0, 5.35202]
reward:0.6192398518628166
observation:
[24.9517   44.6132    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       40.6785    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.4262    0.        0.        0.        0.        0.
  0.        6.36446   0.575618]
done:False
-------------------------
[70]>>[43]: env.step(4)
action:[0, 4.36446]
reward:0.523610609380436
observation:
[48.6692    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       36.5996    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        6.606     0.        0.        0.
 29.0356    5.34428   0.944521]
done:False
-------------------------
[70]>>[44]: env.step(1)
action:[0, 5.34428]
reward:0.532302318670796
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.6763   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       9.78048  0.      32.92     5.21301  1.02277]
done:False
-------------------------
[70]>>[45]: env.step(0)
action:[-3.5, 5.21301]
reward:-0.20765622428910446
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       29.3312
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.2786   36.0379    0.        0.        0.
  0.        5.37752  -0.656944]
done:False
-------------------------
[70]>>[46]: env.step(0)
action:[-3.5, 5.37752]
reward:0.5437153323971775
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      26.7798
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.6205   0.       0.       5.35441 -3.16367]
done:False
-------------------------
[70]>>[47]: env.step(2)
action:[3.5, 5.35441]
reward:-0.9685902475247666
observation:
[ 0.       0.      18.1911  42.1678   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.174    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.19879 -1.87003]
done:False
-------------------------
[70]>>[48]: env.step(2)
action:[3.5, 5.19879]
reward:0.5039908906378852
observation:
[ 0.       0.       0.       0.       0.       0.      20.0708  43.7284
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.8615   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.8801   1.69254]
done:False
-------------------------
[70]>>[49]: env.step(0)
action:[-3.5, 4.8801]
reward:-0.9879886638652895
observation:
[ 0.       0.       0.       0.      22.0996  45.1473   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.6175   0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.06409  5.44392]
done:False
-------------------------
[70]>>[50]: env.step(2)
action:[3.5, 5.06409]
reward:-0.995452270130555
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      19.0254   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.6028  48.56     4.92101  6.86033]
done:False
-------------------------
[70]>>[51]: env.step(1)
action:[0, 4.92101]
reward:-0.26622016891212574
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.6048   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.9081   0.
  0.       0.       0.       0.       4.68769  5.13556]
done:False
-------------------------
[70]>>[52]: env.step(2)
action:[3.5, 4.68769]
reward:-0.29361328780307694
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.8951   0.      12.3912   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.8186   0.       4.39338  4.67612]
done:False
-------------------------
[70]>>[53]: env.step(1)
action:[0, 4.39338]
reward:-0.2931593823919475
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      47.2377   0.       9.33882
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.0003   0.
  0.       0.       0.       0.       4.47278  2.93325]
done:False
-------------------------
[70]>>[54]: env.step(2)
action:[3.5, 4.47278]
reward:-0.2995966425269341
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.6041   0.       6.40676  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.3933   0.       4.37042  1.64187]
done:False
-------------------------
[70]>>[55]: env.step(5)
action:[3.5, 4.37042]
reward:0.4400716568811155
observation:
[ 0.       0.      38.2894   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.8614   0.       0.
  0.       4.58178  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.26387  3.20136]
done:False
-------------------------
[70]>>[56]: env.step(0)
action:[-3.5, 4.26387]
reward:-1.0732634891803963
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.1982   0.       0.       0.       0.       0.
  0.       0.       3.94377  0.       0.       0.       0.       0.
  0.       0.       0.      41.0708   4.12047  4.09282]
done:False
-------------------------
[70]>>[57]: env.step(1)
action:[0, 4.12047]
reward:-0.3347612664543507
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.7978   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       2.7989   0.       0.       0.       0.      43.201
  0.       0.       0.       0.       4.01017  2.3843 ]
done:False
-------------------------
[70]>>[58]: env.step(3)
action:[0, 9.010169999999999]
reward:-24.490488004033033
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.6977   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       2.73007  0.       0.       0.      43.2827   0.
  0.       0.       0.       0.       3.99904  2.21093]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 35}
{'x': 186.03, 'y': 2.21093, 'z': 0.56883}
.........................
** Rewards description :
count    58.000000
mean     -0.236340
std       3.290356
min     -24.490488
25%      -0.293500
50%       0.394273
75%       0.554155
max       0.943707
dtype: float64
#########################
[71]>> env.reset()
=========================
[71]>>[1]: env.step(3)
action:[0, 8.989609999999999]
reward:0.30104222252826623
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.363    -0.661287]
done:False
-------------------------
[71]>>[2]: env.step(2)
action:[3.5, 1.363]
reward:-0.6481979922779869
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.857373 -1.32324 ]
done:False
-------------------------
[71]>>[3]: env.step(3)
action:[3.5, 5.857373]
reward:0.270937346587044
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.77524 -1.81159]
done:False
-------------------------
[71]>>[4]: env.step(3)
action:[3.5, 6.77524]
reward:0.43673775464793474
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.6201  -2.55744]
done:False
-------------------------
[71]>>[5]: env.step(5)
action:[3.5, 3.6201]
reward:0.4204608966653109
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.20159 -1.86731]
done:False
-------------------------
[71]>>[6]: env.step(1)
action:[0, 4.20159]
reward:-0.3258567354185534
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.10304  0.239402]
done:False
-------------------------
[71]>>[7]: env.step(3)
action:[0, 9.10304]
reward:0.49650798541430163
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.80692  0.314148]
done:False
-------------------------
[71]>>[8]: env.step(5)
action:[0, 3.80692]
reward:0.44261569358989794
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.246     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.43725   0.288514]
done:False
-------------------------
[71]>>[9]: env.step(5)
action:[0, 4.43725]
reward:0.4525685836591301
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.7031    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.40704   0.285515]
done:False
-------------------------
[71]>>[10]: env.step(5)
action:[0, 4.40704]
reward:0.44544227529026026
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.4416    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.32336   0.301503]
done:False
-------------------------
[71]>>[11]: env.step(2)
action:[3.5, 4.32336]
reward:-0.2956995275870525
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      38.6152   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.45771  1.83433]
done:False
-------------------------
[71]>>[12]: env.step(2)
action:[3.5, 4.45771]
reward:0.4595300072318982
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.4805   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.49121  4.16048]
done:False
-------------------------
[71]>>[13]: env.step(5)
action:[3.5, 4.49121]
reward:0.42252791687648916
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.3942   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.01009  3.86   ]
done:False
-------------------------
[71]>>[14]: env.step(2)
action:[3.5, 4.01009]
reward:0.39500326380956396
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.5236   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.78156  3.84085]
done:False
-------------------------
[71]>>[15]: env.step(4)
action:[3.5, 1.89078]
reward:0.34297987973919447
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.7451   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.65841  3.88052]
done:False
-------------------------
[71]>>[16]: env.step(3)
action:[3.5, 8.65841]
reward:0.4764446687409367
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.034    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.65866  3.89719]
done:False
-------------------------
[71]>>[17]: env.step(3)
action:[3.5, 8.65866]
reward:0.5922742759665568
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.7005   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.17677  3.91111]
done:False
-------------------------
[71]>>[18]: env.step(3)
action:[3.5, 10.176770000000001]
reward:0.7294685647780135
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.1908   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.66844  3.93378]
done:False
-------------------------
[71]>>[19]: env.step(5)
action:[3.5, 6.66844]
reward:0.7272974825580294
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 11.377   0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  7.5152  3.9646]
done:False
-------------------------
[71]>>[20]: env.step(5)
action:[3.5, 7.5152]
reward:0.7364201457884249
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.78541 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.43109 3.99492]
done:False
-------------------------
[71]>>[21]: env.step(2)
action:[3.5, 7.43109]
reward:-24.267487870043844
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.94317 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.39741 4.0049 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.0263, 'y': 4.0049, 'z': 0.570126}
.........................
** Rewards description :
count    21.000000
mean     -0.828047
std       5.382135
min     -24.267488
25%       0.301042
50%       0.436738
75%       0.476445
max       0.736420
dtype: float64
#########################
[72]>> env.reset()
=========================
[72]>>[1]: env.step(4)
action:[0, 0.0]
reward:5.703950029786346e-05
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00066546 0.199424  ]
done:False
-------------------------
[72]>>[2]: env.step(5)
action:[0, 0.000665464]
reward:0.04430811166684734
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.518699 0.200738]
done:False
-------------------------
[72]>>[3]: env.step(3)
action:[0, 5.518699]
reward:0.23697066514334303
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.44437  0.204038]
done:False
-------------------------
[72]>>[4]: env.step(3)
action:[0, 6.44437]
reward:0.4103996471630622
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.36781  0.213576]
done:False
-------------------------
[72]>>[5]: env.step(5)
action:[0, 3.36781]
reward:0.3937306772305809
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.92606  0.228724]
done:False
-------------------------
[72]>>[6]: env.step(5)
action:[0, 3.92606]
reward:0.3969974694901057
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.82776  0.244429]
done:False
-------------------------
[72]>>[7]: env.step(3)
action:[0, 8.82776]
reward:0.48969652820793136
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.6293    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.78751   0.259724]
done:False
-------------------------
[72]>>[8]: env.step(1)
action:[0, 3.78751]
reward:0.44054548775601843
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.5468    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.41565   0.276232]
done:False
-------------------------
[72]>>[9]: env.step(0)
action:[-3.5, 4.41565]
reward:-0.2798724047945149
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      43.6941   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.63796 -1.44194]
done:False
-------------------------
[72]>>[10]: env.step(2)
action:[3.5, 4.63796]
reward:-1.0325177590513355
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 41.0388   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.54834 -2.66384]
done:False
-------------------------
[72]>>[11]: env.step(4)
action:[3.5, 2.27417]
reward:0.2951677569698466
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.7768   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.96931 -1.28096]
done:False
-------------------------
[72]>>[12]: env.step(1)
action:[0, 2.96931]
reward:-0.4541755951932634
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 37.1386    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.80363   0.182379]
done:False
-------------------------
[72]>>[13]: env.step(1)
action:[0, 2.80363]
reward:0.2687926510947908
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       35.2016    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.51235   0.388111]
done:False
-------------------------
[72]>>[14]: env.step(1)
action:[0, 2.51235]
reward:0.2545804299988276
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.3677    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.41102   0.391964]
done:False
-------------------------
[72]>>[15]: env.step(0)
action:[-3.5, 2.41102]
reward:-0.5046971445680981
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.6081    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.32295   0.371689]
done:False
-------------------------
[72]>>[16]: env.step(2)
action:[3.5, 2.32295]
reward:-1.2633080256336644
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.911     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.23991   0.367112]
done:False
-------------------------
[72]>>[17]: env.step(4)
action:[3.5, 1.119955]
reward:0.1699811657574024
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      28.7042   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.73293  1.01893]
done:False
-------------------------
[72]>>[18]: env.step(1)
action:[0, 1.73293]
reward:-0.5647065842224929
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      27.8007   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.76414  1.99737]
done:False
-------------------------
[72]>>[19]: env.step(5)
action:[0, 1.76414]
reward:0.2083646832532709
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.5605  49.5909   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03531  2.41295]
done:False
-------------------------
[72]>>[20]: env.step(1)
action:[0, 2.03531]
reward:0.2122949858336877
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.2158  48.2341   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01517  2.17518]
done:False
-------------------------
[72]>>[21]: env.step(1)
action:[0, 2.01517]
reward:0.21192272910384702
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.017
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01569  1.32981]
done:False
-------------------------
[72]>>[22]: env.step(4)
action:[0, 1.007845]
reward:0.16076816712626016
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 22.9903   45.8365    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.65024   0.664688]
done:False
-------------------------
[72]>>[23]: env.step(1)
action:[0, 1.65024]
reward:0.18652728982868208
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       21.7763   44.5703    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.7997    0.439106]
done:False
-------------------------
[72]>>[24]: env.step(2)
action:[3.5, 1.7997]
reward:-0.5552466824096671
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.4373   43.2008    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86168   0.395695]
done:False
-------------------------
[72]>>[25]: env.step(5)
action:[3.5, 1.86168]
reward:0.19842501558359338
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       19.0497   41.7923    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.89058   0.405635]
done:False
-------------------------
[72]>>[26]: env.step(4)
action:[3.5, 0.94529]
reward:0.15399275674167637
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       17.9409   40.7469    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.58458   0.912234]
done:False
-------------------------
[72]>>[27]: env.step(2)
action:[3.5, 1.58458]
reward:0.1775981265235474
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.9998  39.926    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.70846  1.75011]
done:False
-------------------------
[72]>>[28]: env.step(2)
action:[3.5, 1.70846]
reward:0.18266782295736256
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      16.2189  39.3034
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.73859  2.91853]
done:False
-------------------------
[72]>>[29]: env.step(4)
action:[3.5, 0.869295]
reward:0.14707079881512058
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      15.3248   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.52063  3.7655 ]
done:False
-------------------------
[72]>>[30]: env.step(4)
action:[3.5, 0.760315]
reward:0.13268158026156485
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.3644  37.5823   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.37579  3.95685]
done:False
-------------------------
[72]>>[31]: env.step(2)
action:[3.5, 1.37579]
reward:0.14472330686229665
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      13.368   36.6028   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.3659   3.99616]
done:False
-------------------------
[72]>>[32]: env.step(2)
action:[3.5, 1.3659]
reward:0.1620925520847893
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.2701  35.5173   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.57663  4.00592]
done:False
-------------------------
[72]>>[33]: env.step(0)
action:[-3.5, 1.57663]
reward:-1.3032297911798305
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 11.0436  34.2642   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.94183  3.56342]
done:False
-------------------------
[72]>>[34]: env.step(0)
action:[-3.5, 1.94183]
reward:0.2090810335370618
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      10.0109  33.1111   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99957  2.554  ]
done:False
-------------------------
[72]>>[35]: env.step(5)
action:[-3.5, 1.99957]
reward:0.21256169081355636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       9.56971 48.4501  32.3729   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02734  1.15785]
done:False
-------------------------
[72]>>[36]: env.step(1)
action:[0, 2.02734]
reward:-0.5219905319629476
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.76229  0.      31.2418   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.20807  0.31715]
done:False
-------------------------
[72]>>[37]: env.step(3)
action:[0, 7.20807]
reward:0.3586787023821754
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  7.47841   0.       29.7146    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.52529   0.137022]
done:False
-------------------------
[72]>>[38]: env.step(4)
action:[0, 1.262645]
reward:0.19681683199895236
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.97606   0.        0.       44.2614   28.0783    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.02089   0.379407]
done:False
-------------------------
[72]>>[39]: env.step(0)
action:[-3.5, 2.02089]
reward:-0.5485646542724605
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  4.69323   0.        0.       42.7309   26.5525    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.8872    0.471709]
done:False
-------------------------
[72]>>[40]: env.step(0)
action:[-3.5, 1.8872]
reward:0.2162765483131095
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        4.26008   0.        0.        0.        0.
  0.       25.2216    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.10051  -0.177367]
done:False
-------------------------
[72]>>[41]: env.step(2)
action:[3.5, 2.10051]
reward:-1.2724949567558173
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        3.6782    0.        0.        0.
  0.        0.        0.       40.0448   23.8048    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.18364  -0.075223]
done:False
-------------------------
[72]>>[42]: env.step(0)
action:[-3.5, 2.18364]
reward:-1.271808499791775
observation:
[ 0.        0.        0.        0.        0.        4.15604   0.
  0.        0.        0.        0.        0.        0.        0.
  0.       22.487     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.17121  -0.671985]
done:False
-------------------------
[72]>>[43]: env.step(0)
action:[-3.5, 2.17121]
reward:0.21629817289364567
observation:
[ 0.       0.       5.40581  0.       0.       0.       0.       0.
  0.       0.       0.       0.      37.9331  21.5331   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.02977 -1.85795]
done:False
-------------------------
[72]>>[44]: env.step(4)
action:[-3.5, 1.014885]
reward:0.1609630517893714
observation:
[ 0.       0.       6.50084  0.       0.       0.       0.       0.
  0.       0.       0.       0.      37.1304  20.6657   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.65082 -2.71796]
done:False
-------------------------
[72]>>[45]: env.step(1)
action:[0, 1.65082]
reward:-0.5823766404846652
observation:
[ 0.       0.       0.       7.25263  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      36.0605  19.5708
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.57186 -2.90958]
done:False
-------------------------
[72]>>[46]: env.step(4)
action:[0, 0.78593]
reward:0.1529043565778042
observation:
[ 0.       0.       0.       0.       7.99904  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      34.9232
 18.4182   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.61137 -2.96183]
done:False
-------------------------
[72]>>[47]: env.step(3)
action:[0, 6.61137]
reward:0.27341674919654146
observation:
[ 0.       0.       0.       0.       8.80035  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.2308   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.61719 -2.96294]
done:False
-------------------------
[72]>>[48]: env.step(1)
action:[0, 1.61719]
reward:0.20094989739087157
observation:
[ 0.       0.       0.       0.       0.       9.40824  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.9701   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.98225 -2.49281]
done:False
-------------------------
[72]>>[49]: env.step(2)
action:[3.5, 1.98225]
reward:-0.5385596384165736
observation:
[ 0.       0.       0.       0.       0.       0.       0.       9.69635
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.7751   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.01807 -1.34851]
done:False
-------------------------
[72]>>[50]: env.step(3)
action:[3.5, 7.01807]
reward:0.30358924327634845
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         9.86557    0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        30.2607    13.9271
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.88737   -0.0965101]
done:False
-------------------------
[72]>>[51]: env.step(0)
action:[-3.5, 1.88737]
reward:-1.2851428488158045
observation:
[ 0.        0.        0.        0.       10.8756    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       12.6358
 48.8823    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.08324   0.451307]
done:False
-------------------------
[72]>>[52]: env.step(4)
action:[-3.5, 1.04162]
reward:0.16130481107737538
observation:
[ 0.        0.       12.0522    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       27.6548   11.4015    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.64824   0.381389]
done:False
-------------------------
[72]>>[53]: env.step(1)
action:[0, 1.64824]
reward:-0.5778958274644924
observation:
[13.2221    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.277    46.5141    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.6264   -0.111369]
done:False
-------------------------
[72]>>[54]: env.step(5)
action:[0, 1.6264]
reward:0.20356642388944146
observation:
[ 0.         0.        14.2965     0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.        25.4444
  9.1334    45.3815     0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.01162    0.0611445]
done:False
-------------------------
[72]>>[55]: env.step(0)
action:[-3.5, 2.01162]
reward:-0.5304948178730877
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       24.317     7.92809   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 15.5473    2.10861  -0.349304]
done:False
-------------------------
[72]>>[56]: env.step(3)
action:[-3.5, 7.1086100000000005]
reward:0.34941246381252355
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.4084   6.88632 42.9843   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.8687   0.       0.       2.43426 -1.42144]
done:False
-------------------------
[72]>>[57]: env.step(1)
action:[0, 2.43426]
reward:-0.348139137540825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.55431 22.0024   0.      41.0678
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.0995   0.       4.2622  -2.96414]
done:False
-------------------------
[72]>>[58]: env.step(4)
action:[0, 2.1311]
reward:0.4604590182677996
observation:
[ 0.      22.5128   0.       0.       0.       0.       0.       0.
  0.       0.       0.       2.88753  0.       0.       0.      18.6357
  0.       0.      37.4991   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.08479 -2.85251]
done:False
-------------------------
[72]>>[59]: env.step(4)
action:[0, 3.08479]
reward:-24.58586833891521
observation:
[ 0.       0.       0.      24.2577   0.       0.       0.       0.
  0.       2.16565  0.       0.       0.       0.       0.       0.
  0.      16.6883   0.       0.      35.592    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.25504 -2.44114]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 83.6369, 'y': -2.44114, 'z': 0.567243}
.........................
** Rewards description :
count    59.000000
mean     -0.485838
std       3.231141
min     -24.585868
25%      -0.513344
50%       0.162093
75%       0.216287
max       0.489697
dtype: float64
#########################
[73]>> env.reset()
=========================
[73]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.27318209110885355
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.01715 1.1648 ]
done:False
-------------------------
[73]>>[2]: env.step(2)
action:[3.5, 2.01715]
reward:-0.43184552739173676
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.31799  0.572301]
done:False
-------------------------
[73]>>[3]: env.step(0)
action:[-3.5, 3.31799]
reward:-1.1308475995615082
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.62911 -1.08897]
done:False
-------------------------
[73]>>[4]: env.step(1)
action:[0, 3.62911]
reward:-0.38667235322440896
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.47827 -2.03909]
done:False
-------------------------
[73]>>[5]: env.step(1)
action:[0, 3.47827]
reward:0.35299636115463834
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.38664 -1.02671]
done:False
-------------------------
[73]>>[6]: env.step(3)
action:[0, 8.38664]
reward:0.4503811036753036
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.39167  0.202268]
done:False
-------------------------
[73]>>[7]: env.step(3)
action:[0, 8.39167]
reward:0.5645196992257129
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.9965    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.87506   0.294749]
done:False
-------------------------
[73]>>[8]: env.step(1)
action:[0, 4.87506]
reward:0.5865544100729877
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.7978    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.04648   0.292431]
done:False
-------------------------
[73]>>[9]: env.step(1)
action:[0, 6.04648]
reward:0.7070137230521178
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.408     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.38858   0.323791]
done:False
-------------------------
[73]>>[10]: env.step(3)
action:[0, 12.388580000000001]
reward:0.8772905235695427
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.5506   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.2449   0.35599]
done:False
-------------------------
[73]>>[11]: env.step(4)
action:[0, 6.2448999999999995]
reward:0.8523391457143354
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.9023   47.7014    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.41159   0.392012]
done:False
-------------------------
[73]>>[12]: env.step(2)
action:[3.5, 9.41159]
reward:0.1854939039770288
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      18.4351   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.86854  3.35002]
done:False
-------------------------
[73]>>[13]: env.step(4)
action:[3.5, 7.868539999999999]
reward:0.8275714193283923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.1091  35.3569   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.64339  3.94205]
done:False
-------------------------
[73]>>[14]: env.step(2)
action:[3.5, 8.64339]
reward:0.8321771280495737
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.7688   5.71564  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.51674  3.99795]
done:False
-------------------------
[73]>>[15]: env.step(3)
action:[3.5, 13.51674]
reward:-24.087583677557824
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.02159 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.49039 3.95473]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8881, 'y': 3.95473, 'z': 0.574411}
.........................
** Rewards description :
count    15.000000
mean     -1.301829
std       6.329510
min     -24.087584
25%      -0.100589
50%       0.450381
75%       0.767293
max       0.877291
dtype: float64
#########################
[74]>> env.reset()
=========================
[74]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.23807839930361446
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.58755  0.304379]
done:False
-------------------------
[74]>>[2]: env.step(4)
action:[0, 0.793775]
reward:0.13974581089778354
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.45185  0.259003]
done:False
-------------------------
[74]>>[3]: env.step(4)
action:[0, 0.725925]
reward:0.12518773439501907
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.29495  0.244259]
done:False
-------------------------
[74]>>[4]: env.step(4)
action:[0, 0.647475]
reward:0.1227235326007057
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.28518  0.233427]
done:False
-------------------------
[74]>>[5]: env.step(2)
action:[3.5, 1.28518]
reward:-0.5752675156978033
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.7488  0.65537]
done:False
-------------------------
[74]>>[6]: env.step(0)
action:[-3.5, 1.7488]
reward:-1.29050710657234
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.05282  0.537412]
done:False
-------------------------
[74]>>[7]: env.step(3)
action:[-3.5, 7.0528200000000005]
reward:0.33968410292227247
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.3268   -0.260862]
done:False
-------------------------
[74]>>[8]: env.step(3)
action:[-3.5, 7.3268]
reward:0.4753687087847216
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.97769 -2.30317]
done:False
-------------------------
[74]>>[9]: env.step(4)
action:[-3.5, 1.988845]
reward:0.26922725811315673
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.72138 -3.46182]
done:False
-------------------------
[74]>>[10]: env.step(4)
action:[-3.5, 1.36069]
reward:0.19050451928827222
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 49.3625   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.9201  -3.32496]
done:False
-------------------------
[74]>>[11]: env.step(5)
action:[-3.5, 1.9201]
reward:0.2010025759726403
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.939    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90716 -3.27033]
done:False
-------------------------
[74]>>[12]: env.step(1)
action:[0, 1.90716]
reward:-0.5339186950399534
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      46.5515   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09315 -2.57301]
done:False
-------------------------
[74]>>[13]: env.step(4)
action:[0, 1.046575]
reward:0.16297414347407216
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      45.6129   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.66705 -1.51703]
done:False
-------------------------
[74]>>[14]: env.step(1)
action:[0, 1.66705]
reward:0.17762033294736035
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       44.8373    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.68811  -0.446369]
done:False
-------------------------
[74]>>[15]: env.step(3)
action:[0, 6.68811]
reward:0.307715957805172
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 43.6797    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.02091   0.268839]
done:False
-------------------------
[74]>>[16]: env.step(5)
action:[0, 2.02091]
reward:0.2071427516936478
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       42.2512    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.95631   0.361758]
done:False
-------------------------
[74]>>[17]: env.step(2)
action:[3.5, 1.95631]
reward:-0.5281678157668976
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.0631   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15071  1.25245]
done:False
-------------------------
[74]>>[18]: env.step(1)
action:[0, 2.15071]
reward:-0.5418149877044454
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      40.2566
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.93649  2.59171]
done:False
-------------------------
[74]>>[19]: env.step(2)
action:[3.5, 1.93649]
reward:-0.5337586690634133
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      39.2235   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.08776  3.72379]
done:False
-------------------------
[74]>>[20]: env.step(3)
action:[3.5, 7.087759999999999]
reward:0.31701064312498695
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      37.7894   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03615  3.9978 ]
done:False
-------------------------
[74]>>[21]: env.step(3)
action:[3.5, 7.03615]
reward:0.34346661713962034
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.2296   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.37814  3.9205 ]
done:False
-------------------------
[74]>>[22]: env.step(3)
action:[3.5, 7.37814]
reward:0.48755583425708116
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.7138   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.12222  3.86726]
done:False
-------------------------
[74]>>[23]: env.step(3)
action:[3.5, 9.12222]
reward:0.6283348128863597
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.023    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.54438  3.86664]
done:False
-------------------------
[74]>>[24]: env.step(1)
action:[0, 5.54438]
reward:-0.13323622793331402
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      26.3117  49.3071   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.28309  1.87456]
done:False
-------------------------
[74]>>[25]: env.step(0)
action:[-3.5, 6.28309]
reward:-0.12935056292915492
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       22.9906   45.6548    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.15065  -0.419756]
done:False
-------------------------
[74]>>[26]: env.step(5)
action:[-3.5, 6.15065]
reward:0.6006691996937659
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       18.6348   41.3693    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.91584   0.438615]
done:False
-------------------------
[74]>>[27]: env.step(0)
action:[-3.5, 5.91584]
reward:0.5991484817415904
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      15.5268   0.      37.6991   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.95422 -1.55012]
done:False
-------------------------
[74]>>[28]: env.step(5)
action:[-3.5, 5.95422]
reward:0.5939914881617292
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      13.5021   0.       0.
 34.5219   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.87578 -3.85391]
done:False
-------------------------
[74]>>[29]: env.step(5)
action:[-3.5, 5.87578]
reward:0.5744540573855483
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.6068   0.       0.
 46.5404  30.1108   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.63556 -3.00989]
done:False
-------------------------
[74]>>[30]: env.step(3)
action:[-3.5, 10.63556]
reward:0.6463507702249272
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.18414  0.       0.       0.       0.
 42.5107  26.0558   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.40972 -3.02258]
done:False
-------------------------
[74]>>[31]: env.step(0)
action:[-3.5, 5.40972]
reward:0.5314973963468146
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.60756  0.       0.       0.       0.       0.       0.       0.
 38.6369  22.1556   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.18611 -2.99715]
done:False
-------------------------
[74]>>[32]: env.step(5)
action:[-3.5, 5.18611]
reward:0.512890770460756
observation:
[ 0.       0.       0.       0.       0.       8.06492  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.9107  18.4026   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.99904 -2.96007]
done:False
-------------------------
[74]>>[33]: env.step(2)
action:[3.5, 4.99904]
reward:-0.9845738847223566
observation:
[ 0.       0.       0.       0.       0.       0.       0.       9.20004
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      31.5832  15.1622   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.07884 -1.15851]
done:False
-------------------------
[74]>>[34]: env.step(4)
action:[3.5, 3.0788399999999996]
reward:0.3795113891607255
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  8.79574  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.5226  14.5351   0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.81908  1.94038]
done:False
-------------------------
[74]>>[35]: env.step(3)
action:[3.5, 8.81908]
reward:0.5113319831044936
observation:
[ 0.       0.       0.       0.       0.       0.       9.4044   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 29.7183   0.      14.4359   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.0705   4.65044]
done:False
-------------------------
[74]>>[36]: env.step(5)
action:[3.5, 4.0705]
reward:0.5234544461460815
observation:
[12.6202   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.7716  47.7109   0.      12.2935   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.41573  5.99403]
done:False
-------------------------
[74]>>[37]: env.step(0)
action:[-3.5, 5.41573]
reward:-0.8901773459473057
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      22.9338  43.6732   0.
  8.122    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      16.1476
  0.       0.       0.       0.       6.2221   3.98097]
done:False
-------------------------
[74]>>[38]: env.step(5)
action:[-3.5, 6.2221]
reward:0.6012954971855182
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.       22.3716    5.94855  42.182     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 17.4806    0.        0.        0.        0.        0.        0.
  0.        5.90635  -0.460707]
done:False
-------------------------
[74]>>[39]: env.step(0)
action:[-3.5, 5.90635]
reward:0.6037376104351164
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.38288  0.      22.3516   0.      40.7749   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 20.0483   0.       0.       0.       6.01795 -4.80883]
done:False
-------------------------
[74]>>[40]: env.step(0)
action:[-3.5, 6.01795]
reward:0.59482145833082
observation:
[ 0.       0.      24.1194   0.       0.       0.       0.       0.
  0.       0.       5.25805  0.       0.       0.       0.      19.0663
  0.       0.      36.7582   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.87092 -5.60557]
done:False
-------------------------
[74]>>[41]: env.step(2)
action:[3.5, 5.87092]
reward:-0.9149318213025723
observation:
[ 0.       0.       0.       0.       0.       0.       0.      25.7942
  0.       0.       0.       3.02155  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      15.2805   0.
 34.0292   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.77774 -2.43011]
done:False
-------------------------
[74]>>[42]: env.step(1)
action:[0, 5.77774]
reward:-25.17265569186781
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 25.7567   0.       0.       2.71796  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.985
  0.      33.9691   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.69841 -1.85871]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 85.1433, 'y': -1.85871, 'z': 0.569682}
.........................
** Rewards description :
count    42.000000
mean     -0.481473
std       3.936905
min     -25.172656
25%      -0.132265
50%       0.253653
75%       0.520814
max       0.646351
dtype: float64
#########################
[75]>> env.reset()
=========================
[75]>>[1]: env.step(3)
action:[0, 10.673490000000001]
reward:0.3406648772334004
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.43386 -0.97139]
done:False
-------------------------
[75]>>[2]: env.step(3)
action:[0, 6.43386]
reward:0.4239709108525326
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.54278 -1.37096]
done:False
-------------------------
[75]>>[3]: env.step(3)
action:[0, 8.54278]
reward:0.5580328873844012
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.75161  -0.269165]
done:False
-------------------------
[75]>>[4]: env.step(4)
action:[0, 2.375805]
reward:0.3105247943928554
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.13376  0.222766]
done:False
-------------------------
[75]>>[5]: env.step(2)
action:[3.5, 3.13376]
reward:-0.4143050312194705
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.25686 1.55085]
done:False
-------------------------
[75]>>[6]: env.step(0)
action:[-3.5, 3.25686]
reward:-1.1723147116701744
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.8114   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.12642  2.24092]
done:False
-------------------------
[75]>>[7]: env.step(3)
action:[-3.5, 8.12642]
reward:0.43581576015711176
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      47.7718
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.27054  1.30148]
done:False
-------------------------
[75]>>[8]: env.step(0)
action:[-3.5, 3.27054]
reward:0.38735093489459116
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      46.524    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.86989 -1.05315]
done:False
-------------------------
[75]>>[9]: env.step(1)
action:[0, 3.86989]
reward:-0.34790457726462165
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.4976   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.90626 -3.64318]
done:False
-------------------------
[75]>>[10]: env.step(3)
action:[0, 8.90626]
reward:0.4949307356678282
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 43.023    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.83567 -4.13661]
done:False
-------------------------
[75]>>[11]: env.step(3)
action:[0, 8.83567]
reward:0.6134716318654392
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      39.9046   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.41606 -2.36372]
done:False
-------------------------
[75]>>[12]: env.step(4)
action:[0, 3.41606]
reward:0.6108744665732826
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.9737   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.73612  1.2662 ]
done:False
-------------------------
[75]>>[13]: env.step(2)
action:[3.5, 6.73612]
reward:-0.02576427184127361
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      32.7477   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.45556  4.38166]
done:False
-------------------------
[75]>>[14]: env.step(0)
action:[-3.5, 7.45556]
reward:-0.7677711560289546
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      27.7493   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.38733  3.04922]
done:False
-------------------------
[75]>>[15]: env.step(1)
action:[0, 7.38733]
reward:-0.024874301446311753
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 24.4504   47.09      0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.30517  -0.696512]
done:False
-------------------------
[75]>>[16]: env.step(0)
action:[-3.5, 7.30517]
reward:-0.052945487075839015
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.6559  42.6855   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.93616 -3.01036]
done:False
-------------------------
[75]>>[17]: env.step(5)
action:[-3.5, 6.93616]
reward:0.6825225829296304
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.9805   0.      37.6773   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.8283  -2.94179]
done:False
-------------------------
[75]>>[18]: env.step(4)
action:[-3.5, 4.8283]
reward:0.5600414652903998
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      12.0078   0.
  0.      33.1797   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.70674 -2.96823]
done:False
-------------------------
[75]>>[19]: env.step(5)
action:[-3.5, 5.70674]
reward:0.5672922002901721
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.59619  0.       0.
  0.      28.6992   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.58296 -2.99017]
done:False
-------------------------
[75]>>[20]: env.step(4)
action:[-3.5, 3.58296]
reward:0.4387439977855693
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.83646  0.       0.       0.       0.       0.
  0.      25.1595   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44378 -2.9876 ]
done:False
-------------------------
[75]>>[21]: env.step(0)
action:[-3.5, 4.44378]
reward:0.44826796992171003
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.63232
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.8876   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.35033 -2.97046]
done:False
-------------------------
[75]>>[22]: env.step(4)
action:[-3.5, 2.175165]
reward:0.2986041864500282
observation:
[ 0.       0.       0.       0.       0.       7.53447  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.8512  19.3505   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.03649 -2.95306]
done:False
-------------------------
[75]>>[23]: env.step(1)
action:[0, 3.03649]
reward:-0.4258411614137876
observation:
[ 0.       0.       0.       0.       0.       0.       0.       7.97694
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.2758   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.13769 -1.83386]
done:False
-------------------------
[75]>>[24]: env.step(0)
action:[-3.5, 3.13769]
reward:-0.44645806802943205
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         7.9444     0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        32.2479    15.9561
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.85688    0.0847868]
done:False
-------------------------
[75]>>[25]: env.step(2)
action:[3.5, 2.85688]
reward:-1.2185028005151433
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.99141  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.3469  15.3519   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.65516  1.98466]
done:False
-------------------------
[75]>>[26]: env.step(4)
action:[3.5, 1.32758]
reward:0.24917388615025637
observation:
[ 0.       0.       0.       0.       0.       0.       0.       8.36705
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.7033  15.1403   0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.6411   3.8558 ]
done:False
-------------------------
[75]>>[27]: env.step(3)
action:[3.5, 7.6411]
reward:0.401590518453457
observation:
[ 0.       0.      10.0451   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.1249  49.8786  13.9908
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.95707  4.97241]
done:False
-------------------------
[75]>>[28]: env.step(5)
action:[3.5, 2.95707]
reward:0.3740150926914786
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.65     0.      11.7741   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.5278   3.78041  4.95442]
done:False
-------------------------
[75]>>[29]: env.step(5)
action:[3.5, 3.78041]
reward:0.3650174577419309
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      23.9135  44.6685   0.       9.05836  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.1802   0.       3.46163  4.17606]
done:False
-------------------------
[75]>>[30]: env.step(5)
action:[3.5, 3.46163]
reward:0.3500579373559436
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.368   42.1524   0.       0.       6.91632  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      17.7184   3.35407  4.11778]
done:False
-------------------------
[75]>>[31]: env.step(3)
action:[3.5, 8.35407]
reward:0.46288124745079273
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.8432  39.6781   0.       0.       0.       5.2491
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.2431   3.56016  4.12535]
done:False
-------------------------
[75]>>[32]: env.step(1)
action:[0, 3.56016]
reward:-0.3104353138818463
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      16.2672   0.      36.8864
  0.       0.       0.       0.       0.       0.       3.16646  0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.8323   0.       0.       0.       4.45996  2.73607]
done:False
-------------------------
[75]>>[33]: env.step(2)
action:[3.5, 4.45996]
reward:-25.292193283048412
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.939    0.      36.4311   0.
  0.       0.       0.       0.       0.       0.       2.6264   0.
  0.       0.       0.       0.       0.       0.       0.      23.2191
  0.       0.       0.       0.       4.46853  2.16164]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 83.2534, 'y': 2.16164, 'z': 0.570222}
.........................
** Rewards description :
count    33.000000
mean     -0.640166
std       4.454102
min     -25.292193
25%      -0.310435
50%       0.350058
75%       0.448268
max       0.682523
dtype: float64
#########################
[76]>> env.reset()
=========================
[76]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.1021882581820763
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.20271  -0.569866]
done:False
-------------------------
[76]>>[2]: env.step(0)
action:[-3.5, 1.20271]
reward:-0.6225525363062595
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.20271 -1.08913]
done:False
-------------------------
[76]>>[3]: env.step(3)
action:[-3.5, 6.20271]
reward:0.22958815564044577
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.18344 -1.40149]
done:False
-------------------------
[76]>>[4]: env.step(0)
action:[-3.5, 1.18344]
reward:0.1788842802311686
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.82424 -2.62053]
done:False
-------------------------
[76]>>[5]: env.step(0)
action:[-3.5, 1.82424]
reward:0.1900173960063604
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.79833 -3.60024]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.0246, 'y': -3.60024, 'z': 0.569335}
.........................
** Rewards description :
count    5.000000
mean     0.015625
std      0.359726
min     -0.622553
25%      0.102188
50%      0.178884
75%      0.190017
max      0.229588
dtype: float64
#########################
[77]>> env.reset()
=========================
[77]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.08506965434345531
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.999722 -0.455851]
done:False
-------------------------
[77]>>[2]: env.step(3)
action:[0, 5.999722]
reward:0.2271255499949485
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.20422 -1.13644]
done:False
-------------------------
[77]>>[3]: env.step(3)
action:[0, 6.20422]
reward:0.42454002314499056
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.60743 -1.55389]
done:False
-------------------------
[77]>>[4]: env.step(1)
action:[0, 3.60743]
reward:0.41491964431424905
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.13438  -0.481823]
done:False
-------------------------
[77]>>[5]: env.step(3)
action:[0, 9.13438]
reward:0.511201013297044
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.98997  0.204933]
done:False
-------------------------
[77]>>[6]: env.step(0)
action:[-3.5, 3.98997]
reward:-0.214578072636873
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.59246  0.251439]
done:False
-------------------------
[77]>>[7]: env.step(3)
action:[-3.5, 10.592459999999999]
reward:0.7530028465656216
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.4006    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.89483   0.280596]
done:False
-------------------------
[77]>>[8]: env.step(3)
action:[-3.5, 11.894829999999999]
reward:0.8878737810723129
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      40.6312   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.5263  -2.16725]
done:False
-------------------------
[77]>>[9]: env.step(1)
action:[0, 8.5263]
reward:0.1295375739932796
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.5105   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.24394 -3.39081]
done:False
-------------------------
[77]>>[10]: env.step(5)
action:[0, 9.24394]
reward:0.8857307832122521
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.0575   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.15697  1.31766]
done:False
-------------------------
[77]>>[11]: env.step(4)
action:[0, 7.156969999999999]
reward:0.7678503125104887
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       23.2723   46.0361    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.96366   0.204542]
done:False
-------------------------
[77]>>[12]: env.step(3)
action:[0, 12.96366]
reward:0.8514341770672742
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.5242   40.236     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.71859   0.366271]
done:False
-------------------------
[77]>>[13]: env.step(5)
action:[0, 7.71859]
reward:0.7772518897378712
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.8194    0.       34.4098    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.95685   0.444742]
done:False
-------------------------
[77]>>[14]: env.step(2)
action:[3.5, 7.95685]
reward:0.029050413391099483
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       6.40112 29.5647
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.9229   3.03361]
done:False
-------------------------
[77]>>[15]: env.step(3)
action:[3.5, 12.9229]
reward:-24.127529426771066
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      42.103   26.5103   3.26579  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.03965  4.85957]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.8903, 'y': 4.85957, 'z': 0.570636}
.........................
** Rewards description :
count    15.000000
mean     -1.173168
std       6.359962
min     -24.127529
25%       0.107304
50%       0.424540
75%       0.772551
max       0.887874
dtype: float64
#########################
[78]>> env.reset()
=========================
[78]>>[1]: env.step(3)
action:[0, 13.57395]
reward:0.521119786583509
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        3.00938   0.0990731]
done:False
-------------------------
[78]>>[2]: env.step(0)
action:[-3.5, 3.00938]
reward:-0.22556658580554512
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.6938   0.237856]
done:False
-------------------------
[78]>>[3]: env.step(3)
action:[-3.5, 10.6938]
reward:0.7831030215157853
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.29645 -1.96319]
done:False
-------------------------
[78]>>[4]: env.step(0)
action:[-3.5, 7.29645]
reward:0.8515856549905321
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.5387   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.13762 -4.18901]
done:False
-------------------------
[78]>>[5]: env.step(2)
action:[3.5, 9.13762]
reward:-0.6025881517107441
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       42.6531    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.35868   0.650295]
done:False
-------------------------
[78]>>[6]: env.step(3)
action:[3.5, 14.35868]
reward:0.982965697842934
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.     39.4607  0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  9.37    6.5101]
done:False
-------------------------
[78]>>[7]: env.step(3)
action:[3.5, 14.37]
reward:1.0323420463719009
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      32.7797   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.1581   4.91338]
done:False
-------------------------
[78]>>[8]: env.step(3)
action:[3.5, 15.1581]
reward:1.1161556383692384
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      25.1496   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.3688   3.76998]
done:False
-------------------------
[78]>>[9]: env.step(4)
action:[3.5, 9.3688]
reward:1.0825085973325432
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.6767   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.24     3.90947]
done:False
-------------------------
[78]>>[10]: env.step(3)
action:[3.5, 17.240000000000002]
reward:1.2431877732133856
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.15537  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.2009   3.98201]
done:False
-------------------------
[78]>>[11]: env.step(2)
action:[3.5, 13.2009]
reward:-23.791252934285136
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.48092  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.5395   4.00986]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.1862, 'y': 4.00986, 'z': 0.570018}
.........................
** Rewards description :
count    11.000000
mean     -1.546040
std       7.401015
min     -23.791253
25%       0.147777
50%       0.851586
75%       1.057425
max       1.243188
dtype: float64
#########################
[79]>> env.reset()
=========================
[79]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.00022206360462766788
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00259079 0.199039  ]
done:False
-------------------------
[79]>>[2]: env.step(4)
action:[0, 0.001295395]
reward:6.661520876402198e-05
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00045333 0.198812  ]
done:False
-------------------------
[79]>>[3]: env.step(5)
action:[0, 0.000453333]
reward:0.04455098373143583
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.521607 0.186497]
done:False
-------------------------
[79]>>[4]: env.step(3)
action:[0, 5.521607]
reward:0.23430693301294903
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.41118  0.190383]
done:False
-------------------------
[79]>>[5]: env.step(3)
action:[0, 6.41118]
reward:0.3941910157787528
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.17103  0.204075]
done:False
-------------------------
[79]>>[6]: env.step(2)
action:[3.5, 3.17103]
reward:-0.38652236878895707
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.59467 1.40988]
done:False
-------------------------
[79]>>[7]: env.step(3)
action:[3.5, 8.59467]
reward:0.47115166868087544
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.60639 3.5705 ]
done:False
-------------------------
[79]>>[8]: env.step(3)
action:[3.5, 8.606390000000001]
reward:0.5971784617611063
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.25527 3.94478]
done:False
-------------------------
[79]>>[9]: env.step(3)
action:[3.5, 10.25527]
reward:0.7278172793420608
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      46.5248   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.62575  3.78176]
done:False
-------------------------
[79]>>[10]: env.step(1)
action:[0, 6.62575]
reward:-0.03826197460795122
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      42.1596   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.30928  1.3365 ]
done:False
-------------------------
[79]>>[11]: env.step(3)
action:[0, 12.309280000000001]
reward:0.8383809883165585
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       37.4269    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.69082  -0.288258]
done:False
-------------------------
[79]>>[12]: env.step(3)
action:[0, 12.69082]
reward:0.9164118445891152
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.3909    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.75748   0.240233]
done:False
-------------------------
[79]>>[13]: env.step(5)
action:[0, 8.75748]
reward:0.9317783025505539
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      24.3177  47.1095   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.97512  0.37309]
done:False
-------------------------
[79]>>[14]: env.step(3)
action:[0, 14.97512]
reward:1.090733852414918
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       16.5217    0.       39.2286    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.9778    0.436385]
done:False
-------------------------
[79]>>[15]: env.step(3)
action:[0, 15.9778]
reward:1.175462172943523
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.07154   0.       46.6444   30.4759    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       12.2224    0.485355]
done:False
-------------------------
[79]>>[16]: env.step(0)
action:[-3.5, 12.2224]
reward:0.4156788712854693
observation:
[ 0.       0.       0.       0.       6.40277  0.       0.       0.
  0.       0.       0.       0.       0.      38.4654  21.9952   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.9824  -2.65101]
done:False
-------------------------
[79]>>[17]: env.step(3)
action:[-3.5, 17.9824]
reward:1.2352884424254063
observation:
[ 0.       0.       0.      12.2978   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.6673   0.      48.5216   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.8587  -2.78198]
done:False
-------------------------
[79]>>[18]: env.step(0)
action:[-3.5, 12.8587]
reward:1.1598990777264362
observation:
[ 0.      21.1255   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       3.79921  0.       0.
 19.9946   0.      38.9455   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.7185  -2.848  ]
done:False
-------------------------
[79]>>[19]: env.step(1)
action:[0, 12.7185]
reward:0.3999829568538913
observation:
[ 0.      30.9065   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.8959   0.
  0.       0.      28.8435   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.5751  -2.80891]
done:False
-------------------------
[79]>>[20]: env.step(1)
action:[0, 12.5751]
reward:1.1405403817647015
observation:
[40.1201   0.       0.       0.       0.       0.       0.       0.
  6.37085  0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.4843   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.4426  -2.76112]
done:False
-------------------------
[79]>>[21]: env.step(3)
action:[0, 17.4426]
reward:1.2023852138907283
observation:
[ 0.       0.      24.951   48.0082   9.31696  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      35.4479   0.      12.099
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.3582   0.58965]
done:False
-------------------------
[79]>>[22]: env.step(2)
action:[3.5, 12.3582]
reward:0.38661056924424964
observation:
[33.5048   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      28.3571   0.       0.       0.
  0.       0.       9.39368  0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.4272   4.83664]
done:False
-------------------------
[79]>>[23]: env.step(3)
action:[3.5, 17.4272]
reward:1.2073550939792987
observation:
[26.2618   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      19.5346   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.4395
  0.       0.       0.      42.5842  12.4564   4.32423]
done:False
-------------------------
[79]>>[24]: env.step(3)
action:[3.5, 17.456400000000002]
reward:1.2511757573538138
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.4555   0.       0.       0.      11.5345   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      18.0216   0.      35.9253  13.3069   4.41269]
done:False
-------------------------
[79]>>[25]: env.step(0)
action:[-3.5, 13.3069]
reward:-0.24977126214417833
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.0893   0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.60085  0.       0.       0.
  0.       0.      27.6851  46.3469  14.3252   4.48246]
done:False
-------------------------
[79]>>[26]: env.step(2)
action:[3.5, 14.3252]
reward:-0.21875641661061884
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.2931   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.6319   0.      38.2156   0.      14.7096   4.54366]
done:False
-------------------------
[79]>>[27]: env.step(5)
action:[3.5, 14.7096]
reward:1.2814472598075926
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      17.5159   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.6422  49.0147  14.6178   4.60334]
done:False
-------------------------
[79]>>[28]: env.step(5)
action:[3.5, 14.6178]
reward:1.272961305644622
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      44.4053   0.       0.       7.53568  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.1251   0.      14.4628   4.66218]
done:False
-------------------------
[79]>>[29]: env.step(1)
action:[0, 14.4628]
reward:0.5137851730955727
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.9083   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.09994  0.      47.3948   0.      14.3118   4.7243 ]
done:False
-------------------------
[79]>>[30]: env.step(4)
action:[0, 12.3118]
reward:1.1938433262609003
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      23.6578   0.
 42.5837   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.8584   0.       0.      13.48     1.38509]
done:False
-------------------------
[79]>>[31]: env.step(3)
action:[0, 18.48]
reward:1.2642282122543245
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.     13.8411  0.
 32.8394  0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.     24.7288
 13.3166  1.4511]
done:False
-------------------------
[79]>>[32]: env.step(0)
action:[-3.5, 13.3166]
reward:0.44130574339381745
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       4.40956  0.
  0.       0.       0.      23.1007   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.6424  13.1813   1.40034]
done:False
-------------------------
[79]>>[33]: env.step(4)
action:[-3.5, 11.1813]
reward:1.1142190724020977
observation:
[ 0.       7.38991  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.1239
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.1605   0.       0.      12.3294  -1.78587]
done:False
-------------------------
[79]>>[34]: env.step(0)
action:[-3.5, 12.3294]
reward:1.1215748094865874
observation:
[ 0.       0.      14.7976   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.49531  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.1703  -1.87365]
done:False
-------------------------
[79]>>[35]: env.step(3)
action:[-3.5, 17.170299999999997]
reward:1.181382587479678
observation:
[ 0.      23.4529   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       4.54067  0.       0.      12.0334  -1.95399]
done:False
-------------------------
[79]>>[36]: env.step(3)
action:[-3.5, 17.0334]
reward:1.1738062468527908
observation:
[ 0.      32.2249   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      13.1698  11.9281  -1.92469]
done:False
-------------------------
[79]>>[37]: env.step(3)
action:[-3.5, 16.9281]
reward:1.2074666939685064
observation:
[41.2779   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      22.2746  12.5833  -1.87731]
done:False
-------------------------
[79]>>[38]: env.step(2)
action:[3.5, 12.5833]
reward:-0.3228046472729553
observation:
[ 0.       0.       0.       0.       0.      30.9358  49.074    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1029   1.87764]
done:False
-------------------------
[79]>>[39]: env.step(1)
action:[0, 13.1029]
reward:0.4298914209474658
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.9451   0.       0.      13.0227   7.54765]
done:False
-------------------------
[79]>>[40]: env.step(0)
action:[-3.5, 13.0227]
reward:0.4205363899453016
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       44.3032
  0.        0.        0.        0.        0.        0.        0.
  0.       12.8709    0.816905]
done:False
-------------------------
[79]>>[41]: env.step(3)
action:[-3.5, 17.8709]
reward:1.237239571504416
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.9251  -5.83658]
done:False
-------------------------
[79]>>[42]: env.step(3)
action:[-3.5, 17.9251]
reward:1.2797245103312285
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.7776  -1.46621]
done:False
-------------------------
[79]>>[43]: env.step(3)
action:[-3.5, 18.7776]
reward:1.3361041475052071
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.8149  -1.76403]
done:False
-------------------------
[79]>>[44]: env.step(3)
action:[-3.5, 19.8149]
reward:1.3782477982721835
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.6003  -1.57807]
done:False
-------------------------
[79]>>[45]: env.step(3)
action:[-3.5, 20.6003]
reward:1.4110056313777726
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.3182  -1.49822]
done:False
-------------------------
[79]>>[46]: env.step(4)
action:[-3.5, 14.318200000000001]
reward:1.3313879097698018
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.8196  -1.43126]
done:False
-------------------------
[79]>>[47]: env.step(3)
action:[-3.5, 20.8196]
reward:1.3899849880728734
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.664   -1.36834]
done:False
-------------------------
[79]>>[48]: env.step(3)
action:[-3.5, 20.664]
reward:1.382673625507965
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.5053  -1.30557]
done:False
-------------------------
[79]>>[49]: env.step(1)
action:[0, 15.5053]
reward:0.5965838543993933
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.8821  -1.23816]
done:False
-------------------------
[79]>>[50]: env.step(2)
action:[3.5, 15.8821]
reward:0.6333519264023004
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.7189  -1.17222]
done:False
-------------------------
[79]>>[51]: env.step(3)
action:[3.5, 21.7189]
reward:1.460613922065881
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.7548   3.65845]
done:False
-------------------------
[79]>>[52]: env.step(1)
action:[0, 17.7548]
reward:0.6937301253124062
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.0936   6.98782]
done:False
-------------------------
[79]>>[53]: env.step(3)
action:[0, 23.0936]
reward:1.478241783072718
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 18.242   1.5017]
done:False
-------------------------
[79]>>[54]: env.step(3)
action:[0, 23.242]
reward:1.4886317974375571
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.8497   2.63655]
done:False
-------------------------
[79]>>[55]: env.step(3)
action:[0, 23.8497]
reward:1.498213422437751
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      19.6732   2.67652]
done:False
-------------------------
[79]>>[56]: env.step(3)
action:[0, 24.6732]
reward:1.4990927132610548
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.5068   2.73897]
done:False
-------------------------
[79]>>[57]: env.step(3)
action:[0, 25.5068]
reward:1.4925506088667837
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.0631   2.84173]
done:False
-------------------------
[79]>>[58]: env.step(3)
action:[0, 26.0631]
reward:1.4714392141753878
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.9824   2.92115]
done:False
-------------------------
[79]>>[59]: env.step(5)
action:[0, 21.9824]
reward:1.481582463750613
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.5861   3.01815]
done:False
-------------------------
[79]>>[60]: env.step(3)
action:[0, 27.5861]
reward:1.4355404555850457
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.6052   3.11302]
done:False
-------------------------
[79]>>[61]: env.step(3)
action:[0, 27.6052]
reward:1.4028393761624538
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.2358   3.19816]
done:False
-------------------------
[79]>>[62]: env.step(4)
action:[0, 21.2358]
reward:1.4705762735057801
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.2204   3.29872]
done:False
-------------------------
[79]>>[63]: env.step(3)
action:[0, 28.2204]
reward:1.4082147010812447
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.9884   3.38931]
done:False
-------------------------
[79]>>[64]: env.step(5)
action:[0, 22.9884]
reward:1.4618021314803418
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.0727   3.48119]
done:False
-------------------------
[79]>>[65]: env.step(1)
action:[0, 23.0727]
reward:1.4620011949205085
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.0455   3.57802]
done:False
-------------------------
[79]>>[66]: env.step(3)
action:[0, 28.0455]
reward:1.4084919122443238
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.0272   3.66749]
done:False
-------------------------
[79]>>[67]: env.step(3)
action:[0, 28.0272]
reward:1.3687676279777463
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.6539   3.76375]
done:False
-------------------------
[79]>>[68]: env.step(5)
action:[0, 23.6539]
reward:1.4175151665566434
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.9591   3.86023]
done:False
-------------------------
[79]>>[69]: env.step(0)
action:[-3.5, 23.9591]
reward:0.6398076689989978
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       24.3606    0.961513]
done:False
-------------------------
[79]>>[70]: env.step(0)
action:[-3.5, 24.3606]
reward:1.4164194562513979
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       23.8032    0.476637]
done:False
-------------------------
[79]>>[71]: env.step(3)
action:[-3.5, 28.8032]
reward:1.3432709178826354
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      23.7917   0.61896]
done:False
-------------------------
[79]>>[72]: env.step(0)
action:[-3.5, 23.7917]
reward:1.4097930733389517
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       24.0674    0.778077]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': 750.215, 'y': 0.778077, 'z': 0.569226}
.........................
** Rewards description :
count    72.000000
mean      0.963985
std       0.538095
min      -0.386522
25%       0.575884
50%       1.198114
75%       1.404183
max       1.499093
dtype: float64
#########################
[80]>> env.reset()
=========================
[80]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.6946458205133731
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.648834 -0.212885]
done:False
-------------------------
[80]>>[2]: env.step(3)
action:[-3.5, 5.648834]
reward:0.1739804348516371
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.648833 -0.452986]
done:False
-------------------------
[80]>>[3]: env.step(5)
action:[-3.5, 0.648833]
reward:0.06825012914035865
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.638678 -0.413126]
done:False
-------------------------
[80]>>[4]: env.step(3)
action:[-3.5, 5.638678]
reward:0.1518328333791365
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.385338 -0.32225 ]
done:False
-------------------------
[80]>>[5]: env.step(3)
action:[-3.5, 5.385338]
reward:0.18476886136325302
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.84471  -0.899304]
done:False
-------------------------
[80]>>[6]: env.step(5)
action:[-3.5, 0.84471]
reward:0.08355269899472541
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.770587 -1.3933  ]
done:False
-------------------------
[80]>>[7]: env.step(3)
action:[-3.5, 5.770587]
reward:0.21177136557296145
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  1.075  -2.0489]
done:False
-------------------------
[80]>>[8]: env.step(3)
action:[-3.5, 6.075]
reward:0.3061556458843214
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15488 -3.11644]
done:False
-------------------------
[80]>>[9]: env.step(3)
action:[-3.5, 7.15488]
reward:0.38338636111790947
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84885 -3.6146 ]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.11289, 'y': -3.6146, 'z': 0.570807}
.........................
** Rewards description :
count    9.000000
mean     0.096561
std      0.312906
min     -0.694646
25%      0.083553
50%      0.173980
75%      0.211771
max      0.383386
dtype: float64
#########################
[81]>> env.reset()
=========================
[81]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.09862281080149415
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.16038  -0.556481]
done:False
-------------------------
[81]>>[2]: env.step(1)
action:[0, 1.16038]
reward:0.11658854704054178
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.08386 -1.12838]
done:False
-------------------------
[81]>>[3]: env.step(3)
action:[0, 6.08386]
reward:0.1777175834986972
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.585079 -1.45963 ]
done:False
-------------------------
[81]>>[4]: env.step(4)
action:[0, 0.2925395]
reward:0.09735332128210494
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.07218 -1.49418]
done:False
-------------------------
[81]>>[5]: env.step(3)
action:[0, 6.0721799999999995]
reward:0.21419314303714287
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.02898 -1.04224]
done:False
-------------------------
[81]>>[6]: env.step(4)
action:[0, 0.51449]
reward:0.15289768369640402
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.67915  -0.908803]
done:False
-------------------------
[81]>>[7]: env.step(3)
action:[0, 6.67915]
reward:0.411420607915385
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.32206 -0.27565]
done:False
-------------------------
[81]>>[8]: env.step(5)
action:[0, 3.32206]
reward:0.39502642329220583
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.95386  0.237591]
done:False
-------------------------
[81]>>[9]: env.step(1)
action:[0, 3.95386]
reward:0.41513296418422996
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.05048  0.262093]
done:False
-------------------------
[81]>>[10]: env.step(3)
action:[0, 9.05048]
reward:0.517589892050029
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.3539    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.09419   0.263855]
done:False
-------------------------
[81]>>[11]: env.step(0)
action:[-3.5, 4.09419]
reward:-0.3252986514954842
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.2713    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.13699   0.276985]
done:False
-------------------------
[81]>>[12]: env.step(0)
action:[-3.5, 4.13699]
reward:0.44840722787057075
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      43.7136   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.42881 -1.23511]
done:False
-------------------------
[81]>>[13]: env.step(0)
action:[-3.5, 4.42881]
reward:0.4663683337752822
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.8858   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.5863  -3.54772]
done:False
-------------------------
[81]>>[14]: env.step(0)
action:[-3.5, 4.5863]
reward:0.4437371087517893
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.6902   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.25674 -3.17717]
done:False
-------------------------
[81]>>[15]: env.step(3)
action:[-3.5, 9.25674]
reward:0.5484942767016281
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.4944   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44744 -3.13293]
done:False
-------------------------
[81]>>[16]: env.step(1)
action:[0, 4.44744]
reward:-0.22688967321279108
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.9024   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.317   -3.13878]
done:False
-------------------------
[81]>>[17]: env.step(1)
action:[0, 5.317]
reward:0.6227790515515669
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 27.55    49.8038   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.42083 -3.11975]
done:False
-------------------------
[81]>>[18]: env.step(0)
action:[-3.5, 6.42083]
reward:-0.07529457295024067
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.7267  44.8153   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.84991 -3.09232]
done:False
-------------------------
[81]>>[19]: env.step(1)
action:[0, 6.84991]
reward:-0.0707069264223339
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      17.5529
  0.      39.3514   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.80553 -3.06232]
done:False
-------------------------
[81]>>[20]: env.step(5)
action:[0, 6.80553]
reward:0.6829879580354457
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 12.7738    0.       35.0173    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.86735  -0.739764]
done:False
-------------------------
[81]>>[21]: env.step(4)
action:[0, 4.86735]
reward:0.5625221210028406
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.69041 47.4385  31.3152   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.72974  1.01821]
done:False
-------------------------
[81]>>[22]: env.step(4)
action:[0, 3.7297399999999996]
reward:0.5196094301693679
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.16897   0.        0.       43.4174   27.2531    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.45072   0.605129]
done:False
-------------------------
[81]>>[23]: env.step(0)
action:[-3.5, 5.45072]
reward:-0.19742569289017176
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        2.9854    0.        0.        0.        0.
  0.        0.        0.       39.3508   23.1751    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.45266   0.574416]
done:False
-------------------------
[81]>>[24]: env.step(4)
action:[-3.5, 3.45266]
reward:0.4246382732305702
observation:
[ 0.       5.26047  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      36.6768  20.3243   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.29657 -1.09437]
done:False
-------------------------
[81]>>[25]: env.step(2)
action:[3.5, 4.29657]
reward:-1.062149518978201
observation:
[ 0.       0.       8.15975  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      34.9497  18.4361   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.25397 -3.26045]
done:False
-------------------------
[81]>>[26]: env.step(1)
action:[0, 4.25397]
reward:-0.33885264825810396
observation:
[ 0.       0.       0.       0.      10.1068   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      15.4855   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.92489 -2.94716]
done:False
-------------------------
[81]>>[27]: env.step(4)
action:[0, 1.962445]
reward:0.2562624754406332
observation:
[ 0.       0.       0.       0.       0.       0.      11.09     0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.4975  49.5063   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.56908 -1.87012]
done:False
-------------------------
[81]>>[28]: env.step(1)
action:[0, 2.56908]
reward:0.26223271583624225
observation:
[ 0.        0.        0.        0.        0.        0.        0.
 11.3431    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       28.738    12.3769    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.49054  -0.211589]
done:False
-------------------------
[81]>>[29]: env.step(3)
action:[0, 7.49054]
reward:0.3882083492187225
observation:
[ 0.        0.        0.       12.7374    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       26.8528    0.
 10.6458    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.8257    0.740895]
done:False
-------------------------
[81]>>[30]: env.step(2)
action:[3.5, 2.8257]
reward:-0.4591291101227574
observation:
[ 0.       0.       0.       0.       0.       0.      13.6989   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      25.4935
 45.8534   9.6802   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.77842  2.30368]
done:False
-------------------------
[81]>>[31]: env.step(4)
action:[3.5, 1.38921]
reward:0.2789051526038571
observation:
[ 0.       0.       0.       0.       0.      14.7481   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.325
 45.0038   9.22306  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.99019  4.0403 ]
done:False
-------------------------
[81]>>[32]: env.step(4)
action:[3.5, 1.495095]
reward:0.22395030254626946
observation:
[ 0.      16.4663   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.6329  43.4237   0.       8.02382
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29176  4.44486]
done:False
-------------------------
[81]>>[33]: env.step(2)
action:[3.5, 2.29176]
reward:0.23379213974799257
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.9737  41.782    0.       0.       6.68408  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      18.1188   2.21237  4.23277]
done:False
-------------------------
[81]>>[34]: env.step(3)
action:[3.5, 7.21237]
reward:0.3557829282205971
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.2304  40.0655   0.       0.       0.       5.50028
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      19.8588   2.48797  4.17054]
done:False
-------------------------
[81]>>[35]: env.step(0)
action:[-3.5, 2.48797]
reward:-1.1874164658170625
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      17.4201   0.
 38.1178   0.       0.       0.       0.       3.84967  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.6546   0.       0.       3.13122  3.17137]
done:False
-------------------------
[81]>>[36]: env.step(0)
action:[-3.5, 3.13122]
reward:-24.66665623342811
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.7476   0.      37.2292   0.
  0.       0.       0.       0.       2.68765  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      22.4097
  0.       0.       0.       0.       3.22822  2.10539]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 82.4791, 'y': 2.10539, 'z': 0.568606}
.........................
** Rewards description :
count    36.000000
mean     -0.535961
std       4.158311
min     -24.666656
25%      -0.071854
50%       0.245027
75%       0.429413
max       0.682988
dtype: float64
#########################
[82]>> env.reset()
=========================
[82]>>[1]: env.step(4)
action:[0, 1.55541]
reward:-24.707479234653626
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.11634  -0.385065]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 82.9719, 'y': -0.385065, 'z': 0.568883}
.........................
** Rewards description :
count     1.000000
mean    -24.707479
std            NaN
min     -24.707479
25%     -24.707479
50%     -24.707479
75%     -24.707479
max     -24.707479
dtype: float64
#########################
[83]>> env.reset()
=========================
[83]>>[1]: env.step(5)
action:[0, 0.35917]
reward:0.037285529345984364
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.346574  -0.0464994]
done:False
-------------------------
[83]>>[2]: env.step(0)
action:[-3.5, 0.346574]
reward:-0.7095501478006572
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.386884 -0.180446]
done:False
-------------------------
[83]>>[3]: env.step(5)
action:[-3.5, 0.386884]
reward:0.0654736085077019
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.671399 -0.384073]
done:False
-------------------------
[83]>>[4]: env.step(1)
action:[0, 0.671399]
reward:-0.6673833812158265
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.802836 -0.810108]
done:False
-------------------------
[83]>>[5]: env.step(3)
action:[0, 5.802836]
reward:0.23471707463173908
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.34587  -0.980307]
done:False
-------------------------
[83]>>[6]: env.step(5)
action:[0, 1.34587]
reward:0.16483310236754356
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.61456  -0.759023]
done:False
-------------------------
[83]>>[7]: env.step(3)
action:[0, 6.61456]
reward:0.2811233675784859
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.71114  -0.157345]
done:False
-------------------------
[83]>>[8]: env.step(3)
action:[0, 6.71114]
reward:0.30621182081251014
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.99654  0.156396]
done:False
-------------------------
[83]>>[9]: env.step(3)
action:[0, 6.9965399999999995]
reward:0.3995212401991708
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.09204  0.256402]
done:False
-------------------------
[83]>>[10]: env.step(1)
action:[0, 3.09204]
reward:0.3716216724047072
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.7166   0.256904]
done:False
-------------------------
[83]>>[11]: env.step(5)
action:[0, 3.7166]
reward:0.39101373040987475
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.4302    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.80457   0.265647]
done:False
-------------------------
[83]>>[12]: env.step(0)
action:[-3.5, 3.80457]
reward:-0.33386283170320297
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      46.0392   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.10055 -1.11968]
done:False
-------------------------
[83]>>[13]: env.step(0)
action:[-3.5, 4.10055]
reward:0.43330396017537104
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      44.4261   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24497 -3.40128]
done:False
-------------------------
[83]>>[14]: env.step(2)
action:[3.5, 4.24497]
reward:-1.0665042906296405
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.4687   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.21131 -3.1515 ]
done:False
-------------------------
[83]>>[15]: env.step(2)
action:[3.5, 4.21131]
reward:0.436539307092039
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       39.1603    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.25855  -0.765033]
done:False
-------------------------
[83]>>[16]: env.step(5)
action:[3.5, 4.25855]
reward:0.4218338511605221
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.3698   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.05943  2.29745]
done:False
-------------------------
[83]>>[17]: env.step(4)
action:[3.5, 2.029715]
reward:0.27526724483956344
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      37.4809
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.78534  4.43188]
done:False
-------------------------
[83]>>[18]: env.step(3)
action:[3.5, 7.78534]
reward:0.3984937233307636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      35.8016   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88185  5.23766]
done:False
-------------------------
[83]>>[19]: env.step(4)
action:[3.5, 1.440925]
reward:0.215848259154323
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.9534   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.20688  4.95346]
done:False
-------------------------
[83]>>[20]: env.step(4)
action:[3.5, 1.10344]
reward:0.17247480128335063
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.7051   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.76706  4.22506]
done:False
-------------------------
[83]>>[21]: env.step(2)
action:[3.5, 1.76706]
reward:0.1993116273976996
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.3639   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92496  3.91646]
done:False
-------------------------
[83]>>[22]: env.step(3)
action:[3.5, 6.9249600000000004]
reward:0.3135509701791092
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.8917   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.03396  3.84726]
done:False
-------------------------
[83]>>[23]: env.step(3)
action:[3.5, 7.03396]
reward:0.33737677989173065
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      28.2921   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30276  3.85629]
done:False
-------------------------
[83]>>[24]: env.step(5)
action:[3.5, 2.30276]
reward:0.3236369454758099
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.1726   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.31464  3.88055]
done:False
-------------------------
[83]>>[25]: env.step(5)
action:[3.5, 3.31464]
reward:0.43835708681819313
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.1703   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.50592  3.90166]
done:False
-------------------------
[83]>>[26]: env.step(3)
action:[3.5, 9.50592]
reward:0.6364745521197297
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.353    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.55837  3.92194]
done:False
-------------------------
[83]>>[27]: env.step(4)
action:[3.5, 3.55837]
reward:0.6099062003093181
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.6989   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.68756  3.9468 ]
done:False
-------------------------
[83]>>[28]: env.step(2)
action:[3.5, 6.68756]
reward:0.6994008213387719
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.50388 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.12297 3.97486]
done:False
-------------------------
[83]>>[29]: env.step(3)
action:[3.5, 12.122969999999999]
reward:-24.19582754245432
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.1465  0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.24117 4.00387]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8291, 'y': 4.00387, 'z': 0.569951}
.........................
** Rewards description :
count    29.000000
mean     -0.648605
std       4.546700
min     -24.195828
25%       0.164833
50%       0.306212
75%       0.399521
max       0.699401
dtype: float64
#########################
[84]>> env.reset()
=========================
[84]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.00012225475443118836
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00142632 0.199287  ]
done:False
-------------------------
[84]>>[2]: env.step(3)
action:[0, 5.00142632]
reward:0.10621818132819072
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00023089 0.199383  ]
done:False
-------------------------
[84]>>[3]: env.step(2)
action:[3.5, 0.000230894]
reward:-0.7342380934776157
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.184074 0.202492]
done:False
-------------------------
[84]>>[4]: env.step(0)
action:[-3.5, 0.184074]
reward:-1.4613339493242345
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.406558 0.200935]
done:False
-------------------------
[84]>>[5]: env.step(5)
action:[-3.5, 0.406558]
reward:0.06411880275377081
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.650498  -0.0178278]
done:False
-------------------------
[84]>>[6]: env.step(4)
action:[-3.5, 0.325249]
reward:0.06784245890177537
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.714762 -0.285755]
done:False
-------------------------
[84]>>[7]: env.step(5)
action:[-3.5, 0.714762]
reward:0.09486185224255195
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.937068 -0.704924]
done:False
-------------------------
[84]>>[8]: env.step(3)
action:[-3.5, 5.937068]
reward:0.22980253839927478
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.25246 -1.32963]
done:False
-------------------------
[84]>>[9]: env.step(3)
action:[-3.5, 6.25246]
reward:0.32191726291413936
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30586 -2.52537]
done:False
-------------------------
[84]>>[10]: env.step(0)
action:[-3.5, 2.30586]
reward:0.2916169446900627
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.91758 -3.36825]
done:False
-------------------------
[84]>>[11]: env.step(3)
action:[-3.5, 7.91758]
reward:0.39628277785457044
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82085 -3.32916]
done:False
-------------------------
[84]>>[12]: env.step(3)
action:[-3.5, 7.82085]
reward:0.39963018613767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88734 -3.27571]
done:False
-------------------------
[84]>>[13]: env.step(1)
action:[0, 2.88734]
reward:-0.42546824573329745
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.17961 -2.19444]
done:False
-------------------------
[84]>>[14]: env.step(1)
action:[0, 3.17961]
reward:0.32191625611496355
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       48.9824    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.07406  -0.192169]
done:False
-------------------------
[84]>>[15]: env.step(3)
action:[0, 8.07406]
reward:0.4503463562605212
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       46.6854    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.46937   0.469683]
done:False
-------------------------
[84]>>[16]: env.step(3)
action:[0, 8.46937]
reward:0.51300632292434
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.8858    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.17973   0.333377]
done:False
-------------------------
[84]>>[17]: env.step(3)
action:[0, 9.17973]
reward:0.6220295896225445
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.2332    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.44506   0.312752]
done:False
-------------------------
[84]>>[18]: env.step(5)
action:[0, 5.44506]
reward:0.6381310862127343
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.6565    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.59599   0.334212]
done:False
-------------------------
[84]>>[19]: env.step(2)
action:[3.5, 6.59599]
reward:-0.056244850503050614
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      30.9811
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.06793  2.85648]
done:False
-------------------------
[84]>>[20]: env.step(1)
action:[0, 7.06793]
reward:-0.04145147406253258
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      26.3785   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.15449  4.5226 ]
done:False
-------------------------
[84]>>[21]: env.step(5)
action:[0, 7.15449]
reward:0.6876640370947895
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       23.0361   45.8823    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.8444    0.740282]
done:False
-------------------------
[84]>>[22]: env.step(4)
action:[0, 4.8444]
reward:0.5563927866646758
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.2387   41.859     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.65457  -0.277927]
done:False
-------------------------
[84]>>[23]: env.step(0)
action:[-3.5, 5.65457]
reward:-0.17990814887064233
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       15.7172
 38.0997    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.63306  -0.831843]
done:False
-------------------------
[84]>>[24]: env.step(5)
action:[-3.5, 5.63306]
reward:0.5771423593833949
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.1309   0.      35.3646   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.7319  -3.68282]
done:False
-------------------------
[84]>>[25]: env.step(4)
action:[-3.5, 3.7319000000000004]
reward:0.5178019035927499
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.4885
  0.       0.      31.3378   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.4266  -2.89214]
done:False
-------------------------
[84]>>[26]: env.step(1)
action:[0, 5.4266]
reward:-0.19204176595916145
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.87959  0.       0.       0.      27.8671   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.52967 -1.26244]
done:False
-------------------------
[84]>>[27]: env.step(4)
action:[0, 3.5296700000000003]
reward:-24.471125041126623
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.78703  0.       0.       0.      25.8489   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.6218   1.1632 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.1543, 'y': 1.1632, 'z': 0.569385}
.........................
** Rewards description :
count    27.000000
mean     -0.766851
std       4.760506
min     -24.471125
25%      -0.048848
50%       0.229803
75%       0.481676
max       0.687664
dtype: float64
#########################
[85]>> env.reset()
=========================
[85]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.16433646018330628
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.94506  -0.909198]
done:False
-------------------------
[85]>>[2]: env.step(3)
action:[0, 6.94506]
reward:0.3013490975850926
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.87793  -0.962812]
done:False
-------------------------
[85]>>[3]: env.step(0)
action:[-3.5, 1.87793]
reward:-0.5675936288349701
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.69307  -0.733809]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.01309, 'y': -0.733809, 'z': 0.570628}
.........................
** Rewards description :
count    3.000000
mean    -0.033969
std      0.467182
min     -0.567594
25%     -0.201629
50%      0.164336
75%      0.232843
max      0.301349
dtype: float64
#########################
[86]>> env.reset()
=========================
[86]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.12790778078387482
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.50888  -0.758451]
done:False
-------------------------
[86]>>[2]: env.step(3)
action:[0, 6.5088799999999996]
reward:0.24445890172037976
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.28818 -1.42836]
done:False
-------------------------
[86]>>[3]: env.step(1)
action:[0, 1.28818]
reward:0.11296441127420767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.00877 -1.90573]
done:False
-------------------------
[86]>>[4]: env.step(3)
action:[0, 6.00877]
reward:0.26907417755233354
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.71452 -2.75594]
done:False
-------------------------
[86]>>[5]: env.step(0)
action:[-3.5, 1.71452]
reward:-0.5685103708949563
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.72287 -3.06229]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.01388, 'y': -3.06229, 'z': 0.570915}
.........................
** Rewards description :
count    5.000000
mean     0.037179
std      0.345534
min     -0.568510
25%      0.112964
50%      0.127908
75%      0.244459
max      0.269074
dtype: float64
#########################
[87]>> env.reset()
=========================
[87]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.045687610071115055
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.535083 -0.160779]
done:False
-------------------------
[87]>>[2]: env.step(5)
action:[0, 0.535083]
reward:0.05303780861370733
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.487788 -0.544421]
done:False
-------------------------
[87]>>[3]: env.step(4)
action:[0, 0.243894]
reward:0.030851527035190278
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.299896 -0.746601]
done:False
-------------------------
[87]>>[4]: env.step(3)
action:[0, 5.299896]
reward:0.1757950593122735
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.757915 -0.656958]
done:False
-------------------------
[87]>>[5]: env.step(3)
action:[0, 5.757915]
reward:0.2724402864702985
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.81856  -0.653704]
done:False
-------------------------
[87]>>[6]: env.step(4)
action:[0, 0.90928]
reward:0.15254713696503053
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.57625  -0.170603]
done:False
-------------------------
[87]>>[7]: env.step(3)
action:[0, 6.57625]
reward:0.26453592088891376
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.51698   0.0952993]
done:False
-------------------------
[87]>>[8]: env.step(3)
action:[0, 6.51698]
reward:0.2626223389230632
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.50834 0.20422]
done:False
-------------------------
[87]>>[9]: env.step(2)
action:[3.5, 1.50834]
reward:-0.5615243998976296
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.85869  0.894585]
done:False
-------------------------
[87]>>[10]: env.step(4)
action:[3.5, 0.929345]
reward:0.18224412333153545
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.92826 2.03921]
done:False
-------------------------
[87]>>[11]: env.step(1)
action:[0, 1.92826]
reward:-0.5311073588178034
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.12201 2.51888]
done:False
-------------------------
[87]>>[12]: env.step(3)
action:[0, 7.1220099999999995]
reward:0.32859797715955835
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.17148 2.34545]
done:False
-------------------------
[87]>>[13]: env.step(5)
action:[0, 2.17148]
reward:0.23485585301436704
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.2554  1.46395]
done:False
-------------------------
[87]>>[14]: env.step(0)
action:[-3.5, 2.2554]
reward:-0.5026580995224861
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 4.93392e+01 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 2.38676e+00 6.61728e-03]
done:False
-------------------------
[87]>>[15]: env.step(1)
action:[0, 2.38676]
reward:-0.49528369315672294
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      47.9959
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.44408 -0.73829]
done:False
-------------------------
[87]>>[16]: env.step(3)
action:[0, 7.44408]
reward:0.37343352941881036
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.2572    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.65135  -0.542275]
done:False
-------------------------
[87]>>[17]: env.step(4)
action:[0, 1.325675]
reward:0.19745917481679115
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       44.6925    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.0129    0.078433]
done:False
-------------------------
[87]>>[18]: env.step(3)
action:[0, 7.0129]
reward:0.33453337944223727
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       43.1191    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.27261   0.268551]
done:False
-------------------------
[87]>>[19]: env.step(1)
action:[0, 2.27261]
reward:0.32494931014061557
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.8668    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.33848   0.325037]
done:False
-------------------------
[87]>>[20]: env.step(0)
action:[-3.5, 3.33848]
reward:-0.3492115285105286
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       38.6228
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.02258  -0.986514]
done:False
-------------------------
[87]>>[21]: env.step(3)
action:[-3.5, 9.02258]
reward:0.5372854115796495
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      37.0862   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.35874 -3.32444]
done:False
-------------------------
[87]>>[22]: env.step(3)
action:[-3.5, 9.358740000000001]
reward:0.5948534984958196
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.7352   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.03615 -3.18959]
done:False
-------------------------
[87]>>[23]: env.step(2)
action:[3.5, 5.03615]
reward:-0.9283766382834389
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      30.1427   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.80795 -1.15721]
done:False
-------------------------
[87]>>[24]: env.step(5)
action:[3.5, 5.80795]
reward:0.5699857479588475
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.9486   0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.59331  3.04476]
done:False
-------------------------
[87]>>[25]: env.step(1)
action:[0, 5.59331]
reward:-0.17210322189119998
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      26.6114   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.75185  6.16771]
done:False
-------------------------
[87]>>[26]: env.step(4)
action:[0, 3.75185]
reward:0.5426346134444613
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      22.5967
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.74663  5.36469]
done:False
-------------------------
[87]>>[27]: env.step(1)
action:[0, 5.74663]
reward:0.5618257157342517
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.8518   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.50072  1.55549]
done:False
-------------------------
[87]>>[28]: env.step(0)
action:[-3.5, 5.50072]
reward:-0.2023840441066047
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 20.9862  43.1969   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.37489 -2.44319]
done:False
-------------------------
[87]>>[29]: env.step(4)
action:[-3.5, 3.3748899999999997]
reward:0.5261149739320035
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      19.7073   0.      40.8497   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.6244  -5.58271]
done:False
-------------------------
[87]>>[30]: env.step(5)
action:[-3.5, 5.6244]
reward:0.5692563386365455
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      15.9349   0.       0.      36.9159   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.62954 -4.63133]
done:False
-------------------------
[87]>>[31]: env.step(1)
action:[0, 5.62954]
reward:-0.1990327399465135
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.9047    0.       35.0877    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.38679  -0.831897]
done:False
-------------------------
[87]>>[32]: env.step(4)
action:[0, 3.3867900000000004]
reward:0.41647230657836687
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4196  49.3438  33.2815   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.20925  1.76224]
done:False
-------------------------
[87]>>[33]: env.step(2)
action:[3.5, 4.20925]
reward:-0.32059461134821376
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      47.3415   8.27398
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.16811  3.9425 ]
done:False
-------------------------
[87]>>[34]: env.step(5)
action:[3.5, 4.16811]
reward:0.42981555365967494
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.3168   5.27509  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.18362  4.14854]
done:False
-------------------------
[87]>>[35]: env.step(1)
action:[0, 4.18362]
reward:-25.330392103125998
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.3089   4.26507  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.04987  4.00714]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8719, 'y': 4.00714, 'z': 0.56957}
.........................
** Rewards description :
count    35.000000
mean     -0.617452
std       4.318154
min     -25.330392
25%      -0.200708
50%       0.197459
75%       0.394953
max       0.594853
dtype: float64
#########################
[88]>> env.reset()
=========================
[88]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.032947445763631525
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.385454 0.459181]
done:False
-------------------------
[88]>>[2]: env.step(5)
action:[0, 0.385454]
reward:0.041155524559843774
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.385454 0.73152 ]
done:False
-------------------------
[88]>>[3]: env.step(5)
action:[0, 0.385454]
reward:0.040437082909465155
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.377014 1.00239 ]
done:False
-------------------------
[88]>>[4]: env.step(5)
action:[0, 0.377014]
reward:0.0520701211636447
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.515914 1.16653 ]
done:False
-------------------------
[88]>>[5]: env.step(5)
action:[0, 0.515914]
reward:0.06819474548964014
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.671254 1.08118 ]
done:False
-------------------------
[88]>>[6]: env.step(1)
action:[0, 0.671254]
reward:0.08262200568093293
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.802936 1.13001 ]
done:False
-------------------------
[88]>>[7]: env.step(5)
action:[0, 0.802936]
reward:0.10292194980094369
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.01069  0.991353]
done:False
-------------------------
[88]>>[8]: env.step(5)
action:[0, 1.01069]
reward:0.12213242214224429
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.18733 0.71371]
done:False
-------------------------
[88]>>[9]: env.step(5)
action:[0, 1.18733]
reward:0.13263751713474065
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.26851  0.437543]
done:False
-------------------------
[88]>>[10]: env.step(5)
action:[0, 1.26851]
reward:0.1475562449247746
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.42664  0.292428]
done:False
-------------------------
[88]>>[11]: env.step(4)
action:[0, 0.71332]
reward:0.11884589752805878
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.22251  0.236887]
done:False
-------------------------
[88]>>[12]: env.step(0)
action:[-3.5, 1.22251]
reward:-0.6212862879441481
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.21287  0.220242]
done:False
-------------------------
[88]>>[13]: env.step(5)
action:[-3.5, 1.21287]
reward:0.16015733553822514
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.59165  -0.221995]
done:False
-------------------------
[88]>>[14]: env.step(3)
action:[-3.5, 6.59165]
reward:0.2862083455586737
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.77947 -1.0968 ]
done:False
-------------------------
[88]>>[15]: env.step(1)
action:[0, 1.77947]
reward:-0.4878996817320501
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.68632 -2.54038]
done:False
-------------------------
[88]>>[16]: env.step(2)
action:[3.5, 2.68632]
reward:-0.4221075857383809
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.27163 -3.33184]
done:False
-------------------------
[88]>>[17]: env.step(0)
action:[-3.5, 3.27163]
reward:-1.1656390984479652
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 48.1616   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.20578 -3.28631]
done:False
-------------------------
[88]>>[18]: env.step(3)
action:[-3.5, 8.20578]
reward:0.436898777753511
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.759    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.26452 -3.22429]
done:False
-------------------------
[88]>>[19]: env.step(4)
action:[-3.5, 1.63226]
reward:0.22411408262988353
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.7347   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.25946 -3.20156]
done:False
-------------------------
[88]>>[20]: env.step(4)
action:[-3.5, 1.12973]
reward:0.16994240261041987
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.3597   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.73002 -3.1959 ]
done:False
-------------------------
[88]>>[21]: env.step(5)
action:[-3.5, 1.73002]
reward:0.18007303152325704
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      41.0937   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.70192 -3.19034]
done:False
-------------------------
[88]>>[22]: env.step(4)
action:[-3.5, 0.85096]
reward:0.13883062524686832
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.9967   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.42661 -3.18418]
done:False
-------------------------
[88]>>[23]: env.step(4)
action:[-3.5, 0.713305]
reward:0.12326267958552732
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.0337   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.27515 -3.17846]
done:False
-------------------------
[88]>>[24]: env.step(2)
action:[3.5, 1.27515]
reward:-1.33487230537063
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.0287   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.63578 -2.75422]
done:False
-------------------------
[88]>>[25]: env.step(5)
action:[3.5, 1.63578]
reward:0.17707261561349188
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      37.0435   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.68933 -1.89219]
done:False
-------------------------
[88]>>[26]: env.step(3)
action:[3.5, 6.68933]
reward:0.3041201473724206
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       36.2674    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.97612  -0.661397]
done:False
-------------------------
[88]>>[27]: env.step(3)
action:[3.5, 6.97612]
reward:0.38378255217266527
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.6567   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.89853  1.09984]
done:False
-------------------------
[88]>>[28]: env.step(3)
action:[3.5, 7.89853]
reward:0.5058080936966436
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.0491   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.22878  3.71864]
done:False
-------------------------
[88]>>[29]: env.step(4)
action:[3.5, 2.11439]
reward:0.2886946773407829
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      33.0686   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.92942  5.3098 ]
done:False
-------------------------
[88]>>[30]: env.step(3)
action:[3.5, 7.92942]
reward:0.42983576643177246
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.8868   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.24355  5.13503]
done:False
-------------------------
[88]>>[31]: env.step(4)
action:[3.5, 1.621775]
reward:0.37995672133945063
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.3744   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.18895  3.90493]
done:False
-------------------------
[88]>>[32]: env.step(5)
action:[3.5, 4.18895]
reward:0.5123356059063726
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.8107   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.2411   3.86314]
done:False
-------------------------
[88]>>[33]: env.step(3)
action:[3.5, 10.2411]
reward:0.6916809518747971
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.4882   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.12806  3.91414]
done:False
-------------------------
[88]>>[34]: env.step(2)
action:[3.5, 6.12806]
reward:0.6347445967563841
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.7956   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.37945  3.94218]
done:False
-------------------------
[88]>>[35]: env.step(3)
action:[3.5, 11.37945]
reward:0.7371297603879745
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.9956   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.47497  3.96796]
done:False
-------------------------
[88]>>[36]: env.step(5)
action:[3.5, 6.47497]
reward:0.664820744050953
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.09959 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.70121 3.99393]
done:False
-------------------------
[88]>>[37]: env.step(4)
action:[3.5, 4.70121]
reward:-24.42595567491926
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.92031 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.92377 4.0052 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.1205, 'y': 4.0052, 'z': 0.568699}
.........................
** Rewards description :
count    37.000000
mean     -0.542886
std       4.059543
min     -24.425956
25%       0.052070
50%       0.147556
75%       0.379957
max       0.737130
dtype: float64
#########################
[89]>> env.reset()
=========================
[89]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.0008825265050520821
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0102969 0.200389 ]
done:False
-------------------------
[89]>>[2]: env.step(4)
action:[0, 0.00514845]
reward:0.016022159300350988
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.185889 0.201926]
done:False
-------------------------
[89]>>[3]: env.step(5)
action:[0, 0.185889]
reward:0.0371197553131741
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.387948 0.202429]
done:False
-------------------------
[89]>>[4]: env.step(4)
action:[0, 0.193974]
reward:0.05352482931080539
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.578799 0.204389]
done:False
-------------------------
[89]>>[5]: env.step(3)
action:[0, 5.578799]
reward:0.19484347763138565
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.917995 0.20651 ]
done:False
-------------------------
[89]>>[6]: env.step(1)
action:[0, 0.917995]
reward:0.13732406742619066
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.39184  0.210538]
done:False
-------------------------
[89]>>[7]: env.step(2)
action:[3.5, 1.39184]
reward:-0.5691831539548728
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.79543  0.696688]
done:False
-------------------------
[89]>>[8]: env.step(0)
action:[-3.5, 1.79543]
reward:-1.2885608753166073
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.06476  0.604541]
done:False
-------------------------
[89]>>[9]: env.step(5)
action:[-3.5, 2.06476]
reward:0.2111177263847129
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.99353  -0.213994]
done:False
-------------------------
[89]>>[10]: env.step(3)
action:[-3.5, 6.99353]
reward:0.3307415203558539
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.23026 -1.51147]
done:False
-------------------------
[89]>>[11]: env.step(4)
action:[-3.5, 1.11513]
reward:0.17326853022327932
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.77369 -2.74969]
done:False
-------------------------
[89]>>[12]: env.step(4)
action:[-3.5, 0.886845]
reward:0.14421566880220002
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.48206 -3.22495]
done:False
-------------------------
[89]>>[13]: env.step(1)
action:[0, 1.48206]
reward:-0.5814950528964073
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.62465 -3.35389]
done:False
-------------------------
[89]>>[14]: env.step(3)
action:[0, 6.62465]
reward:0.28482398912647255
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.75417 -3.05249]
done:False
-------------------------
[89]>>[15]: env.step(0)
action:[-3.5, 1.75417]
reward:-0.5524462483153667
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      49.6455   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90692 -2.28519]
done:False
-------------------------
[89]>>[16]: env.step(4)
action:[-3.5, 0.95346]
reward:0.1887315632066855
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     48.6304  0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  2.0005 -1.0661]
done:False
-------------------------
[89]>>[17]: env.step(4)
action:[-3.5, 1.00025]
reward:0.16376818665865855
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       47.6652    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.68817  -0.824627]
done:False
-------------------------
[89]>>[18]: env.step(1)
action:[0, 1.68817]
reward:-0.642129543489
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.0692    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.848185 -1.3634  ]
done:False
-------------------------
[89]>>[19]: env.step(1)
action:[0, 0.848185]
reward:0.11198287891773362
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      46.3711   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.10709 -1.16137]
done:False
-------------------------
[89]>>[20]: env.step(1)
action:[0, 1.10709]
reward:0.1225241960414315
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       45.6456    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.1679   -0.631788]
done:False
-------------------------
[89]>>[21]: env.step(1)
action:[0, 1.1679]
reward:0.13220900783783002
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       44.8337
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.26825  -0.117223]
done:False
-------------------------
[89]>>[22]: env.step(3)
action:[0, 6.26825]
reward:0.25337432753899997
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       43.8482    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.45729   0.193614]
done:False
-------------------------
[89]>>[23]: env.step(5)
action:[0, 1.45729]
reward:0.1654176935544055
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       42.714     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.59373   0.312922]
done:False
-------------------------
[89]>>[24]: env.step(1)
action:[0, 1.59373]
reward:0.17857989062750512
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       41.4729    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.718     0.339371]
done:False
-------------------------
[89]>>[25]: env.step(1)
action:[0, 1.718]
reward:0.19178762576752742
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      40.1345   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.84627  0.33642]
done:False
-------------------------
[89]>>[26]: env.step(1)
action:[0, 1.84627]
reward:0.20498822120765933
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.7002    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.97387   0.330792]
done:False
-------------------------
[89]>>[27]: env.step(3)
action:[0, 6.97387]
reward:0.33166543077381205
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.1411    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.24667   0.331067]
done:False
-------------------------
[89]>>[28]: env.step(5)
action:[0, 2.24667]
reward:0.2688317643190776
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.3321    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.65207   0.337601]
done:False
-------------------------
[89]>>[29]: env.step(5)
action:[0, 2.65207]
reward:0.28807393030205425
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.1487    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.78735   0.349155]
done:False
-------------------------
[89]>>[30]: env.step(4)
action:[0, 1.393675]
reward:0.27019573587269285
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.0271    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.88206   0.360697]
done:False
-------------------------
[89]>>[31]: env.step(1)
action:[0, 2.88206]
reward:0.3077109078145802
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      28.8381   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.97236  0.37251]
done:False
-------------------------
[89]>>[32]: env.step(0)
action:[-3.5, 2.97236]
reward:-0.41649596631126884
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       26.9683
 49.6392    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.26993  -0.726055]
done:False
-------------------------
[89]>>[33]: env.step(5)
action:[-3.5, 3.26993]
reward:0.33248870895581945
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.     25.9867 48.3096  0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  3.1829 -2.7546]
done:False
-------------------------
[89]>>[34]: env.step(3)
action:[-3.5, 8.1829]
reward:0.4590577234905169
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      23.8748
 45.989    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.55385 -3.2819 ]
done:False
-------------------------
[89]>>[35]: env.step(4)
action:[-3.5, 1.776925]
reward:0.24840682485711568
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.8438  43.8866   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.51939 -3.12815]
done:False
-------------------------
[89]>>[36]: env.step(2)
action:[3.5, 2.51939]
reward:-1.214495147908354
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      19.9581  42.1247   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.78887 -2.1961 ]
done:False
-------------------------
[89]>>[37]: env.step(2)
action:[3.5, 2.78887]
reward:0.29874556489150095
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       18.5154    0.       41.0499    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.88481  -0.332869]
done:False
-------------------------
[89]>>[38]: env.step(3)
action:[3.5, 7.88481]
reward:0.4053000548048975
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      17.7428   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.94309  1.76432]
done:False
-------------------------
[89]>>[39]: env.step(4)
action:[3.5, 1.471545]
reward:0.37985202337463314
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 16.9194  40.1546   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.22519  4.39075]
done:False
-------------------------
[89]>>[40]: env.step(4)
action:[3.5, 2.112595]
reward:0.2926080164619346
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.9092   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.97812  5.50512]
done:False
-------------------------
[89]>>[41]: env.step(3)
action:[3.5, 7.9781200000000005]
reward:0.43146618395909675
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.7145   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.25215  5.07252]
done:False
-------------------------
[89]>>[42]: env.step(3)
action:[3.5, 8.25215]
reward:0.5112365407707803
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 49.1932  10.1357   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.21099  4.00055]
done:False
-------------------------
[89]>>[43]: env.step(2)
action:[3.5, 4.21099]
reward:0.5220618766430916
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.51831 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.36242 3.98785]
done:False
-------------------------
[89]>>[44]: env.step(5)
action:[3.5, 5.36242]
reward:-24.412903876167167
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.23712 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.93185 3.99278]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8023, 'y': 3.99278, 'z': 0.574433}
.........................
** Rewards description :
count    44.000000
mean     -0.478017
std       3.714524
min     -24.412904
25%       0.049424
50%       0.190260
75%       0.294142
max       0.522062
dtype: float64
#########################
[90]>> env.reset()
=========================
[90]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.004916234008108589
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0573796 0.238141 ]
done:False
-------------------------
[90]>>[2]: env.step(3)
action:[0, 5.0573796]
reward:0.13891274437713058
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.375987 0.282051]
done:False
-------------------------
[90]>>[3]: env.step(5)
action:[0, 0.375987]
reward:0.08397209400607508
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.892732 0.254664]
done:False
-------------------------
[90]>>[4]: env.step(5)
action:[0, 0.892732]
reward:0.09894719099979328
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.941047 0.242823]
done:False
-------------------------
[90]>>[5]: env.step(5)
action:[0, 0.941047]
reward:0.0995499608597622
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.936123 0.235052]
done:False
-------------------------
[90]>>[6]: env.step(3)
action:[0, 5.936123]
reward:0.20319167676761984
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.929652 0.227007]
done:False
-------------------------
[90]>>[7]: env.step(4)
action:[0, 0.464826]
reward:0.08843091214559579
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.923323 0.222055]
done:False
-------------------------
[90]>>[8]: env.step(5)
action:[0, 0.923323]
reward:0.10998497791121384
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.06454  0.222849]
done:False
-------------------------
[90]>>[9]: env.step(5)
action:[0, 1.06454]
reward:0.12741037680331552
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.23681  0.226304]
done:False
-------------------------
[90]>>[10]: env.step(5)
action:[0, 1.23681]
reward:0.14400856855674654
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.39209  0.231202]
done:False
-------------------------
[90]>>[11]: env.step(0)
action:[-3.5, 1.39209]
reward:-0.5903195522424842
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54112 0.23705]
done:False
-------------------------
[90]>>[12]: env.step(5)
action:[-3.5, 1.54112]
reward:0.16684436024777785
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.58992  0.243539]
done:False
-------------------------
[90]>>[13]: env.step(1)
action:[0, 1.58992]
reward:-0.571909204022756
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.71306 0.2503 ]
done:False
-------------------------
[90]>>[14]: env.step(3)
action:[0, 6.7130600000000005]
reward:0.29424500933685693
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.8482   0.257566]
done:False
-------------------------
[90]>>[15]: env.step(0)
action:[-3.5, 1.8482]
reward:-0.5278639813678981
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       48.8197    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.18143  -0.400737]
done:False
-------------------------
[90]>>[16]: env.step(4)
action:[-3.5, 1.090715]
reward:0.16105445351576694
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      48.0639   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.63296 -1.46979]
done:False
-------------------------
[90]>>[17]: env.step(3)
action:[-3.5, 6.63296]
reward:0.27171892660859087
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      47.5114   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.59094 -2.49182]
done:False
-------------------------
[90]>>[18]: env.step(3)
action:[-3.5, 6.59094]
reward:0.3075533452681142
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      46.5706   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04319 -3.18578]
done:False
-------------------------
[90]>>[19]: env.step(4)
action:[-3.5, 1.021595]
reward:0.268301365316797
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.6943   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.95183 -3.27386]
done:False
-------------------------
[90]>>[20]: env.step(0)
action:[-3.5, 2.95183]
reward:0.3502732071183716
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.3138   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.48421 -3.21197]
done:False
-------------------------
[90]>>[21]: env.step(3)
action:[-3.5, 8.484210000000001]
reward:0.4813224431111906
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.6402   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.76515 -3.18417]
done:False
-------------------------
[90]>>[22]: env.step(1)
action:[0, 3.76515]
reward:-0.3192528039980753
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.9477   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.29623 -1.74685]
done:False
-------------------------
[90]>>[23]: env.step(3)
action:[0, 9.296230000000001]
reward:0.5623624147295586
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 34.6455    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.62041   0.638645]
done:False
-------------------------
[90]>>[24]: env.step(3)
action:[0, 9.62041]
reward:0.6070218289144889
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       31.1183    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.1334    0.341673]
done:False
-------------------------
[90]>>[25]: env.step(3)
action:[0, 10.1334]
reward:0.7033464884177604
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.8053    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.31607   0.337415]
done:False
-------------------------
[90]>>[26]: env.step(5)
action:[0, 6.31607]
reward:0.7155220735632093
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.6153   44.3847    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.43926   0.393191]
done:False
-------------------------
[90]>>[27]: env.step(1)
action:[0, 7.43926]
reward:0.7619307072950777
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.9558    0.       38.6522    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.80923   0.436184]
done:False
-------------------------
[90]>>[28]: env.step(2)
action:[3.5, 7.80923]
reward:0.018731148675795062
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.6953  33.8229
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.81309  2.90047]
done:False
-------------------------
[90]>>[29]: env.step(5)
action:[3.5, 7.81309]
reward:0.7657292464857113
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.2407   5.22883  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.76956  4.38221]
done:False
-------------------------
[90]>>[30]: env.step(5)
action:[3.5, 7.76956]
reward:-24.244648859214657
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 43.1431   4.09923  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.63368  3.98952]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8532, 'y': 3.98952, 'z': 0.568899}
.........................
** Rewards description :
count    30.000000
mean     -0.623957
std       4.475672
min     -24.244649
25%       0.085087
50%       0.152532
75%       0.339593
max       0.765729
dtype: float64
#########################
[91]>> env.reset()
=========================
[91]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.06788259606795043
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.796548 0.707235]
done:False
-------------------------
[91]>>[2]: env.step(2)
action:[3.5, 0.796548]
reward:-0.6649010369782901
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.800932 1.05613 ]
done:False
-------------------------
[91]>>[3]: env.step(5)
action:[3.5, 0.800932]
reward:0.05174876145248142
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.406152 1.26372 ]
done:False
-------------------------
[91]>>[4]: env.step(3)
action:[3.5, 5.406152]
reward:0.16312392942677992
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.578955 1.64047 ]
done:False
-------------------------
[91]>>[5]: env.step(3)
action:[3.5, 5.578955]
reward:0.19511971846195916
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.921295 2.16787 ]
done:False
-------------------------
[91]>>[6]: env.step(5)
action:[3.5, 0.921295]
reward:0.18495946207191974
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.96302 3.21501]
done:False
-------------------------
[91]>>[7]: env.step(5)
action:[3.5, 1.96302]
reward:0.25631343722746713
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.56956 4.73005]
done:False
-------------------------
[91]>>[8]: env.step(3)
action:[3.5, 7.56956]
reward:0.369959587783026
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.57635 5.37436]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.09562, 'y': 5.37436, 'z': 0.570441}
.........................
** Rewards description :
count    8.000000
mean     0.078026
std      0.316709
min     -0.664901
25%      0.063849
50%      0.174042
75%      0.210418
max      0.369960
dtype: float64
#########################
[92]>> env.reset()
=========================
[92]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.08069012198049968
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.947891 0.831399]
done:False
-------------------------
[92]>>[2]: env.step(4)
action:[0, 0.4739455]
reward:0.08607318831088152
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.893118 1.3783  ]
done:False
-------------------------
[92]>>[3]: env.step(5)
action:[0, 0.893118]
reward:0.05250313182666412
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.391985 1.73216 ]
done:False
-------------------------
[92]>>[4]: env.step(3)
action:[0, 5.391985]
reward:0.19540036993965032
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.97143 1.84333]
done:False
-------------------------
[92]>>[5]: env.step(5)
action:[0, 0.97143]
reward:0.08476410009085532
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.753247 1.99758 ]
done:False
-------------------------
[92]>>[6]: env.step(3)
action:[0, 5.753247]
reward:0.2215362927824316
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.19788 2.19445]
done:False
-------------------------
[92]>>[7]: env.step(3)
action:[0, 6.19788]
reward:0.31748796302091165
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.26454 2.24157]
done:False
-------------------------
[92]>>[8]: env.step(4)
action:[0, 1.13227]
reward:0.3231963176456192
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.60179 1.37319]
done:False
-------------------------
[92]>>[9]: env.step(2)
action:[3.5, 3.60179]
reward:-0.35247055002588334
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.91555 1.29642]
done:False
-------------------------
[92]>>[10]: env.step(3)
action:[3.5, 8.91555]
reward:0.5034890076455473
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.94439 3.41722]
done:False
-------------------------
[92]>>[11]: env.step(5)
action:[3.5, 3.94439]
reward:0.4299890268996321
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.7449   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24176  3.77315]
done:False
-------------------------
[92]>>[12]: env.step(3)
action:[3.5, 9.24176]
reward:0.5474395804393402
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.5091   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.43731  3.77981]
done:False
-------------------------
[92]>>[13]: env.step(3)
action:[3.5, 9.43731]
reward:0.6179598347573528
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.8443   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.32593  3.80254]
done:False
-------------------------
[92]>>[14]: env.step(2)
action:[3.5, 5.32593]
reward:0.6268393309885284
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.3577   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.47329  3.82697]
done:False
-------------------------
[92]>>[15]: env.step(3)
action:[3.5, 11.47329]
reward:0.8125093547132854
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.0622   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.52384  3.85392]
done:False
-------------------------
[92]>>[16]: env.step(3)
action:[3.5, 12.52384]
reward:0.9018973653948509
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.9602   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.57965  3.88589]
done:False
-------------------------
[92]>>[17]: env.step(4)
action:[3.5, 6.579650000000001]
reward:0.8550081415318095
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.174    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.36719  3.92211]
done:False
-------------------------
[92]>>[18]: env.step(0)
action:[-3.5, 9.36719]
reward:-0.5636498353592861
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.9147   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.89278  3.96114]
done:False
-------------------------
[92]>>[19]: env.step(0)
action:[-3.5, 9.89278]
reward:-24.032252102648584
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.85179  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2476   4.00468]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9759, 'y': 4.00468, 'z': 0.569796}
.........................
** Rewards description :
count    19.000000
mean     -0.962715
std       5.599679
min     -24.032252
25%       0.082727
50%       0.317488
75%       0.582700
max       0.901897
dtype: float64
#########################
[93]>> env.reset()
=========================
[93]>>[1]: env.step(4)
action:[0, 8.2653]
reward:-24.056215497234298
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       2.83495  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2826   4.01023]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.0024, 'y': 4.01023, 'z': 0.569782}
.........................
** Rewards description :
count     1.000000
mean    -24.056215
std            NaN
min     -24.056215
25%     -24.056215
50%     -24.056215
75%     -24.056215
max     -24.056215
dtype: float64
#########################
[94]>> env.reset()
=========================
[94]>>[1]: env.step(3)
action:[0, 15.4952]
reward:1.080986113028519
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.631   47.3238  11.4429   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.4563  10.6827   4.09236]
done:False
-------------------------
[94]>>[2]: env.step(2)
action:[3.5, 10.6827]
reward:0.267766732610065
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.5524  39.3953   0.       0.       0.       0.
  5.11141  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      20.5346  10.8438   4.13594]
done:False
-------------------------
[94]>>[3]: env.step(3)
action:[3.5, 15.8438]
reward:0.4000375114376591
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.886753 0.216794]
done:False
-------------------------
[94]>>[4]: env.step(0)
action:[-3.5, 0.886753]
reward:-1.343450538309495
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.62988   0.0109124]
done:False
-------------------------
[94]>>[5]: env.step(5)
action:[-3.5, 1.62988]
reward:0.16436142866662223
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.53789  -0.777263]
done:False
-------------------------
[94]>>[6]: env.step(1)
action:[0, 1.53789]
reward:-0.5491273655298229
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.00114  -0.983178]
done:False
-------------------------
[94]>>[7]: env.step(3)
action:[0, 7.0011399999999995]
reward:0.3025197658451805
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.87838  -0.533197]
done:False
-------------------------
[94]>>[8]: env.step(5)
action:[0, 1.87838]
reward:0.19865774048907192
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.88922   0.0141042]
done:False
-------------------------
[94]>>[9]: env.step(3)
action:[0, 6.88922]
reward:0.3147277526549723
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.05748  0.218618]
done:False
-------------------------
[94]>>[10]: env.step(3)
action:[0, 7.05748]
reward:0.34644897094213944
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.41003  0.265803]
done:False
-------------------------
[94]>>[11]: env.step(2)
action:[3.5, 2.41003]
reward:-0.40092251617692554
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.9382    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.60472   0.271021]
done:False
-------------------------
[94]>>[12]: env.step(4)
action:[3.5, 1.80236]
reward:0.25732847396326164
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      48.049    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.62215  1.3329 ]
done:False
-------------------------
[94]>>[13]: env.step(5)
action:[3.5, 2.62215]
reward:0.2730158084694533
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      46.898
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.60957  3.04436]
done:False
-------------------------
[94]>>[14]: env.step(5)
action:[3.5, 2.60957]
reward:0.30068211856598964
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.1214   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.95356  3.92239]
done:False
-------------------------
[94]>>[15]: env.step(1)
action:[0, 2.95356]
reward:-0.4525198118978087
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.004    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82801  3.86284]
done:False
-------------------------
[94]>>[16]: env.step(5)
action:[0, 2.82801]
reward:0.3194356165265909
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      41.0198
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.13117  2.89495]
done:False
-------------------------
[94]>>[17]: env.step(0)
action:[-3.5, 3.13117]
reward:-0.4183767618644687
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       39.9798    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.20682   0.784842]
done:False
-------------------------
[94]>>[18]: env.step(2)
action:[3.5, 3.20682]
reward:-1.1583629884464488
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 38.4313    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.31265  -0.652037]
done:False
-------------------------
[94]>>[19]: env.step(2)
action:[3.5, 3.31265]
reward:0.3517649952389882
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       35.8958    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.41265  -0.409774]
done:False
-------------------------
[94]>>[20]: env.step(3)
action:[3.5, 8.41265]
reward:0.47340116542704685
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.902    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.68087  1.43041]
done:False
-------------------------
[94]>>[21]: env.step(3)
action:[3.5, 8.68087]
reward:0.5639129850426008
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      32.3061
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.79474  4.08641]
done:False
-------------------------
[94]>>[22]: env.step(2)
action:[3.5, 4.79474]
reward:0.5468773230352861
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      28.6478   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.54167  4.5156 ]
done:False
-------------------------
[94]>>[23]: env.step(5)
action:[3.5, 5.54167]
reward:0.5423197919224401
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.7426   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.29504  4.02204]
done:False
-------------------------
[94]>>[24]: env.step(3)
action:[3.5, 10.29504]
reward:0.6404906649010191
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.772    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.41543  3.97157]
done:False
-------------------------
[94]>>[25]: env.step(3)
action:[3.5, 10.41543]
reward:0.7123985981413674
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.3618   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.37103  3.95868]
done:False
-------------------------
[94]>>[26]: env.step(1)
action:[0, 6.37103]
reward:-0.023358899553148627
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.062    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.58039  3.97384]
done:False
-------------------------
[94]>>[27]: env.step(3)
action:[0, 12.580390000000001]
reward:0.9070293423013833
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.18908 44.9329  28.8565   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.64296  1.41896]
done:False
-------------------------
[94]>>[28]: env.step(4)
action:[0, 6.64296]
reward:0.8817556756561729
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         3.4608     0.         0.
  0.         0.         0.         0.         0.         0.
  0.        22.4676     0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  9.74785    0.0927431]
done:False
-------------------------
[94]>>[29]: env.step(4)
action:[0, 7.74785]
reward:0.8386390693030137
observation:
[ 0.        0.        8.32011   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.4726   15.2689    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.83495   0.501264]
done:False
-------------------------
[94]>>[30]: env.step(0)
action:[-3.5, 8.83495]
reward:0.10010441991633157
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.243    9.70764 45.6786   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.5335   0.       0.       8.73122 -2.001  ]
done:False
-------------------------
[94]>>[31]: env.step(0)
action:[-3.5, 8.73122]
reward:0.8431781446992872
observation:
[ 0.       0.       0.      20.5085   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       4.57412
  0.      20.805    0.      39.6886   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.65553 -3.16614]
done:False
-------------------------
[94]>>[32]: env.step(1)
action:[0, 8.65553]
reward:-24.911368455493008
observation:
[ 0.       0.       0.      22.5378   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       2.26289  0.
  0.       0.      18.2468   0.      37.3261   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.60792 -2.28949]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 81.6828, 'y': -2.28949, 'z': 0.569525}
.........................
** Rewards description :
count    32.000000
mean     -0.550926
std       4.479936
min     -24.911368
25%       0.069239
50%       0.308624
75%       0.551136
max       1.080986
dtype: float64
#########################
[95]>> env.reset()
=========================
[95]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.12689280986255114
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.49677  0.959406]
done:False
-------------------------
[95]>>[2]: env.step(5)
action:[0, 1.49677]
reward:0.1611796858505427
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.53295  0.658256]
done:False
-------------------------
[95]>>[3]: env.step(3)
action:[0, 6.53295]
reward:0.23730064759625819
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.19483   0.0284759]
done:False
-------------------------
[95]>>[4]: env.step(3)
action:[0, 6.19483]
reward:0.25185063008423314
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.45701  0.145162]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02383, 'y': 0.145162, 'z': 0.571693}
.........................
** Rewards description :
count    4.000000
mean     0.194306
std      0.060005
min      0.126893
25%      0.152608
50%      0.199240
75%      0.240938
max      0.251851
dtype: float64
#########################
[96]>> env.reset()
=========================
[96]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.726235154830477
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.27781  0.012698]
done:False
-------------------------
[96]>>[2]: env.step(5)
action:[-3.5, 0.27781]
reward:0.029686892916988734
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.27776  -0.175535]
done:False
-------------------------
[96]>>[3]: env.step(3)
action:[-3.5, 5.27776]
reward:0.17638862364490013
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.770597 -0.464752]
done:False
-------------------------
[96]>>[4]: env.step(3)
action:[-3.5, 5.770597]
reward:0.3336582099539387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.57229 -1.58954]
done:False
-------------------------
[96]>>[5]: env.step(3)
action:[-3.5, 7.572290000000001]
reward:0.5294454952536274
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.61861 -3.7407 ]
done:False
-------------------------
[96]>>[6]: env.step(3)
action:[-3.5, 9.61861]
reward:0.6597265412457014
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.84582 -4.01866]
done:False
-------------------------
[96]>>[7]: env.step(3)
action:[-3.5, 10.84582]
reward:0.712520862125821
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.26513 -3.3786 ]
done:False
-------------------------
[96]>>[8]: env.step(3)
action:[-3.5, 11.26513]
reward:0.7270197264620045
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      46.5143   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.36215 -3.27803]
done:False
-------------------------
[96]>>[9]: env.step(1)
action:[0, 6.36215]
reward:0.03854683974380002
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      40.6835   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.45714 -3.21286]
done:False
-------------------------
[96]>>[10]: env.step(0)
action:[-3.5, 8.45714]
reward:0.12738322042381456
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.0265   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.22914 -3.16051]
done:False
-------------------------
[96]>>[11]: env.step(4)
action:[-3.5, 7.229139999999999]
reward:0.7748335807041293
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 27.8965   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.0448  -3.12177]
done:False
-------------------------
[96]>>[12]: env.step(5)
action:[-3.5, 8.0448]
reward:0.781403904477983
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.1216  44.184    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.93446 -3.08845]
done:False
-------------------------
[96]>>[13]: env.step(3)
action:[-3.5, 12.93446]
reward:0.8587967445992055
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      16.5668
  0.      38.2868   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.83434 -3.05626]
done:False
-------------------------
[96]>>[14]: env.step(5)
action:[-3.5, 7.83434]
reward:0.7559466421869837
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.4952   0.
  0.      32.5403   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.62589 -3.02504]
done:False
-------------------------
[96]>>[15]: env.step(3)
action:[-3.5, 12.62589]
reward:0.8332008531942778
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.53977  0.       0.       0.
  0.      26.8859   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.53604 -2.99436]
done:False
-------------------------
[96]>>[16]: env.step(2)
action:[3.5, 7.53604]
reward:-0.722523880909795
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        4.16779
  0.        0.        0.        0.        0.        0.        0.
  0.       38.2654   21.9706    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.00568  -0.512139]
done:False
-------------------------
[96]>>[17]: env.step(5)
action:[3.5, 8.00568]
reward:-24.220376394567577
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       2.96903  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 37.639   21.5139   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.91886  1.00585]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 61.4583, 'y': 1.00585, 'z': 0.568878}
.........................
** Rewards description :
count    17.000000
mean     -1.078269
std       5.984552
min     -24.220376
25%       0.038547
50%       0.529445
75%       0.755947
max       0.858797
dtype: float64
#########################
[97]>> env.reset()
=========================
[97]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.07842427381266098
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.921091 0.803311]
done:False
-------------------------
[97]>>[2]: env.step(5)
action:[0, 0.921091]
reward:0.08049897642697193
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.715357 1.38786 ]
done:False
-------------------------
[97]>>[3]: env.step(2)
action:[3.5, 0.715357]
reward:-0.6244342960362488
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.3021  1.52051]
done:False
-------------------------
[97]>>[4]: env.step(5)
action:[3.5, 1.3021]
reward:0.1682147051354152
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.66615 2.27587]
done:False
-------------------------
[97]>>[5]: env.step(5)
action:[3.5, 1.66615]
reward:0.1637144981387118
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.52105 3.16855]
done:False
-------------------------
[97]>>[6]: env.step(3)
action:[3.5, 6.52105]
reward:0.29385336772468684
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.89137 3.74099]
done:False
-------------------------
[97]>>[7]: env.step(1)
action:[0, 1.89137]
reward:-0.5450187969814944
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.96251 3.8261 ]
done:False
-------------------------
[97]>>[8]: env.step(3)
action:[0, 6.96251]
reward:0.34818647869191643
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.45547 3.40971]
done:False
-------------------------
[97]>>[9]: env.step(3)
action:[0, 7.45547]
reward:0.5022925211111432
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.29387 1.50229]
done:False
-------------------------
[97]>>[10]: env.step(3)
action:[0, 9.29387]
reward:0.6522632540426113
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.82543  -0.334076]
done:False
-------------------------
[97]>>[11]: env.step(1)
action:[0, 5.82543]
reward:0.6329497975974946
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.0687    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.43086   0.292459]
done:False
-------------------------
[97]>>[12]: env.step(5)
action:[0, 6.43086]
reward:0.6353491018104778
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.3262    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.31192   0.296669]
done:False
-------------------------
[97]>>[13]: env.step(5)
action:[0, 6.31192]
reward:0.6206522247503303
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.6978    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.14348   0.319046]
done:False
-------------------------
[97]>>[14]: env.step(5)
action:[0, 6.14348]
reward:0.6034859154788946
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.2114    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.9553    0.346894]
done:False
-------------------------
[97]>>[15]: env.step(5)
action:[0, 5.9553]
reward:0.5853684859369515
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.8757    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.76064   0.373804]
done:False
-------------------------
[97]>>[16]: env.step(1)
action:[0, 5.76064]
reward:0.5745155222782652
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       23.6252   46.4145    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.66516   0.398987]
done:False
-------------------------
[97]>>[17]: env.step(3)
action:[0, 10.66516]
reward:0.6572552573723048
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.4667   42.2155    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.55052   0.422657]
done:False
-------------------------
[97]>>[18]: env.step(3)
action:[0, 10.550519999999999]
reward:0.7192083323519939
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.1608    0.       37.843     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.43192   0.446291]
done:False
-------------------------
[97]>>[19]: env.step(2)
action:[3.5, 6.43192]
reward:0.049703527346694365
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.25909  47.909    31.742     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.59965   0.478616]
done:False
-------------------------
[97]>>[20]: env.step(5)
action:[3.5, 8.59965]
reward:-24.12431772862947
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       3.36513 26.5513
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.1682   3.06943]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.5286, 'y': 3.06943, 'z': 0.570517}
.........................
** Rewards description :
count    20.000000
mean     -0.896392
std       5.480734
min     -24.124318
25%       0.079980
50%       0.425239
75%       0.623727
max       0.719208
dtype: float64
#########################
[98]>> env.reset()
=========================
[98]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.18492574427515251
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.942937 -0.153431]
done:False
-------------------------
[98]>>[2]: env.step(3)
action:[0, 5.942937]
reward:0.35163473939411083
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.75345  0.112319]
done:False
-------------------------
[98]>>[3]: env.step(3)
action:[0, 7.75345]
reward:0.5224129899060921
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.48139  0.209806]
done:False
-------------------------
[98]>>[4]: env.step(3)
action:[0, 9.481390000000001]
reward:0.6679349861324643
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.99214  0.236555]
done:False
-------------------------
[98]>>[5]: env.step(3)
action:[0, 10.99214]
reward:0.7539431333938739
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.6379    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.80817   0.266439]
done:False
-------------------------
[98]>>[6]: env.step(2)
action:[3.5, 6.80817]
reward:-0.017760967929041915
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      42.9235   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.54932  2.63789]
done:False
-------------------------
[98]>>[7]: env.step(5)
action:[3.5, 7.54932]
reward:0.759648644010934
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      37.9483   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.74944  4.46932]
done:False
-------------------------
[98]>>[8]: env.step(0)
action:[-3.5, 7.74944]
reward:-0.7465053386943632
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.2948    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.61252   0.588568]
done:False
-------------------------
[98]>>[9]: env.step(2)
action:[3.5, 7.61252]
reward:-0.7538139289485064
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      33.409    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.54383 -4.94336]
done:False
-------------------------
[98]>>[10]: env.step(0)
action:[-3.5, 7.54383]
reward:-0.7700244077335167
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.6449   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.33376 -5.36769]
done:False
-------------------------
[98]>>[11]: env.step(5)
action:[-3.5, 7.33376]
reward:0.7216370739797799
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      23.6475  45.8791   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.26993 -2.54689]
done:False
-------------------------
[98]>>[12]: env.step(5)
action:[-3.5, 7.26993]
reward:0.6864210374017359
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 18.8988   0.      40.8064   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.79844 -3.01243]
done:False
-------------------------
[98]>>[13]: env.step(5)
action:[-3.5, 6.79844]
reward:0.6614488790073312
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.3468
  0.      35.8524   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.57434 -3.01661]
done:False
-------------------------
[98]>>[14]: env.step(5)
action:[-3.5, 6.57434]
reward:0.6425738517365627
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.2914   0.
  0.      31.0482   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.37382 -3.00447]
done:False
-------------------------
[98]>>[15]: env.step(4)
action:[-3.5, 4.37382]
reward:0.5100724006821845
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.55588  0.       0.       0.
  0.      26.9233   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.16542 -2.98892]
done:False
-------------------------
[98]>>[16]: env.step(2)
action:[3.5, 5.16542]
reward:-0.9829472860105462
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.51366  0.       0.       0.       0.       0.       0.
  0.      23.1191   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.05845 -2.97206]
done:False
-------------------------
[98]>>[17]: env.step(5)
action:[3.5, 5.05845]
reward:0.5286131612625125
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       5.84696  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.1588  19.7719   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.23618 -1.24672]
done:False
-------------------------
[98]>>[18]: env.step(0)
action:[-3.5, 5.23618]
reward:-0.9745894197857492
observation:
[ 0.        0.        0.        6.95904   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       32.9725   16.7679    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.14987   0.561911]
done:False
-------------------------
[98]>>[19]: env.step(3)
action:[-3.5, 10.14987]
reward:0.6085747914337989
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.5334  49.625    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.7419   0.       5.02184 -1.55224]
done:False
-------------------------
[98]>>[20]: env.step(3)
action:[-3.5, 10.021840000000001]
reward:0.6983353367074151
observation:
[ 0.      14.5649   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.739
 46.3304   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.27468 -3.61191]
done:False
-------------------------
[98]>>[21]: env.step(4)
action:[-3.5, 4.27468]
reward:0.5154138391317873
observation:
[ 0.      17.9766   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.72683
 23.2195   0.      42.3013   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.25977 -2.87533]
done:False
-------------------------
[98]>>[22]: env.step(3)
action:[-3.5, 10.25977]
reward:0.6214722513611457
observation:
[ 0.      21.6203   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       3.46999  0.      19.5331
  0.      38.4401   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.16755 -2.88958]
done:False
-------------------------
[98]>>[23]: env.step(2)
action:[3.5, 5.16755]
reward:-25.91797572977811
observation:
[ 0.       0.       0.      23.6803   0.       0.       0.       0.
  0.       0.       0.       1.94603  0.       0.       0.       0.
  0.       0.      17.1526   0.      36.1543   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.91311 -2.29338]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 82.9977, 'y': -2.29338, 'z': 0.570446}
.........................
** Rewards description :
count    23.000000
mean     -0.901241
std       5.488041
min     -25.917976
25%      -0.382133
50%       0.522413
75%       0.664692
max       0.759649
dtype: float64
#########################
[99]>> env.reset()
=========================
[99]>>[1]: env.step(3)
action:[0, 10.74733]
reward:0.6724125056699946
observation:
[ 0.       0.      27.5628   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.7997   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       7.5702   0.       0.       5.73689  5.88987]
done:False
-------------------------
[99]>>[2]: env.step(5)
action:[0, 5.73689]
reward:0.6073003061078153
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.69474  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      10.0307   0.       0.
 31.5341   0.       0.       0.       6.10801  4.9689 ]
done:False
-------------------------
[99]>>[3]: env.step(3)
action:[0, 11.10801]
reward:0.6827950468279238
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        6.17892   0.        0.       49.897    26.1401    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 10.529    33.5187    0.        0.        0.        0.        0.
  0.        5.78908   0.939496]
done:False
-------------------------
[99]>>[4]: env.step(2)
action:[3.5, 5.78908]
reward:-0.11881197844522873
observation:
[37.5205   0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.80766  0.       0.       0.       0.       0.
  0.      45.9194  22.0327   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      14.2774   6.41616 -0.94347]
done:False
-------------------------
[99]>>[5]: env.step(2)
action:[3.5, 6.41616]
reward:-24.360850895811257
observation:
[ 0.       0.       0.       0.      17.6506  40.6411   0.       0.
  0.       0.       2.8058   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      42.8068
 19.2215   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.36699  1.26106]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 100.589, 'y': 1.26106, 'z': 0.569023}
.........................
** Rewards description :
count     5.000000
mean     -4.503431
std      11.105718
min     -24.360851
25%      -0.118812
50%       0.607300
75%       0.672413
max       0.682795
dtype: float64
#########################
[100]>> env.reset()
=========================
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 100      |
| mean 100 episode reward | -16.6    |
| steps                   | 2444     |
--------------------------------------
[100]>>[1]: env.step(2)
action:[3.5, 6.36076]
reward:-0.4714609598325202
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.7428  1.37702]
done:False
-------------------------
[100]>>[2]: env.step(3)
action:[3.5, 6.7428]
reward:0.42745622883921675
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.5099  3.05514]
done:False
-------------------------
[100]>>[3]: env.step(3)
action:[3.5, 8.5099]
reward:0.5788449717379387
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.03529 4.65787]
done:False
-------------------------
[100]>>[4]: env.step(3)
action:[3.5, 10.03529]
reward:0.6213830679430308
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.22247 3.61924]
done:False
-------------------------
[100]>>[5]: env.step(0)
action:[-3.5, 5.22247]
reward:-0.931954157557215
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.714   1.90336]
done:False
-------------------------
[100]>>[6]: env.step(4)
action:[-3.5, 3.7140000000000004]
reward:0.437198474662591
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.39129 -1.65996]
done:False
-------------------------
[100]>>[7]: env.step(3)
action:[-3.5, 9.39129]
reward:0.5645745401663602
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      49.0633   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.62588 -4.53454]
done:False
-------------------------
[100]>>[8]: env.step(0)
action:[-3.5, 4.62588]
reward:0.5605008227335984
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.6966   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.76341 -5.12192]
done:False
-------------------------
[100]>>[9]: env.step(1)
action:[0, 5.76341]
reward:-0.1161459164300056
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      41.9324
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.45858 -1.63027]
done:False
-------------------------
[100]>>[10]: env.step(2)
action:[3.5, 6.45858]
reward:-0.11995123870811697
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      40.9448   0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.23341  3.05796]
done:False
-------------------------
[100]>>[11]: env.step(5)
action:[3.5, 6.23341]
reward:0.6370752010676226
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      38.3589   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.38462  6.55667]
done:False
-------------------------
[100]>>[12]: env.step(2)
action:[3.5, 6.38462]
reward:0.6328859359193783
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      34.0015   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.2902   5.43499]
done:False
-------------------------
[100]>>[13]: env.step(5)
action:[3.5, 6.2902]
reward:0.6263858143866161
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.1608   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.22611  3.35393]
done:False
-------------------------
[100]>>[14]: env.step(5)
action:[3.5, 6.22611]
reward:0.5891759234500618
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.8524  49.0201   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.74362  3.79651]
done:False
-------------------------
[100]>>[15]: env.step(0)
action:[-3.5, 5.74362]
reward:-0.9160773019915625
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      22.2294   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.79433  2.1669 ]
done:False
-------------------------
[100]>>[16]: env.step(4)
action:[-3.5, 3.7943300000000004]
reward:0.45165229224844844
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 21.8305  44.297    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.55603 -1.45831]
done:False
-------------------------
[100]>>[17]: env.step(3)
action:[-3.5, 9.55603]
reward:0.5799250329477259
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.3413   0.      43.0444   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.7881  -4.42827]
done:False
-------------------------
[100]>>[18]: env.step(2)
action:[3.5, 4.7881]
reward:-0.9709708381080738
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      18.4463
  0.      39.6743   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.30921 -4.91425]
done:False
-------------------------
[100]>>[19]: env.step(0)
action:[-3.5, 5.30921]
reward:-0.9558309010956777
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.3968   0.      35.9539   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.37745 -2.79043]
done:False
-------------------------
[100]>>[20]: env.step(0)
action:[-3.5, 5.37745]
reward:0.511998856249136
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.1982   0.
  0.      32.2149   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.93959 -2.94638]
done:False
-------------------------
[100]>>[21]: env.step(5)
action:[-3.5, 4.93959]
reward:0.48855251896008456
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.55588  0.       0.
  0.      28.6439   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.74475 -2.98142]
done:False
-------------------------
[100]>>[22]: env.step(5)
action:[-3.5, 4.74475]
reward:0.47057384122010326
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.84915  0.       0.       0.       0.       0.
  0.      25.2083   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.56143 -2.98441]
done:False
-------------------------
[100]>>[23]: env.step(3)
action:[-3.5, 9.56143]
reward:0.5564312682112271
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.64056
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.8436   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.47582 -2.96976]
done:False
-------------------------
[100]>>[24]: env.step(0)
action:[-3.5, 4.47582]
reward:0.45213017247047943
observation:
[ 0.       0.       0.       0.       0.       7.9727   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.0549  18.5482   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.39178 -2.95   ]
done:False
-------------------------
[100]>>[25]: env.step(3)
action:[-3.5, 9.39178]
reward:0.540102474671144
observation:
[ 0.       0.       0.      10.1998   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.8604  15.3307   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.3034  -2.93086]
done:False
-------------------------
[100]>>[26]: env.step(5)
action:[-3.5, 4.3034]
reward:0.5470753971961064
observation:
[ 0.       0.      13.2697   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 11.6845   0.      47.4826   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.66711 -2.91081]
done:False
-------------------------
[100]>>[27]: env.step(2)
action:[3.5, 5.66711]
reward:-0.8109732908711774
observation:
[ 0.       0.      17.6944   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.98752
 23.4925   0.      42.5939   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.235   -2.88489]
done:False
-------------------------
[100]>>[28]: env.step(5)
action:[3.5, 7.235]
reward:-24.221618744046296
observation:
[ 0.       0.       0.       0.      20.8543   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.26618 19.7213   0.      38.993    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.09383 -1.94975]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 80.0721, 'y': -1.94975, 'z': 0.571164}
.........................
** Rewards description :
count    28.000000
mean     -0.687181
std       4.649087
min     -24.221619
25%      -0.207829
50%       0.479563
75%       0.568142
max       0.637075
dtype: float64
#########################
[101]>> env.reset()
=========================
[101]>>[1]: env.step(0)
action:[-3.5, 7.93938]
reward:-0.5790433333577855
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0398084 0.172168 ]
done:False
-------------------------
[101]>>[2]: env.step(2)
action:[3.5, 0.0398084]
reward:-1.495736699657586
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0398041 0.142628 ]
done:False
-------------------------
[101]>>[3]: env.step(5)
action:[3.5, 0.0398041]
reward:0.004263105481165295
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0398029 0.11369  ]
done:False
-------------------------
[101]>>[4]: env.step(5)
action:[3.5, 0.0398029]
reward:0.03347195565622079
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.381657  0.0467697]
done:False
-------------------------
[101]>>[5]: env.step(5)
action:[3.5, 0.381657]
reward:0.07996280422802776
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.843873 0.107374]
done:False
-------------------------
[101]>>[6]: env.step(4)
action:[3.5, 0.4219365]
reward:0.088960964581953
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.940325 0.289631]
done:False
-------------------------
[101]>>[7]: env.step(4)
action:[3.5, 0.4701625]
reward:0.08975055265189574
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.937624 0.616036]
done:False
-------------------------
[101]>>[8]: env.step(5)
action:[3.5, 0.937624]
reward:0.12411478255037725
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.22923 1.09265]
done:False
-------------------------
[101]>>[9]: env.step(5)
action:[3.5, 1.22923]
reward:0.15647021327731483
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54331 1.97885]
done:False
-------------------------
[101]>>[10]: env.step(4)
action:[3.5, 0.771655]
reward:0.15764006289400812
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.67174 2.99992]
done:False
-------------------------
[101]>>[11]: env.step(3)
action:[3.5, 6.67174]
reward:0.33290752118319566
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.33766 3.71607]
done:False
-------------------------
[101]>>[12]: env.step(3)
action:[3.5, 7.33766]
reward:0.44183829705730354
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.54463 3.78561]
done:False
-------------------------
[101]>>[13]: env.step(4)
action:[3.5, 1.772315]
reward:0.4294443463457637
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.77784 3.75951]
done:False
-------------------------
[101]>>[14]: env.step(3)
action:[3.5, 9.777840000000001]
reward:0.6328478033818118
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      46.5519   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.44138  3.77556]
done:False
-------------------------
[101]>>[15]: env.step(4)
action:[3.5, 3.4413799999999997]
reward:0.4229606144711412
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      42.9916   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.27805  3.79578]
done:False
-------------------------
[101]>>[16]: env.step(0)
action:[-3.5, 4.27805]
reward:-1.0406550041753186
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      40.2102   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.53375  2.3199 ]
done:False
-------------------------
[101]>>[17]: env.step(4)
action:[-3.5, 2.266875]
reward:0.29312277434987927
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.5724   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.9459  -0.22336]
done:False
-------------------------
[101]>>[18]: env.step(0)
action:[-3.5, 2.9459]
reward:0.29691773061790605
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.4479   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82298 -2.35929]
done:False
-------------------------
[101]>>[19]: env.step(4)
action:[-3.5, 1.41149]
reward:0.19589472940828476
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      38.7244   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.97253 -3.74635]
done:False
-------------------------
[101]>>[20]: env.step(0)
action:[-3.5, 1.97253]
reward:0.21358550684707392
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      37.626    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04652 -4.3248 ]
done:False
-------------------------
[101]>>[21]: env.step(5)
action:[-3.5, 2.04652]
reward:0.2154815218829087
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.2193   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.05103 -4.28847]
done:False
-------------------------
[101]>>[22]: env.step(3)
action:[-3.5, 7.05103]
reward:0.3486900432559964
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.6609   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.43963 -3.61769]
done:False
-------------------------
[101]>>[23]: env.step(1)
action:[0, 2.43963]
reward:-0.35759340496060715
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      32.1654   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.14139 -3.12303]
done:False
-------------------------
[101]>>[24]: env.step(3)
action:[0, 9.141390000000001]
reward:0.6431068762861535
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.8839   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.73928 -1.17317]
done:False
-------------------------
[101]>>[25]: env.step(5)
action:[0, 5.73928]
reward:0.6349528944908825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.1972  48.1249   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.47946  1.44392]
done:False
-------------------------
[101]>>[26]: env.step(4)
action:[0, 4.47946]
reward:0.521795168072742
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       21.4      44.1598    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.29182   0.260923]
done:False
-------------------------
[101]>>[27]: env.step(1)
action:[0, 5.29182]
reward:0.5090210656674361
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       17.7651   40.4852    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.92224   0.374183]
done:False
-------------------------
[101]>>[28]: env.step(2)
action:[3.5, 4.92224]
reward:-0.2455625151772285
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.5336  37.5279   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.95504  2.14424]
done:False
-------------------------
[101]>>[29]: env.step(1)
action:[0, 4.95504]
reward:-0.25476795662265694
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.3127  34.5297   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.82738  3.66298]
done:False
-------------------------
[101]>>[30]: env.step(4)
action:[0, 2.41369]
reward:0.4387355785719801
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.65374 31.531    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73599  1.65772]
done:False
-------------------------
[101]>>[31]: env.step(4)
action:[0, 2.367995]
reward:0.29997285284335135
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        7.01697
  0.       45.5331   29.372     0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.00519   0.459544]
done:False
-------------------------
[101]>>[32]: env.step(0)
action:[-3.5, 3.00519]
reward:-0.46157470847373944
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.26688   0.        0.       27.3064    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.7034    0.478244]
done:False
-------------------------
[101]>>[33]: env.step(0)
action:[-3.5, 2.7034]
reward:0.2898842083461078
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        4.76247   0.        0.        0.        0.        0.
 25.5632    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.79683  -0.592406]
done:False
-------------------------
[101]>>[34]: env.step(5)
action:[-3.5, 2.79683]
reward:0.26965795499238077
observation:
[ 0.       0.       0.       0.       0.       5.8057   0.       0.
  0.       0.       0.       0.      24.5192   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.52467 -2.31392]
done:False
-------------------------
[101]>>[35]: env.step(0)
action:[-3.5, 2.52467]
reward:0.26615909312050917
observation:
[ 0.       0.       0.       0.       0.       0.       6.44094  0.
  0.       0.       0.       0.       0.       0.      22.9956   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.54978 -3.06878]
done:False
-------------------------
[101]>>[36]: env.step(3)
action:[-3.5, 7.54978]
reward:0.37487823649977414
observation:
[ 0.       0.       0.       0.       0.       0.       6.82114  0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.1925   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.64308 -3.03286]
done:False
-------------------------
[101]>>[37]: env.step(0)
action:[-3.5, 2.64308]
reward:0.41761908659281566
observation:
[ 0.       0.       0.       0.       0.       8.00734  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.0194  18.5117   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.40974 -2.96709]
done:False
-------------------------
[101]>>[38]: env.step(0)
action:[-3.5, 4.40974]
reward:0.5152929935645969
observation:
[ 0.       0.       0.      10.5921   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.3693  14.8363   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.22443 -2.93088]
done:False
-------------------------
[101]>>[39]: env.step(4)
action:[-3.5, 3.22443]
reward:0.40278104382803165
observation:
[ 0.       0.      13.5567   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 11.3639   0.      47.1543   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.0763  -2.90852]
done:False
-------------------------
[101]>>[40]: env.step(4)
action:[-3.5, 2.03815]
reward:0.2833307736497126
observation:
[ 0.       0.      15.7066   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.03594  0.      44.7523   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.88241 -2.89499]
done:False
-------------------------
[101]>>[41]: env.step(0)
action:[-3.5, 2.88241]
reward:0.2922783586374076
observation:
[ 0.       0.      17.6547   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       7.02744
 23.5337   0.      42.6367   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.7816  -2.88398]
done:False
-------------------------
[101]>>[42]: env.step(5)
action:[-3.5, 2.7816]
reward:0.2790887061707417
observation:
[ 0.      19.5407   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.19665
 21.6012   0.      40.6238   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.64435 -2.87323]
done:False
-------------------------
[101]>>[43]: env.step(2)
action:[3.5, 2.64435]
reward:-26.20794662896164
observation:
[ 0.       0.       0.      20.7127   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.67709 20.073    0.      39.228    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.83834 -2.22248]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 80.0583, 'y': -2.22248, 'z': 0.569797}
.........................
** Rewards description :
count    43.000000
mean     -0.456884
std       4.042721
min     -26.207947
25%       0.084462
50%       0.279089
75%       0.410200
max       0.643107
dtype: float64
#########################
[102]>> env.reset()
=========================
[102]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.09464612940597661
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.1132   0.918773]
done:False
-------------------------
[102]>>[2]: env.step(3)
action:[0, 6.1132]
reward:0.22197309825649394
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.1132  1.46543]
done:False
-------------------------
[102]>>[3]: env.step(3)
action:[0, 6.1132]
reward:0.22914058741046034
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.20037 1.90665]
done:False
-------------------------
[102]>>[4]: env.step(3)
action:[0, 6.2003699999999995]
reward:0.4305396165650106
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.68478 3.48109]
done:False
-------------------------
[102]>>[5]: env.step(3)
action:[0, 8.68478]
reward:0.4870362222100244
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.78884 3.60604]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.13679, 'y': 3.60604, 'z': 0.572295}
.........................
** Rewards description :
count    5.000000
mean     0.292667
std      0.162045
min      0.094646
25%      0.221973
50%      0.229141
75%      0.430540
max      0.487036
dtype: float64
#########################
[103]>> env.reset()
=========================
[103]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.10852083895597808
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.27796 1.01665]
done:False
-------------------------
[103]>>[2]: env.step(1)
action:[0, 1.27796]
reward:0.09454612761336989
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.792524 1.6849  ]
done:False
-------------------------
[103]>>[3]: env.step(3)
action:[0, 5.792524]
reward:0.26865848211017734
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.76348 2.10121]
done:False
-------------------------
[103]>>[4]: env.step(3)
action:[0, 6.7634799999999995]
reward:0.4238046423624122
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.45826 2.67401]
done:False
-------------------------
[103]>>[5]: env.step(1)
action:[0, 3.45826]
reward:0.39221783012780476
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.88435 1.81994]
done:False
-------------------------
[103]>>[6]: env.step(3)
action:[0, 8.88435]
reward:0.4961259824272669
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.85664  0.244531]
done:False
-------------------------
[103]>>[7]: env.step(4)
action:[0, 1.92832]
reward:0.25538317092885676
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.56685  0.209974]
done:False
-------------------------
[103]>>[8]: env.step(3)
action:[0, 7.5668500000000005]
reward:0.38176408546629226
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.72543  0.256883]
done:False
-------------------------
[103]>>[9]: env.step(3)
action:[0, 7.725429999999999]
reward:0.5263180609944901
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.2358    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.53942   0.274848]
done:False
-------------------------
[103]>>[10]: env.step(3)
action:[0, 9.53942]
reward:0.6418164957550041
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.3191   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.62229  0.29239]
done:False
-------------------------
[103]>>[11]: env.step(3)
action:[0, 10.62229]
reward:0.7321003275379072
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.7864    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.59385   0.316312]
done:False
-------------------------
[103]>>[12]: env.step(4)
action:[0, 4.59385]
reward:0.5314548158297898
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.4598    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.38952   0.340586]
done:False
-------------------------
[103]>>[13]: env.step(0)
action:[-3.5, 5.38952]
reward:-0.19163706608991915
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      31.29     0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.54428 -1.46814]
done:False
-------------------------
[103]>>[14]: env.step(5)
action:[-3.5, 5.54428]
reward:0.5577763306603019
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.9445   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.49785 -3.9187 ]
done:False
-------------------------
[103]>>[15]: env.step(3)
action:[-3.5, 10.49785]
reward:0.6309874313486399
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.0829  47.2713   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.23626 -2.98534]
done:False
-------------------------
[103]>>[16]: env.step(0)
action:[-3.5, 5.23626]
reward:0.5093561736969239
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.5178  43.5597   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.94049 -3.03637]
done:False
-------------------------
[103]>>[17]: env.step(3)
action:[-3.5, 9.94049]
reward:0.5899142440869833
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      18.0886
  0.      39.9251   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.82486 -3.06377]
done:False
-------------------------
[103]>>[18]: env.step(2)
action:[3.5, 4.82486]
reward:-1.0144789571332211
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.808
  0.      36.3545   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73423 -3.0522 ]
done:False
-------------------------
[103]>>[19]: env.step(4)
action:[3.5, 2.367115]
reward:0.3007862077286129
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.1509   0.      33.9113   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.01546 -1.72539]
done:False
-------------------------
[103]>>[20]: env.step(5)
action:[3.5, 3.01546]
reward:0.29972082492636204
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.6461   33.078     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.84021   0.372624]
done:False
-------------------------
[103]>>[21]: env.step(3)
action:[3.5, 7.84021]
reward:0.4082922368496512
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       9.79704 32.7919   0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.99214  2.4421 ]
done:False
-------------------------
[103]>>[22]: env.step(4)
action:[3.5, 1.49607]
reward:0.23708737457639728
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.08487 32.3553   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.45145  4.27044]
done:False
-------------------------
[103]>>[23]: env.step(4)
action:[3.5, 1.225725]
reward:0.19350437641494903
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      7.95055 0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.99008 5.04461]
done:False
-------------------------
[103]>>[24]: env.step(3)
action:[3.5, 6.99008]
reward:0.3460116313364018
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      45.4518   6.54843  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.42142  5.23094]
done:False
-------------------------
[103]>>[25]: env.step(4)
action:[3.5, 1.21071]
reward:-24.633697587604154
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 43.2353   4.27108  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.12017  4.50113]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9616, 'y': 4.50113, 'z': 0.570535}
.........................
** Rewards description :
count    25.000000
mean     -0.676547
std       5.002957
min     -24.633698
25%       0.237087
50%       0.381764
75%       0.526318
max       0.732100
dtype: float64
#########################
[104]>> env.reset()
=========================
[104]>>[1]: env.step(3)
action:[0, 9.17241]
reward:0.4834392695678328
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.62044  0.118342]
done:False
-------------------------
[104]>>[2]: env.step(3)
action:[0, 8.62044]
reward:0.6313643374517061
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.7107   0.258751]
done:False
-------------------------
[104]>>[3]: env.step(4)
action:[0, 3.7107]
reward:0.6274522605468074
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.88536  0.269125]
done:False
-------------------------
[104]>>[4]: env.step(3)
action:[0, 11.88536]
reward:0.841445217917723
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.6476    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.84162   0.286351]
done:False
-------------------------
[104]>>[5]: env.step(4)
action:[0, 5.84162]
reward:0.64378256918861
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      40.4379   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.57338  0.31066]
done:False
-------------------------
[104]>>[6]: env.step(4)
action:[0, 4.57338]
reward:0.5222646229627256
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      36.2002   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.27447  0.33273]
done:False
-------------------------
[104]>>[7]: env.step(2)
action:[3.5, 5.27447]
reward:-0.2228567077723136
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.3125    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.16295   0.353255]
done:False
-------------------------
[104]>>[8]: env.step(4)
action:[3.5, 3.1629500000000004]
reward:0.3779221907187623
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.5842   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.77806  1.76596]
done:False
-------------------------
[104]>>[9]: env.step(4)
action:[3.5, 1.88903]
reward:0.25430416917836624
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.174    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.56347  3.68949]
done:False
-------------------------
[104]>>[10]: env.step(1)
action:[0, 2.56347]
reward:-0.4992085178627007
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.4756  49.6456   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.3519   3.99283]
done:False
-------------------------
[104]>>[11]: env.step(2)
action:[3.5, 2.3519]
reward:-0.5200127853294312
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.8388   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.151    3.95613]
done:False
-------------------------
[104]>>[12]: env.step(5)
action:[3.5, 2.151]
reward:0.21797656935077722
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.2737   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.0552   3.92442]
done:False
-------------------------
[104]>>[13]: env.step(5)
action:[3.5, 2.0552]
reward:0.20959518283737516
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.7671   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.97746  3.91421]
done:False
-------------------------
[104]>>[14]: env.step(5)
action:[3.5, 1.97746]
reward:0.20393765376290926
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.3076   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.92835  3.9169 ]
done:False
-------------------------
[104]>>[15]: env.step(5)
action:[3.5, 1.92835]
reward:0.1989001680315179
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.9068   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.87966  3.92404]
done:False
-------------------------
[104]>>[16]: env.step(5)
action:[3.5, 1.87966]
reward:0.19911241170103974
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.4928   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.8944   3.93237]
done:False
-------------------------
[104]>>[17]: env.step(1)
action:[0, 1.8944]
reward:-0.5319608441481591
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      16.1654
 39.3327   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.12011  3.28101]
done:False
-------------------------
[104]>>[18]: env.step(5)
action:[0, 2.12011]
reward:0.21862936515151205
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.2497  38.2783   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07085  2.06078]
done:False
-------------------------
[104]>>[19]: env.step(5)
action:[0, 2.07085]
reward:0.20563756746105227
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       14.4807   37.2855
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.92559   0.802576]
done:False
-------------------------
[104]>>[20]: env.step(5)
action:[0, 1.92559]
reward:0.21201053968620137
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 13.2188   35.8835    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.03915   0.402908]
done:False
-------------------------
[104]>>[21]: env.step(3)
action:[0, 7.039149999999999]
reward:0.30668321812902427
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.8374    0.       34.4324    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.92037   0.402878]
done:False
-------------------------
[104]>>[22]: env.step(5)
action:[0, 1.92037]
reward:0.19753886757410477
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.5074   33.0454    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.86519   0.432382]
done:False
-------------------------
[104]>>[23]: env.step(3)
action:[0, 6.86519]
reward:0.3356008244575437
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.07261  47.7075   31.5389    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.32283   0.462273]
done:False
-------------------------
[104]>>[24]: env.step(0)
action:[-3.5, 2.32283]
reward:-0.36915067123946477
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.8031    0.       45.2568   29.086     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.02492   0.491647]
done:False
-------------------------
[104]>>[25]: env.step(2)
action:[3.5, 4.02492]
reward:-26.03085615809173
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.07332  0.       0.      26.6256   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.72298  1.62673]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.5261, 'y': 1.62673, 'z': 0.567716}
.........................
** Rewards description :
count    25.000000
mean     -0.851458
std       5.258688
min     -26.030856
25%       0.197539
50%       0.212011
75%       0.377922
max       0.841445
dtype: float64
#########################
[105]>> env.reset()
=========================
[105]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.1313502112193335
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54997 1.14959]
done:False
-------------------------
[105]>>[2]: env.step(3)
action:[0, 6.54997]
reward:0.26669024346721415
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54997 1.47575]
done:False
-------------------------
[105]>>[3]: env.step(3)
action:[0, 6.54997]
reward:0.26605187745049463
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.54214 1.17113]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.06647, 'y': 1.17113, 'z': 0.571874}
.........................
** Rewards description :
count    3.000000
mean     0.221364
std      0.077955
min      0.131350
25%      0.198701
50%      0.266052
75%      0.266371
max      0.266690
dtype: float64
#########################
[106]>> env.reset()
=========================
[106]>>[1]: env.step(1)
action:[0, 0.0]
reward:0.08800127906466848
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.03444  0.889689]
done:False
-------------------------
[106]>>[2]: env.step(3)
action:[0, 6.03444]
reward:0.22589813943436582
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.18061 1.58012]
done:False
-------------------------
[106]>>[3]: env.step(3)
action:[0, 6.18061]
reward:0.42236276772931547
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.58564 2.03476]
done:False
-------------------------
[106]>>[4]: env.step(4)
action:[0, 1.79282]
reward:0.4218352276144771
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.67588  0.956643]
done:False
-------------------------
[106]>>[5]: env.step(2)
action:[3.5, 4.67588]
reward:-0.24279067259474985
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.05266 0.32054]
done:False
-------------------------
[106]>>[6]: env.step(4)
action:[3.5, 3.0526600000000004]
reward:0.37106068257240665
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.7194  1.46839]
done:False
-------------------------
[106]>>[7]: env.step(5)
action:[3.5, 3.7194]
reward:0.37115106710051243
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      48.6364   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.55385  3.65998]
done:False
-------------------------
[106]>>[8]: env.step(3)
action:[3.5, 8.55385]
reward:0.46418271608092887
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      46.1369   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.52694  3.90375]
done:False
-------------------------
[106]>>[9]: env.step(5)
action:[3.5, 3.52694]
reward:0.40113516170863434
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.1177   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.97985  3.78754]
done:False
-------------------------
[106]>>[10]: env.step(1)
action:[0, 3.97985]
reward:-0.32855196796223174
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      40.6006   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.1242   2.31988]
done:False
-------------------------
[106]>>[11]: env.step(5)
action:[0, 4.1242]
reward:0.4239147026611886
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       38.826
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.11948   0.117841]
done:False
-------------------------
[106]>>[12]: env.step(4)
action:[0, 2.05974]
reward:0.269049121974915
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.5844    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.70147   0.220832]
done:False
-------------------------
[106]>>[13]: env.step(3)
action:[0, 7.7014700000000005]
reward:0.397772369363716
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.5659    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.8937    0.321192]
done:False
-------------------------
[106]>>[14]: env.step(3)
action:[0, 7.8937]
reward:0.5316467104712879
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.7224    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.56707   0.355327]
done:False
-------------------------
[106]>>[15]: env.step(5)
action:[0, 4.56707]
reward:0.5253266096796673
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.9394    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.31605   0.374857]
done:False
-------------------------
[106]>>[16]: env.step(3)
action:[0, 10.31605]
reward:0.6282271031627578
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.0029   46.7953    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.24447   0.397201]
done:False
-------------------------
[106]>>[17]: env.step(0)
action:[-3.5, 5.24447]
reward:-0.12008964600969785
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.6809   42.4322    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.53507   0.421032]
done:False
-------------------------
[106]>>[18]: env.step(3)
action:[-3.5, 11.535070000000001]
reward:0.8886775048610156
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      15.5809  37.5914   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.62827 -1.98973]
done:False
-------------------------
[106]>>[19]: env.step(3)
action:[-3.5, 13.62827]
reward:1.0055567061058186
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.3624
  0.       0.       0.      30.8465   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.91135 -3.41681]
done:False
-------------------------
[106]>>[20]: env.step(3)
action:[-3.5, 14.91135]
reward:1.0731699276866604
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.62146  0.       0.       0.       0.       0.       0.
  0.      23.2386   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6972  -3.08449]
done:False
-------------------------
[106]>>[21]: env.step(4)
action:[-3.5, 8.6972]
reward:1.0513428021724314
observation:
[ 0.       0.       0.      10.6579   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.3073  14.7734   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.8877  -2.95148]
done:False
-------------------------
[106]>>[22]: env.step(3)
action:[-3.5, 16.887700000000002]
reward:1.2292002132805244
observation:
[ 0.       0.      18.9435   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.76272
 22.2105   0.      41.2591   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.0128  -2.88192]
done:False
-------------------------
[106]>>[23]: env.step(1)
action:[0, 13.0128]
reward:-24.549103188576797
observation:
[ 0.       0.       0.      23.1276   0.       0.       0.       0.
  0.       0.       0.       0.       2.04096  0.       0.       0.
  0.       0.      17.6909   0.      36.7247   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.4375  -2.37161]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 82.0361, 'y': -2.37161, 'z': 0.568546}
.........................
** Rewards description :
count    23.000000
mean     -0.628305
std       5.229981
min     -24.549103
25%       0.247474
50%       0.421835
75%       0.579937
max       1.229200
dtype: float64
#########################
[107]>> env.reset()
=========================
[107]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.6995650709674881
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.590923 0.473711]
done:False
-------------------------
[107]>>[2]: env.step(2)
action:[3.5, 0.590923]
reward:0.057386338798368686
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.525041 0.301034]
done:False
-------------------------
[107]>>[3]: env.step(4)
action:[3.5, 0.2625205]
reward:0.05035174224978256
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.524314  -0.0627212]
done:False
-------------------------
[107]>>[4]: env.step(1)
action:[0, 0.524314]
reward:-0.6393257768005088
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17249 0.57879]
done:False
-------------------------
[107]>>[5]: env.step(3)
action:[0, 6.17249]
reward:0.21078228725295492
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.96253 1.33676]
done:False
-------------------------
[107]>>[6]: env.step(4)
action:[0, 0.481265]
reward:0.11078584873592667
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.18458 1.61322]
done:False
-------------------------
[107]>>[7]: env.step(0)
action:[-3.5, 1.18458]
reward:-0.6021876378962854
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.45069 0.76328]
done:False
-------------------------
[107]>>[8]: env.step(3)
action:[-3.5, 6.45069]
reward:0.21272673567714864
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.916562 -0.108352]
done:False
-------------------------
[107]>>[9]: env.step(1)
action:[0, 0.916562]
reward:-0.6025345158024373
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.51354  -0.246087]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02712, 'y': -0.246087, 'z': 0.570052}
.........................
** Rewards description :
count    9.000000
mean    -0.211287
std      0.407709
min     -0.699565
25%     -0.602535
50%      0.050352
75%      0.110786
max      0.212727
dtype: float64
#########################
[108]>> env.reset()
=========================
Retrying to reset environment!
Retrying to reset environment!
[108]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.000663489592728439
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00774114 0.20458   ]
done:False
-------------------------
[108]>>[2]: env.step(4)
action:[0, 0.00387057]
reward:0.021378693830667674
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.248898 0.210057]
done:False
-------------------------
[108]>>[3]: env.step(3)
action:[0, 5.248898]
reward:0.17173389112962234
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.72178  0.208296]
done:False
-------------------------
[108]>>[4]: env.step(0)
action:[-3.5, 0.72178]
reward:-0.5655776245168425
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.00642  0.210513]
done:False
-------------------------
[108]>>[5]: env.step(3)
action:[-3.5, 7.00642]
reward:0.44583278236500334
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.67851  -0.769759]
done:False
-------------------------
[108]>>[6]: env.step(0)
action:[-3.5, 3.67851]
reward:0.42776626621694114
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.27992 -3.23151]
done:False
-------------------------
[108]>>[7]: env.step(3)
action:[-3.5, 9.27992]
reward:0.5473924440808597
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.42715 -3.44271]
done:False
-------------------------
[108]>>[8]: env.step(3)
action:[-3.5, 9.427150000000001]
reward:0.6179330497607596
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.5081   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.32811 -3.231  ]
done:False
-------------------------
[108]>>[9]: env.step(0)
action:[-3.5, 5.32811]
reward:0.5951602060277827
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.9283   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.0479  -3.19878]
done:False
-------------------------
[108]>>[10]: env.step(1)
action:[0, 6.0479]
reward:-0.12821841353213237
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      40.9062   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.22468 -1.05267]
done:False
-------------------------
[108]>>[11]: env.step(3)
action:[0, 11.22468]
reward:0.724793585245578
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.0652   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.3412   1.16656]
done:False
-------------------------
[108]>>[12]: env.step(3)
action:[0, 11.3412]
reward:0.7793878182118306
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.3156    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.08162   0.334337]
done:False
-------------------------
[108]>>[13]: env.step(5)
action:[0, 7.08162]
reward:0.7420029853207206
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.8311   49.642     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.61778   0.370212]
done:False
-------------------------
[108]>>[14]: env.step(3)
action:[0, 12.61778]
reward:0.8418581717876938
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.1618   43.9288    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.66456   0.409274]
done:False
-------------------------
[108]>>[15]: env.step(2)
action:[3.5, 7.66456]
reward:0.08232274181115018
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.0867    0.       37.7671    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.76357   0.443846]
done:False
-------------------------
[108]>>[16]: env.step(3)
action:[3.5, 13.76357]
reward:1.0117988089723249
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.23913   0.       46.8238   30.6553    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.97756   0.482932]
done:False
-------------------------
[108]>>[17]: env.step(4)
action:[3.5, 7.97756]
reward:0.967286746125473
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        3.01917   0.        0.        0.        0.        0.
  0.        0.        0.       39.0176   22.8372    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.7192    0.525723]
done:False
-------------------------
[108]>>[18]: env.step(1)
action:[0, 10.7192]
reward:0.28883221243753043
observation:
[ 0.       8.9284   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.7978  14.6017   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.1767   0.57039]
done:False
-------------------------
[108]>>[19]: env.step(5)
action:[0, 11.1767]
reward:1.066739787250828
observation:
[17.7296    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.7854   41.837     5.58921   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.5233    0.619296]
done:False
-------------------------
[108]>>[20]: env.step(2)
action:[3.5, 11.5233]
reward:-24.677660003948933
observation:
[ 0.       19.429     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.0677   40.1257    3.91046   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.5303    0.642731]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.9513, 'y': 0.642731, 'z': 0.570697}
.........................
** Rewards description :
count    20.000000
mean     -0.801929
std       5.635827
min     -24.677660
25%       0.067087
50%       0.496613
75%       0.751349
max       1.066740
dtype: float64
#########################
[109]>> env.reset()
=========================
[109]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.0921193920793138
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.08324  0.851609]
done:False
-------------------------
[109]>>[2]: env.step(5)
action:[0, 1.08324]
reward:0.11428656839460871
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.07574 1.14465]
done:False
-------------------------
[109]>>[3]: env.step(3)
action:[0, 6.07574]
reward:0.21727941736491374
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.06555 1.45914]
done:False
-------------------------
[109]>>[4]: env.step(3)
action:[0, 6.06555]
reward:0.34982585011305745
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.70019 2.16363]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.06331, 'y': 2.16363, 'z': 0.572488}
.........................
** Rewards description :
count    4.000000
mean     0.193378
std      0.117694
min      0.092119
25%      0.108745
50%      0.165783
75%      0.250416
max      0.349826
dtype: float64
#########################
[110]>> env.reset()
=========================
[110]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.09112305509987983
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.07143  0.899232]
done:False
-------------------------
[110]>>[2]: env.step(3)
action:[0, 6.07143]
reward:0.2008381756501557
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.867338 1.56885 ]
done:False
-------------------------
[110]>>[3]: env.step(0)
action:[-3.5, 0.867338]
reward:-0.607746145276888
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.46346 1.78685]
done:False
-------------------------
[110]>>[4]: env.step(3)
action:[-3.5, 6.4634599999999995]
reward:0.2897491466618217
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.85515 1.93692]
done:False
-------------------------
[110]>>[5]: env.step(5)
action:[-3.5, 1.85515]
reward:0.33098788863816764
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.51792 1.44031]
done:False
-------------------------
[110]>>[6]: env.step(2)
action:[3.5, 3.51792]
reward:-1.1114779973181745
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.82281 1.76949]
done:False
-------------------------
[110]>>[7]: env.step(3)
action:[3.5, 8.82281]
reward:0.4810684047927453
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.67722 3.65718]
done:False
-------------------------
[110]>>[8]: env.step(3)
action:[3.5, 8.67722]
reward:0.46529843313119884
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.51044 3.82794]
done:False
-------------------------
[110]>>[9]: env.step(1)
action:[0, 3.51044]
reward:-0.2567861502068376
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      46.8653   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.16238  3.78986]
done:False
-------------------------
[110]>>[10]: env.step(1)
action:[0, 5.16238]
reward:0.6144563043149629
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      42.4362   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.3476   3.79896]
done:False
-------------------------
[110]>>[11]: env.step(3)
action:[0, 11.3476]
reward:0.8251601469283154
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.1116   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.73857  1.44922]
done:False
-------------------------
[110]>>[12]: env.step(1)
action:[0, 7.73857]
reward:0.8215725216918569
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       32.8055    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.58874  -0.376377]
done:False
-------------------------
[110]>>[13]: env.step(4)
action:[0, 6.58874]
reward:0.7199320859406719
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.1207    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.43244   0.265589]
done:False
-------------------------
[110]>>[14]: env.step(0)
action:[-3.5, 7.43244]
reward:-0.023312866924456888
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.6433   44.4108    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.31568   0.376277]
done:False
-------------------------
[110]>>[15]: env.step(3)
action:[-3.5, 12.31568]
reward:0.8059600401171709
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       16.2673    0.       38.9683    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.21874   0.429218]
done:False
-------------------------
[110]>>[16]: env.step(0)
action:[-3.5, 7.21874]
reward:0.7174471635111579
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.5748   0.      34.4089   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.24036 -1.82548]
done:False
-------------------------
[110]>>[17]: env.step(3)
action:[-3.5, 12.240359999999999]
reward:0.8036867501793198
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.87336  0.       0.
  0.      29.9635   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.20483 -3.68584]
done:False
-------------------------
[110]>>[18]: env.step(3)
action:[-3.5, 12.204830000000001]
reward:0.8082503562866679
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.81991  0.       0.       0.       0.       0.
 41.2496  24.7828   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.27947 -3.09444]
done:False
-------------------------
[110]>>[19]: env.step(3)
action:[-3.5, 12.27947]
reward:0.9779029560288143
observation:
[ 0.       0.       0.       0.       0.       8.42057  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.3731  17.8599   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.81009 -2.98169]
done:False
-------------------------
[110]>>[20]: env.step(3)
action:[-3.5, 14.81009]
reward:1.093638678718146
observation:
[ 0.       0.      14.7273   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.0856   0.      45.8383   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.0685  -2.90867]
done:False
-------------------------
[110]>>[21]: env.step(3)
action:[-3.5, 16.0685]
reward:1.18110402054053
observation:
[ 0.      22.9669   0.       0.       0.       0.       0.       0.
  0.       0.       0.       2.68499  0.       0.       0.      18.1902
  0.       0.      37.0252   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.3037  -2.85606]
done:False
-------------------------
[110]>>[22]: env.step(0)
action:[-3.5, 12.3037]
reward:1.189049287032419
observation:
[ 0.      32.3989   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.6998   0.       0.
  0.       0.      27.3208   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.3924  -2.80393]
done:False
-------------------------
[110]>>[23]: env.step(3)
action:[-3.5, 18.392400000000002]
reward:1.3161511012564069
observation:
[42.6998   0.       0.       0.       0.       0.       7.0799   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.8796   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.4528  -2.74793]
done:False
-------------------------
[110]>>[24]: env.step(0)
action:[-3.5, 14.4528]
reward:1.3086992474804626
observation:
[30.5385   0.      15.6808   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.666    5.78279  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.2713  -2.6877 ]
done:False
-------------------------
[110]>>[25]: env.step(3)
action:[-3.5, 20.2713]
reward:-23.629298195085973
observation:
[32.8253   0.      17.8025   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.3743   0.       3.59654  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.29    -2.67533]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 115.282, 'y': -2.67533, 'z': 0.568601}
.........................
** Rewards description :
count    25.000000
mean     -0.423462
std       4.870589
min     -23.629298
25%       0.200838
50%       0.717447
75%       0.825160
max       1.316151
dtype: float64
#########################
[111]>> env.reset()
=========================
[111]>>[1]: env.step(3)
action:[0, 20.2863]
reward:0.4947851268568706
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.988773 0.200731]
done:False
-------------------------
[111]>>[2]: env.step(3)
action:[0, 5.988773]
reward:0.31706654137324186
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.31159  0.207017]
done:False
-------------------------
[111]>>[3]: env.step(3)
action:[0, 7.31159]
reward:0.45539374051078874
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.72467  0.219365]
done:False
-------------------------
[111]>>[4]: env.step(3)
action:[0, 8.72467]
reward:0.5692840980149124
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.85484  0.236703]
done:False
-------------------------
[111]>>[5]: env.step(3)
action:[0, 9.85484]
reward:0.6766505478559355
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.6964    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.01806   0.258764]
done:False
-------------------------
[111]>>[6]: env.step(0)
action:[-3.5, 6.01806]
reward:-0.09512125688243467
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      45.8833   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.67995 -1.80258]
done:False
-------------------------
[111]>>[7]: env.step(5)
action:[-3.5, 6.67995]
reward:0.6691904283617262
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 42.2031   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.70966 -4.00885]
done:False
-------------------------
[111]>>[8]: env.step(1)
action:[0, 6.70966]
reward:-0.09368167425983787
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      38.1934
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.52664 -0.91773]
done:False
-------------------------
[111]>>[9]: env.step(0)
action:[-3.5, 6.52664]
reward:-0.09681195186772407
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      33.861    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.52981  1.37489]
done:False
-------------------------
[111]>>[10]: env.step(3)
action:[-3.5, 11.529810000000001]
reward:0.7440526712551063
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      30.7054   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.53452 -1.69014]
done:False
-------------------------
[111]>>[11]: env.step(4)
action:[-3.5, 4.53452]
reward:0.6815111258299823
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      27.5389
 49.5232   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.41482 -4.50049]
done:False
-------------------------
[111]>>[12]: env.step(4)
action:[-3.5, 5.41482]
reward:0.6335988896101882
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      22.5925  44.707    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.54228 -2.87844]
done:False
-------------------------
[111]>>[13]: env.step(5)
action:[-3.5, 6.54228]
reward:0.6324486789271163
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      18.1897
  0.      40.0538   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.24488 -2.98141]
done:False
-------------------------
[111]>>[14]: env.step(2)
action:[3.5, 6.24488]
reward:-0.8776904785993085
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.9671
  0.      35.4242   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.18254 -3.01471]
done:False
-------------------------
[111]>>[15]: env.step(4)
action:[3.5, 4.18254]
reward:0.5066844333522865
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      10.1953   0.       0.      31.9595   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.16917 -1.25852]
done:False
-------------------------
[111]>>[16]: env.step(5)
action:[3.5, 5.16917]
reward:0.5066650127279002
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       8.18452 31.1861   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.92226  2.4332 ]
done:False
-------------------------
[111]>>[17]: env.step(5)
action:[3.5, 4.92226]
reward:0.5196852985542058
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      45.5958  30.0374
  6.75276  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.15358  5.57922]
done:False
-------------------------
[111]>>[18]: env.step(3)
action:[3.5, 10.15358]
reward:0.6156783797897842
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.0447  26.6297   0.       3.69817  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.11621  5.8506 ]
done:False
-------------------------
[111]>>[19]: env.step(1)
action:[0, 5.11621]
reward:-25.229309598635467
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 41.3584  25.9014   0.       0.       2.97096  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.11821  5.48645]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.8319, 'y': 5.48645, 'z': 0.570025}
.........................
** Rewards description :
count    19.000000
mean     -0.966838
std       5.889347
min     -25.229310
25%       0.111692
50%       0.506684
75%       0.633024
max       0.744053
dtype: float64
#########################
[112]>> env.reset()
=========================
[112]>>[1]: env.step(0)
action:[-3.5, 0.0]
reward:-0.6127335517972917
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.62065  -0.778673]
done:False
-------------------------
[112]>>[2]: env.step(3)
action:[-3.5, 6.6206499999999995]
reward:0.2738872509743031
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.62065 -1.04614]
done:False
-------------------------
[112]>>[3]: env.step(3)
action:[-3.5, 6.6206499999999995]
reward:0.2738872509743031
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.62065  -0.420075]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.0106, 'y': -0.420075, 'z': 0.569953}
.........................
** Rewards description :
count    3.000000
mean    -0.021653
std      0.511891
min     -0.612734
25%     -0.169423
50%      0.273887
75%      0.273887
max      0.273887
dtype: float64
#########################
[113]>> env.reset()
=========================
[113]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.23234886017763984
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.51773  -0.797738]
done:False
-------------------------
[113]>>[2]: env.step(3)
action:[0, 6.51773]
reward:0.26634294396355784
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.55377 -1.46375]
done:False
-------------------------
[113]>>[3]: env.step(3)
action:[0, 6.55377]
reward:0.3685631937380021
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.81277 -2.00839]
done:False
-------------------------
[113]>>[4]: env.step(3)
action:[0, 7.81277]
reward:0.5123705461885351
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.3356  -1.70197]
done:False
-------------------------
[113]>>[5]: env.step(3)
action:[0, 9.3356]
reward:0.6406930292992961
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.65803  0.479437]
done:False
-------------------------
[113]>>[6]: env.step(3)
action:[0, 10.65803]
reward:0.7389050042940641
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.4589    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.68021   0.255235]
done:False
-------------------------
[113]>>[7]: env.step(5)
action:[0, 6.68021]
reward:0.7116195087193474
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.1994    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.29402   0.287226]
done:False
-------------------------
[113]>>[8]: env.step(4)
action:[0, 5.29402]
reward:0.6851434854188696
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.7343    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.27485   0.318132]
done:False
-------------------------
[113]>>[9]: env.step(1)
action:[0, 7.27485]
reward:0.7139600659795143
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.9786    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.17786   0.350516]
done:False
-------------------------
[113]>>[10]: env.step(5)
action:[0, 7.17786]
reward:0.702507710636848
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      27.6921   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.04335  0.37826]
done:False
-------------------------
[113]>>[11]: env.step(2)
action:[3.5, 7.04335]
reward:-0.05369995569357
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      23.2151
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.9912   2.83576]
done:False
-------------------------
[113]>>[12]: env.step(4)
action:[3.5, 4.9912]
reward:0.5710105780050796
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.3339   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.81107  4.3945 ]
done:False
-------------------------
[113]>>[13]: env.step(4)
action:[3.5, 3.81107]
reward:0.4558608240381652
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.7173   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.60579  4.01487]
done:False
-------------------------
[113]>>[14]: env.step(2)
action:[3.5, 4.60579]
reward:0.4705334521127761
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.2889   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.59565  3.97123]
done:False
-------------------------
[113]>>[15]: env.step(3)
action:[3.5, 9.59565]
reward:0.5775106428082789
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.81435 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.74614 3.97247]
done:False
-------------------------
[113]>>[16]: env.step(3)
action:[3.5, 9.74614]
reward:0.6451655779880302
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.93728 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.616   3.99413]
done:False
-------------------------
[113]>>[17]: env.step(5)
action:[3.5, 5.616]
reward:-24.42708746346928
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.80577 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.68007 4.00561]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.2493, 'y': 4.00561, 'z': 0.571156}
.........................
** Rewards description :
count    17.000000
mean     -0.952250
std       6.053068
min     -24.427087
25%       0.368563
50%       0.571011
75%       0.685143
max       0.738905
dtype: float64
#########################
[114]>> env.reset()
=========================
[114]>>[1]: env.step(3)
action:[0, 10.757010000000001]
reward:-24.320514142266507
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.8314  4.01274]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.8249, 'y': 4.01274, 'z': 0.570782}
.........................
** Rewards description :
count     1.000000
mean    -24.320514
std            NaN
min     -24.320514
25%     -24.320514
50%     -24.320514
75%     -24.320514
max     -24.320514
dtype: float64
#########################
[115]>> env.reset()
=========================
[115]>>[1]: env.step(3)
action:[0, 5.0166283]
reward:0.10672186711401033
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00241691 0.200837  ]
done:False
-------------------------
[115]>>[2]: env.step(5)
action:[0, 0.00241691]
reward:0.01656377203346615
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.192908 0.201973]
done:False
-------------------------
[115]>>[3]: env.step(1)
action:[0, 0.192908]
reward:0.0378346686448123
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.394587 0.202309]
done:False
-------------------------
[115]>>[4]: env.step(5)
action:[0, 0.394587]
reward:0.058315172650330184
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.585069 0.2034  ]
done:False
-------------------------
[115]>>[5]: env.step(3)
action:[0, 5.585069]
reward:0.19546646657087763
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.923958 0.205787]
done:False
-------------------------
[115]>>[6]: env.step(4)
action:[0, 0.461979]
reward:0.0989315832729665
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.04855 0.20941]
done:False
-------------------------
[115]>>[7]: env.step(4)
action:[0, 0.524275]
reward:0.10274470329669885
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.07825  0.213592]
done:False
-------------------------
[115]>>[8]: env.step(3)
action:[0, 6.07825]
reward:0.2180311267069483
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.07405  0.217925]
done:False
-------------------------
[115]>>[9]: env.step(3)
action:[0, 6.07405]
reward:0.2451118424944751
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.40486  0.223091]
done:False
-------------------------
[115]>>[10]: env.step(0)
action:[-3.5, 1.40486]
reward:-0.5139473378980752
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.46164  0.230859]
done:False
-------------------------
[115]>>[11]: env.step(3)
action:[-3.5, 7.46164]
reward:0.47651737067331945
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.95879  -0.903823]
done:False
-------------------------
[115]>>[12]: env.step(0)
action:[-3.5, 3.95879]
reward:0.4554584649986434
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.5637  -3.40806]
done:False
-------------------------
[115]>>[13]: env.step(1)
action:[0, 4.5637]
reward:-0.2827070476423663
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.1023   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.56447 -3.29226]
done:False
-------------------------
[115]>>[14]: env.step(4)
action:[0, 2.282235]
reward:0.2997332698281667
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      46.186    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.02367 -1.27774]
done:False
-------------------------
[115]>>[15]: env.step(5)
action:[0, 3.02367]
reward:0.33283059128256604
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      44.5804   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.24872  0.35606]
done:False
-------------------------
[115]>>[16]: env.step(1)
action:[0, 3.24872]
reward:0.33101381076343905
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.2665   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.16985  0.41342]
done:False
-------------------------
[115]>>[17]: env.step(4)
action:[0, 1.584925]
reward:0.2254410855918541
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.3982    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.28743   0.317675]
done:False
-------------------------
[115]>>[18]: env.step(2)
action:[3.5, 2.28743]
reward:-0.48797312420174904
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      38.757    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.55843  1.13843]
done:False
-------------------------
[115]>>[19]: env.step(2)
action:[3.5, 2.55843]
reward:0.26222924784248264
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      37.5059
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.49316  2.86728]
done:False
-------------------------
[115]>>[20]: env.step(2)
action:[3.5, 2.49316]
reward:0.28964328472842865
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      35.944    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84642  3.90159]
done:False
-------------------------
[115]>>[21]: env.step(4)
action:[3.5, 1.42321]
reward:0.2062583510394688
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.2895   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09502  3.92239]
done:False
-------------------------
[115]>>[22]: env.step(0)
action:[-3.5, 2.09502]
reward:-1.2591884667403268
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.7432   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.34713  3.34583]
done:False
-------------------------
[115]>>[23]: env.step(4)
action:[-3.5, 1.173565]
reward:0.17966446830203278
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      31.7449   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.83611  2.23822]
done:False
-------------------------
[115]>>[24]: env.step(0)
action:[-3.5, 1.83611]
reward:0.201891830854859
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       31.2545    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.93892   0.914676]
done:False
-------------------------
[115]>>[25]: env.step(0)
action:[-3.5, 1.93892]
reward:0.20628868655618607
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.0509    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.96646  -0.506929]
done:False
-------------------------
[115]>>[26]: env.step(0)
action:[-3.5, 1.96646]
reward:0.21521167816373957
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.9907   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06777 -1.99801]
done:False
-------------------------
[115]>>[27]: env.step(4)
action:[-3.5, 1.033885]
reward:0.22477583007091595
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.6359   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.4171  -3.44321]
done:False
-------------------------
[115]>>[28]: env.step(0)
action:[-3.5, 2.4171]
reward:0.2539786430719414
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      29.4591   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.42747 -4.27063]
done:False
-------------------------
[115]>>[29]: env.step(0)
action:[-3.5, 2.42747]
reward:0.2643405806289683
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      27.6624
  0.      49.7046   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.55178 -4.24699]
done:False
-------------------------
[115]>>[30]: env.step(4)
action:[-3.5, 1.27589]
reward:0.18583134291546521
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.1786  48.2899   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.88489 -3.50823]
done:False
-------------------------
[115]>>[31]: env.step(4)
action:[-3.5, 0.942445]
reward:0.15316615621112487
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      24.9512   0.      47.0843   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.57538 -3.19209]
done:False
-------------------------
[115]>>[32]: env.step(0)
action:[-3.5, 1.57538]
reward:0.17558545193702407
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      23.7516  45.8697   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.68652 -3.08849]
done:False
-------------------------
[115]>>[33]: env.step(4)
action:[-3.5, 0.84326]
reward:0.14125001040602367
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.6651   0.      44.75     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.45747 -3.06315]
done:False
-------------------------
[115]>>[34]: env.step(3)
action:[-3.5, 6.45747]
reward:0.28035021193726756
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.5413  43.5793   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.7409  -3.06124]
done:False
-------------------------
[115]>>[35]: env.step(1)
action:[0, 1.7409]
reward:-0.5186271149665621
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.1116   0.      42.2323   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.32062 -2.41222]
done:False
-------------------------
[115]>>[36]: env.step(0)
action:[-3.5, 2.32062]
reward:-0.4964873087072945
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      18.5813
  0.      40.6371   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.44589 -2.4188 ]
done:False
-------------------------
[115]>>[37]: env.step(4)
action:[-3.5, 1.222945]
reward:0.21877994264752076
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      17.1824   0.
 39.0198   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29697 -2.92434]
done:False
-------------------------
[115]>>[38]: env.step(4)
action:[-3.5, 1.148485]
reward:0.1780087222761781
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      15.9029   0.
 37.5832   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.82243 -3.04452]
done:False
-------------------------
[115]>>[39]: env.step(4)
action:[-3.5, 0.911215]
reward:0.15142954785066742
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.7519
  0.      36.298    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.56237 -3.05949]
done:False
-------------------------
[115]>>[40]: env.step(5)
action:[-3.5, 1.56237]
reward:0.17510022456200655
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.6763
  0.      35.0854   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.68393 -3.0512 ]
done:False
-------------------------
[115]>>[41]: env.step(4)
action:[-3.5, 0.841965]
reward:0.1431018482090136
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      12.6925   0.
  0.      33.9556   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.47995 -3.04053]
done:False
-------------------------
[115]>>[42]: env.step(4)
action:[-3.5, 0.739975]
reward:0.140112050048049
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.7568   0.
  0.      32.8529   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.46968 -3.03055]
done:False
-------------------------
[115]>>[43]: env.step(3)
action:[-3.5, 6.46968]
reward:0.2579157482355741
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.8577   0.
  0.      31.7562   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.46251 -3.02206]
done:False
-------------------------
[115]>>[44]: env.step(3)
action:[-3.5, 6.46251]
reward:0.2812987066242927
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.93897  0.       0.
  0.      30.5808   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.75131 -3.01415]
done:False
-------------------------
[115]>>[45]: env.step(3)
action:[-3.5, 6.75131]
reward:0.3718165481322614
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.71168  0.       0.
  0.      28.8655   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.80423 -3.00396]
done:False
-------------------------
[115]>>[46]: env.step(3)
action:[-3.5, 7.8042300000000004]
reward:0.49838617912044214
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.21935  0.       0.       0.       0.
  0.      26.2045   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.15598 -2.9896 ]
done:False
-------------------------
[115]>>[47]: env.step(4)
action:[-3.5, 2.07799]
reward:0.482315581713916
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.53716  0.       0.       0.       0.       0.       0.       0.
  0.      22.5659   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.37953 -2.97026]
done:False
-------------------------
[115]>>[48]: env.step(5)
action:[-3.5, 5.37953]
reward:0.5794706108819278
observation:
[ 0.       0.       0.       0.       0.       8.07656  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.8781  18.3702   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.82619 -2.9476 ]
done:False
-------------------------
[115]>>[49]: env.step(3)
action:[-3.5, 10.82619]
reward:0.6809347840393691
observation:
[ 0.       0.       0.      11.4763   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.755    0.      49.5941   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.83399 -2.92241]
done:False
-------------------------
[115]>>[50]: env.step(3)
action:[-3.5, 10.83399]
reward:0.6795080872054926
observation:
[ 0.       0.      15.2735   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.49567  0.      45.2297   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.81246 -2.89884]
done:False
-------------------------
[115]>>[51]: env.step(5)
action:[-3.5, 5.81246]
reward:0.5850279602323025
observation:
[ 0.      19.2979   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.42364
 21.8477   0.      40.8814   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.79182 -2.87535]
done:False
-------------------------
[115]>>[52]: env.step(3)
action:[-3.5, 10.791820000000001]
reward:0.6860983859232608
observation:
[ 0.      23.4539   0.       0.       0.       0.       0.       0.
  0.       2.55038  0.       0.       0.       0.       0.      17.7158
  0.       0.      36.5183   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.91353 -2.85182]
done:False
-------------------------
[115]>>[53]: env.step(5)
action:[-3.5, 5.91353]
reward:0.6153334394361735
observation:
[ 0.      27.805    0.       4.77347  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.6107
  0.       0.      32.0219   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.17159 -2.8276 ]
done:False
-------------------------
[115]>>[54]: env.step(5)
action:[-3.5, 6.17159]
reward:0.6203182429408025
observation:
[ 0.      32.3347   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.74951  0.       0.
  0.       0.      27.3862   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.17407 -2.80256]
done:False
-------------------------
[115]>>[55]: env.step(5)
action:[-3.5, 6.17407]
reward:0.6175647327183934
observation:
[ 0.      36.8663   0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.9334   0.       0.       0.       0.
  0.       0.      22.7788   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.13643 -2.77764]
done:False
-------------------------
[115]>>[56]: env.step(3)
action:[-3.5, 11.13643]
reward:0.7149183912826008
observation:
[41.415    0.       0.       0.       0.       0.       0.       6.60861
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.1761   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.22578 -2.75277]
done:False
-------------------------
[115]>>[57]: env.step(5)
action:[-3.5, 6.22578]
reward:0.6831206223842055
observation:
[46.3217   0.       0.       0.       9.29805  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      13.2338   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.01411 -2.7262 ]
done:False
-------------------------
[115]>>[58]: env.step(0)
action:[-3.5, 7.01411]
reward:0.7368168185674517
observation:
[28.4919   0.      13.8278   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.7183   7.79302  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.56192 -2.69671]
done:False
-------------------------
[115]>>[59]: env.step(0)
action:[-3.5, 7.56192]
reward:-24.253144837309005
observation:
[32.2699   0.      17.2833   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.9308   4.11662  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.56589 -2.67625]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 115.111, 'y': -2.67625, 'z': 0.569251}
.........................
** Rewards description :
count    59.000000
mean     -0.191077
std       3.205947
min     -24.253145
25%       0.142176
50%       0.218780
75%       0.413638
max       0.736817
dtype: float64
#########################
[116]>> env.reset()
=========================
[116]>>[1]: env.step(0)
action:[-3.5, 7.55995]
reward:-25.00403172341742
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.55391 -2.67217]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 115.867, 'y': -2.67217, 'z': 0.569206}
.........................
** Rewards description :
count     1.000000
mean    -25.004032
std            NaN
min     -25.004032
25%     -25.004032
50%     -25.004032
75%     -25.004032
max     -25.004032
dtype: float64
#########################
[117]>> env.reset()
=========================
[117]>>[1]: env.step(5)
action:[0, 0.00105385]
reward:7.926903349719794e-05
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00066135 0.1992    ]
done:False
-------------------------
[117]>>[2]: env.step(5)
action:[0, 0.000661349]
reward:0.015807609366040865
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.184501 0.199526]
done:False
-------------------------
[117]>>[3]: env.step(1)
action:[0, 0.184501]
reward:0.03697801849397158
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.386631 0.200686]
done:False
-------------------------
[117]>>[4]: env.step(3)
action:[0, 5.386631]
reward:0.17658804768738584
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.745781 0.202788]
done:False
-------------------------
[117]>>[5]: env.step(3)
action:[0, 5.745781]
reward:0.27365222986492477
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.83648  0.207812]
done:False
-------------------------
[117]>>[6]: env.step(1)
action:[0, 1.83648]
reward:0.24381672610351096
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.44844  0.216651]
done:False
-------------------------
[117]>>[7]: env.step(3)
action:[0, 7.44844]
reward:0.3568024050014737
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.44171  0.226561]
done:False
-------------------------
[117]>>[8]: env.step(3)
action:[0, 7.4417100000000005]
reward:0.3754735213291432
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.67758 0.23672]
done:False
-------------------------
[117]>>[9]: env.step(3)
action:[0, 7.67758]
reward:0.46382344638930484
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.74139  0.250328]
done:False
-------------------------
[117]>>[10]: env.step(5)
action:[0, 3.74139]
reward:0.43769654759287946
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.2935    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.3908    0.266792]
done:False
-------------------------
[117]>>[11]: env.step(4)
action:[0, 2.1954]
reward:0.41044835471247154
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.9795    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.43067   0.284704]
done:False
-------------------------
[117]>>[12]: env.step(5)
action:[0, 4.43067]
reward:0.45630524129462885
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.655     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.45659   0.302684]
done:False
-------------------------
[117]>>[13]: env.step(5)
action:[0, 4.45659]
reward:0.45911167391054314
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.3095    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.48612   0.320784]
done:False
-------------------------
[117]>>[14]: env.step(5)
action:[0, 4.48612]
reward:0.46190456132686153
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.9442    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.5146    0.339001]
done:False
-------------------------
[117]>>[15]: env.step(5)
action:[0, 4.5146]
reward:0.46459640789244006
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.5606    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.54207   0.357332]
done:False
-------------------------
[117]>>[16]: env.step(5)
action:[0, 4.54207]
reward:0.46719130785669655
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       28.1602    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.56857   0.375772]
done:False
-------------------------
[117]>>[17]: env.step(5)
action:[0, 4.56857]
reward:0.46969256125292835
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.7453   47.5434    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.59413   0.394317]
done:False
-------------------------
[117]>>[18]: env.step(4)
action:[0, 2.297065]
reward:0.303517164102761
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.104    44.8804    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.06673   0.409109]
done:False
-------------------------
[117]>>[19]: env.step(5)
action:[0, 3.06673]
reward:0.3226813576954439
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.6706   42.4218    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.11178   0.422366]
done:False
-------------------------
[117]>>[20]: env.step(5)
action:[0, 3.11178]
reward:0.3300117794298009
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.3344    0.       40.0545    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.19162   0.435125]
done:False
-------------------------
[117]>>[21]: env.step(3)
action:[0, 8.19162]
reward:0.4368854573584886
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 14.951    0.      37.629    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.26789  0.4482 ]
done:False
-------------------------
[117]>>[22]: env.step(1)
action:[0, 3.26789]
reward:0.3451145865867531
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.5299    0.       35.1478    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.34077   0.461577]
done:False
-------------------------
[117]>>[23]: env.step(3)
action:[0, 8.34077]
reward:0.4509520486352659
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.0874   48.7793   32.6135    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.41045   0.475242]
done:False
-------------------------
[117]>>[24]: env.step(0)
action:[-3.5, 3.41045]
reward:-0.39112522761870117
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.65838   0.       46.1977   30.0284    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.47715   0.489183]
done:False
-------------------------
[117]>>[25]: env.step(1)
action:[0, 3.47715]
reward:-0.38466954040561263
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.33764   0.        0.       43.5677   27.3947    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.54137   0.503389]
done:False
-------------------------
[117]>>[26]: env.step(0)
action:[-3.5, 3.54137]
reward:-0.3592404869538893
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  4.65412   0.        0.        0.        0.        0.       41.3063
 25.0135    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.84517  -0.750482]
done:False
-------------------------
[117]>>[27]: env.step(3)
action:[-3.5, 8.84517]
reward:0.49918743715997593
observation:
[ 0.       0.       0.       0.       6.34433  0.       0.       0.
  0.       0.       0.       0.      39.897   23.4357   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.90614 -2.99968]
done:False
-------------------------
[117]>>[28]: env.step(3)
action:[-3.5, 8.90614]
reward:0.5051266054414089
observation:
[ 0.       0.       0.       0.       0.       0.       7.04337  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.6493   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.96802 -3.06667]
done:False
-------------------------
[117]>>[29]: env.step(0)
action:[-3.5, 3.96802]
reward:0.42902795996890297
observation:
[ 0.       0.       0.       0.       0.       8.64371  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      17.4587   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.22361 -2.92066]
done:False
-------------------------
[117]>>[30]: env.step(1)
action:[0, 4.22361]
reward:-0.29175201394053574
observation:
[ 0.       0.       0.       0.       0.       0.       0.       9.81108
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.5828   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.53328 -1.34393]
done:False
-------------------------
[117]>>[31]: env.step(1)
action:[0, 4.53328]
reward:0.47607454551790873
observation:
[ 0.        0.        0.        0.       11.004     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       28.5395
 12.3843    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.68517   0.990385]
done:False
-------------------------
[117]>>[32]: env.step(1)
action:[0, 4.68517]
reward:0.4536508374495569
observation:
[14.2498    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       25.2966   45.3567    9.09676   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.35893   0.587049]
done:False
-------------------------
[117]>>[33]: env.step(1)
action:[0, 4.35893]
reward:0.45042034054809144
observation:
[17.477     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.0438    5.84184   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.3991    0.591693]
done:False
-------------------------
[117]>>[34]: env.step(3)
action:[0, 9.3991]
reward:-24.450484403334222
observation:
[19.4309    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.0798   40.1254    3.90362   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.42529   0.622412]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.3003, 'y': 0.622412, 'z': 0.570426}
.........................
** Rewards description :
count    34.000000
mean     -0.450137
std       4.249392
min     -24.450484
25%       0.193395
50%       0.392961
75%       0.458410
max       0.505127
dtype: float64
#########################
[118]>> env.reset()
=========================
Retrying to reset environment!
[118]>>[1]: env.step(0)
action:[-3.5, 6.16489]
reward:-0.6173840184581432
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0238628 0.215379 ]
done:False
-------------------------
[118]>>[2]: env.step(3)
action:[-3.5, 5.0238628]
reward:0.14175496129514464
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.41836  0.226655]
done:False
-------------------------
[118]>>[3]: env.step(3)
action:[-3.5, 5.41836]
reward:0.25447111272977807
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.68318   -0.0348196]
done:False
-------------------------
[118]>>[4]: env.step(3)
action:[-3.5, 6.68318]
reward:0.397326676420353
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.14264 -1.23342]
done:False
-------------------------
[118]>>[5]: env.step(2)
action:[3.5, 3.14264]
reward:-1.1422061204369922
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.53057 -1.90195]
done:False
-------------------------
[118]>>[6]: env.step(3)
action:[3.5, 8.53057]
reward:0.4748188783344841
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.66966  -0.601013]
done:False
-------------------------
[118]>>[7]: env.step(5)
action:[3.5, 3.66966]
reward:0.3691545913851661
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.54122 1.92738]
done:False
-------------------------
[118]>>[8]: env.step(4)
action:[3.5, 1.77061]
reward:0.3610680660739798
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.91458 4.23222]
done:False
-------------------------
[118]>>[9]: env.step(4)
action:[3.5, 1.95729]
reward:0.2635538361534644
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      49.5711   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.65968  4.69354]
done:False
-------------------------
[118]>>[10]: env.step(1)
action:[0, 2.65968]
reward:-0.4883809546814403
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 47.7618   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.46037  4.02169]
done:False
-------------------------
[118]>>[11]: env.step(0)
action:[-3.5, 2.46037]
reward:-0.47124608634927845
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      46.2802   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.72054  2.77747]
done:False
-------------------------
[118]>>[12]: env.step(4)
action:[-3.5, 1.36027]
reward:0.19656096777584153
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      45.7578   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99339  1.18088]
done:False
-------------------------
[118]>>[13]: env.step(4)
action:[-3.5, 0.996695]
reward:0.15866748923585533
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        45.5663     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.62781   -0.0979218]
done:False
-------------------------
[118]>>[14]: env.step(1)
action:[0, 1.62781]
reward:-0.548562175507938
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      44.9013   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.9855  -1.08191]
done:False
-------------------------
[118]>>[15]: env.step(3)
action:[0, 6.9855]
reward:0.3154811828911487
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.7675   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.04275 -1.68058]
done:False
-------------------------
[118]>>[16]: env.step(3)
action:[0, 7.04275]
reward:0.3373926315985144
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 42.2666   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.30076 -1.6872 ]
done:False
-------------------------
[118]>>[17]: env.step(1)
action:[0, 2.30076]
reward:0.2783739650483835
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       40.5335    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.75577  -0.892949]
done:False
-------------------------
[118]>>[18]: env.step(5)
action:[0, 2.75577]
reward:0.28722625224768045
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       38.7158    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.75098   0.175081]
done:False
-------------------------
[118]>>[19]: env.step(5)
action:[0, 2.75098]
reward:0.29189100826222614
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       36.5015    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.80968   0.362775]
done:False
-------------------------
[118]>>[20]: env.step(4)
action:[0, 1.40484]
reward:0.20558369928893047
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.8068    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09144   0.370008]
done:False
-------------------------
[118]>>[21]: env.step(2)
action:[3.5, 2.09144]
reward:-0.5073417001905578
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      33.319    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.37056  1.21467]
done:False
-------------------------
[118]>>[22]: env.step(3)
action:[3.5, 7.370559999999999]
reward:0.34756855123310665
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      32.2375
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.34574  2.73455]
done:False
-------------------------
[118]>>[23]: env.step(5)
action:[3.5, 2.34574]
reward:0.27398268867462633
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      30.8757   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.69055  3.87408]
done:False
-------------------------
[118]>>[24]: env.step(4)
action:[3.5, 1.345275]
reward:0.244634891195739
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.9747   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.58123  3.93614]
done:False
-------------------------
[118]>>[25]: env.step(5)
action:[3.5, 2.58123]
reward:0.2737248599561491
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.0343   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.62851  3.90785]
done:False
-------------------------
[118]>>[26]: env.step(5)
action:[3.5, 2.62851]
reward:0.2828766625454589
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.0202   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.72923  3.90251]
done:False
-------------------------
[118]>>[27]: env.step(0)
action:[-3.5, 2.72923]
reward:-1.190521335153261
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      23.146   46.2536
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.03245  2.89885]
done:False
-------------------------
[118]>>[28]: env.step(5)
action:[-3.5, 3.03245]
reward:0.3204871769377373
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.2547   45.1303    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.09311   0.826176]
done:False
-------------------------
[118]>>[29]: env.step(3)
action:[-3.5, 8.09311]
reward:0.42923699278929
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 22.1822   0.      44.6456   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.195   -1.58181]
done:False
-------------------------
[118]>>[30]: env.step(5)
action:[-3.5, 3.195]
reward:0.38208398447294123
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.8626  43.7809   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.82242 -3.83408]
done:False
-------------------------
[118]>>[31]: env.step(3)
action:[-3.5, 8.822420000000001]
reward:0.502404756648478
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      19.8652  41.3427
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.95359 -4.68927]
done:False
-------------------------
[118]>>[32]: env.step(3)
action:[-3.5, 8.95359]
reward:0.5631404380826335
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.7106   0.      38.3031   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.71635 -3.36628]
done:False
-------------------------
[118]>>[33]: env.step(2)
action:[3.5, 4.71635]
reward:-0.9641359933827481
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      13.5467   0.
 35.8557   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.41666 -0.59267]
done:False
-------------------------
[118]>>[34]: env.step(4)
action:[3.5, 3.4166600000000003]
reward:0.4201060268234598
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.4932  35.5837   0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24794  2.87762]
done:False
-------------------------
[118]>>[35]: env.step(3)
action:[3.5, 9.24794]
reward:0.5256492827750168
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      11.1844
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.15005  5.46184]
done:False
-------------------------
[118]>>[36]: env.step(1)
action:[0, 4.15005]
reward:-0.3217723551714511
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      47.3072   8.50364  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.16791  5.92036]
done:False
-------------------------
[118]>>[37]: env.step(3)
action:[0, 9.16791]
reward:0.539306406616102
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      44.7855   5.7455   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.34892  4.05028]
done:False
-------------------------
[118]>>[38]: env.step(0)
action:[-3.5, 4.34892]
reward:-0.25170228225573715
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        5.21142   0.       43.6563   27.5271    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.01866   0.756229]
done:False
-------------------------
[118]>>[39]: env.step(2)
action:[3.5, 5.01866]
reward:-0.9241969945881476
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       4.55866  0.       0.       0.       0.       0.       0.
 40.1205  23.7946   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.86773 -1.02909]
done:False
-------------------------
[118]>>[40]: env.step(2)
action:[3.5, 5.86773]
reward:0.5940415285508127
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.36686  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.468
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.89807  1.47159]
done:False
-------------------------
[118]>>[41]: env.step(2)
action:[3.5, 5.89807]
reward:0.5981713910127855
observation:
[ 0.       0.       4.91913  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      34.3933  19.0451
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.94561  5.11929]
done:False
-------------------------
[118]>>[42]: env.step(3)
action:[3.5, 10.94561]
reward:0.6953279526035276
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 30.2442   0.      15.0802   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       8.95944  0.       0.       6.00222  4.92208]
done:False
-------------------------
[118]>>[43]: env.step(3)
action:[3.5, 11.002220000000001]
reward:0.7381302447358382
observation:
[13.2825   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.8107  46.5309   0.      10.7302   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.5833   4.20241]
done:False
-------------------------
[118]>>[44]: env.step(3)
action:[3.5, 11.583300000000001]
reward:0.8326880206346269
observation:
[18.7103   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.3783  41.1881   0.       0.       6.21996  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.78921  4.16586]
done:False
-------------------------
[118]>>[45]: env.step(3)
action:[3.5, 12.78921]
reward:0.9330124535269599
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.03    34.9873   0.       0.       0.       0.
  0.       0.       0.       0.       0.       4.95596  0.       0.
  0.       0.       0.      25.0602   8.98609  4.16873]
done:False
-------------------------
[118]>>[46]: env.step(3)
action:[3.5, 13.98609]
reward:1.0238610010651783
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.82409 28.0272   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      10.3314   0.      32.2807  10.1164   4.19944]
done:False
-------------------------
[118]>>[47]: env.step(1)
action:[0, 10.1164]
reward:-24.770237976200896
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.76654 25.0513   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.0576   0.      35.3252   0.      10.3801   4.01201]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 95.1245, 'y': 4.01201, 'z': 0.569485}
.........................
** Rewards description :
count    47.000000
mean     -0.369020
std       3.674572
min     -24.770238
25%      -0.054974
50%       0.287226
75%       0.452028
max       1.023861
dtype: float64
#########################
[119]>> env.reset()
=========================
[119]>>[1]: env.step(3)
action:[0, 15.4481]
reward:0.5184574107980713
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5061  -0.67593]
done:False
-------------------------
[119]>>[2]: env.step(3)
action:[0, 7.5061]
reward:0.5264096566884879
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.59545  -0.235131]
done:False
-------------------------
[119]>>[3]: env.step(3)
action:[0, 9.59545]
reward:0.6774035379597798
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.09323  0.172231]
done:False
-------------------------
[119]>>[4]: env.step(3)
action:[0, 11.09323]
reward:0.7655948115358147
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.9775    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.94762   0.237249]
done:False
-------------------------
[119]>>[5]: env.step(0)
action:[-3.5, 6.94762]
reward:-0.0002837872257599461
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      44.4206   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.75973 -2.02926]
done:False
-------------------------
[119]>>[6]: env.step(0)
action:[-3.5, 7.75973]
reward:0.7755075735434305
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.6155   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.92174 -3.80792]
done:False
-------------------------
[119]>>[7]: env.step(3)
action:[-3.5, 12.92174]
reward:0.8457038735530205
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.9741   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.64492 -3.26806]
done:False
-------------------------
[119]>>[8]: env.step(3)
action:[-3.5, 12.644919999999999]
reward:0.8977513191154346
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.0903   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.48696 -3.15533]
done:False
-------------------------
[119]>>[9]: env.step(3)
action:[-3.5, 13.48696]
reward:0.997873722017505
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 20.9477  42.9523   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.8241  -3.09085]
done:False
-------------------------
[119]>>[10]: env.step(1)
action:[0, 9.8241]
reward:0.21983479090636937
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        13.7735     0.        36.3317     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 10.2974     0.0519544]
done:False
-------------------------
[119]>>[11]: env.step(3)
action:[0, 15.2974]
reward:1.0487311697630624
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  6.78716   0.       45.2135   29.037     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.1946    0.431509]
done:False
-------------------------
[119]>>[12]: env.step(0)
action:[-3.5, 10.1946]
reward:0.24148414338476432
observation:
[ 0.       0.       0.       0.       6.13275  0.       0.       0.
  0.       0.       0.       0.       0.      22.2844   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.5457  -2.48784]
done:False
-------------------------
[119]>>[13]: env.step(0)
action:[-3.5, 10.5457]
reward:0.9915898047779385
observation:
[ 0.       0.       0.       0.      10.494    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.407   14.8775   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4596  -2.84669]
done:False
-------------------------
[119]>>[14]: env.step(5)
action:[-3.5, 10.4596]
reward:0.9803782322690813
observation:
[ 0.       0.      17.3193   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.36714  0.      42.9984   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.304   -2.89006]
done:False
-------------------------
[119]>>[15]: env.step(4)
action:[-3.5, 8.304]
reward:0.8810296519676365
observation:
[ 0.      24.1378   0.       0.       0.       0.       0.       0.
  2.52953  0.       0.       0.       0.       0.       0.      17.0558
  0.       0.      35.8084   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.32176 -2.85254]
done:False
-------------------------
[119]>>[16]: env.step(5)
action:[-3.5, 9.32176]
reward:0.8902734731171039
observation:
[ 0.      30.8774   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.924    0.
  0.       0.      28.874    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.2055  -2.81324]
done:False
-------------------------
[119]>>[17]: env.step(4)
action:[-3.5, 7.205500000000001]
reward:0.8471428132978884
observation:
[37.6078  14.2898   0.       0.       0.       0.       0.       0.
  0.       0.       6.66742  0.       0.       0.       0.       0.
  0.       0.      22.0271   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.09509 -2.77501]
done:False
-------------------------
[119]>>[18]: env.step(1)
action:[0, 9.09509]
reward:0.11546563222361872
observation:
[ 0.         0.         0.         0.        19.8526    42.9928
  0.         0.         0.         5.23367    0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.        40.4181
 16.7056     0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  8.89274   -0.0529203]
done:False
-------------------------
[119]>>[19]: env.step(1)
action:[0, 8.89274]
reward:0.8476701626651992
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.098     0.       10.9185    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       49.3819
 10.5937    8.68102   0.866246]
done:False
-------------------------
[119]>>[20]: env.step(2)
action:[3.5, 8.68102]
reward:0.08709885778677862
observation:
[16.9012    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       27.7309    0.        0.
  0.        0.        5.90297   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 32.7766    8.57915   0.855225]
done:False
-------------------------
[119]>>[21]: env.step(5)
action:[3.5, 8.57915]
reward:0.8227960700186101
observation:
[ 0.       0.       0.       0.      38.347   22.0899   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 23.0745   0.       0.       0.       0.       0.       0.       0.
  0.       7.7075   0.       0.       8.39635  3.38313]
done:False
-------------------------
[119]>>[22]: env.step(1)
action:[0, 8.39635]
reward:0.06842810667193056
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.411    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      11.6207   0.       0.
  0.      44.042    0.       0.       8.37871  4.74081]
done:False
-------------------------
[119]>>[23]: env.step(3)
action:[0, 13.37871]
reward:0.8947807141457987
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.8053    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.6948    0.       47.9874   32.0683    0.
  0.        8.25887   0.308643]
done:False
-------------------------
[119]>>[24]: env.step(5)
action:[0, 8.25887]
reward:0.7860909338739308
observation:
[18.357     0.       37.7625    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       47.5264    0.
  0.        0.        7.91496   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.94785   0.958647]
done:False
-------------------------
[119]>>[25]: env.step(0)
action:[-3.5, 7.94785]
reward:-24.976817998873763
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      42.4875   0.       0.       0.
  0.       0.       0.       2.87477  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      22.902   42.9958
  0.       0.       0.       0.       7.84164 -1.23391]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 34}
{'x': 141.732, 'y': -1.23391, 'z': 0.569708}
.........................
** Rewards description :
count    25.000000
mean     -0.369984
std       5.137304
min     -24.976818
25%       0.241484
50%       0.786091
75%       0.890273
max       1.048731
dtype: float64
#########################
[120]>> env.reset()
=========================
[120]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.16292196608378184
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.678067  -0.0579572]
done:False
-------------------------
[120]>>[2]: env.step(3)
action:[0, 5.678067]
reward:0.31960599825411606
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.42077  0.118932]
done:False
-------------------------
[120]>>[3]: env.step(0)
action:[-3.5, 2.42077]
reward:-0.4470598138884796
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.02867  -0.855545]
done:False
-------------------------
[120]>>[4]: env.step(3)
action:[-3.5, 8.02867]
reward:0.4031097848660141
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.8794  -2.72799]
done:False
-------------------------
[120]>>[5]: env.step(3)
action:[-3.5, 7.8794]
reward:0.40538278397033956
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.94549 -3.38807]
done:False
-------------------------
[120]>>[6]: env.step(3)
action:[-3.5, 7.9454899999999995]
reward:0.4180507420460933
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.08962 -3.31146]
done:False
-------------------------
[120]>>[7]: env.step(4)
action:[-3.5, 1.54481]
reward:0.2256278384023196
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29973 -3.25491]
done:False
-------------------------
[120]>>[8]: env.step(3)
action:[-3.5, 7.29973]
reward:0.3331804808996124
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.1306   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.18406 -3.23372]
done:False
-------------------------
[120]>>[9]: env.step(4)
action:[-3.5, 1.09203]
reward:0.17001681096823645
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.653    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.74034 -3.22508]
done:False
-------------------------
[120]>>[10]: env.step(3)
action:[-3.5, 6.74034]
reward:0.2841014013077748
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      46.3729   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.71635 -3.21887]
done:False
-------------------------
[120]>>[11]: env.step(4)
action:[-3.5, 0.858175]
reward:0.14373043782296158
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.2388   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.48342 -3.21281]
done:False
-------------------------
[120]>>[12]: env.step(0)
action:[-3.5, 1.48342]
reward:0.17402641573624855
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.0588   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.69074 -3.20682]
done:False
-------------------------
[120]>>[13]: env.step(2)
action:[3.5, 1.69074]
reward:-1.2872287064488142
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      42.7298   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.10709 -2.58015]
done:False
-------------------------
[120]>>[14]: env.step(5)
action:[3.5, 2.10709]
reward:0.2340385955965653
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      41.5689   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.26154 -1.3071 ]
done:False
-------------------------
[120]>>[15]: env.step(1)
action:[0, 2.26154]
reward:-0.5104673170356693
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        40.4662     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  2.2899     0.0486792]
done:False
-------------------------
[120]>>[16]: env.step(4)
action:[0, 1.14495]
reward:0.1714465733316042
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       39.1303    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.74431   0.350488]
done:False
-------------------------
[120]>>[17]: env.step(5)
action:[0, 1.74431]
reward:0.19505301749042075
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       37.7798    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.87915   0.371922]
done:False
-------------------------
[120]>>[18]: env.step(5)
action:[0, 1.87915]
reward:0.21153230362333098
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.3049    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04496   0.363846]
done:False
-------------------------
[120]>>[19]: env.step(5)
action:[0, 2.04496]
reward:0.22911593812825415
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.5965    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.21713   0.357503]
done:False
-------------------------
[120]>>[20]: env.step(5)
action:[0, 2.21713]
reward:0.2444779445223999
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.8789    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.36135   0.356463]
done:False
-------------------------
[120]>>[21]: env.step(5)
action:[0, 2.36135]
reward:0.2578673559892002
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.0613    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.489     0.360913]
done:False
-------------------------
[120]>>[22]: env.step(5)
action:[0, 2.489]
reward:0.2697469614279261
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.1551    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.60272   0.370035]
done:False
-------------------------
[120]>>[23]: env.step(5)
action:[0, 2.60272]
reward:0.28027075552591235
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.1708   49.9849    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.70361   0.381453]
done:False
-------------------------
[120]>>[24]: env.step(4)
action:[0, 1.351805]
reward:0.19428966807927037
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.5506  48.3544   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.96805  0.3908 ]
done:False
-------------------------
[120]>>[25]: env.step(5)
action:[0, 1.96805]
reward:0.217927364274475
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.0419   46.8347    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.10034   0.398952]
done:False
-------------------------
[120]>>[26]: env.step(4)
action:[0, 1.05017]
reward:0.16086488163380938
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.7352   45.5173    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.64082   0.406154]
done:False
-------------------------
[120]>>[27]: env.step(5)
action:[0, 1.64082]
reward:0.18790067151682344
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.4514   44.2216    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.81863   0.413052]
done:False
-------------------------
[120]>>[28]: env.step(5)
action:[0, 1.81863]
reward:0.20714440231819764
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.0213   42.7765    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.0069    0.420762]
done:False
-------------------------
[120]>>[29]: env.step(2)
action:[3.5, 2.0069]
reward:-0.511343032873246
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      18.4014  41.2616   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.34288  1.2287 ]
done:False
-------------------------
[120]>>[30]: env.step(1)
action:[0, 2.34288]
reward:-0.4994168991279602
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.7943  39.6494   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.4045   1.21013]
done:False
-------------------------
[120]>>[31]: env.step(5)
action:[0, 2.4045]
reward:0.24648438720674193
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       15.2523   37.9908    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.33901   0.613966]
done:False
-------------------------
[120]>>[32]: env.step(5)
action:[0, 2.33901]
reward:0.2560779258806336
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.5344   36.1927    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.47268   0.464073]
done:False
-------------------------
[120]>>[33]: env.step(3)
action:[0, 7.47268]
reward:0.38671588970636916
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.6585   34.2483    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.81135   0.455549]
done:False
-------------------------
[120]>>[34]: env.step(2)
action:[3.5, 2.81135]
reward:-0.4114076212584443
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.47012 48.3472  32.2695   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.37356  1.5088 ]
done:False
-------------------------
[120]>>[35]: env.step(2)
action:[3.5, 3.37356]
reward:0.3396957347424606
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.81897 31.0362
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.24676  3.61257]
done:False
-------------------------
[120]>>[36]: env.step(1)
action:[0, 3.24676]
reward:-0.3981976066821008
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      5.50387 0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.42959 4.17392]
done:False
-------------------------
[120]>>[37]: env.step(4)
action:[0, 1.714795]
reward:-24.747909662952
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       4.40754 27.7017   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.57995  3.7808 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.7937, 'y': 3.7808, 'z': 0.567826}
.........................
** Rewards description :
count    37.000000
mean     -0.580612
std       4.099365
min     -24.747910
25%       0.160865
50%       0.211532
75%       0.269747
max       0.418051
dtype: float64
#########################
[121]>> env.reset()
=========================
[121]>>[1]: env.step(1)
action:[0, 2.28515]
reward:-24.78406801609924
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.00494  0.       0.      41.6416  25.6332   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99684  1.70308]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 57.5776, 'y': 1.70308, 'z': 0.56941}
.........................
** Rewards description :
count     1.000000
mean    -24.784068
std            NaN
min     -24.784068
25%     -24.784068
50%     -24.784068
75%     -24.784068
max     -24.784068
dtype: float64
#########################
[122]>> env.reset()
=========================
[122]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7252888815642903
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.288895   0.00321353]
done:False
-------------------------
[122]>>[2]: env.step(3)
action:[3.5, 5.288895]
reward:0.17080948440288118
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.700659 -0.199185]
done:False
-------------------------
[122]>>[3]: env.step(2)
action:[3.5, 0.700659]
reward:0.1256038935114141
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.30623   0.0811504]
done:False
-------------------------
[122]>>[4]: env.step(3)
action:[3.5, 6.30623]
reward:0.2398690288194434
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.28283  0.569025]
done:False
-------------------------
[122]>>[5]: env.step(3)
action:[3.5, 6.28283]
reward:0.23822581560520156
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.26864 1.27001]
done:False
-------------------------
[122]>>[6]: env.step(3)
action:[3.5, 6.2686399999999995]
reward:0.2761168086960628
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.73605 2.2011 ]
done:False
-------------------------
[122]>>[7]: env.step(4)
action:[3.5, 0.868025]
reward:0.14910392563672736
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.5453  3.22011]
done:False
-------------------------
[122]>>[8]: env.step(3)
action:[3.5, 6.5453]
reward:0.2607273674105518
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.47804 3.68056]
done:False
-------------------------
[122]>>[9]: env.step(3)
action:[3.5, 6.47804]
reward:0.3007992566390824
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.98789 3.80039]
done:False
-------------------------
[122]>>[10]: env.step(3)
action:[3.5, 6.98789]
reward:0.4337937059174778
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.52938 3.78316]
done:False
-------------------------
[122]>>[11]: env.step(5)
action:[3.5, 3.52938]
reward:0.4840207207626097
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.5443   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.03871  3.75942]
done:False
-------------------------
[122]>>[12]: env.step(5)
action:[3.5, 5.03871]
reward:0.5428268421840647
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.5699   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.42744  3.77945]
done:False
-------------------------
[122]>>[13]: env.step(3)
action:[3.5, 10.42744]
reward:0.6363429074233576
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.5408   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.32621  3.80217]
done:False
-------------------------
[122]>>[14]: env.step(5)
action:[3.5, 5.32621]
reward:0.6203535571281658
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.2488   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.38589  3.82534]
done:False
-------------------------
[122]>>[15]: env.step(3)
action:[3.5, 11.38589]
reward:0.8746440421457743
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.6591   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.4562   3.85493]
done:False
-------------------------
[122]>>[16]: env.step(3)
action:[3.5, 13.4562]
reward:1.0129938285120206
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.5716   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.0736   3.89274]
done:False
-------------------------
[122]>>[17]: env.step(5)
action:[3.5, 10.0736]
reward:0.9980031499124757
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.7369   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6795   3.93489]
done:False
-------------------------
[122]>>[18]: env.step(3)
action:[3.5, 15.6795]
reward:1.0778391570456134
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       8.77079  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.5836   3.97795]
done:False
-------------------------
[122]>>[19]: env.step(2)
action:[3.5, 10.5836]
reward:-23.98387017635469
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.47775  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.8422   4.00656]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.3242, 'y': 4.00656, 'z': 0.570587}
.........................
** Rewards description :
count    19.000000
mean     -0.856162
std       5.615934
min     -23.983870
25%       0.204518
50%       0.300799
75%       0.628348
max       1.077839
dtype: float64
#########################
[123]>> env.reset()
=========================
[123]>>[1]: env.step(3)
action:[0, 16.005000000000003]
reward:0.33264304058308014
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00105324 0.1992    ]
done:False
-------------------------
[123]>>[2]: env.step(3)
action:[0, 5.00105324]
reward:0.14566813449274868
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.470895 0.199844]
done:False
-------------------------
[123]>>[3]: env.step(2)
action:[3.5, 0.470895]
reward:-0.6502723737325263
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.05577  0.348989]
done:False
-------------------------
[123]>>[4]: env.step(3)
action:[3.5, 6.05577]
reward:0.21384266411743877
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.02883  0.866078]
done:False
-------------------------
[123]>>[5]: env.step(4)
action:[3.5, 0.514415]
reward:0.09900985315570081
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.03637 1.44595]
done:False
-------------------------
[123]>>[6]: env.step(1)
action:[0, 1.03637]
reward:-0.6410121866783521
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.02442 2.1189 ]
done:False
-------------------------
[123]>>[7]: env.step(5)
action:[0, 1.02442]
reward:0.1471343654682603
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.48261 2.47961]
done:False
-------------------------
[123]>>[8]: env.step(3)
action:[0, 6.48261]
reward:0.25607465764455184
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.43674 2.50147]
done:False
-------------------------
[123]>>[9]: env.step(5)
action:[0, 1.43674]
reward:0.17061931289902027
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.66141 2.15517]
done:False
-------------------------
[123]>>[10]: env.step(3)
action:[0, 6.66141]
reward:0.3108648375735399
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.06657 1.38216]
done:False
-------------------------
[123]>>[11]: env.step(3)
action:[0, 7.0665700000000005]
reward:0.40920287392334487
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.19709  0.354506]
done:False
-------------------------
[123]>>[12]: env.step(3)
action:[0, 8.19709]
reward:0.5253836103975608
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.40929  0.221559]
done:False
-------------------------
[123]>>[13]: env.step(4)
action:[0, 2.204645]
reward:0.4758039581915341
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.4687    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.26384   0.270357]
done:False
-------------------------
[123]>>[14]: env.step(3)
action:[0, 10.26384]
reward:0.6838058651325125
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.2409    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.01401   0.296535]
done:False
-------------------------
[123]>>[15]: env.step(5)
action:[0, 6.01401]
reward:0.689128038560513
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.2648    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.14967   0.324624]
done:False
-------------------------
[123]>>[16]: env.step(3)
action:[0, 12.14967]
reward:0.8727999624881851
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      31.4701   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.23785  0.35646]
done:False
-------------------------
[123]>>[17]: env.step(5)
action:[0, 8.23785]
reward:0.8425232086406842
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       25.0888   47.8892    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.76928   0.391229]
done:False
-------------------------
[123]>>[18]: env.step(1)
action:[0, 8.76928]
reward:0.8460642092471087
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      18.604   41.342    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.68832  0.42667]
done:False
-------------------------
[123]>>[19]: env.step(3)
action:[0, 13.68832]
reward:0.9207068039897057
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.8501    0.       34.4465    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.5734    0.463945]
done:False
-------------------------
[123]>>[20]: env.step(5)
action:[0, 8.5734]
reward:0.8502849096092616
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.83636   0.        0.       44.1591   27.987     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.79926   0.498773]
done:False
-------------------------
[123]>>[21]: env.step(0)
action:[-3.5, 8.79926]
reward:0.09892465581811294
observation:
[ 0.       0.       0.       5.84133  0.       0.       0.       0.
  0.       0.       0.       0.      22.442    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.72281 -2.26161]
done:False
-------------------------
[123]>>[22]: env.step(4)
action:[-3.5, 6.722810000000001]
reward:0.8068719623978797
observation:
[ 0.       0.       0.       0.       0.       0.       9.43072  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.5694   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.6301  -3.14054]
done:False
-------------------------
[123]>>[23]: env.step(3)
action:[-3.5, 13.6301]
reward:0.9162070320064712
observation:
[ 0.       0.      14.5624   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.2972   0.      46.0437   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.51955 -2.96231]
done:False
-------------------------
[123]>>[24]: env.step(5)
action:[-3.5, 8.51955]
reward:0.8157697199662612
observation:
[ 0.      20.3414   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       4.4863   0.
 20.8023   0.      39.7816   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.30942 -2.88782]
done:False
-------------------------
[123]>>[25]: env.step(3)
action:[-3.5, 13.30942]
reward:0.8900715644790603
observation:
[ 0.      26.274    0.       0.       3.53339  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.0269
  0.       0.      33.5989   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.20556 -2.84204]
done:False
-------------------------
[123]>>[26]: env.step(3)
action:[-3.5, 13.20556]
reward:0.8814955972712296
observation:
[ 0.      32.2286   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.83308  0.       0.
  0.       0.      27.4947   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.10332 -2.80525]
done:False
-------------------------
[123]>>[27]: env.step(5)
action:[-3.5, 8.10332]
reward:0.780339248441645
observation:
[38.0912   0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.53452  0.       0.       0.       0.       0.
  0.       0.      21.5374   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.90465 -2.77186]
done:False
-------------------------
[123]>>[28]: env.step(3)
action:[-3.5, 12.90465]
reward:0.8564191627011573
observation:
[43.9009   0.       0.       0.       0.       7.69469  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.669    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.80673 -2.73975]
done:False
-------------------------
[123]>>[29]: env.step(0)
action:[-3.5, 7.80673]
reward:0.7873331896647761
observation:
[26.8699   0.       0.      12.4035   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       9.40048  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.07864 -2.70567]
done:False
-------------------------
[123]>>[30]: env.step(5)
action:[-3.5, 8.07864]
reward:0.7872036065826205
observation:
[32.8855   0.      17.8589   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.314    0.       3.5408   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.00881 -2.67304]
done:False
-------------------------
[123]>>[31]: env.step(5)
action:[-3.5, 8.00881]
reward:-24.21447915768673
observation:
[33.2843   0.      18.2333   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.9145   0.       3.17616  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.00222 -2.67088]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 116.107, 'y': -2.67088, 'z': 0.570848}
.........................
** Rewards description :
count    31.000000
mean     -0.293341
std       4.459428
min     -24.214479
25%       0.192231
50%       0.683806
75%       0.844294
max       0.920707
dtype: float64
#########################
[124]>> env.reset()
=========================
[124]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.10618403399871619
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 1.81639e-04 1.99215e-01]
done:False
-------------------------
[124]>>[2]: env.step(0)
action:[-3.5, 0.000181639]
reward:-0.7499921674636845
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 4.59699e-05 1.99231e-01]
done:False
-------------------------
[124]>>[3]: env.step(3)
action:[-3.5, 5.0000459699]
reward:0.16170290102702467
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.663414 0.18693 ]
done:False
-------------------------
[124]>>[4]: env.step(3)
action:[-3.5, 5.6634139999999995]
reward:0.3229020851385762
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.46535  -0.317729]
done:False
-------------------------
[124]>>[5]: env.step(3)
action:[-3.5, 7.46535]
reward:0.4777809950495825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.97416 -2.25584]
done:False
-------------------------
[124]>>[6]: env.step(3)
action:[-3.5, 8.97416]
reward:0.6232329125412781
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.51265 -3.80321]
done:False
-------------------------
[124]>>[7]: env.step(5)
action:[-3.5, 5.51265]
reward:0.5683764163508409
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.64583 -3.28407]
done:False
-------------------------
[124]>>[8]: env.step(3)
action:[-3.5, 10.64583]
reward:0.653400402977737
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 47.2548   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.5029  -3.26898]
done:False
-------------------------
[124]>>[9]: env.step(3)
action:[-3.5, 10.5029]
reward:0.7336065605883186
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.5664   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.64477 -3.22706]
done:False
-------------------------
[124]>>[10]: env.step(5)
action:[-3.5, 6.64477]
reward:0.8086375465607194
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.7973   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.67507 -3.17985]
done:False
-------------------------
[124]>>[11]: env.step(4)
action:[-3.5, 6.67507]
reward:0.7321249945995745
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 30.9319   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.581   -3.13958]
done:False
-------------------------
[124]>>[12]: env.step(4)
action:[-3.5, 5.581]
reward:0.7017771409310767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 25.4755  47.6667   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.43246 -3.10751]
done:False
-------------------------
[124]>>[13]: env.step(3)
action:[-3.5, 12.432459999999999]
reward:0.816110910702335
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 20.1757  42.142    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.33613 -3.0771 ]
done:False
-------------------------
[124]>>[14]: env.step(3)
action:[-3.5, 12.33613]
reward:0.8092752124863163
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.1092
  0.      36.6908   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.26143 -3.04744]
done:False
-------------------------
[124]>>[15]: env.step(4)
action:[-3.5, 5.26143]
reward:0.6034565777989369
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.9014   0.
  0.      31.8123   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.17542 -3.02069]
done:False
-------------------------
[124]>>[16]: env.step(3)
action:[-3.5, 11.175419999999999]
reward:0.7023378279661363
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.73781  0.       0.       0.
  0.      27.2638   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.04161 -2.996  ]
done:False
-------------------------
[124]>>[17]: env.step(5)
action:[-3.5, 6.04161]
reward:0.600604113057944
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.52181  0.       0.       0.       0.       0.       0.       0.
  0.      22.7979   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.94223 -2.97175]
done:False
-------------------------
[124]>>[18]: env.step(4)
action:[-3.5, 3.9422300000000003]
reward:0.4732051886665608
observation:
[ 0.       0.       0.       0.       0.       7.73006  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.481   18.9776   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.79595 -2.95066]
done:False
-------------------------
[124]>>[19]: env.step(0)
action:[-3.5, 4.79595]
reward:0.48137162230387986
observation:
[ 0.       0.       0.      10.2741   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.7659  15.2356   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.68785 -2.93021]
done:False
-------------------------
[124]>>[20]: env.step(0)
action:[-3.5, 4.68785]
reward:0.47252171241109453
observation:
[ 0.       0.      13.1504   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 11.8186   0.      47.6197   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.60074 -2.91142]
done:False
-------------------------
[124]>>[21]: env.step(3)
action:[-3.5, 9.60074]
reward:0.559227874000155
observation:
[ 0.       0.      16.1993   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.51904  0.      44.213    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.50289 -2.893  ]
done:False
-------------------------
[124]>>[22]: env.step(5)
action:[-3.5, 4.50289]
reward:0.5070833982606631
observation:
[ 0.      19.5204   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.21545
 21.6218   0.      40.6453   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.09427 -2.87389]
done:False
-------------------------
[124]>>[23]: env.step(1)
action:[0, 5.09427]
reward:-0.23484876542473954
observation:
[ 0.      23.1522   0.       0.       0.       0.       0.       0.
  0.       0.       2.62298  0.       0.       0.       0.      18.0094
  0.       0.      36.8322   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.05145 -2.85328]
done:False
-------------------------
[124]>>[24]: env.step(1)
action:[0, 5.05145]
reward:-24.463598631976595
observation:
[ 0.       0.       0.      25.257    0.       0.       0.       2.40731
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.539    0.       0.      34.5029   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.33993 -2.10628]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 84.6893, 'y': -2.10628, 'z': 0.569685}
.........................
** Rewards description :
count    24.000000
mean     -0.563897
std       5.103156
min     -24.463599
25%       0.435117
50%       0.563802
75%       0.701917
max       0.816111
dtype: float64
#########################
[125]>> env.reset()
=========================
[125]>>[1]: env.step(5)
action:[0, 5.18515]
reward:0.22659920815082102
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.40146  -0.970435]
done:False
-------------------------
[125]>>[2]: env.step(3)
action:[0, 6.40146]
reward:0.3777637743398614
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.96644 -1.43648]
done:False
-------------------------
[125]>>[3]: env.step(3)
action:[0, 7.96644]
reward:0.5506228212810647
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.79803  -0.921108]
done:False
-------------------------
[125]>>[4]: env.step(4)
action:[0, 2.399015]
reward:0.3078974507137262
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.09543  0.106222]
done:False
-------------------------
[125]>>[5]: env.step(4)
action:[0, 1.547715]
reward:0.2714028449516963
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.85837  0.214001]
done:False
-------------------------
[125]>>[6]: env.step(1)
action:[0, 2.85837]
reward:0.2905397891952562
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.76617  0.273156]
done:False
-------------------------
[125]>>[7]: env.step(3)
action:[0, 7.76617]
reward:0.38132718806336463
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.1748    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.6701    0.284689]
done:False
-------------------------
[125]>>[8]: env.step(5)
action:[0, 2.6701]
reward:0.26389583529720134
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.2825    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.48567   0.278087]
done:False
-------------------------
[125]>>[9]: env.step(1)
action:[0, 2.48567]
reward:0.24481169321583224
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.4116   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.29829  0.28417]
done:False
-------------------------
[125]>>[10]: env.step(5)
action:[0, 2.29829]
reward:0.22644835634290722
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.7956   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.12134  0.29652]
done:False
-------------------------
[125]>>[11]: env.step(4)
action:[0, 1.06067]
reward:0.19458639626275215
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.2413    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04442   0.306594]
done:False
-------------------------
[125]>>[12]: env.step(5)
action:[0, 2.04442]
reward:0.20389801317704248
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.7998    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.91113   0.314445]
done:False
-------------------------
[125]>>[13]: env.step(4)
action:[0, 0.955565]
reward:0.15497327016781298
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.5669    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.59377   0.320968]
done:False
-------------------------
[125]>>[14]: env.step(5)
action:[0, 1.59377]
reward:0.16719727432897535
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.3807    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.581     0.327148]
done:False
-------------------------
[125]>>[15]: env.step(5)
action:[0, 1.581]
reward:0.16637099754169377
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.2011    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.57426   0.333366]
done:False
-------------------------
[125]>>[16]: env.step(5)
action:[0, 1.57426]
reward:0.17843816796136458
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.9669    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.72116   0.339869]
done:False
-------------------------
[125]>>[17]: env.step(5)
action:[0, 1.72116]
reward:0.19027079704675898
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.6322    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.82716   0.346969]
done:False
-------------------------
[125]>>[18]: env.step(1)
action:[0, 1.82716]
reward:0.19679191811454544
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.2428    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.87946   0.354406]
done:False
-------------------------
[125]>>[19]: env.step(5)
action:[0, 1.87946]
reward:0.19942817731677312
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.7357    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.89827   0.362498]
done:False
-------------------------
[125]>>[20]: env.step(2)
action:[3.5, 1.89827]
reward:-0.5335564300026184
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.3738   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.09977  1.06681]
done:False
-------------------------
[125]>>[21]: env.step(3)
action:[3.5, 7.0997699999999995]
reward:0.35502280775444156
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      28.2832   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.50661  2.36554]
done:False
-------------------------
[125]>>[22]: env.step(2)
action:[3.5, 2.50661]
reward:0.41314370589452815
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      26.4878  49.6603   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.38705  4.08004]
done:False
-------------------------
[125]>>[23]: env.step(1)
action:[0, 4.38705]
reward:-0.24752151246406173
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 23.0741   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.06339  3.65301]
done:False
-------------------------
[125]>>[24]: env.step(4)
action:[0, 3.06339]
reward:0.45219046428879367
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       21.0089   43.8429    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.74566   0.673019]
done:False
-------------------------
[125]>>[25]: env.step(0)
action:[-3.5, 4.74566]
reward:-0.2591318155886255
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        17.8838    40.5209
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.8232    -0.0791915]
done:False
-------------------------
[125]>>[26]: env.step(2)
action:[3.5, 4.8232]
reward:-1.0131389313736148
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      14.9206  37.9105
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.75197  2.13509]
done:False
-------------------------
[125]>>[27]: env.step(3)
action:[3.5, 9.75197]
reward:0.5798930334531229
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      12.6402   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73869  4.52703]
done:False
-------------------------
[125]>>[28]: env.step(3)
action:[3.5, 9.73869]
reward:0.6505143877224469
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 47.9549   8.89416  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.69046  3.93199]
done:False
-------------------------
[125]>>[29]: env.step(2)
action:[3.5, 5.69046]
reward:-24.29258828910318
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.6469   3.60022  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.4831   3.94624]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.361, 'y': 3.94624, 'z': 0.571555}
.........................
** Rewards description :
count    29.000000
mean     -0.658687
std       4.557685
min     -24.292588
25%       0.167197
50%       0.226448
75%       0.355023
max       0.650514
dtype: float64
#########################
[126]>> env.reset()
=========================
[126]>>[1]: env.step(1)
action:[0, 8.79988]
reward:0.18550871778452002
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.1992]
done:False
-------------------------
[126]>>[2]: env.step(3)
action:[0, 5.0]
reward:0.1643084121105155
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.694723 0.223081]
done:False
-------------------------
[126]>>[3]: env.step(3)
action:[0, 5.694723]
reward:0.3222278093013118
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.44915  0.216463]
done:False
-------------------------
[126]>>[4]: env.step(3)
action:[0, 7.4491499999999995]
reward:0.4982219745963743
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.24262 0.22111]
done:False
-------------------------
[126]>>[5]: env.step(2)
action:[3.5, 4.24262]
reward:-0.2637077545110643
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.88976 1.79365]
done:False
-------------------------
[126]>>[6]: env.step(3)
action:[3.5, 9.889759999999999]
reward:0.5981401326606266
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.94727 4.25635]
done:False
-------------------------
[126]>>[7]: env.step(3)
action:[3.5, 9.94727]
reward:0.6745528414657582
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.6169   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.96621  3.65645]
done:False
-------------------------
[126]>>[8]: env.step(4)
action:[3.5, 3.9662100000000002]
reward:0.6911821682149039
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.4778   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.68991  3.737  ]
done:False
-------------------------
[126]>>[9]: env.step(4)
action:[3.5, 5.68991]
reward:0.6405687688258607
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.8677   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.56777  3.81106]
done:False
-------------------------
[126]>>[10]: env.step(2)
action:[3.5, 6.56777]
reward:0.6497251664721941
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.9839   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.47247  3.84857]
done:False
-------------------------
[126]>>[11]: env.step(3)
action:[3.5, 11.472470000000001]
reward:0.7295147272656592
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.1848   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.34516  3.87829]
done:False
-------------------------
[126]>>[12]: env.step(3)
action:[3.5, 11.34516]
reward:0.7706533453738716
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      22.3252   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.95639  3.90543]
done:False
-------------------------
[126]>>[13]: env.step(1)
action:[0, 6.95639]
reward:0.005472129924791402
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.6417  40.5602   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.83868  1.50174]
done:False
-------------------------
[126]>>[14]: env.step(3)
action:[0, 12.83868]
reward:0.8800028547280263
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       12.7589    0.       35.2358    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.17278  -0.100467]
done:False
-------------------------
[126]>>[15]: env.step(2)
action:[3.5, 8.17278]
reward:0.07968238048506837
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.53243 30.801
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.59805  3.81961]
done:False
-------------------------
[126]>>[16]: env.step(1)
action:[0, 8.59805]
reward:-24.905452365219634
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.619   27.0384   3.78996  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.70889  4.9795 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.3571, 'y': 4.9795, 'z': 0.569289}
.........................
** Rewards description :
count    16.000000
mean     -1.142462
std       6.345134
min     -24.905452
25%       0.143152
50%       0.548181
75%       0.678710
max       0.880003
dtype: float64
#########################
[127]>> env.reset()
=========================
[127]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.24994256301288487
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.73239  -0.715373]
done:False
-------------------------
[127]>>[2]: env.step(3)
action:[0, 6.7323900000000005]
reward:0.2852425876112762
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.73239  -0.359278]
done:False
-------------------------
[127]>>[3]: env.step(3)
action:[0, 6.7323900000000005]
reward:0.2750059267976549
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.60646  0.869644]
done:False
-------------------------
[127]>>[4]: env.step(3)
action:[0, 6.60646]
reward:0.3509203521391885
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.57864 1.26601]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.12138, 'y': 1.26601, 'z': 0.572771}
.........................
** Rewards description :
count    4.000000
mean     0.290278
std      0.043062
min      0.249943
25%      0.268740
50%      0.280124
75%      0.301662
max      0.350920
dtype: float64
#########################
[128]>> env.reset()
=========================
Retrying to reset environment!
Retrying to reset environment!
[128]>>[1]: env.step(5)
action:[0, 0.0]
reward:0.0004422385568277422
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00515964 0.202734  ]
done:False
-------------------------
[128]>>[2]: env.step(3)
action:[0, 5.00515964]
reward:0.20010964345246962
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.12509  0.206909]
done:False
-------------------------
[128]>>[3]: env.step(3)
action:[0, 6.12509]
reward:0.36979330347666817
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.93538  0.211111]
done:False
-------------------------
[128]>>[4]: env.step(3)
action:[0, 7.93538]
reward:0.5069197799249083
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.23402  0.223682]
done:False
-------------------------
[128]>>[5]: env.step(3)
action:[0, 9.234020000000001]
reward:0.6260463288188429
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.48558  0.243575]
done:False
-------------------------
[128]>>[6]: env.step(1)
action:[0, 5.48558]
reward:0.6043024033873334
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.1295   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.1307   0.26719]
done:False
-------------------------
[128]>>[7]: env.step(0)
action:[-3.5, 6.1307]
reward:-0.12086146926835462
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.     44.409   0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  6.3031 -1.7148]
done:False
-------------------------
[128]>>[8]: env.step(5)
action:[-3.5, 6.3031]
reward:0.6269819569632367
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 41.1736   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.23092 -4.03186]
done:False
-------------------------
[128]>>[9]: env.step(1)
action:[0, 6.23092]
reward:-0.13578466692900237
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      37.0827   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.07723 -1.23735]
done:False
-------------------------
[128]>>[10]: env.step(3)
action:[0, 11.07723]
reward:0.6988462341082153
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      33.6786   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.01789  1.46329]
done:False
-------------------------
[128]>>[11]: env.step(2)
action:[3.5, 6.01789]
reward:-0.1340783419382061
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      30.0026   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.1534   3.66025]
done:False
-------------------------
[128]>>[12]: env.step(3)
action:[3.5, 11.153400000000001]
reward:0.7055872755718959
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 25.5781  48.7545   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.09209  3.897  ]
done:False
-------------------------
[128]>>[13]: env.step(2)
action:[3.5, 6.09209]
reward:0.6592575881853744
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.8314  44.0248   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.72106  3.88042]
done:False
-------------------------
[128]>>[14]: env.step(3)
action:[3.5, 11.72106]
reward:0.7555279282435515
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.8146   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.6483   3.92499]
done:False
-------------------------
[128]>>[15]: env.step(3)
action:[3.5, 11.648299999999999]
reward:0.8373418594407083
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.537    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.84088  3.96227]
done:False
-------------------------
[128]>>[16]: env.step(3)
action:[3.5, 12.84088]
reward:-24.012594305932176
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.71241 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.81956 4.00449]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.1375, 'y': 4.00449, 'z': 0.570977}
.........................
** Rewards description :
count    16.000000
mean     -1.113260
std       6.116115
min     -24.012594
25%      -0.029884
50%       0.555611
75%       0.669155
max       0.837342
dtype: float64
#########################
[129]>> env.reset()
=========================
[129]>>[1]: env.step(3)
action:[0, 14.88562]
reward:0.6235274037417291
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.03875  0.206957]
done:False
-------------------------
[129]>>[2]: env.step(3)
action:[0, 9.03875]
reward:0.7038860839655258
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.5972   0.228433]
done:False
-------------------------
[129]>>[3]: env.step(4)
action:[0, 4.5972]
reward:0.7762495426078297
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.4068    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.72293   0.259448]
done:False
-------------------------
[129]>>[4]: env.step(3)
action:[0, 13.72293]
reward:1.0871201552970926
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.7162    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.2295    0.300485]
done:False
-------------------------
[129]>>[5]: env.step(0)
action:[-3.5, 11.2295]
reward:0.3688274903802371
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.7711    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       12.3974    0.348646]
done:False
-------------------------
[129]>>[6]: env.step(5)
action:[-3.5, 12.3974]
reward:1.167131939428236
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     24.8284 47.0426  0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 12.9651 -2.7858]
done:False
-------------------------
[129]>>[7]: env.step(3)
action:[-3.5, 17.9651]
reward:1.2335050841650579
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.9299
  0.      37.6515   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.8279  -2.91674]
done:False
-------------------------
[129]>>[8]: env.step(5)
action:[-3.5, 12.8279]
reward:1.1578011134911612
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.22627  0.       0.       0.
  0.      28.1339   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.6883  -2.98349]
done:False
-------------------------
[129]>>[9]: env.step(2)
action:[3.5, 12.6883]
reward:-0.3521102526103137
observation:
[ 0.       0.       0.       0.       0.       8.2301   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.6218  18.1121   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.5452  -2.94477]
done:False
-------------------------
[129]>>[10]: env.step(3)
action:[3.5, 17.5452]
reward:1.2065984511133032
observation:
[ 0.       0.      15.7928   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.94495  0.      44.6577   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.4125  -2.89712]
done:False
-------------------------
[129]>>[11]: env.step(3)
action:[3.5, 17.4125]
reward:-23.797822162391668
observation:
[ 0.       0.       0.       0.      20.4405   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       3.5035   0.      39.3743   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.3618  -1.80096]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.4896, 'y': -1.80096, 'z': 0.569306}
.........................
** Rewards description :
count    11.000000
mean     -1.438662
std       7.430867
min     -23.797822
25%       0.496177
50%       0.776250
75%       1.162467
max       1.233505
dtype: float64
#########################
[130]>> env.reset()
=========================
[130]>>[1]: env.step(0)
action:[-3.5, 12.3542]
reward:-24.617888407646745
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 12.3488 -1.0284]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 80.4509, 'y': -1.0284, 'z': 0.569306}
.........................
** Rewards description :
count     1.000000
mean    -24.617888
std            NaN
min     -24.617888
25%     -24.617888
50%     -24.617888
75%     -24.617888
max     -24.617888
dtype: float64
#########################
[131]>> env.reset()
=========================
[131]>>[1]: env.step(3)
action:[0, 5.932291]
reward:0.2032741074361249
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.931608 0.660733]
done:False
-------------------------
[131]>>[2]: env.step(3)
action:[0, 5.931608]
reward:0.21150298955242391
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.03149  0.428877]
done:False
-------------------------
[131]>>[3]: env.step(3)
action:[0, 6.03149]
reward:0.2909525969038805
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.97798  0.259253]
done:False
-------------------------
[131]>>[4]: env.step(3)
action:[0, 6.9779800000000005]
reward:0.3612773960036877
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.61536  0.198065]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.11438, 'y': 0.198065, 'z': 0.572049}
.........................
** Rewards description :
count    4.000000
mean     0.266752
std      0.074392
min      0.203274
25%      0.209446
50%      0.251228
75%      0.308534
max      0.361277
dtype: float64
#########################
[132]>> env.reset()
=========================
[132]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.12848549935211093
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.265774 0.377827]
done:False
-------------------------
[132]>>[2]: env.step(3)
action:[0, 5.265774]
reward:0.15488766105265
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.515191 0.605965]
done:False
-------------------------
[132]>>[3]: env.step(0)
action:[-3.5, 0.515191]
reward:-0.6469741802183628
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.08386  0.579344]
done:False
-------------------------
[132]>>[4]: env.step(2)
action:[3.5, 1.08386]
reward:-1.3849459969560018
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.08472  0.413712]
done:False
-------------------------
[132]>>[5]: env.step(3)
action:[3.5, 6.08472]
reward:0.2714835725059963
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.72511  0.677994]
done:False
-------------------------
[132]>>[6]: env.step(3)
action:[3.5, 6.72511]
reward:0.37007488766647334
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.78891 1.83097]
done:False
-------------------------
[132]>>[7]: env.step(2)
action:[3.5, 2.78891]
reward:0.3965900788687356
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.1069  3.77428]
done:False
-------------------------
[132]>>[8]: env.step(3)
action:[3.5, 9.1069]
reward:0.5863853408399557
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.98627 3.75605]
done:False
-------------------------
[132]>>[9]: env.step(3)
action:[3.5, 9.986270000000001]
reward:0.7065306837005504
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.8709   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.39694  3.73363]
done:False
-------------------------
[132]>>[10]: env.step(3)
action:[3.5, 11.39694]
reward:0.8228372339809555
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 42.5219  0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  7.6925  3.7836]
done:False
-------------------------
[132]>>[11]: env.step(1)
action:[0, 7.6925]
reward:0.08633819241499219
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.2551   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.81517  3.82613]
done:False
-------------------------
[132]>>[12]: env.step(3)
action:[0, 13.81517]
reward:0.9977664333614946
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      30.3102   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.74034  1.02938]
done:False
-------------------------
[132]>>[13]: env.step(3)
action:[0, 14.74034]
reward:1.0794312532812762
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       23.1672   45.9324    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.8452    0.251693]
done:False
-------------------------
[132]>>[14]: env.step(4)
action:[0, 8.8452]
reward:1.0522819111246073
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.7398  37.3966   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.8662   0.37676]
done:False
-------------------------
[132]>>[15]: env.step(3)
action:[0, 16.8662]
reward:1.2001741579941285
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.1034    0.       44.4594   28.2861    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       12.4605    0.480282]
done:False
-------------------------
[132]>>[16]: env.step(0)
action:[-3.5, 12.4605]
reward:0.436239953782398
observation:
[ 0.       0.       7.20002  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      36.065   19.5782   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.3009  -2.5997 ]
done:False
-------------------------
[132]>>[17]: env.step(4)
action:[-3.5, 11.3009]
reward:1.1639689780268472
observation:
[ 0.       0.      14.6541   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.0541   0.      45.8492   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1817  -2.77587]
done:False
-------------------------
[132]>>[18]: env.step(3)
action:[-3.5, 18.1817]
reward:1.2469322051124865
observation:
[ 0.      23.9179   0.       0.       0.       0.       0.       0.
  2.49189  0.       0.       0.       0.       0.       0.      17.2531
  0.       0.      36.0309   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.0403  -2.83357]
done:False
-------------------------
[132]>>[19]: env.step(5)
action:[-3.5, 13.0403]
reward:1.2050028215085113
observation:
[ 0.      34.2043   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.3922   0.       0.
  0.       0.      25.4818   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.5084  -2.79128]
done:False
-------------------------
[132]>>[20]: env.step(5)
action:[-3.5, 13.5084]
reward:1.2332775780753706
observation:
[44.3675   0.       0.       0.       0.       7.97022  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.1992   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.9376  -2.73839]
done:False
-------------------------
[132]>>[21]: env.step(5)
action:[-3.5, 13.9376]
reward:1.2327536734146745
observation:
[31.4247   0.      16.4976   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.7777   4.92381  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.82    -2.68246]
done:False
-------------------------
[132]>>[22]: env.step(3)
action:[-3.5, 18.82]
reward:-23.709533393344635
observation:
[34.175   19.0731   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.0223   0.       0.       2.40285  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.7821  -2.6676 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 116.711, 'y': -2.6676, 'z': 0.568274}
.........................
** Rewards description :
count    22.000000
mean     -0.516819
std       5.222841
min     -23.709533
25%       0.184037
50%       0.646458
75%       1.142835
max       1.246932
dtype: float64
#########################
[133]>> env.reset()
=========================
[133]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.1457048597739115
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.471598 0.199882]
done:False
-------------------------
[133]>>[2]: env.step(4)
action:[0, 0.235799]
reward:0.15831553723390307
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.81381 0.20432]
done:False
-------------------------
[133]>>[3]: env.step(5)
action:[0, 1.81381]
reward:0.2414284983434834
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.42496  0.213144]
done:False
-------------------------
[133]>>[4]: env.step(3)
action:[0, 7.4249600000000004]
reward:0.354148822525466
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.41438 0.22294]
done:False
-------------------------
[133]>>[5]: env.step(3)
action:[0, 7.4143799999999995]
reward:0.37697577747250477
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.7033   0.233054]
done:False
-------------------------
[133]>>[6]: env.step(3)
action:[0, 7.7033000000000005]
reward:0.47382820407410414
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.86371  0.246107]
done:False
-------------------------
[133]>>[7]: env.step(3)
action:[0, 8.863710000000001]
reward:0.6059588361567173
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.6427    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.30834   0.264653]
done:False
-------------------------
[133]>>[8]: env.step(2)
action:[3.5, 5.30834]
reward:-0.15587057467087595
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      44.9494   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.03909  2.15396]
done:False
-------------------------
[133]>>[9]: env.step(2)
action:[3.5, 6.03909]
reward:0.5983701645311847
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      41.3491   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.91301  4.63433]
done:False
-------------------------
[133]>>[10]: env.step(3)
action:[3.5, 10.91301]
reward:0.6876146183185793
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.1708   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.90409  3.79205]
done:False
-------------------------
[133]>>[11]: env.step(5)
action:[3.5, 5.90409]
reward:0.6076437026638113
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.7818   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.07081  3.85801]
done:False
-------------------------
[133]>>[12]: env.step(3)
action:[3.5, 11.07081]
reward:0.6989515508855288
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.2437   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.02095  3.89001]
done:False
-------------------------
[133]>>[13]: env.step(1)
action:[0, 6.02095]
reward:-0.13276046414186427
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      24.508   47.4993   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.17034  1.84801]
done:False
-------------------------
[133]>>[14]: env.step(4)
action:[0, 4.17034]
reward:0.4904463848427554
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       21.7475   44.4306    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.96157  -0.226598]
done:False
-------------------------
[133]>>[15]: env.step(5)
action:[0, 4.96157]
reward:0.49008074742508123
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       18.2198   40.9466    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.75903   0.435708]
done:False
-------------------------
[133]>>[16]: env.step(4)
action:[0, 2.379515]
reward:0.3171443905628638
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.5203    0.       38.2048    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.21487   0.424022]
done:False
-------------------------
[133]>>[17]: env.step(3)
action:[0, 8.21487]
reward:0.44949689933115267
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.1247    0.       35.7581    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.42329   0.448156]
done:False
-------------------------
[133]>>[18]: env.step(3)
action:[0, 8.42329]
reward:0.5398432345400579
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.2315   48.9304   32.7649    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.54212   0.475222]
done:False
-------------------------
[133]>>[19]: env.step(4)
action:[0, 2.27106]
reward:0.31855650690818593
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.41085   0.       45.9287   29.7593    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.2595    0.493319]
done:False
-------------------------
[133]>>[20]: env.step(0)
action:[-3.5, 3.2595]
reward:-0.4234088194201378
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.34185   0.        0.       43.5726   27.3996    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.11216   0.503379]
done:False
-------------------------
[133]>>[21]: env.step(4)
action:[-3.5, 1.55608]
reward:0.22215412056269482
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        4.76272   0.        0.        0.        0.
 42.0661   25.8096    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.25468  -0.424575]
done:False
-------------------------
[133]>>[22]: env.step(5)
action:[-3.5, 2.25468]
reward:0.23525468541370134
observation:
[ 0.       0.       0.       0.       0.       5.49836  0.       0.
  0.       0.       0.       0.      24.8749   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.23946 -1.87142]
done:False
-------------------------
[133]>>[23]: env.step(3)
action:[-3.5, 7.239459999999999]
reward:0.3805583360763687
observation:
[ 0.       0.       0.       0.       0.       6.33513  0.       0.
  0.       0.       0.       0.       0.      23.638    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.7921  -2.99111]
done:False
-------------------------
[133]>>[24]: env.step(2)
action:[3.5, 2.7921]
reward:-1.1675030550233088
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.66155
  0.       0.       0.       0.       0.       0.       0.       0.
 37.9997  21.5174   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.30246 -2.9817 ]
done:False
-------------------------
[133]>>[25]: env.step(0)
action:[-3.5, 3.30246]
reward:-1.1474581114106464
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.35057  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      35.7785  19.3619   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.42491 -1.52774]
done:False
-------------------------
[133]>>[26]: env.step(2)
action:[3.5, 3.42491]
reward:-1.1515605308213743
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        5.39711   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.6239   18.4517    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.34303   0.902144]
done:False
-------------------------
[133]>>[27]: env.step(4)
action:[3.5, 1.671515]
reward:0.24938938585504594
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  5.00839  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.1437  18.3104   0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.55775  2.991  ]
done:False
-------------------------
[133]>>[28]: env.step(3)
action:[3.5, 7.55775]
reward:0.4113669833446263
observation:
[ 0.       0.       0.       0.       5.95542  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      33.1923
  0.      17.7571   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10173  4.68938]
done:False
-------------------------
[133]>>[29]: env.step(5)
action:[3.5, 3.10173]
reward:0.3631844386143521
observation:
[ 8.41773  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      30.9035  15.838    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.60832  5.48765]
done:False
-------------------------
[133]>>[30]: env.step(2)
action:[3.5, 3.60832]
reward:0.3709137538086156
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      28.3825
 49.1187  13.2314   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      10.7535   0.       0.       3.57864  4.49906]
done:False
-------------------------
[133]>>[31]: env.step(3)
action:[3.5, 8.57864]
reward:0.4652552652490386
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      25.7888  46.4972  10.679    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      13.2991   0.       3.53453  4.06702]
done:False
-------------------------
[133]>>[32]: env.step(1)
action:[0, 3.53453]
reward:-0.37966106954330925
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      23.1141   0.       0.       8.31352  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      15.9713   3.58987  4.08536]
done:False
-------------------------
[133]>>[33]: env.step(3)
action:[0, 8.58987]
reward:0.47399601831100313
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.401   41.2042   0.       0.       6.21021  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      18.6853   3.64423  4.12386]
done:False
-------------------------
[133]>>[34]: env.step(3)
action:[0, 8.64423]
reward:0.5098835596388951
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      17.9468  38.5625
  0.       0.       0.       0.       3.75734  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 21.1444   0.       0.       0.       4.09536  2.83457]
done:False
-------------------------
[133]>>[35]: env.step(3)
action:[0, 9.09536]
reward:-24.46913659145347
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.5183   0.      37.9858   0.
  0.       0.       0.       2.942    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      21.6411
  0.       0.       0.       0.       4.2564   2.12531]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 81.6752, 'y': 2.12531, 'z': 0.570684}
.........................
** Rewards description :
count    35.000000
mean     -0.508311
std       4.198553
min     -24.469137
25%       0.152010
50%       0.363184
75%       0.482038
max       0.698952
dtype: float64
#########################
[134]>> env.reset()
=========================
[134]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.2326863205592305
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.52184  -0.379517]
done:False
-------------------------
[134]>>[2]: env.step(3)
action:[0, 6.52184]
reward:0.38322596843755763
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        3.00509   0.0704885]
done:False
-------------------------
[134]>>[3]: env.step(2)
action:[3.5, 3.00509]
reward:-0.3261472058819323
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.39847  0.214799]
done:False
-------------------------
[134]>>[4]: env.step(1)
action:[0, 4.39847]
reward:-0.2625816006504526
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.86536 0.24123]
done:False
-------------------------
[134]>>[5]: env.step(3)
action:[0, 9.865359999999999]
reward:0.6033192290090876
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.7592    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.0226    0.263953]
done:False
-------------------------
[134]>>[6]: env.step(5)
action:[0, 5.0226]
reward:0.5841516759377833
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.6394    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.97763   0.286775]
done:False
-------------------------
[134]>>[7]: env.step(5)
action:[0, 5.97763]
reward:0.6476933599642241
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.8965    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.59242   0.312008]
done:False
-------------------------
[134]>>[8]: env.step(1)
action:[0, 6.59242]
reward:0.6553557422242959
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.9751   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.54285  0.33845]
done:False
-------------------------
[134]>>[9]: env.step(1)
action:[0, 6.54285]
reward:0.6463207314832822
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.8133    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.43249   0.366355]
done:False
-------------------------
[134]>>[10]: env.step(5)
action:[0, 6.43249]
reward:0.6367631520559569
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       25.0615   47.8618    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.33063   0.392147]
done:False
-------------------------
[134]>>[11]: env.step(3)
action:[0, 11.33063]
reward:0.716966334329779
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.409    43.1685    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.2057    0.417504]
done:False
-------------------------
[134]>>[12]: env.step(3)
action:[0, 11.2057]
reward:0.7636390415175756
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.6956    0.       38.3881    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.8918    0.443122]
done:False
-------------------------
[134]>>[13]: env.step(3)
action:[0, 11.8918]
reward:0.9322047424954439
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.75597  48.432    32.2657    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.19807   0.475559]
done:False
-------------------------
[134]>>[14]: env.step(0)
action:[-3.5, 9.19807]
reward:0.1862589536095951
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.68216
  0.       0.       0.       0.      42.4557  26.0333   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.93366 -2.41706]
done:False
-------------------------
[134]>>[15]: env.step(0)
action:[-3.5, 9.93366]
reward:0.9421825193631685
observation:
[ 0.       0.       0.       0.       0.       0.       0.       7.66206
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.1409   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.84083 -2.97435]
done:False
-------------------------
[134]>>[16]: env.step(3)
action:[-3.5, 14.84083]
reward:1.0122399496345706
observation:
[ 0.       0.       0.      13.0548   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.4921  11.9447  47.7429   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.71533 -2.93944]
done:False
-------------------------
[134]>>[17]: env.step(4)
action:[-3.5, 7.71533]
reward:0.8296753403834847
observation:
[ 0.       0.      19.1913   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.52998
 21.9607   0.      40.997    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.71231 -2.88527]
done:False
-------------------------
[134]>>[18]: env.step(3)
action:[-3.5, 13.71231]
reward:0.9215329998156765
observation:
[ 0.      25.3707   0.       0.       0.       2.95253  0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.8765
  0.       0.      34.5312   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.57998 -2.8448 ]
done:False
-------------------------
[134]>>[19]: env.step(5)
action:[-3.5, 8.57998]
reward:0.8276745397653459
observation:
[ 0.      32.0026   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.0097   0.
  0.       0.      27.7251   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.46703 -2.80555]
done:False
-------------------------
[134]>>[20]: env.step(5)
action:[-3.5, 8.46703]
reward:0.818544758971847
observation:
[38.1979   0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.50964  0.       0.       0.       0.       0.
  0.       0.      21.4293   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.36273 -2.77113]
done:False
-------------------------
[134]>>[21]: env.step(0)
action:[-3.5, 8.36273]
reward:0.8029059689700289
observation:
[44.2795   0.       0.       0.       0.       7.91711  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.2878   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.163   -2.7377 ]
done:False
-------------------------
[134]>>[22]: env.step(1)
action:[0, 8.163]
reward:0.03828063043510799
observation:
[ 0.        0.        0.        0.        0.       49.0656    0.
 10.5411    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       34.3541    0.       10.8565    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.00312  -0.137866]
done:False
-------------------------
[134]>>[23]: env.step(4)
action:[0, 6.003119999999999]
reward:0.6693500632227956
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.7642   0.       0.       0.       7.39965  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.767   14.8678   6.88105  1.11831]
done:False
-------------------------
[134]>>[24]: env.step(4)
action:[0, 4.88105]
reward:0.5677507539223949
observation:
[19.3278    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       25.3144    0.        0.
  0.        0.        0.        0.        4.96631   0.        0.
  0.        0.        0.        0.        0.        0.        0.
 35.2314    5.79545   0.872227]
done:False
-------------------------
[134]>>[25]: env.step(5)
action:[0, 5.79545]
reward:0.5757274291331078
observation:
[23.5723    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       21.1219    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        5.96258   0.        0.        0.        0.
 39.508     5.67253   0.856739]
done:False
-------------------------
[134]>>[26]: env.step(3)
action:[0, 10.67253]
reward:0.657607952836904
observation:
[27.7478    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       17.0542    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        9.06223   0.        0.
 43.7083    5.55348   0.872476]
done:False
-------------------------
[134]>>[27]: env.step(1)
action:[0, 5.55348]
reward:0.5944596258980476
observation:
[31.9859    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       13.0212
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       12.8615    0.
 47.9657    5.98221   0.899871]
done:False
-------------------------
[134]>>[28]: env.step(3)
action:[0, 10.98221]
reward:0.6899937297666272
observation:
[36.4415    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       48.8507    0.        0.
  9.01197   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       17.0857
  0.        5.91954   0.929617]
done:False
-------------------------
[134]>>[29]: env.step(1)
action:[0, 5.91954]
reward:0.6950309676830759
observation:
[41.5925    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       43.687     0.        0.
  0.        0.        0.        5.37832   0.        0.        0.
  0.        0.        0.        0.        0.        0.       22.0858
  0.        7.25464   0.960085]
done:False
-------------------------
[134]>>[30]: env.step(3)
action:[0, 12.25464]
reward:0.957390605995853
observation:
[48.0444    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       37.2239    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        6.21612   0.        0.        0.        0.
 28.4273    9.49578   0.994792]
done:False
-------------------------
[134]>>[31]: env.step(4)
action:[0, 7.49578]
reward:0.946119995893737
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.6138   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.5409   0.      35.952   10.511    1.03594]
done:False
-------------------------
[134]>>[32]: env.step(5)
action:[0, 10.511]
reward:1.0158783122574913
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.5965   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.1933  43.9153  10.8563   1.07928]
done:False
-------------------------
[134]>>[33]: env.step(3)
action:[0, 15.8563]
reward:1.0910511476835305
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      13.509    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      28.1311  10.7629   1.12305]
done:False
-------------------------
[134]>>[34]: env.step(0)
action:[-3.5, 10.7629]
reward:0.29620133556376316
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.51026 44.8697   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      35.0584
  0.       0.       0.       0.      11.2866  -1.84404]
done:False
-------------------------
[134]>>[35]: env.step(4)
action:[-3.5, 9.2866]
reward:0.9716378820202399
observation:
[42.6798   0.       0.       0.       0.       0.       2.79174  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      37.3451   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.46    -2.19404]
done:False
-------------------------
[134]>>[36]: env.step(5)
action:[-3.5, 10.46]
reward:0.9808164261943316
observation:
[ 0.       9.55106  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.7212  47.8629   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.3108  -2.25094]
done:False
-------------------------
[134]>>[37]: env.step(5)
action:[-3.5, 10.3108]
reward:0.9678058124268303
observation:
[17.0545   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.2762   0.      40.2228   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.144   -2.21738]
done:False
-------------------------
[134]>>[38]: env.step(5)
action:[-3.5, 10.144]
reward:0.9577742838373334
observation:
[24.5574   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.1149
  0.       0.      32.6761   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.0294  -2.17418]
done:False
-------------------------
[134]>>[39]: env.step(1)
action:[0, 10.0294]
reward:0.1931053924648618
observation:
[ 0.        0.        0.        0.       31.3185    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        7.57905
  0.        0.       26.239     0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.83111   0.914987]
done:False
-------------------------
[134]>>[40]: env.step(3)
action:[0, 14.83111]
reward:-23.977266562211053
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       3.77044
  0.       0.       0.      22.9923   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.9881   9.8869   2.20897]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 36}
{'x': 219.01, 'y': 2.20897, 'z': 0.568878}
.........................
** Rewards description :
count    40.000000
mean      0.036083
std       3.908666
min     -23.977267
25%       0.573733
50%       0.679672
75%       0.934699
max       1.091051
dtype: float64
#########################
[135]>> env.reset()
=========================
[135]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.2367520657931362
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.57138  -0.619743]
done:False
-------------------------
[135]>>[2]: env.step(3)
action:[0, 6.5713799999999996]
reward:0.26887067350522337
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.57137  -0.232496]
done:False
-------------------------
[135]>>[3]: env.step(3)
action:[0, 6.57137]
reward:0.2549862100919269
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.40123  0.893515]
done:False
-------------------------
[135]>>[4]: env.step(3)
action:[0, 6.40123]
reward:0.3685197668710623
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.85036 0.95091]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.08933, 'y': 0.95091, 'z': 0.572978}
.........................
** Rewards description :
count    4.000000
mean     0.282282
std      0.058977
min      0.236752
25%      0.250428
50%      0.261928
75%      0.293783
max      0.368520
dtype: float64
#########################
[136]>> env.reset()
=========================
Retrying to reset environment!
[136]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.21105505232408056
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.25896 0.20038]
done:False
-------------------------
[136]>>[2]: env.step(3)
action:[0, 6.25896]
reward:0.3812419877348991
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.04583  0.209946]
done:False
-------------------------
[136]>>[3]: env.step(3)
action:[0, 8.04583]
reward:0.5132032525697048
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.28818  0.224833]
done:False
-------------------------
[136]>>[4]: env.step(3)
action:[0, 9.28818]
reward:0.6487444225758181
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.77905 0.2452 ]
done:False
-------------------------
[136]>>[5]: env.step(1)
action:[0, 5.77905]
reward:0.6352986076676184
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.5335    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.47419   0.270344]
done:False
-------------------------
[136]>>[6]: env.step(5)
action:[0, 6.47419]
reward:0.6420787499638738
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      42.7201   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.39215  0.2964 ]
done:False
-------------------------
[136]>>[7]: env.step(5)
action:[0, 6.39215]
reward:0.6329638654977404
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.9832    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.28937   0.322064]
done:False
-------------------------
[136]>>[8]: env.step(5)
action:[0, 6.28937]
reward:0.619548293911945
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.3633    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.13427   0.347131]
done:False
-------------------------
[136]>>[9]: env.step(5)
action:[0, 6.13427]
reward:0.6087971672182506
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       28.5267    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.02872   0.373389]
done:False
-------------------------
[136]>>[10]: env.step(5)
action:[0, 6.02872]
reward:0.5922101440038008
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.1474   46.941     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.8334    0.397235]
done:False
-------------------------
[136]>>[11]: env.step(1)
action:[0, 5.8334]
reward:0.5813170851372773
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.8545   42.6078    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.73725   0.420653]
done:False
-------------------------
[136]>>[12]: env.step(3)
action:[0, 10.73725]
reward:0.6637861979949504
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.6637    0.       38.3557    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.62152   0.443641]
done:False
-------------------------
[136]>>[13]: env.step(1)
action:[0, 5.62152]
reward:0.6354915166722258
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.3473    0.       33.9259    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.51618   0.467317]
done:False
-------------------------
[136]>>[14]: env.step(3)
action:[0, 11.51618]
reward:0.8913434147807513
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  6.01255   0.        0.       44.3633   28.1915    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.67293   0.497702]
done:False
-------------------------
[136]>>[15]: env.step(0)
action:[-3.5, 8.67293]
reward:0.14257295451518082
observation:
[ 0.       0.       0.       5.83233  0.       0.       0.       0.
  0.       0.       0.       0.      22.2789   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.40218 -2.21073]
done:False
-------------------------
[136]>>[16]: env.step(4)
action:[-3.5, 7.4021799999999995]
reward:0.7848482132284949
observation:
[ 0.       0.       0.       0.       0.       0.       9.39484  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.4945   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.14427 -3.01855]
done:False
-------------------------
[136]>>[17]: env.step(0)
action:[-3.5, 8.14427]
reward:0.7902591026937349
observation:
[ 0.       0.       0.      14.2957   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.5639   0.      46.3276   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.03611 -2.92828]
done:False
-------------------------
[136]>>[18]: env.step(5)
action:[-3.5, 8.03611]
reward:0.7809058254579304
observation:
[ 0.       0.      19.7976   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       4.96505
 21.3451   0.      40.3536   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.92953 -2.88111]
done:False
-------------------------
[136]>>[19]: env.step(3)
action:[-3.5, 12.92953]
reward:0.8586867818674525
observation:
[ 0.      25.8226   0.       0.       0.       3.22049  0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.4477
  0.       0.      34.0637   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.83395 -2.8392 ]
done:False
-------------------------
[136]>>[20]: env.step(5)
action:[-3.5, 7.83395]
reward:0.834246726442443
observation:
[ 0.      31.8514   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.1294   0.
  0.       0.      27.8792   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.74928 -2.80628]
done:False
-------------------------
[136]>>[21]: env.step(3)
action:[-3.5, 13.74928]
reward:1.0216908661940094
observation:
[38.8794   0.       0.       0.       0.       0.       0.       0.
  0.       6.39349  0.       0.       0.       0.       0.       0.
  0.       0.      20.7393   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.1405  -2.76802]
done:False
-------------------------
[136]>>[22]: env.step(0)
action:[-3.5, 10.1405]
reward:1.0057697457854866
observation:
[46.6951   0.       0.       0.       9.57702  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.8588   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.7867  -2.7253 ]
done:False
-------------------------
[136]>>[23]: env.step(1)
action:[0, 10.7867]
reward:0.2613019457269259
observation:
[ 0.        0.        0.       30.3485    0.       14.6058    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       30.0545    0.        0.        7.26874   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.7138    0.380452]
done:False
-------------------------
[136]>>[24]: env.step(2)
action:[3.5, 10.7138]
reward:0.2526548769331163
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       22.605     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.15151   0.        0.        0.        0.        0.       37.9694
 22.0581   10.5936    0.766648]
done:False
-------------------------
[136]>>[25]: env.step(5)
action:[3.5, 10.5936]
reward:0.9917711477084017
observation:
[29.8611    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       15.0295    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       10.921     0.
 45.8332   10.4505    0.898724]
done:False
-------------------------
[136]>>[26]: env.step(1)
action:[0, 10.4505]
reward:0.2257494826730133
observation:
[37.5514    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       47.7373    0.        0.
  8.0932    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       18.1581
  0.       10.2335    0.943888]
done:False
-------------------------
[136]>>[27]: env.step(1)
action:[0, 10.2335]
reward:0.9587443657610402
observation:
[45.094     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       40.1788    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  4.88364   0.        0.        0.        0.        0.       25.5208
  0.       10.0221    0.981373]
done:False
-------------------------
[136]>>[28]: env.step(1)
action:[0, 10.0221]
reward:0.9477521152267929
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.715    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       9.74355  0.      32.8806   9.90462  1.02016]
done:False
-------------------------
[136]>>[29]: env.step(0)
action:[-3.5, 9.90462]
reward:0.18253609559661987
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      26.0145   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      39.3244
  0.       0.       0.       0.       9.69994 -2.00367]
done:False
-------------------------
[136]>>[30]: env.step(4)
action:[-3.5, 7.69994]
reward:0.8882237378286979
observation:
[ 0.      46.1443   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.2514   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.58026 -2.39134]
done:False
-------------------------
[136]>>[31]: env.step(2)
action:[3.5, 9.58026]
reward:-0.5872286790085761
observation:
[ 0.       0.       0.       0.       0.      28.1199   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.535    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.47989  1.12026]
done:False
-------------------------
[136]>>[32]: env.step(4)
action:[3.5, 7.479889999999999]
reward:0.8100304810929551
observation:
[ 0.      32.5781   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      48.6886   0.       0.
 12.0639   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.48639  6.56124]
done:False
-------------------------
[136]>>[33]: env.step(2)
action:[3.5, 8.48639]
reward:0.8075361208017229
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      42.9115   0.
  0.       0.       0.       6.82088  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      37.7351
  0.       0.       0.       0.       8.19878  5.26031]
done:False
-------------------------
[136]>>[34]: env.step(2)
action:[3.5, 8.19878]
reward:0.795557073254268
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      37.038    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       4.82504  0.       0.
  0.       0.       0.      43.3573   8.0984   4.83753]
done:False
-------------------------
[136]>>[35]: env.step(4)
action:[3.5, 6.0984]
reward:0.6851620337755229
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      31.5253   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.23465  0.       0.      48.7652   7.07401  4.77642]
done:False
-------------------------
[136]>>[36]: env.step(3)
action:[3.5, 12.074010000000001]
reward:0.7861507699305106
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.27    45.8323   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.938    0.       0.       6.99492  4.77687]
done:False
-------------------------
[136]>>[37]: env.step(4)
action:[3.5, 4.99492]
reward:0.7283122718333893
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.699   40.3786   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.2647   0.       7.94775  4.79707]
done:False
-------------------------
[136]>>[38]: env.step(3)
action:[3.5, 12.94775]
reward:0.9559573422894078
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.1608  34.0243   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.6658   0.       9.30025  4.82831]
done:False
-------------------------
[136]>>[39]: env.step(5)
action:[3.5, 9.30025]
reward:0.9560652686124298
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.32705 26.5013   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      32.4554  10.2138   4.86961]
done:False
-------------------------
[136]>>[40]: env.step(3)
action:[3.5, 15.2138]
reward:-23.94006254890077
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       3.81115 24.0866   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      35.0188  10.4008   4.88332]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 36}
{'x': 218.751, 'y': 4.88332, 'z': 0.570693}
.........................
** Rewards description :
count    40.000000
mean      0.029557
std       3.899908
min     -23.940063
25%       0.564289
50%       0.674474
75%       0.840357
max       1.021691
dtype: float64
#########################
[137]>> env.reset()
=========================
[137]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.39210492358072147
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.49749  0.206397]
done:False
-------------------------
[137]>>[2]: env.step(1)
action:[0, 3.49749]
reward:0.3951513238913848
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.91158  0.221855]
done:False
-------------------------
[137]>>[3]: env.step(3)
action:[0, 8.91158]
reward:0.5040846011012354
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.95312  0.237558]
done:False
-------------------------
[137]>>[4]: env.step(3)
action:[0, 8.95312]
reward:0.6199399842352423
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.4736   0.256454]
done:False
-------------------------
[137]>>[5]: env.step(3)
action:[0, 10.473600000000001]
reward:0.7517681047236595
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.4588    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.90714   0.281441]
done:False
-------------------------
[137]>>[6]: env.step(4)
action:[0, 4.90714]
reward:0.5664909500013672
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.7728    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.77226   0.307105]
done:False
-------------------------
[137]>>[7]: env.step(3)
action:[0, 10.77226]
reward:0.6685055261387741
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.5043    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.67722   0.330236]
done:False
-------------------------
[137]>>[8]: env.step(5)
action:[0, 5.67722]
reward:0.6270628186896059
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.989     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.38848   0.354513]
done:False
-------------------------
[137]>>[9]: env.step(5)
action:[0, 6.38848]
reward:0.63560840284913
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.9227   49.7353    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.32602   0.382018]
done:False
-------------------------
[137]>>[10]: env.step(4)
action:[0, 4.32602]
reward:0.5028321054188947
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.9015   45.685     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.08324   0.404222]
done:False
-------------------------
[137]>>[11]: env.step(4)
action:[0, 3.08324]
reward:0.3808479384000609
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.7929   42.5455    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.8348    0.421507]
done:False
-------------------------
[137]>>[12]: env.step(4)
action:[0, 1.9174]
reward:0.34982605019364343
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.0017    0.       39.7167    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.73723   0.436802]
done:False
-------------------------
[137]>>[13]: env.step(3)
action:[0, 8.73723]
reward:0.4781205248329736
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       14.2841    0.       36.9476    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.66057   0.451773]
done:False
-------------------------
[137]>>[14]: env.step(0)
action:[-3.5, 3.66057]
reward:-0.3601766490896211
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       12.3259    0.
 34.5587    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.80356  -0.828942]
done:False
-------------------------
[137]>>[15]: env.step(3)
action:[-3.5, 8.803560000000001]
reward:0.4810790546136022
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      11.7802   0.      49.4138  33.0147   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.68217 -3.00821]
done:False
-------------------------
[137]>>[16]: env.step(4)
action:[-3.5, 1.841085]
reward:0.25137250907688213
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     10.2753  0.      0.     30.9821  0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  2.5396 -3.141 ]
done:False
-------------------------
[137]>>[17]: env.step(5)
action:[-3.5, 2.5396]
reward:0.2512505432432255
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.94649  0.       0.
  0.      29.1836   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.36348 -3.04398]
done:False
-------------------------
[137]>>[18]: env.step(3)
action:[-3.5, 7.36348]
reward:0.3709328667829822
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.81134  0.       0.       0.
  0.      27.3836   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.64009 -3.00284]
done:False
-------------------------
[137]>>[19]: env.step(3)
action:[-3.5, 7.64009]
reward:0.5174167846416853
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.66274  0.       0.       0.       0.       0.
  0.      24.4939   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44453 -2.98087]
done:False
-------------------------
[137]>>[20]: env.step(0)
action:[-3.5, 4.44453]
reward:0.5342079228809737
observation:
[ 0.       0.       0.       0.       0.       0.       6.95411  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.6928   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.46291 -2.96084]
done:False
-------------------------
[137]>>[21]: env.step(0)
action:[-3.5, 5.46291]
reward:0.615534116326611
observation:
[ 0.       0.       0.       0.       9.4176   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.8878  16.3653   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.28694 -2.93722]
done:False
-------------------------
[137]>>[22]: env.step(4)
action:[-3.5, 4.28694]
reward:0.5093638592941591
observation:
[ 0.       0.       0.      12.7641   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.2556   0.      48.0664   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.17792 -2.9141 ]
done:False
-------------------------
[137]>>[23]: env.step(4)
action:[-3.5, 3.1779200000000003]
reward:0.39688865128686424
observation:
[ 0.       0.      15.652    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.0939   0.      44.8125   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.01342 -2.89608]
done:False
-------------------------
[137]>>[24]: env.step(3)
action:[-3.5, 9.01342]
reward:0.5032655626377662
observation:
[ 0.       0.      18.3891   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.298
 22.7761   0.      41.8493   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.91702 -2.88005]
done:False
-------------------------
[137]>>[25]: env.step(2)
action:[3.5, 3.91702]
reward:-26.071944924106724
observation:
[ 0.       0.       0.       0.      20.0662   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       4.1973  20.666    0.      39.8782   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.22397 -2.15927]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.3538, 'y': -2.15927, 'z': 0.569582}
.........................
** Rewards description :
count    25.000000
mean     -0.605139
std       5.309764
min     -26.071945
25%       0.380848
50%       0.502832
75%       0.566491
max       0.751768
dtype: float64
#########################
[138]>> env.reset()
=========================
[138]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.24077013988535562
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.62038 1.19181]
done:False
-------------------------
[138]>>[2]: env.step(0)
action:[-3.5, 1.62038]
reward:-0.6351884391448088
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.947704 1.80679 ]
done:False
-------------------------
[138]>>[3]: env.step(3)
action:[-3.5, 5.947704]
reward:0.23060338147171094
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.25955 2.49862]
done:False
-------------------------
[138]>>[4]: env.step(3)
action:[-3.5, 6.25955]
reward:0.29533911834546395
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.97508 3.39905]
done:False
-------------------------
[138]>>[5]: env.step(3)
action:[-3.5, 6.97508]
reward:0.45072621829600434
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.74898 4.45808]
done:False
-------------------------
[138]>>[6]: env.step(4)
action:[-3.5, 1.87449]
reward:0.25768480864305665
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.60848 4.181  ]
done:False
-------------------------
[138]>>[7]: env.step(3)
action:[-3.5, 7.60848]
reward:0.3964232724831537
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.8999  2.92762]
done:False
-------------------------
[138]>>[8]: env.step(3)
action:[-3.5, 7.899900000000001]
reward:0.5299057162598818
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.54273 0.30371]
done:False
-------------------------
[138]>>[9]: env.step(0)
action:[-3.5, 4.54273]
reward:0.5203027225276607
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.25652 -3.61604]
done:False
-------------------------
[138]>>[10]: env.step(0)
action:[-3.5, 5.25652]
reward:0.5343908900101767
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.26231 -5.60412]
done:False
-------------------------
[138]>>[11]: env.step(5)
action:[-3.5, 5.26231]
reward:0.5252638695675673
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      47.9842   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.14142 -4.02448]
done:False
-------------------------
[138]>>[12]: env.step(3)
action:[-3.5, 10.14142]
reward:0.6001411741300198
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 44.4989   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.91109 -3.1919 ]
done:False
-------------------------
[138]>>[13]: env.step(0)
action:[-3.5, 4.91109]
reward:0.4875595068496243
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 40.9651   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.73903 -3.22492]
done:False
-------------------------
[138]>>[14]: env.step(3)
action:[-3.5, 9.73903]
reward:0.5721879208679055
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 37.5008   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.63971 -3.18693]
done:False
-------------------------
[138]>>[15]: env.step(3)
action:[-3.5, 9.639710000000001]
reward:0.6632435009309625
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.6703   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.8885  -3.15465]
done:False
-------------------------
[138]>>[16]: env.step(3)
action:[-3.5, 10.8885]
reward:0.8085295765343522
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.6857   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.61258 -3.12567]
done:False
-------------------------
[138]>>[17]: env.step(3)
action:[-3.5, 12.612580000000001]
reward:0.9343820871383327
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 22.5357  44.6162   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.05124 -3.09132]
done:False
-------------------------
[138]>>[18]: env.step(3)
action:[-3.5, 14.05124]
reward:1.034907885692975
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.6837
  0.      37.3233   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2796  -3.05187]
done:False
-------------------------
[138]>>[19]: env.step(5)
action:[-3.5, 10.2796]
reward:1.0205012965139653
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.65452  0.       0.
  0.      28.7795   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9887  -3.00561]
done:False
-------------------------
[138]>>[20]: env.step(5)
action:[-3.5, 10.9887]
reward:1.02657997966734
observation:
[ 0.       0.       0.       0.       0.       0.       6.98517  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.6045   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9098  -2.96118]
done:False
-------------------------
[138]>>[21]: env.step(0)
action:[-3.5, 10.9098]
reward:1.0170640870488088
observation:
[ 0.      0.      0.     12.4772  0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.     12.5836  0.
 48.4012  0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 10.7757 -2.9173]
done:False
-------------------------
[138]>>[22]: env.step(4)
action:[-3.5, 8.7757]
reward:0.9156148609325365
observation:
[ 0.      19.2855   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.43536
 21.8603   0.      40.8946   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.72416 -2.87648]
done:False
-------------------------
[138]>>[23]: env.step(0)
action:[-3.5, 9.72416]
reward:0.9233731003354434
observation:
[ 0.      26.2156   0.       0.       3.48894  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.0786
  0.       0.      33.6581   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.60505 -2.83737]
done:False
-------------------------
[138]>>[24]: env.step(5)
action:[-3.5, 9.60505]
reward:0.9107128315793582
observation:
[ 0.      33.161    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.12632  0.       0.
  0.       0.      26.5442   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.44251 -2.79889]
done:False
-------------------------
[138]>>[25]: env.step(2)
action:[3.5, 9.44251]
reward:-0.599423640896978
observation:
[40.0818   0.       0.       0.       0.       0.       0.       0.
  6.36825  0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.523    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.33008 -2.76089]
done:False
-------------------------
[138]>>[26]: env.step(0)
action:[-3.5, 9.33008]
reward:-0.6152216865682387
observation:
[46.8862   0.       0.       0.       9.72226  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      12.6669   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.1212  -2.72369]
done:False
-------------------------
[138]>>[27]: env.step(1)
action:[0, 9.1212]
reward:0.12391330294191738
observation:
[30.3579   0.      15.5153   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.847    5.95888  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.01151 -2.68699]
done:False
-------------------------
[138]>>[28]: env.step(3)
action:[0, 14.01151]
reward:-24.047858185379937
observation:
[32.5972   0.      17.5891   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.6027   0.       3.80877  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.97516 -2.67486]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 115.369, 'y': -2.67486, 'z': 0.57001}
.........................
** Rewards description :
count    28.000000
mean     -0.388485
std       4.661034
min     -24.047858
25%       0.253456
50%       0.527585
75%       0.911938
max       1.034908
dtype: float64
#########################
[139]>> env.reset()
=========================
[139]>>[1]: env.step(2)
action:[3.5, 8.96791]
reward:-0.5014952782295526
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.72284 0.21304]
done:False
-------------------------
[139]>>[2]: env.step(3)
action:[3.5, 5.72284]
reward:0.34264199702474485
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.69618  0.759064]
done:False
-------------------------
[139]>>[3]: env.step(2)
action:[3.5, 2.69618]
reward:0.3977785015070858
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.1451  2.92533]
done:False
-------------------------
[139]>>[4]: env.step(3)
action:[3.5, 9.1451]
reward:0.6183658596684665
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.40444 4.20987]
done:False
-------------------------
[139]>>[5]: env.step(4)
action:[3.5, 3.40444]
reward:0.4182119365889947
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.22693 3.82767]
done:False
-------------------------
[139]>>[6]: env.step(3)
action:[3.5, 9.22693]
reward:0.5191608922394507
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.2667   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.07057  3.78916]
done:False
-------------------------
[139]>>[7]: env.step(2)
action:[3.5, 4.07057]
reward:0.41005335306891766
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      45.2632   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.95687  3.77942]
done:False
-------------------------
[139]>>[8]: env.step(0)
action:[-3.5, 3.95687]
reward:-1.101442790949997
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      42.3462   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.83977  3.7926 ]
done:False
-------------------------
[139]>>[9]: env.step(2)
action:[3.5, 3.83977]
reward:-1.1209700561023053
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.4008   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.62279  3.8142 ]
done:False
-------------------------
[139]>>[10]: env.step(5)
action:[3.5, 3.62279]
reward:0.35837200051545437
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.8003   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.41777  3.82958]
done:False
-------------------------
[139]>>[11]: env.step(2)
action:[3.5, 3.41777]
reward:0.3382084152513181
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.3497   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.21717  3.84215]
done:False
-------------------------
[139]>>[12]: env.step(2)
action:[3.5, 3.21717]
reward:0.318387032204977
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.0487   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.02087  3.85413]
done:False
-------------------------
[139]>>[13]: env.step(2)
action:[3.5, 3.02087]
reward:0.3067090799098623
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.824    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.92526  3.86623]
done:False
-------------------------
[139]>>[14]: env.step(1)
action:[0, 2.92526]
reward:-0.4527955653212177
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.6703   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.83168  3.87801]
done:False
-------------------------
[139]>>[15]: env.step(4)
action:[0, 1.41584]
reward:0.19778010877274962
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      26.263
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99424  3.06676]
done:False
-------------------------
[139]>>[16]: env.step(3)
action:[0, 6.99424]
reward:0.3430508197488591
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      25.3737  48.3801   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.38343  1.82399]
done:False
-------------------------
[139]>>[17]: env.step(5)
action:[0, 2.38343]
reward:0.40501453738640025
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       23.7971
 46.5846    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.31482   0.201608]
done:False
-------------------------
[139]>>[18]: env.step(4)
action:[0, 2.15741]
reward:0.30010184607135826
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.2441   44.0009    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.05943   0.341763]
done:False
-------------------------
[139]>>[19]: env.step(3)
action:[0, 8.059429999999999]
reward:0.43865295183892306
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       18.8131   41.5493    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.3235    0.407929]
done:False
-------------------------
[139]>>[20]: env.step(4)
action:[0, 1.66175]
reward:0.25434830659835633
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 16.6871   0.      39.3961   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.62083  0.43377]
done:False
-------------------------
[139]>>[21]: env.step(3)
action:[0, 7.62083]
reward:0.4107526156936106
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       14.6716    0.       37.3442    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.07817   0.452482]
done:False
-------------------------
[139]>>[22]: env.step(3)
action:[0, 8.07817]
reward:0.5605047987610319
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.6856    0.       34.2768    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.90039   0.467912]
done:False
-------------------------
[139]>>[23]: env.step(3)
action:[0, 9.90039]
reward:0.7064852082971722
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.59836   0.       46.1327   29.9634    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.41778   0.489682]
done:False
-------------------------
[139]>>[24]: env.step(1)
action:[0, 6.41778]
reward:0.7132388493593602
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        3.45001   0.        0.
  0.        0.        0.       40.8472   24.67      0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.38211   0.517413]
done:False
-------------------------
[139]>>[25]: env.step(0)
action:[-3.5, 7.38211]
reward:-0.018429176222903076
observation:
[ 6.17361  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.0447   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.39649 -1.8774 ]
done:False
-------------------------
[139]>>[26]: env.step(5)
action:[-3.5, 7.39649]
reward:0.7337507234547898
observation:
[ 0.       0.       0.       0.       0.      10.517    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      15.49     0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.42339 -3.53631]
done:False
-------------------------
[139]>>[27]: env.step(3)
action:[-3.5, 12.423390000000001]
reward:0.8003768522656776
observation:
[ 0.       0.      14.6336   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.252    0.      45.9846   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.11146 -3.01505]
done:False
-------------------------
[139]>>[28]: env.step(3)
action:[-3.5, 12.111460000000001]
reward:0.8096779953011044
observation:
[ 0.      19.5209   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.23857
 21.6401   0.      40.6543   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.32341 -2.91079]
done:False
-------------------------
[139]>>[29]: env.step(3)
action:[-3.5, 12.323409999999999]
reward:0.9801567095532899
observation:
[ 0.      26.2179   0.       0.       3.49673  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.0837
  0.       0.      33.6582   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.83456 -2.84935]
done:False
-------------------------
[139]>>[30]: env.step(5)
action:[-3.5, 9.83456]
reward:0.9822407039730761
observation:
[ 0.      33.7381   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.71539  0.       0.
  0.       0.      25.957    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4896  -2.79845]
done:False
-------------------------
[139]>>[31]: env.step(0)
action:[-3.5, 10.4896]
reward:0.986261861470977
observation:
[41.4459   0.       0.       0.       0.       0.       0.       6.6176
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.145    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.3893  -2.75406]
done:False
-------------------------
[139]>>[32]: env.step(5)
action:[-3.5, 10.3893]
reward:0.9776082573390568
observation:
[49.1093   0.       0.      11.515    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.4392   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.278   -2.71191]
done:False
-------------------------
[139]>>[33]: env.step(4)
action:[-3.5, 8.278]
reward:0.8860762642573727
observation:
[33.0213   0.      17.9863   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.1779   0.       3.41579  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.40362 -2.67267]
done:False
-------------------------
[139]>>[34]: env.step(5)
action:[-3.5, 9.40362]
reward:-24.09628578370088
observation:
[33.9573  18.8675   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.2403   0.       0.       2.58463  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.3871  -2.66762]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 116.713, 'y': -2.66762, 'z': 0.570339}
.........................
** Rewards description :
count    34.000000
mean     -0.346396
std       4.227683
min     -24.096286
25%       0.301754
50%       0.407534
75%       0.711550
max       0.986262
dtype: float64
#########################
[140]>> env.reset()
=========================
[140]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7498312335165017
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00196897 0.199259  ]
done:False
-------------------------
[140]>>[2]: env.step(3)
action:[3.5, 5.00196897]
reward:0.16327271149279582
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.681788 0.214611]
done:False
-------------------------
[140]>>[3]: env.step(3)
action:[3.5, 5.681788]
reward:0.3252144729046085
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.48948  0.744595]
done:False
-------------------------
[140]>>[4]: env.step(3)
action:[3.5, 7.48948]
reward:0.458573498941863
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.72099 2.68103]
done:False
-------------------------
[140]>>[5]: env.step(5)
action:[3.5, 3.72099]
reward:0.451181183608827
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.56833 4.10357]
done:False
-------------------------
[140]>>[6]: env.step(5)
action:[3.5, 4.56833]
reward:0.4403791348563634
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.21832 3.79221]
done:False
-------------------------
[140]>>[7]: env.step(3)
action:[3.5, 9.21832]
reward:0.5236462044445575
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.171    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.13128  3.77953]
done:False
-------------------------
[140]>>[8]: env.step(2)
action:[3.5, 4.13128]
reward:0.4185968877551825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      46.1078   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.05011  3.78077]
done:False
-------------------------
[140]>>[9]: env.step(3)
action:[3.5, 9.05011]
reward:0.5075497946897154
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      42.9072   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.96353  3.7922 ]
done:False
-------------------------
[140]>>[10]: env.step(1)
action:[0, 3.96353]
reward:-0.34250809352842415
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      40.4659   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.95117  2.39989]
done:False
-------------------------
[140]>>[11]: env.step(0)
action:[-3.5, 3.95117]
reward:-0.36780779951127984
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.7037    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.63474  -0.337027]
done:False
-------------------------
[140]>>[12]: env.step(0)
action:[-3.5, 3.63474]
reward:0.3579875937348661
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.5466   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.40997 -2.90437]
done:False
-------------------------
[140]>>[13]: env.step(3)
action:[-3.5, 8.40997]
reward:0.4702099352633087
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      38.0276   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.64044 -4.5683 ]
done:False
-------------------------
[140]>>[14]: env.step(1)
action:[0, 3.64044]
reward:-0.3253919875367952
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.25     0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24924 -4.45313]
done:False
-------------------------
[140]>>[15]: env.step(5)
action:[0, 4.24924]
reward:0.4285666747229594
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      32.7644   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.14743 -2.17864]
done:False
-------------------------
[140]>>[16]: env.step(4)
action:[0, 2.073715]
reward:0.37286511935404854
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       31.1964    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.9868    0.505751]
done:False
-------------------------
[140]>>[17]: env.step(4)
action:[0, 1.9934]
reward:0.26985531480816527
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.0262   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.72795  1.13581]
done:False
-------------------------
[140]>>[18]: env.step(1)
action:[0, 2.72795]
reward:0.2593691231685314
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       27.2209    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.41574   0.595619]
done:False
-------------------------
[140]>>[19]: env.step(3)
action:[0, 7.4157399999999996]
reward:0.34783559000194586
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       25.3768   48.1881    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.33778   0.413905]
done:False
-------------------------
[140]>>[20]: env.step(5)
action:[0, 2.33778]
reward:0.2370231857616028
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       23.6909    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.24024   0.400092]
done:False
-------------------------
[140]>>[21]: env.step(5)
action:[0, 2.24024]
reward:0.22402730968222273
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.0999   44.8762    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.10641   0.406727]
done:False
-------------------------
[140]>>[22]: env.step(3)
action:[0, 7.10641]
reward:0.35522903671719575
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.4633   43.2229    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.50753   0.415195]
done:False
-------------------------
[140]>>[23]: env.step(3)
action:[0, 7.50753]
reward:0.5046885615797293
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       17.8723   40.6       0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.31198   0.430159]
done:False
-------------------------
[140]>>[24]: env.step(1)
action:[0, 4.31198]
reward:0.5017031793613387
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       14.3133    0.       36.9774    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.07209   0.450569]
done:False
-------------------------
[140]>>[25]: env.step(3)
action:[0, 10.07209]
reward:0.6060525671075833
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       10.6455   49.3616   33.1965    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.0075    0.471504]
done:False
-------------------------
[140]>>[26]: env.step(0)
action:[-3.5, 5.0075]
reward:-0.24670518279492193
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.15756   0.       45.6504   29.4804    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.91888   0.491774]
done:False
-------------------------
[140]>>[27]: env.step(0)
action:[-3.5, 4.91888]
reward:0.5153348104307283
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  5.69312  0.       0.       0.      42.6476  26.3251   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.09769 -1.16149]
done:False
-------------------------
[140]>>[28]: env.step(4)
action:[-3.5, 3.09769]
reward:0.3861702125748711
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.75437
  0.       0.       0.       0.       0.       0.      24.3463   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.89822 -3.28123]
done:False
-------------------------
[140]>>[29]: env.step(2)
action:[3.5, 3.89822]
reward:-1.1164171265775602
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.42226  0.       0.       0.       0.       0.       0.
  0.       0.      38.0183  21.5489   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.66549 -2.67029]
done:False
-------------------------
[140]>>[30]: env.step(3)
action:[3.5, 8.66549]
reward:0.4812628076265213
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        5.27368   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       19.8172    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.71906  -0.492141]
done:False
-------------------------
[140]>>[31]: env.step(0)
action:[-3.5, 3.71906]
reward:-1.0050954997256318
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.93479  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.2749  19.4012   0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.13213  2.71913]
done:False
-------------------------
[140]>>[32]: env.step(3)
action:[-3.5, 10.13213]
reward:0.7423226045280354
observation:
[ 6.89368  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      32.6928   0.      17.6837
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.85964  6.03698]
done:False
-------------------------
[140]>>[33]: env.step(1)
action:[0, 6.85964]
reward:-0.0020168057848903853
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      27.5854  48.3575
 12.5553   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      11.5704
  0.       0.       0.       0.       7.75733  4.75676]
done:False
-------------------------
[140]>>[34]: env.step(4)
action:[0, 5.75733]
reward:0.722410943499209
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       25.1096    8.75208
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       14.7187    0.        0.
  0.        7.67482  -0.244247]
done:False
-------------------------
[140]>>[35]: env.step(0)
action:[-3.5, 7.67482]
reward:-24.99948356299651
observation:
[ 0.        0.        0.       19.9185    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       19.9594    3.47636
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.5892   -0.465391]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.479, 'y': -0.465391, 'z': 0.568903}
.........................
** Rewards description :
count    35.000000
mean     -0.516684
std       4.284289
min     -24.999484
25%       0.080628
50%       0.357988
75%       0.475736
max       0.742323
dtype: float64
#########################
[141]>> env.reset()
=========================
[141]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.21842783318777848
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.34843 1.13529]
done:False
-------------------------
[141]>>[2]: env.step(3)
action:[0, 6.3484300000000005]
reward:0.3273460232262898
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.34931 1.67231]
done:False
-------------------------
[141]>>[3]: env.step(3)
action:[0, 7.34931]
reward:0.5004038247887244
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.29589 1.77275]
done:False
-------------------------
[141]>>[4]: env.step(3)
action:[0, 9.29589]
reward:0.6389704677206814
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        5.64464   0.0355882]
done:False
-------------------------
[141]>>[5]: env.step(2)
action:[3.5, 5.64464]
reward:-0.14224003619317038
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.13723  0.171599]
done:False
-------------------------
[141]>>[6]: env.step(3)
action:[3.5, 11.137229999999999]
reward:0.7299104749111499
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      46.2026
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.4345   2.44074]
done:False
-------------------------
[141]>>[7]: env.step(3)
action:[3.5, 11.4345]
reward:0.8652394703416917
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.7685   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.30454  4.84465]
done:False
-------------------------
[141]>>[8]: env.step(3)
action:[3.5, 13.30454]
reward:0.9831759052184958
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.0661   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.63685  3.80694]
done:False
-------------------------
[141]>>[9]: env.step(3)
action:[3.5, 14.63685]
reward:1.0321339604359476
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.1353   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.088    3.86492]
done:False
-------------------------
[141]>>[10]: env.step(3)
action:[3.5, 15.088]
reward:1.0794618170055643
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.362    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.7588   3.91297]
done:False
-------------------------
[141]>>[11]: env.step(5)
action:[3.5, 10.7588]
reward:1.0561467348123497
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.9926   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.4517   3.96341]
done:False
-------------------------
[141]>>[12]: env.step(0)
action:[-3.5, 11.4517]
reward:-25.43683356999045
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.58248  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.395    4.0056 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.1903, 'y': 4.0056, 'z': 0.569526}
.........................
** Rewards description :
count    12.000000
mean     -1.512321
std       7.543901
min     -25.436834
25%       0.300116
50%       0.684440
75%       0.995415
max       1.079462
dtype: float64
#########################
[142]>> env.reset()
=========================
[142]>>[1]: env.step(4)
action:[0, 0.0]
reward:0.00010709647273315123
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00124947 0.20004   ]
done:False
-------------------------
[142]>>[2]: env.step(2)
action:[3.5, 0.00124947]
reward:-0.7281603224307786
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.254951 0.206734]
done:False
-------------------------
[142]>>[3]: env.step(3)
action:[3.5, 5.254951]
reward:0.17532756250966663
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.763522 0.322382]
done:False
-------------------------
[142]>>[4]: env.step(3)
action:[3.5, 5.763522]
reward:0.29714656888448665
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.1214   0.866038]
done:False
-------------------------
[142]>>[5]: env.step(3)
action:[3.5, 7.1213999999999995]
reward:0.43614140219586545
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.52595 2.61408]
done:False
-------------------------
[142]>>[6]: env.step(3)
action:[3.5, 8.52595]
reward:0.5879331231798071
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.15211 4.15988]
done:False
-------------------------
[142]>>[7]: env.step(3)
action:[3.5, 10.15211]
reward:0.7017516524504805
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.28933 3.74366]
done:False
-------------------------
[142]>>[8]: env.step(4)
action:[3.5, 4.28933]
reward:0.50818757951745
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      47.0886   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.16202  3.79141]
done:False
-------------------------
[142]>>[9]: env.step(4)
action:[3.5, 3.16202]
reward:0.47248231461537926
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.0643   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.98169  3.81036]
done:False
-------------------------
[142]>>[10]: env.step(5)
action:[3.5, 4.98169]
reward:0.5008025201784139
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      39.3663   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.89297  3.81855]
done:False
-------------------------
[142]>>[11]: env.step(5)
action:[3.5, 4.89297]
reward:0.4922103202713358
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.7352   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.80375  3.83369]
done:False
-------------------------
[142]>>[12]: env.step(5)
action:[3.5, 4.80375]
reward:0.4837670605956707
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.1698   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.71684  3.85235]
done:False
-------------------------
[142]>>[13]: env.step(5)
action:[3.5, 4.71684]
reward:0.4685237415150496
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      28.7321   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.54202  3.87138]
done:False
-------------------------
[142]>>[14]: env.step(5)
action:[3.5, 4.54202]
reward:0.4516821493042751
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.4235   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.36949  3.88964]
done:False
-------------------------
[142]>>[15]: env.step(5)
action:[3.5, 4.36949]
reward:0.4418114942573431
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      22.1824   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.28633  3.90726]
done:False
-------------------------
[142]>>[16]: env.step(5)
action:[3.5, 4.28633]
reward:0.4337231298295417
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.0036   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.20387  3.92443]
done:False
-------------------------
[142]>>[17]: env.step(1)
action:[0, 4.20387]
reward:-0.31181151339085417
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      16.3557  39.433    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.28146  2.51755]
done:False
-------------------------
[142]>>[18]: env.step(2)
action:[3.5, 4.28146]
reward:-0.30871892609878415
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      14.6977  37.3587   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.30156  0.21378]
done:False
-------------------------
[142]>>[19]: env.step(1)
action:[0, 4.30156]
reward:-0.3451937884728632
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.6298    0.       34.2076    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.83265   0.446793]
done:False
-------------------------
[142]>>[20]: env.step(3)
action:[0, 8.832650000000001]
reward:0.48535452088006714
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.92104 47.5515  31.3841   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.73013  0.4958 ]
done:False
-------------------------
[142]>>[21]: env.step(0)
action:[-3.5, 3.73013]
reward:-0.3661386507999274
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        7.39148   0.        0.       45.3243
 29.0464    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.71102  -0.807566]
done:False
-------------------------
[142]>>[22]: env.step(1)
action:[0, 3.71102]
reward:-0.37637267354094406
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.09049  0.       0.       0.
  0.      26.6753   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.58705 -1.38485]
done:False
-------------------------
[142]>>[23]: env.step(3)
action:[0, 8.58705]
reward:0.46129281283755086
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         3.89827    0.         0.         0.
  0.         0.        40.6894    24.4491     0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  3.48151    0.0438325]
done:False
-------------------------
[142]>>[24]: env.step(2)
action:[3.5, 3.48151]
reward:-25.3381717109539
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       2.5396   0.
  0.       0.       0.       0.       0.       0.      39.4151  23.2939
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.12664  1.1336 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 59.8402, 'y': 1.1336, 'z': 0.570981}
.........................
** Rewards description :
count    24.000000
mean     -0.849013
std       5.231393
min     -25.338172
25%      -0.309492
50%       0.438976
75%       0.484164
max       0.701752
dtype: float64
#########################
[143]>> env.reset()
=========================
Retrying to reset environment!
Retrying to reset environment!
[143]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.19128096278720466
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.01965  -0.733714]
done:False
-------------------------
[143]>>[2]: env.step(3)
action:[0, 6.01965]
reward:0.35696000968072233
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.80088  -0.533188]
done:False
-------------------------
[143]>>[3]: env.step(4)
action:[0, 1.40044]
reward:0.33421893852611945
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.67181  0.153499]
done:False
-------------------------
[143]>>[4]: env.step(3)
action:[0, 8.67181]
reward:0.5103250056635837
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.09421  0.230573]
done:False
-------------------------
[143]>>[5]: env.step(3)
action:[0, 9.09421]
reward:0.5277576920847091
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.21605  0.249099]
done:False
-------------------------
[143]>>[6]: env.step(3)
action:[0, 9.21605]
reward:0.584787202875011
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.5069   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.93772  0.27126]
done:False
-------------------------
[143]>>[7]: env.step(5)
action:[0, 4.93772]
reward:0.6121214185791227
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.1671    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.37243   0.294931]
done:False
-------------------------
[143]>>[8]: env.step(5)
action:[0, 6.37243]
reward:0.6908979906134449
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.0589    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.08444   0.321864]
done:False
-------------------------
[143]>>[9]: env.step(5)
action:[0, 7.08444]
reward:0.6975142291341183
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.445     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.99769   0.352062]
done:False
-------------------------
[143]>>[10]: env.step(3)
action:[0, 11.99769]
reward:0.7754541529567403
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.2818    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.86149   0.379986]
done:False
-------------------------
[143]>>[11]: env.step(1)
action:[0, 6.86149]
reward:0.7125963065221017
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.1343   44.911     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.26226   0.407825]
done:False
-------------------------
[143]>>[12]: env.step(3)
action:[0, 12.262260000000001]
reward:0.9636222264795835
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.7342    0.       38.4275    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.59084   0.442188]
done:False
-------------------------
[143]>>[13]: env.step(3)
action:[0, 14.59084]
reward:1.0533299314015314
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.37717   0.       46.9721   30.8039    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.4471    0.483116]
done:False
-------------------------
[143]>>[14]: env.step(0)
action:[-3.5, 10.4471]
reward:0.263872495609798
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        3.01925   0.        0.        0.        0.        0.
  0.        0.        0.       39.0078   22.8275    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.84      0.526087]
done:False
-------------------------
[143]>>[15]: env.step(5)
action:[-3.5, 10.84]
reward:1.0342081146938416
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      15.6514   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.62191 11.071   -2.43207]
done:False
-------------------------
[143]>>[16]: env.step(5)
action:[-3.5, 11.071]
reward:1.0308948126624324
observation:
[ 0.       0.       0.      16.624    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       8.01317  0.      43.7148   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9593  -2.80834]
done:False
-------------------------
[143]>>[17]: env.step(2)
action:[3.5, 10.9593]
reward:-25.473071655582835
observation:
[ 0.       0.       0.       0.      20.9117   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.27912  0.      19.7123  38.953    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9228  -2.07043]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.953, 'y': -2.07043, 'z': 0.575003}
.........................
** Rewards description :
count    17.000000
mean     -0.890190
std       6.340595
min     -25.473072
25%       0.356960
50%       0.612121
75%       0.775454
max       1.053330
dtype: float64
#########################
[144]>> env.reset()
=========================
[144]>>[1]: env.step(3)
action:[0, 15.773]
reward:1.074297284271214
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       9.8664  31.2482   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       9.51708  0.
  0.       0.      29.7813   0.      10.5007   6.52452]
done:False
-------------------------
[144]>>[2]: env.step(2)
action:[3.5, 10.5007]
reward:-24.759220969102554
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       3.91669 25.165    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.8655   0.      35.1632   0.      10.458    3.83333]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 94.949, 'y': 3.83333, 'z': 0.57504}
.........................
** Rewards description :
count     2.000000
mean    -11.842462
std      18.267056
min     -24.759221
25%     -18.300841
50%     -11.842462
75%      -5.384082
max       1.074297
dtype: float64
#########################
[145]>> env.reset()
=========================
[145]>>[1]: env.step(0)
action:[-3.5, 10.4718]
reward:-24.758200470031326
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4814   3.72768]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 95.9889, 'y': 3.72768, 'z': 0.57583}
.........................
** Rewards description :
count     1.0000
mean    -24.7582
std          NaN
min     -24.7582
25%     -24.7582
50%     -24.7582
75%     -24.7582
max     -24.7582
dtype: float64
#########################
[146]>> env.reset()
=========================
[146]>>[1]: env.step(3)
action:[0, 6.38533]
reward:0.25539399852673106
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.45273 1.12526]
done:False
-------------------------
[146]>>[2]: env.step(3)
action:[0, 6.45273]
reward:0.4423256063011105
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.77209 1.3386 ]
done:False
-------------------------
[146]>>[3]: env.step(3)
action:[0, 8.77209]
reward:0.6005584768090544
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.259    0.142134]
done:False
-------------------------
[146]>>[4]: env.step(3)
action:[0, 10.259]
reward:0.7167062014705606
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.46999  0.181176]
done:False
-------------------------
[146]>>[5]: env.step(3)
action:[0, 11.46999]
reward:0.7626078569317061
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.0621    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.81113   0.253073]
done:False
-------------------------
[146]>>[6]: env.step(5)
action:[0, 6.81113]
reward:0.7358192227882083
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      40.5573   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.59869  0.29915]
done:False
-------------------------
[146]>>[7]: env.step(5)
action:[0, 7.59869]
reward:0.7500575989976659
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.8634    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.60177   0.336033]
done:False
-------------------------
[146]>>[8]: env.step(5)
action:[0, 7.60177]
reward:0.7432162607255763
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.2284    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.50478   0.368415]
done:False
-------------------------
[146]>>[9]: env.step(2)
action:[3.5, 7.50478]
reward:-0.015848984708135117
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.0914
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.40192  2.98458]
done:False
-------------------------
[146]>>[10]: env.step(2)
action:[3.5, 7.40192]
reward:0.7331281047313833
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      19.2166   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.41332  4.4416 ]
done:False
-------------------------
[146]>>[11]: env.step(5)
action:[3.5, 7.41332]
reward:0.712684712443655
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      13.9192   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.12553  4.05565]
done:False
-------------------------
[146]>>[12]: env.step(3)
action:[3.5, 12.125530000000001]
reward:0.7854907416573438
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.65553 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.97261 4.01157]
done:False
-------------------------
[146]>>[13]: env.step(3)
action:[3.5, 11.97261]
reward:-24.20861880571035
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.13843 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.09509 4.01594]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.8443, 'y': 4.01594, 'z': 0.568928}
.........................
** Rewards description :
count    13.000000
mean     -1.306652
std       6.885357
min     -24.208619
25%       0.442326
50%       0.716706
75%       0.743216
max       0.785491
dtype: float64
#########################
[147]>> env.reset()
=========================
[147]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.11191525456214635
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0683317 0.152621 ]
done:False
-------------------------
[147]>>[2]: env.step(4)
action:[0, 0.03416585]
reward:0.05039825624892025
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.58195  0.128082]
done:False
-------------------------
[147]>>[3]: env.step(1)
action:[0, 0.58195]
reward:0.09982902945159289
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.02921  0.160054]
done:False
-------------------------
[147]>>[4]: env.step(3)
action:[0, 6.02921]
reward:0.2718396529694618
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.74336  0.190885]
done:False
-------------------------
[147]>>[5]: env.step(3)
action:[0, 6.74336]
reward:0.4324876470944301
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.57386  0.215171]
done:False
-------------------------
[147]>>[6]: env.step(3)
action:[0, 8.57386]
reward:0.5616506455083508
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.7916  0.23632]
done:False
-------------------------
[147]>>[7]: env.step(4)
action:[0, 2.3958]
reward:0.3119706831857353
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.14667  0.252688]
done:False
-------------------------
[147]>>[8]: env.step(3)
action:[0, 8.14667]
reward:0.440105517832819
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.6321    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.32024   0.265452]
done:False
-------------------------
[147]>>[9]: env.step(4)
action:[0, 1.66012]
reward:0.2412315944468078
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.3947    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.46098   0.277574]
done:False
-------------------------
[147]>>[10]: env.step(0)
action:[-3.5, 2.46098]
reward:-0.484189264815114
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 44.8326    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.56143  -0.639343]
done:False
-------------------------
[147]>>[11]: env.step(3)
action:[-3.5, 7.56143]
reward:0.3801135647068567
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      43.9086   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.70601 -2.26596]
done:False
-------------------------
[147]>>[12]: env.step(0)
action:[-3.5, 2.70601]
reward:0.3394681064185503
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      42.1789   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.41081 -3.38601]
done:False
-------------------------
[147]>>[13]: env.step(4)
action:[-3.5, 1.705405]
reward:0.23834175670347563
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 40.2546   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.41441 -3.27858]
done:False
-------------------------
[147]>>[14]: env.step(1)
action:[0, 2.41441]
reward:-0.5055982271381677
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.5141   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.3111  -3.21035]
done:False
-------------------------
[147]>>[15]: env.step(1)
action:[0, 2.3111]
reward:0.251848790069509
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      36.8669   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.42792 -2.37708]
done:False
-------------------------
[147]>>[16]: env.step(2)
action:[3.5, 2.42792]
reward:-0.503234397038825
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       35.7113    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.33659  -0.877509]
done:False
-------------------------
[147]>>[17]: env.step(4)
action:[3.5, 1.168295]
reward:0.20116029853564804
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.1382    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09702   0.751194]
done:False
-------------------------
[147]>>[18]: env.step(4)
action:[3.5, 1.04851]
reward:0.16899578488336278
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.815    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.73894  2.10964]
done:False
-------------------------
[147]>>[19]: env.step(4)
action:[3.5, 0.86947]
reward:0.15004216367470008
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.5369   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.55618  3.37288]
done:False
-------------------------
[147]>>[20]: env.step(4)
action:[3.5, 0.77809]
reward:0.1399890324658222
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.9157   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.45868  4.19563]
done:False
-------------------------
[147]>>[21]: env.step(0)
action:[-3.5, 1.45868]
reward:-1.325897573404381
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      33.0348   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.69784  4.80205]
done:False
-------------------------
[147]>>[22]: env.step(2)
action:[3.5, 1.69784]
reward:-1.3073846027183276
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      31.809    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.86131  5.05575]
done:False
-------------------------
[147]>>[23]: env.step(2)
action:[3.5, 1.86131]
reward:0.2055380863210401
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.422    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.97677  4.79461]
done:False
-------------------------
[147]>>[24]: env.step(2)
action:[3.5, 1.97677]
reward:0.20039828843162844
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 29.0781   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.88568  4.14967]
done:False
-------------------------
[147]>>[25]: env.step(0)
action:[-3.5, 1.88568]
reward:-1.2977626313570734
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      27.6746   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.93071  3.91754]
done:False
-------------------------
[147]>>[26]: env.step(0)
action:[-3.5, 1.93071]
reward:0.2019257041122542
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      26.2473  49.4208   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.91568  3.8725 ]
done:False
-------------------------
[147]>>[27]: env.step(1)
action:[0, 1.91568]
reward:-0.5492564840292687
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      24.8198  47.9974   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.90513  3.88045]
done:False
-------------------------
[147]>>[28]: env.step(4)
action:[0, 0.952565]
reward:0.1567630909257462
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      23.7855
 46.9281   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.61599  3.31488]
done:False
-------------------------
[147]>>[29]: env.step(5)
action:[0, 1.61599]
reward:0.17049316533050046
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      22.9756  46.0391   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.61508  2.36049]
done:False
-------------------------
[147]>>[30]: env.step(0)
action:[-3.5, 1.61508]
reward:-0.5688919632400652
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      22.5725  45.5045   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.74313  1.17715]
done:False
-------------------------
[147]>>[31]: env.step(3)
action:[-3.5, 6.74313]
reward:0.3238690173686449
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.       22.4033   45.1331    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.20743  -0.190377]
done:False
-------------------------
[147]>>[32]: env.step(5)
action:[-3.5, 2.20743]
reward:0.287711992081338
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
 22.4486  44.8061   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.89405 -2.14106]
done:False
-------------------------
[147]>>[33]: env.step(4)
action:[-3.5, 1.447025]
reward:0.2099833891272352
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      22.0079   0.      44.015    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.13421 -3.57918]
done:False
-------------------------
[147]>>[34]: env.step(5)
action:[-3.5, 2.13421]
reward:0.21958894776956836
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.057    0.      42.8093   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.07898 -4.21581]
done:False
-------------------------
[147]>>[35]: env.step(3)
action:[-3.5, 7.07898]
reward:0.3521859548602332
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      19.6622   0.
 41.2683   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.47633 -4.22502]
done:False
-------------------------
[147]>>[36]: env.step(1)
action:[0, 2.47633]
reward:-0.4319080021393543
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.5382   0.      39.2556   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.20242 -3.22685]
done:False
-------------------------
[147]>>[37]: env.step(0)
action:[-3.5, 3.20242]
reward:-0.43807331131235877
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.4907
  0.      37.1259   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.94447 -3.0021 ]
done:False
-------------------------
[147]>>[38]: env.step(3)
action:[-3.5, 7.94447]
reward:0.4176866034897727
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.5656
  0.      34.9646   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.08525 -3.05428]
done:False
-------------------------
[147]>>[39]: env.step(1)
action:[0, 3.08525]
reward:-0.37304350685216114
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      10.8778   0.      48.8325  32.489    0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.78534 -1.72762]
done:False
-------------------------
[147]>>[40]: env.step(0)
action:[-3.5, 3.78534]
reward:-0.3676964094478364
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        8.49824
 47.0229   30.8331    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.6776    0.457623]
done:False
-------------------------
[147]>>[41]: env.step(1)
action:[0, 3.6776]
reward:-0.3885729463840446
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.05156   0.       44.4338   28.2672    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.44233   0.592498]
done:False
-------------------------
[147]>>[42]: env.step(5)
action:[0, 3.44233]
reward:0.34025663242146365
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        4.12222
  0.        0.        0.       41.9813   25.8063    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.23656   0.508228]
done:False
-------------------------
[147]>>[43]: env.step(2)
action:[3.5, 3.23656]
reward:-25.405560271996666
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       2.43551  0.
  0.       0.       0.       0.      40.0894  24.0037   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.34018  1.37472]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 59.1989, 'y': 1.37472, 'z': 0.569158}
.........................
** Rewards description :
count    43.000000
mean     -0.615565
std       3.899895
min     -25.405560
25%      -0.410240
50%       0.170493
75%       0.279776
max       0.561651
dtype: float64
#########################
[148]>> env.reset()
=========================
Retrying to reset environment!
[148]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.11332037078073956
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0850509 0.141402 ]
done:False
-------------------------
[148]>>[2]: env.step(3)
action:[0, 5.0850509]
reward:0.20483177311130646
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.16228   0.0866672]
done:False
-------------------------
[148]>>[3]: env.step(3)
action:[0, 6.16228]
reward:0.3907062106147962
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.18927  0.173713]
done:False
-------------------------
[148]>>[4]: env.step(3)
action:[0, 8.18927]
reward:0.552263624957617
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.76393  0.225583]
done:False
-------------------------
[148]>>[5]: env.step(2)
action:[3.5, 4.76393]
reward:-0.2125157716144085
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.42601 1.97529]
done:False
-------------------------
[148]>>[6]: env.step(0)
action:[-3.5, 5.42601]
reward:-0.952840016081672
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.305    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.38757  3.77633]
done:False
-------------------------
[148]>>[7]: env.step(0)
action:[-3.5, 5.38757]
reward:0.5396992250090948
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      46.1654   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.29916  1.62723]
done:False
-------------------------
[148]>>[8]: env.step(3)
action:[-3.5, 10.29916]
reward:0.6044858507427868
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.5961   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.92976 -2.11821]
done:False
-------------------------
[148]>>[9]: env.step(4)
action:[-3.5, 2.46488]
reward:0.3243792107913761
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      44.3153   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.28333 -4.4636 ]
done:False
-------------------------
[148]>>[10]: env.step(0)
action:[-3.5, 3.28333]
reward:0.33637519671815697
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 42.134    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.22794 -4.69014]
done:False
-------------------------
[148]>>[11]: env.step(4)
action:[-3.5, 1.61397]
reward:0.22189019604285218
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.3734   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.237   -3.71909]
done:False
-------------------------
[148]>>[12]: env.step(3)
action:[-3.5, 7.237]
reward:0.3278980447338614
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.7804   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.13403 -3.23217]
done:False
-------------------------
[148]>>[13]: env.step(4)
action:[-3.5, 1.067015]
reward:0.1701520111205687
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      37.4171   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.74822 -3.13954]
done:False
-------------------------
[148]>>[14]: env.step(2)
action:[3.5, 1.74822]
reward:-1.2878684656482349
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      36.1637   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.08496 -2.40357]
done:False
-------------------------
[148]>>[15]: env.step(3)
action:[3.5, 7.084960000000001]
reward:0.3191984775130374
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      35.1831   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06399 -1.12015]
done:False
-------------------------
[148]>>[16]: env.step(1)
action:[0, 2.06399]
reward:-0.5416318100301791
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        34.2511     0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.96039    0.0872731]
done:False
-------------------------
[148]>>[17]: env.step(2)
action:[3.5, 1.96039]
reward:-0.5370083961097062
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       32.8423
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.04235   0.557955]
done:False
-------------------------
[148]>>[18]: env.step(3)
action:[3.5, 7.04235]
reward:0.3078347319534951
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.3802    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.93382   0.453988]
done:False
-------------------------
[148]>>[19]: env.step(3)
action:[3.5, 6.93382]
reward:0.35440426126205615
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      29.8824   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.54036  1.33687]
done:False
-------------------------
[148]>>[20]: env.step(2)
action:[3.5, 2.54036]
reward:0.3115605893158663
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      28.5597
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10545  3.21327]
done:False
-------------------------
[148]>>[21]: env.step(2)
action:[3.5, 3.10545]
reward:0.3338641112712111
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.4573  49.6324   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.24114  4.07379]
done:False
-------------------------
[148]>>[22]: env.step(1)
action:[0, 3.24114]
reward:-0.4206346577278247
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.2581   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.15124  3.34052]
done:False
-------------------------
[148]>>[23]: env.step(3)
action:[0, 8.15124]
reward:0.4284174815929302
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      22.8781  45.8381   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.17003  1.47486]
done:False
-------------------------
[148]>>[24]: env.step(3)
action:[0, 8.17003]
reward:0.5739572056385218
observation:
[0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 2.05575e+01 4.32718e+01 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00
 5.05541e+00 3.22054e-02]
done:False
-------------------------
[148]>>[25]: env.step(5)
action:[0, 5.05541]
reward:0.5669337401502934
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       16.5457   39.2505    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.74105   0.440867]
done:False
-------------------------
[148]>>[26]: env.step(4)
action:[0, 3.7410500000000004]
reward:0.5348451182228082
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.3841   34.9926    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.64713   0.443057]
done:False
-------------------------
[148]>>[27]: env.step(4)
action:[0, 3.6471299999999998]
reward:0.5256766330763555
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.38051   0.       46.971    30.8015    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.55061   0.466737]
done:False
-------------------------
[148]>>[28]: env.step(0)
action:[-3.5, 5.55061]
reward:-0.1750250355834646
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.39463  0.       0.       0.      43.579   27.2487   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.72376 -1.30635]
done:False
-------------------------
[148]>>[29]: env.step(4)
action:[-3.5, 3.7237600000000004]
reward:0.44331197128120003
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.11945  0.       0.       0.       0.       0.       0.      24.6448
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.46694 -3.55174]
done:False
-------------------------
[148]>>[30]: env.step(4)
action:[-3.5, 2.23347]
reward:0.29864436387670373
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.7078   0.       0.       0.       0.       0.       0.       0.
  0.      22.1587   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.02241 -3.05766]
done:False
-------------------------
[148]>>[31]: env.step(4)
action:[-3.5, 1.511205]
reward:0.2743274894384497
observation:
[ 0.       0.       0.       0.       0.       0.       7.27326  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      19.9581   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.90342 -2.97569]
done:False
-------------------------
[148]>>[32]: env.step(0)
action:[-3.5, 2.90342]
reward:0.2950569560635459
observation:
[ 0.       0.       0.       0.       0.       8.40544  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      17.8366   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.81063 -2.94274]
done:False
-------------------------
[148]>>[33]: env.step(4)
action:[-3.5, 1.405315]
reward:0.2570775942204726
observation:
[ 0.       0.       0.       0.       9.84126  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.3173  15.791    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.71834 -2.92591]
done:False
-------------------------
[148]>>[34]: env.step(3)
action:[-3.5, 7.7183399999999995]
reward:0.40207427927091866
observation:
[ 0.       0.       0.      11.468    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.7641   0.      49.6035   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.94388 -2.91959]
done:False
-------------------------
[148]>>[35]: env.step(3)
action:[-3.5, 7.94388]
reward:0.5411335282837615
observation:
[ 0.       0.      13.9616   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.9168   0.      46.6953   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.67891 -2.90706]
done:False
-------------------------
[148]>>[36]: env.step(3)
action:[-3.5, 9.67891]
reward:0.6865595390162933
observation:
[ 0.       0.      17.7464   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.93583
 23.4391   0.      42.5383   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.1981  -2.88504]
done:False
-------------------------
[148]>>[37]: env.step(3)
action:[-3.5, 11.1981]
reward:0.8423990951631973
observation:
[ 0.      22.7913   0.       0.       0.       0.       0.       0.
  0.       0.       0.       2.75551  0.       0.       0.      18.3623
  0.       0.      37.2084   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.0274  -2.85639]
done:False
-------------------------
[148]>>[38]: env.step(5)
action:[-3.5, 8.0274]
reward:0.8527649813133605
observation:
[ 0.      29.1297   5.97373  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      12.4233   0.
  0.       0.      30.6623   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.97223 -2.82107]
done:False
-------------------------
[148]>>[39]: env.step(5)
action:[-3.5, 8.97223]
reward:0.8634882974035394
observation:
[ 0.      36.1345   0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.264    0.       0.       0.       0.
  0.       0.      23.5212   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.8942  -2.78241]
done:False
-------------------------
[148]>>[40]: env.step(5)
action:[-3.5, 8.8942]
reward:0.8550772211648123
observation:
[42.6691   0.       0.       0.       0.       0.       7.06615  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.9106   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.78957 -2.74661]
done:False
-------------------------
[148]>>[41]: env.step(1)
action:[0, 8.78957]
reward:0.09088441188424545
observation:
[ 0.         0.         0.         0.        24.7201    47.8374
  0.         9.33469    0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.        35.5854
 12.0676     0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  8.60736    0.0519022]
done:False
-------------------------
[148]>>[42]: env.step(1)
action:[0, 8.60736]
reward:0.8320098920181582
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      29.8482   0.       0.       7.4298   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.6701  14.7843   8.52331  1.04431]
done:False
-------------------------
[148]>>[43]: env.step(5)
action:[0, 8.52331]
reward:0.8225370126839069
observation:
[21.019     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       23.6418    0.        0.
  0.        0.        0.        0.        0.        0.        5.0082
  0.        0.        0.        0.        0.        0.        0.
 36.9446    8.40655   0.912273]
done:False
-------------------------
[148]>>[44]: env.step(1)
action:[0, 8.40655]
reward:0.812864695657167
observation:
[27.2305    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       17.5591    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        8.64623   0.        0.
 43.1919    8.29566   0.902217]
done:False
-------------------------
[148]>>[45]: env.step(1)
action:[0, 8.29566]
reward:0.7967857129190696
observation:
[33.3108    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       11.7974
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       14.1066    0.
 49.2967    8.09181   0.921588]
done:False
-------------------------
[148]>>[46]: env.step(1)
action:[0, 8.09181]
reward:0.7863642081013607
observation:
[39.3196    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       45.9648    0.        0.
  0.        6.74119   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       19.8704
  0.        7.99352   0.950155]
done:False
-------------------------
[148]>>[47]: env.step(3)
action:[0, 12.99352]
reward:0.8654323597519531
observation:
[45.2608    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       40.0118    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  4.9199    0.        0.        0.        0.        0.       25.6844
  0.        7.91764   0.981133]
done:False
-------------------------
[148]>>[48]: env.step(3)
action:[0, 12.917639999999999]
reward:0.9279483249225835
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.7381   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.86518  0.       0.      31.8687   8.8765   1.01442]
done:False
-------------------------
[148]>>[49]: env.step(0)
action:[-3.5, 8.8765]
reward:0.1621536602430531
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      27.3631   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      37.9735
  0.       0.       0.       0.       9.64647 -2.02435]
done:False
-------------------------
[148]>>[50]: env.step(4)
action:[-3.5, 7.646470000000001]
reward:0.822362683494225
observation:
[20.2442  44.2473   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.1345   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.62323 -2.38395]
done:False
-------------------------
[148]>>[51]: env.step(3)
action:[-3.5, 13.62323]
reward:0.9151531489234896
observation:
[26.6313   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.8016   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.50527 -2.38086]
done:False
-------------------------
[148]>>[52]: env.step(3)
action:[-3.5, 13.50527]
reward:0.9641624494214854
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.35061 46.7049   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      33.2453   9.28851 -2.35198]
done:False
-------------------------
[148]>>[53]: env.step(0)
action:[-3.5, 9.28851]
reward:0.9446992556504343
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       2.57023  0.       0.       0.       0.       0.
  0.      39.464    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.5503  10.0409  -2.31117]
done:False
-------------------------
[148]>>[54]: env.step(0)
action:[-3.5, 10.0409]
reward:0.9517044178314791
observation:
[ 0.       7.27742  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.0617   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      48.0519   9.96104 -2.26818]
done:False
-------------------------
[148]>>[55]: env.step(4)
action:[-3.5, 7.961040000000001]
reward:0.9107390861760241
observation:
[14.4807   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.7987   0.      42.8257   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.85391 -2.22723]
done:False
-------------------------
[148]>>[56]: env.step(3)
action:[-3.5, 14.85391]
reward:1.0165978032994927
observation:
[21.7567   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.7441   0.      35.4879   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.78216 -2.18733]
done:False
-------------------------
[148]>>[57]: env.step(1)
action:[0, 9.78216]
reward:0.21742436854180358
observation:
[ 0.       0.       0.       0.      28.1851   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.597    0.       0.      29.2885
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2702   0.72314]
done:False
-------------------------
[148]>>[58]: env.step(3)
action:[0, 15.2702]
reward:1.0482878292926296
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.77017  0.       0.       0.
  0.       0.      22.3342   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.4304   0.      10.1941   1.4029 ]
done:False
-------------------------
[148]>>[59]: env.step(1)
action:[0, 10.1941]
reward:0.9603358602074985
observation:
[ 0.       0.       5.63818  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      14.6576   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      43.4932  10.0567   1.4308 ]
done:False
-------------------------
[148]>>[60]: env.step(4)
action:[0, 8.0567]
reward:0.9181344225576735
observation:
[ 0.      12.8298   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       8.23548  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.94218  1.47666]
done:False
-------------------------
[148]>>[61]: env.step(3)
action:[0, 14.94218]
reward:1.0209547688111682
observation:
[20.1579   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.72247  0.       0.       0.
  0.       0.       0.       0.       9.83038  1.51351]
done:False
-------------------------
[148]>>[62]: env.step(1)
action:[0, 9.83038]
reward:0.9632558876411448
observation:
[27.5803   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.4092   0.       0.       0.      10.1931   1.55207]
done:False
-------------------------
[148]>>[63]: env.step(3)
action:[0, 15.1931]
reward:1.04892091295296
observation:
[35.2059   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.361    0.      10.2238   1.59273]
done:False
-------------------------
[148]>>[64]: env.step(2)
action:[3.5, 10.2238]
reward:0.2943219071662577
observation:
[43.3056   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.1824   0.      11.3905   1.63606]
done:False
-------------------------
[148]>>[65]: env.step(3)
action:[3.5, 16.3905]
reward:1.2019981591739957
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.1063  12.6139   1.68475]
done:False
-------------------------
[148]>>[66]: env.step(3)
action:[3.5, 17.6139]
reward:1.2755690579838532
observation:
[ 0.      43.5849   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.7682   4.96988]
done:False
-------------------------
[148]>>[67]: env.step(4)
action:[3.5, 11.7682]
reward:1.1762781816454382
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.2898   5.16189]
done:False
-------------------------
[148]>>[68]: env.step(3)
action:[3.5, 18.2898]
reward:1.2533528784853745
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1425   5.32213]
done:False
-------------------------
[148]>>[69]: env.step(4)
action:[3.5, 11.1425]
reward:1.1258639535912311
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.542    5.39195]
done:False
-------------------------
[148]>>[70]: env.step(3)
action:[3.5, 17.542]
reward:1.2081425427917618
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.4427   5.44499]
done:False
-------------------------
[148]>>[71]: env.step(3)
action:[3.5, 17.442700000000002]
reward:1.2330881494314756
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.9503   5.49652]
done:False
-------------------------
[148]>>[72]: env.step(3)
action:[3.5, 17.9503]
reward:1.284869801908673
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 13.8801  5.5508]
done:False
-------------------------
[148]>>[73]: env.step(0)
action:[-3.5, 13.8801]
reward:-0.2406799353325184
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.3661   1.63947]
done:False
-------------------------
[148]>>[74]: env.step(4)
action:[-3.5, 12.3661]
reward:1.2169438905259473
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.9053  -3.49755]
done:False
-------------------------
[148]>>[75]: env.step(4)
action:[-3.5, 11.9053]
reward:1.2035400576212432
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.7644  -1.15624]
done:False
-------------------------
[148]>>[76]: env.step(0)
action:[-3.5, 13.7644]
reward:1.2199429757038962
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.6136  -1.22805]
done:False
-------------------------
[148]>>[77]: env.step(1)
action:[0, 13.6136]
reward:0.46020216395173286
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.4641   2.01136]
done:False
-------------------------
[148]>>[78]: env.step(4)
action:[0, 11.4641]
reward:1.1532665545726273
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.9476   2.22221]
done:False
-------------------------
[148]>>[79]: env.step(4)
action:[0, 10.9476]
reward:1.116609052835052
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.4293   2.38874]
done:False
-------------------------
[148]>>[80]: env.step(2)
action:[3.5, 12.4293]
reward:0.38027468963031996
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.2977   2.45678]
done:False
-------------------------
[148]>>[81]: env.step(4)
action:[3.5, 10.2977]
reward:1.0919241007156126
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.1674   2.50918]
done:False
-------------------------
[148]>>[82]: env.step(4)
action:[3.5, 10.1674]
reward:1.056445669669709
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.6045   5.76327]
done:False
-------------------------
[148]>>[83]: env.step(3)
action:[3.5, 16.6045]
reward:1.1420070205166946
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.4613   5.95071]
done:False
-------------------------
[148]>>[84]: env.step(3)
action:[3.5, 16.4613]
reward:1.1322350791987121
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 11.3242  6.1283]
done:False
-------------------------
[148]>>[85]: env.step(2)
action:[3.5, 11.3242]
reward:1.0594675772431563
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.3654   6.19001]
done:False
-------------------------
[148]>>[86]: env.step(1)
action:[0, 11.3654]
reward:0.311261859630946
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.3849   6.23579]
done:False
-------------------------
[148]>>[87]: env.step(4)
action:[0, 9.3849]
reward:0.9967351184257061
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.8315   3.28433]
done:False
-------------------------
[148]>>[88]: env.step(3)
action:[0, 15.8315]
reward:1.087865718945098
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 10.715   2.8909]
done:False
-------------------------
[148]>>[89]: env.step(2)
action:[3.5, 10.715]
reward:0.26772796377163655
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 10.8351  6.0379]
done:False
-------------------------
[148]>>[90]: env.step(3)
action:[3.5, 15.8351]
reward:1.100173341678081
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9239   6.26859]
done:False
-------------------------
[148]>>[91]: env.step(1)
action:[0, 10.9239]
reward:0.34997486621896856
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.1483   6.44397]
done:False
-------------------------
[148]>>[92]: env.step(3)
action:[0, 17.1483]
reward:1.2605079710718226
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.5733   3.08674]
done:False
-------------------------
[148]>>[93]: env.step(5)
action:[0, 13.5733]
reward:1.2597415829927767
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 14.4514  3.1807]
done:False
-------------------------
[148]>>[94]: env.step(0)
action:[-3.5, 14.4514]
reward:0.5202474996145905
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.448    3.12245]
done:False
-------------------------
[148]>>[95]: env.step(3)
action:[-3.5, 19.448]
reward:1.3211840191654165
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.3027   3.16683]
done:False
-------------------------
[148]>>[96]: env.step(3)
action:[-3.5, 19.3027]
reward:1.3148056836569975
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 14.195      0.0487204]
done:False
-------------------------
[148]>>[97]: env.step(3)
action:[-3.5, 19.195]
reward:1.3296887895742966
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       14.561    -0.123622]
done:False
-------------------------
[148]>>[98]: env.step(3)
action:[-3.5, 19.561]
reward:1.3688691329967315
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       15.4206   -0.153975]
done:False
-------------------------
[148]>>[99]: env.step(3)
action:[-3.5, 20.4206]
reward:1.4138205315292647
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 16.4475    -0.0970356]
done:False
-------------------------
[148]>>[100]: env.step(3)
action:[-3.5, 21.4475]
reward:1.4504118881042847
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 17.417     -0.0278546]
done:False
-------------------------
[148]>>[101]: env.step(3)
action:[-3.5, 22.417]
reward:1.4772525602215199
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 18.358      0.0452251]
done:False
-------------------------
[148]>>[102]: env.step(0)
action:[-3.5, 18.358]
reward:1.465293317259781
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       18.7961    0.120144]
done:False
-------------------------
[148]>>[103]: env.step(3)
action:[-3.5, 23.7961]
reward:1.4916024476054601
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       18.9426    0.196296]
done:False
-------------------------
[148]>>[104]: env.step(3)
action:[-3.5, 23.9426]
reward:1.4981121348092352
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       19.6325    0.274382]
done:False
-------------------------
[148]>>[105]: env.step(3)
action:[-3.5, 24.6325]
reward:1.499355726621645
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       20.4508    0.355475]
done:False
-------------------------
[148]>>[106]: env.step(3)
action:[-3.5, 25.4508]
reward:1.4899134640445313
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       21.2635    0.439887]
done:False
-------------------------
[148]>>[107]: env.step(3)
action:[-3.5, 26.2635]
reward:1.4683477226930641
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       22.0416    0.527584]
done:False
-------------------------
[148]>>[108]: env.step(3)
action:[-3.5, 27.0416]
reward:1.4349075181346682
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       22.7554    0.618268]
done:False
-------------------------
[148]>>[109]: env.step(3)
action:[-3.5, 27.7554]
reward:1.4061799825756094
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       23.1405    0.717249]
done:False
-------------------------
[148]>>[110]: env.step(3)
action:[-3.5, 28.1405]
reward:1.3788074643880037
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       23.4822    0.754977]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': 750.842, 'y': 0.754977, 'z': 0.571549}
.........................
** Rewards description :
count    110.000000
mean       0.739411
std        0.552474
min       -1.287868
25%        0.334492
50%        0.853921
75%        1.170525
max        1.499356
dtype: float64
#########################
[149]>> env.reset()
=========================
Retrying to reset environment!
[149]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.10622298205533298
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00064453 0.199238  ]
done:False
-------------------------
[149]>>[2]: env.step(5)
action:[0, 0.00064453]
reward:3.67378446688755e-05
observation:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.00026748 0.199281  ]
done:False
-------------------------
[149]>>[3]: env.step(3)
action:[0, 5.000267477]
reward:0.13754158173490538
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.373872 0.199825]
done:False
-------------------------
[149]>>[4]: env.step(3)
action:[0, 5.373872]
reward:0.23980266334431274
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.51511  0.203409]
done:False
-------------------------
[149]>>[5]: env.step(3)
action:[0, 6.51511]
reward:0.3758672817973632
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.91418  0.212287]
done:False
-------------------------
[149]>>[6]: env.step(3)
action:[0, 7.91418]
reward:0.5029945617193898
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.18831  0.226762]
done:False
-------------------------
[149]>>[7]: env.step(3)
action:[0, 9.188310000000001]
reward:0.6054419591304838
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.22027  0.245768]
done:False
-------------------------
[149]>>[8]: env.step(3)
action:[0, 10.22027]
reward:0.7056975701755055
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.7555    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.3269    0.269176]
done:False
-------------------------
[149]>>[9]: env.step(3)
action:[0, 11.3269]
reward:0.7900060093776267
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.2718    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.23683   0.298595]
done:False
-------------------------
[149]>>[10]: env.step(3)
action:[0, 12.236830000000001]
reward:0.8560361278209163
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.5715    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.96804   0.329254]
done:False
-------------------------
[149]>>[11]: env.step(5)
action:[0, 7.96804]
reward:0.8512352504542408
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.1993    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.96457   0.363519]
done:False
-------------------------
[149]>>[12]: env.step(5)
action:[0, 8.96457]
reward:0.8930035721493601
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       23.3687   46.1561    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.33573   0.400529]
done:False
-------------------------
[149]>>[13]: env.step(4)
action:[0, 7.33573]
reward:0.7919062627141111
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.011     0.       39.7261    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.26183   0.435534]
done:False
-------------------------
[149]>>[14]: env.step(1)
action:[0, 8.26183]
reward:0.8005938893876321
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       11.0139   49.7446   33.5799    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.15497   0.468743]
done:False
-------------------------
[149]>>[15]: env.step(0)
action:[-3.5, 8.15497]
reward:0.040935633583664255
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  7.77892  0.       0.       0.      28.462    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.04312 -2.05028]
done:False
-------------------------
[149]>>[16]: env.step(5)
action:[-3.5, 8.04312]
reward:0.7854128632195527
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.90503  0.       0.       0.       0.       0.
  0.       0.      23.232    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.9921  -3.39505]
done:False
-------------------------
[149]>>[17]: env.step(4)
action:[-3.5, 5.9921]
reward:0.670258698920762
observation:
[ 0.       0.       0.       0.       0.       8.38708  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      17.948    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.89623 -3.02046]
done:False
-------------------------
[149]>>[18]: env.step(3)
action:[-3.5, 11.89623]
reward:0.7684597758494073
observation:
[ 0.       0.       0.      12.2138   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.9      0.      48.7204   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.78749 -2.93861]
done:False
-------------------------
[149]>>[19]: env.step(4)
action:[-3.5, 4.78749]
reward:0.6334099323895642
observation:
[ 0.       0.      17.006    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.68509  0.      43.3362   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.69656 -2.88928]
done:False
-------------------------
[149]>>[20]: env.step(1)
action:[0, 6.69656]
reward:-25.065633108721926
observation:
[ 0.       0.       0.       0.       0.      19.7747   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       4.11482 20.6529   0.      40.0503   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.91354 -1.63558]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.0886, 'y': -1.63558, 'z': 0.569818}
.........................
** Rewards description :
count    20.000000
mean     -0.725538
std       5.736820
min     -25.065633
25%       0.214237
50%       0.651834
75%       0.790481
max       0.893004
dtype: float64
#########################
[150]>> env.reset()
=========================
[150]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.25466972093354073
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.7902  1.29087]
done:False
-------------------------
[150]>>[2]: env.step(0)
action:[-3.5, 1.7902]
reward:-0.603355399363815
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.2853  1.89908]
done:False
-------------------------
[150]>>[3]: env.step(2)
action:[3.5, 1.2853]
reward:-1.330447323475961
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.68644 2.74907]
done:False
-------------------------
[150]>>[4]: env.step(3)
action:[3.5, 6.68644]
reward:0.29324446357534584
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.84251 3.83288]
done:False
-------------------------
[150]>>[5]: env.step(3)
action:[3.5, 6.84251]
reward:0.31736359868897046
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.10184 4.56147]
done:False
-------------------------
[150]>>[6]: env.step(1)
action:[0, 2.10184]
reward:-0.49138925471928807
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.56298 4.76779]
done:False
-------------------------
[150]>>[7]: env.step(0)
action:[-3.5, 2.56298]
reward:-0.4701645515700533
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.70819 4.03651]
done:False
-------------------------
[150]>>[8]: env.step(1)
action:[0, 2.70819]
reward:-0.45917026830745783
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.80729 2.40557]
done:False
-------------------------
[150]>>[9]: env.step(3)
action:[0, 7.80729]
reward:0.4050062440493165
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.95875  0.454862]
done:False
-------------------------
[150]>>[10]: env.step(3)
action:[0, 7.95875]
reward:0.4962717692040319
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.08993  -0.246726]
done:False
-------------------------
[150]>>[11]: env.step(3)
action:[0, 9.089929999999999]
reward:0.5974402026107725
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.9515    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.13788   0.252076]
done:False
-------------------------
[150]>>[12]: env.step(5)
action:[0, 5.13788]
reward:0.5718288557673699
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.8358    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.78524   0.271541]
done:False
-------------------------
[150]>>[13]: env.step(0)
action:[-3.5, 5.78524]
reward:-0.16304023527724754
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.4762    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.82433   0.301996]
done:False
-------------------------
[150]>>[14]: env.step(0)
action:[-3.5, 5.82433]
reward:0.6051651861401426
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      35.9712   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.05756 -1.5976 ]
done:False
-------------------------
[150]>>[15]: env.step(5)
action:[-3.5, 6.05756]
reward:0.6097672661394928
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      33.0707
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.0609  -4.00991]
done:False
-------------------------
[150]>>[16]: env.step(0)
action:[-3.5, 6.0609]
reward:0.6023507049949299
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.7456   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.96076 -3.0434 ]
done:False
-------------------------
[150]>>[17]: env.step(3)
action:[-3.5, 10.96076]
reward:0.6879894163093923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.5506  46.7109   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.89731 -3.08717]
done:False
-------------------------
[150]>>[18]: env.step(0)
action:[-3.5, 5.89731]
reward:0.6536842544478783
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      20.0527
  0.      42.0107   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.69389 -3.08041]
done:False
-------------------------
[150]>>[19]: env.step(0)
action:[-3.5, 6.69389]
reward:0.7540939653350387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.6043
  0.      36.1283   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.88486 -3.05   ]
done:False
-------------------------
[150]>>[20]: env.step(0)
action:[-3.5, 7.88486]
reward:0.8359711170812636
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.38972  0.       0.
  0.      29.8396   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.76172 -3.0116 ]
done:False
-------------------------
[150]>>[21]: env.step(5)
action:[-3.5, 8.76172]
reward:0.8673940244773201
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.51503  0.       0.       0.       0.       0.       0.
  0.      23.2055   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.00464 -2.97477]
done:False
-------------------------
[150]>>[22]: env.step(5)
action:[-3.5, 9.00464]
reward:0.8661909082561303
observation:
[ 0.       0.       0.       0.       9.2943   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.0559  16.5345   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.92609 -2.93839]
done:False
-------------------------
[150]>>[23]: env.step(3)
action:[-3.5, 13.92609]
reward:0.9409675839002594
observation:
[ 0.       0.      14.7922   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.0117   0.      45.7635   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.82402 -2.9025 ]
done:False
-------------------------
[150]>>[24]: env.step(1)
action:[0, 8.82402]
reward:0.09442431868335
observation:
[ 0.        0.        0.        0.        0.       19.2379    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 20.5349    0.        4.11865   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.65059  -0.162677]
done:False
-------------------------
[150]>>[25]: env.step(2)
action:[3.5, 8.65059]
reward:-24.91629208872117
observation:
[ 0.       0.       0.       0.      20.2804   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      19.1195  39.2681   0.
  3.17689  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.53726  1.0033 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 80.0207, 'y': 1.0033, 'z': 0.570076}
.........................
** Rewards description :
count    25.000000
mean     -0.719201
std       5.073363
min     -24.916292
25%      -0.163040
50%       0.496272
75%       0.653684
max       0.940968
dtype: float64
#########################
[151]>> env.reset()
=========================
[151]>>[1]: env.step(4)
action:[0, 6.5542300000000004]
reward:0.2317820629250027
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.12227 0.87668]
done:False
-------------------------
[151]>>[2]: env.step(1)
action:[0, 1.12227]
reward:0.11901357646922735
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.12227 1.0756 ]
done:False
-------------------------
[151]>>[3]: env.step(3)
action:[0, 6.12227]
reward:0.22652768770987994
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.16631  0.626198]
done:False
-------------------------
[151]>>[4]: env.step(5)
action:[0, 1.16631]
reward:0.10917375093703388
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.994146 0.142967]
done:False
-------------------------
[151]>>[5]: env.step(1)
action:[0, 0.994146]
reward:0.11105572886464543
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.05957 0.16738]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02135, 'y': 0.16738, 'z': 0.571593}
.........................
** Rewards description :
count    5.000000
mean     0.159511
std      0.063711
min      0.109174
25%      0.111056
50%      0.119014
75%      0.226528
max      0.231782
dtype: float64
#########################
[152]>> env.reset()
=========================
Retrying to reset environment!
[152]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.10884526527235952
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0318175 0.220833 ]
done:False
-------------------------
[152]>>[2]: env.step(3)
action:[0, 5.0318175]
reward:0.13790249431022364
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.370299 0.243845]
done:False
-------------------------
[152]>>[3]: env.step(2)
action:[3.5, 0.370299]
reward:-0.6648838277036645
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.907698 0.334723]
done:False
-------------------------
[152]>>[4]: env.step(0)
action:[-3.5, 0.907698]
reward:-1.4029068779312135
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.915303 0.807537]
done:False
-------------------------
[152]>>[5]: env.step(3)
action:[-3.5, 5.915303]
reward:0.24582780503137616
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.45329  0.843088]
done:False
-------------------------
[152]>>[6]: env.step(3)
action:[-3.5, 6.45329]
reward:0.33251201082859283
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.38735  0.345763]
done:False
-------------------------
[152]>>[7]: env.step(3)
action:[-3.5, 7.38735]
reward:0.46021778145514575
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.76763 -1.34931]
done:False
-------------------------
[152]>>[8]: env.step(3)
action:[-3.5, 8.76763]
reward:0.5832550360256131
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.02945 -3.71314]
done:False
-------------------------
[152]>>[9]: env.step(3)
action:[-3.5, 10.02945]
reward:0.6806940152713202
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.02987 -3.17391]
done:False
-------------------------
[152]>>[10]: env.step(3)
action:[-3.5, 11.029869999999999]
reward:0.7871677557805912
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      45.254    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.27049 -3.16988]
done:False
-------------------------
[152]>>[11]: env.step(4)
action:[-3.5, 5.27049]
reward:0.762384928279013
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.3957   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.35785 -3.17255]
done:False
-------------------------
[152]>>[12]: env.step(5)
action:[-3.5, 8.35785]
reward:0.8669567766102807
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.903    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.09913 -3.1473 ]
done:False
-------------------------
[152]>>[13]: env.step(0)
action:[-3.5, 9.09913]
reward:0.8903377124940623
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 26.1953  48.4095   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.26212 -3.11161]
done:False
-------------------------
[152]>>[14]: env.step(5)
action:[-3.5, 9.26212]
reward:0.8872891586982663
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 19.5734  41.5056   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.17573 -3.07415]
done:False
-------------------------
[152]>>[15]: env.step(5)
action:[-3.5, 9.17573]
reward:0.877151302476201
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.337
  0.      34.7008   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.04604 -3.03717]
done:False
-------------------------
[152]>>[16]: env.step(5)
action:[-3.5, 9.04604]
reward:0.8680351331617091
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.14968  0.       0.       0.
  0.      27.982    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.94306 -3.0007 ]
done:False
-------------------------
[152]>>[17]: env.step(4)
action:[-3.5, 6.943059999999999]
reward:0.7579804232580398
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.63242
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.8707   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.87743 -2.96723]
done:False
-------------------------
[152]>>[18]: env.step(3)
action:[-3.5, 12.87743]
reward:0.8614843958367358
observation:
[ 0.       0.       0.       0.       9.65798  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.5645  16.0397   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.88828 -2.93548]
done:False
-------------------------
[152]>>[19]: env.step(3)
action:[-3.5, 12.88828]
reward:0.9127914443974117
observation:
[ 0.       0.      15.2013   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.57271  0.      45.3095   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.65319 -2.90004]
done:False
-------------------------
[152]>>[20]: env.step(2)
action:[3.5, 8.65319]
reward:-0.6165681887141705
observation:
[ 0.        0.        0.        0.        0.        0.        0.
 19.5022    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.1464    3.8186    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.27031   0.132185]
done:False
-------------------------
[152]>>[21]: env.step(3)
action:[3.5, 14.27031]
reward:0.9833142849640962
observation:
[ 0.       0.      22.4499   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      16.9593  38.1398
  0.       0.       0.       0.       0.       0.       6.49653  0.
  0.       0.       0.       0.       9.39759  6.1333 ]
done:False
-------------------------
[152]>>[22]: env.step(4)
action:[3.5, 7.397589999999999]
reward:0.9136514391663175
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      10.1883
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       8.16041  0.       0.       0.      29.053
  0.       0.       0.       0.      10.0389   5.22698]
done:False
-------------------------
[152]>>[23]: env.step(5)
action:[3.5, 10.0389]
reward:-23.989280605778426
observation:
[ 0.      35.4293   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.67044 24.9729   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      13.1753  10.8914   4.00256]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 95.1933, 'y': 4.00256, 'z': 0.571091}
.........................
** Rewards description :
count    23.000000
mean     -0.598080
std       5.135761
min     -23.989281
25%       0.191865
50%       0.757980
75%       0.872593
max       0.983314
dtype: float64
#########################
[153]>> env.reset()
=========================
[153]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.23209431253193302
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.51463   0.0738023]
done:False
-------------------------
[153]>>[2]: env.step(3)
action:[0, 6.51463]
reward:0.3695403794623636
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.83482  0.183392]
done:False
-------------------------
[153]>>[3]: env.step(4)
action:[0, 1.41741]
reward:0.20472854164406074
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.07794  0.226656]
done:False
-------------------------
[153]>>[4]: env.step(3)
action:[0, 7.07794]
reward:0.3399520280111865
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.32386 0.23487]
done:False
-------------------------
[153]>>[5]: env.step(3)
action:[0, 7.32386]
reward:0.4250524688668089
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.33404  0.240284]
done:False
-------------------------
[153]>>[6]: env.step(3)
action:[0, 8.33404]
reward:0.5454402773346708
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.63795  0.255037]
done:False
-------------------------
[153]>>[7]: env.step(4)
action:[0, 2.318975]
reward:0.3149688600949361
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.4261    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.20303   0.271449]
done:False
-------------------------
[153]>>[8]: env.step(1)
action:[0, 3.20303]
reward:0.3360946079721775
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.0281    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.24452   0.284906]
done:False
-------------------------
[153]>>[9]: env.step(4)
action:[0, 1.62226]
reward:0.23281973821884172
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.9399    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.3679    0.296366]
done:False
-------------------------
[153]>>[10]: env.step(3)
action:[0, 7.367900000000001]
reward:0.34577732409874173
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.1931    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.32404   0.305709]
done:False
-------------------------
[153]>>[11]: env.step(3)
action:[0, 7.32404]
reward:0.3441824969261967
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.4591    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.3151    0.315106]
done:False
-------------------------
[153]>>[12]: env.step(3)
action:[0, 7.3151]
reward:0.34341031148500306
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.7317    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.3077    0.324501]
done:False
-------------------------
[153]>>[13]: env.step(3)
action:[0, 7.3077000000000005]
reward:0.36368484834162884
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.9372   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.5631   0.33416]
done:False
-------------------------
[153]>>[14]: env.step(2)
action:[3.5, 2.5631]
reward:-0.43521174237567906
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      34.0411   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.13976  1.33365]
done:False
-------------------------
[153]>>[15]: env.step(3)
action:[3.5, 8.139759999999999]
reward:0.4199340885156718
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      32.6472
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.06498  3.33576]
done:False
-------------------------
[153]>>[16]: env.step(3)
action:[3.5, 8.06498]
reward:0.45063447704006904
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      30.4266   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.47533  4.05725]
done:False
-------------------------
[153]>>[17]: env.step(2)
action:[3.5, 3.47533]
reward:0.3744173449429629
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.8413   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.6559   3.92808]
done:False
-------------------------
[153]>>[18]: env.step(3)
action:[3.5, 8.655899999999999]
reward:0.4833543178124418
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.0516   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.74847  3.89229]
done:False
-------------------------
[153]>>[19]: env.step(3)
action:[3.5, 8.748470000000001]
reward:0.5022709591689176
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.9916   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.97034  3.90355]
done:False
-------------------------
[153]>>[20]: env.step(3)
action:[3.5, 8.97034]
reward:0.577921451556147
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.6535   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.90792  3.92509]
done:False
-------------------------
[153]>>[21]: env.step(3)
action:[3.5, 9.90792]
reward:0.6795228460216131
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.4836   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.04418  3.9484 ]
done:False
-------------------------
[153]>>[22]: env.step(3)
action:[3.5, 11.04418]
reward:0.7745551422422553
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.52096 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.08708 3.97495]
done:False
-------------------------
[153]>>[23]: env.step(4)
action:[3.5, 5.08708]
reward:0.5980218348171467
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.68138 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.14636 4.00137]
done:False
-------------------------
[153]>>[24]: env.step(3)
action:[3.5, 11.14636]
reward:-24.29325259666765
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.07398 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.10992 4.00471]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 55.9591, 'y': 4.00471, 'z': 0.568508}
.........................
** Rewards description :
count    24.000000
mean     -0.644587
std       5.042080
min     -24.293253
25%       0.330813
50%       0.366613
75%       0.488083
max       0.774555
dtype: float64
#########################
[154]>> env.reset()
=========================
[154]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.15218217647045382
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.549195 0.199593]
done:False
-------------------------
[154]>>[2]: env.step(3)
action:[0, 5.549195]
reward:0.26687906661992855
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.80248 0.20442]
done:False
-------------------------
[154]>>[3]: env.step(3)
action:[0, 6.80248]
reward:0.40485834336065807
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.20808 0.21469]
done:False
-------------------------
[154]>>[4]: env.step(3)
action:[0, 8.208079999999999]
reward:0.5375694320983266
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.56609  0.230489]
done:False
-------------------------
[154]>>[5]: env.step(3)
action:[0, 9.566089999999999]
reward:0.6584068236153473
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.84097  0.251571]
done:False
-------------------------
[154]>>[6]: env.step(5)
action:[0, 5.84097]
reward:0.6356337399247806
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.3918    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.46324   0.276518]
done:False
-------------------------
[154]>>[7]: env.step(3)
action:[0, 11.463239999999999]
reward:0.7382297549303105
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.5368    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.46944   0.302781]
done:False
-------------------------
[154]>>[8]: env.step(5)
action:[0, 6.46944]
reward:0.6435815189158447
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.723     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.4137    0.328855]
done:False
-------------------------
[154]>>[9]: env.step(3)
action:[0, 11.4137]
reward:0.740228783945862
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.6036    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.50986   0.356566]
done:False
-------------------------
[154]>>[10]: env.step(5)
action:[0, 6.50986]
reward:0.6666956557088116
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.7075   49.5187    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.71809   0.383082]
done:False
-------------------------
[154]>>[11]: env.step(0)
action:[-3.5, 6.71809]
reward:-0.08227906388974482
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.7138   44.4865    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.68004   0.410257]
done:False
-------------------------
[154]>>[12]: env.step(3)
action:[-3.5, 11.68004]
reward:0.7724528299159564
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      18.0784  40.2892   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.89823 -1.8455 ]
done:False
-------------------------
[154]>>[13]: env.step(5)
action:[-3.5, 6.89823]
reward:0.7452804586343604
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.639
  0.      35.8253   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.70967 -3.86138]
done:False
-------------------------
[154]>>[14]: env.step(3)
action:[-3.5, 12.70967]
reward:0.9051039775601808
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.43634  0.       0.
 46.2724  29.8389   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.58156 -3.09141]
done:False
-------------------------
[154]>>[15]: env.step(0)
action:[-3.5, 8.58156]
reward:0.9082943838457931
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.52012  0.       0.       0.       0.       0.       0.       0.
 39.4372  22.9626   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.66179 -2.9778 ]
done:False
-------------------------
[154]>>[16]: env.step(0)
action:[-3.5, 9.66179]
reward:0.9471378176096676
observation:
[ 0.       0.       0.       0.       9.95933  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.1656  15.6382   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.98521 -2.93021]
done:False
-------------------------
[154]>>[17]: env.step(5)
action:[-3.5, 9.98521]
reward:0.9458437799861871
observation:
[ 0.       0.      16.34     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.37127  0.      44.0589   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.88438 -2.89195]
done:False
-------------------------
[154]>>[18]: env.step(3)
action:[-3.5, 14.88438]
reward:1.0158848334493185
observation:
[ 0.      23.2773   0.       0.       0.       0.       0.       0.
  0.       0.       2.588    0.       0.       0.       0.      17.8872
  0.       0.      36.7019   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.76306 -2.85333]
done:False
-------------------------
[154]>>[19]: env.step(0)
action:[-3.5, 9.76306]
reward:0.9417155459916773
observation:
[ 0.      30.8185   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.9718   0.
  0.       0.      28.9339   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.87629 -2.8118 ]
done:False
-------------------------
[154]>>[20]: env.step(5)
action:[-3.5, 9.87629]
reward:0.9385778738564055
observation:
[38.0668   0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.54001  0.       0.       0.       0.       0.
  0.       0.      21.562    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.79972 -2.77202]
done:False
-------------------------
[154]>>[21]: env.step(1)
action:[0, 9.79972]
reward:0.18040165632483907
observation:
[ 0.        0.        0.        0.       43.9529    0.        0.
  5.81276   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       39.4652   15.8258    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.69349   0.220879]
done:False
-------------------------
[154]>>[22]: env.step(1)
action:[0, 9.69349]
reward:0.9181954442502098
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      32.807    0.       9.75071  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.6368  11.8637   9.53391  0.81461]
done:False
-------------------------
[154]>>[23]: env.step(5)
action:[0, 9.53391]
reward:0.9035048956451233
observation:
[18.7652    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       25.8733    0.        0.
  0.        0.        0.        0.        5.0924    0.        0.
  0.        0.        0.        0.        0.        0.        0.
 34.6626    9.35137   0.857625]
done:False
-------------------------
[154]>>[24]: env.step(1)
action:[0, 9.35137]
reward:0.8883151007321759
observation:
[25.6231    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       19.1185    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        7.36457   0.        0.        0.
 41.5746    9.16877   0.883769]
done:False
-------------------------
[154]>>[25]: env.step(3)
action:[0, 14.16877]
reward:0.9600605882234632
observation:
[32.4199    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       12.6199
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       13.2704    0.
 48.4023    9.05875   0.914299]
done:False
-------------------------
[154]>>[26]: env.step(4)
action:[0, 7.05875]
reward:0.8348765492522388
observation:
[39.1469    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       46.1379    0.        0.
  0.        6.86423   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       19.7025
  0.        8.95227   0.948348]
done:False
-------------------------
[154]>>[27]: env.step(1)
action:[0, 8.95227]
reward:0.8535319857166828
observation:
[45.7359    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       39.5359    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.05652   0.        0.        0.        0.        0.       26.152
  0.        8.7523    0.983284]
done:False
-------------------------
[154]>>[28]: env.step(2)
action:[3.5, 8.7523]
reward:0.09327712758855733
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      33.017    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.48103  0.       0.      32.5817   8.65171  1.0183 ]
done:False
-------------------------
[154]>>[29]: env.step(5)
action:[3.5, 8.65171]
reward:0.8276320890923827
observation:
[ 0.      15.9215   0.      38.7852   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      27.4752
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.44848  3.88409]
done:False
-------------------------
[154]>>[30]: env.step(2)
action:[3.5, 8.44848]
reward:0.8126531238836394
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.9405   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      21.5102
  0.      44.6242   0.       0.       8.28212  4.7929 ]
done:False
-------------------------
[154]>>[31]: env.step(5)
action:[3.5, 8.28212]
reward:0.7974659645352299
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      16.0275   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      27.1372   0.       0.       8.10496  4.66868]
done:False
-------------------------
[154]>>[32]: env.step(3)
action:[3.5, 13.10496]
reward:0.8724655234192917
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      47.7148   0.      10.3817   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.9151   0.       7.99406  4.663  ]
done:False
-------------------------
[154]>>[33]: env.step(5)
action:[3.5, 7.99406]
reward:0.7700888007346285
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      41.8366   0.       0.       0.       0.       5.696
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.6318   0.       7.78615  4.68283]
done:False
-------------------------
[154]>>[34]: env.step(5)
action:[3.5, 7.78615]
reward:0.7527866946309887
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      36.1035   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       5.06366  0.       0.
  0.       0.      44.2507   0.       7.59336  4.7103 ]
done:False
-------------------------
[154]>>[35]: env.step(2)
action:[3.5, 7.59336]
reward:0.7362616739939387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      30.5104  49.9976   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       9.07948  0.      49.7592   7.40933  4.73952]
done:False
-------------------------
[154]>>[36]: env.step(3)
action:[3.5, 12.40933]
reward:0.8132566489324103
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      25.0044  44.5893   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.1271   0.       7.30063  4.769  ]
done:False
-------------------------
[154]>>[37]: env.step(1)
action:[0, 7.30063]
reward:-0.032438348871936196
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.4555  39.6879   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      18.0786   0.
  0.       0.       0.       0.       7.22148  2.48789]
done:False
-------------------------
[154]>>[38]: env.step(4)
action:[0, 5.22148]
reward:0.6113945559891558
observation:
[22.0846    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       16.5282    0.       35.3354    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.29174   0.796116]
done:False
-------------------------
[154]>>[39]: env.step(3)
action:[0, 11.29174]
reward:0.6973183294346854
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 11.8142   0.       0.      30.7382   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.8174   5.94316  1.25835]
done:False
-------------------------
[154]>>[40]: env.step(5)
action:[0, 5.94316]
reward:0.630689392632346
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.41301  0.       0.      26.2908   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      31.3589   6.37091  1.33903]
done:False
-------------------------
[154]>>[41]: env.step(4)
action:[0, 4.37091]
reward:0.5966144668103005
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       3.27332  0.       0.
  0.       0.       0.      21.6669   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      36.1154   6.30661  1.38649]
done:False
-------------------------
[154]>>[42]: env.step(5)
action:[0, 6.30661]
reward:0.625075342163584
observation:
[ 0.       0.       0.       0.       3.38552  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      17.1811   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      40.7999   6.20435  1.41753]
done:False
-------------------------
[154]>>[43]: env.step(4)
action:[0, 4.20435]
reward:0.5783246760985603
observation:
[ 0.       7.42151  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.9053   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      45.4094   6.10477  1.44322]
done:False
-------------------------
[154]>>[44]: env.step(3)
action:[0, 11.10477]
reward:0.6970885551708457
observation:
[ 0.      11.8028   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.03237  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      49.9367   5.98673  1.46734]
done:False
-------------------------
[154]>>[45]: env.step(5)
action:[0, 5.98673]
reward:0.6381005958239157
observation:
[16.33     0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  6.10706  0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.46016  1.49161]
done:False
-------------------------
[154]>>[46]: env.step(3)
action:[0, 11.46016]
reward:0.7340627812791889
observation:
[21.1311   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       6.02533  0.       0.
  0.       0.       0.       0.       6.41184  1.51748]
done:False
-------------------------
[154]>>[47]: env.step(3)
action:[0, 11.41184]
reward:0.8260381477752237
observation:
[26.2909   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  9.34033  0.       0.       0.       7.73527  1.54501]
done:False
-------------------------
[154]>>[48]: env.step(4)
action:[0, 5.73527]
reward:0.6843848990331303
observation:
[31.8986   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.2597   0.       0.       7.15411  1.57549]
done:False
-------------------------
[154]>>[49]: env.step(2)
action:[3.5, 7.15411]
reward:-0.041665346050787644
observation:
[ 0.       0.      19.6203   0.       0.      36.5541   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.12998  4.17367]
done:False
-------------------------
[154]>>[50]: env.step(2)
action:[3.5, 7.12998]
reward:0.7128521536528317
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.5297   0.      41.288    0.       7.19869  5.7142 ]
done:False
-------------------------
[154]>>[51]: env.step(3)
action:[3.5, 12.19869]
reward:0.781223163196648
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.1505  46.3728   6.89341  5.26529]
done:False
-------------------------
[154]>>[52]: env.step(4)
action:[3.5, 4.89341]
reward:0.6435861303112664
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.0305   0.       6.80777  5.21813]
done:False
-------------------------
[154]>>[53]: env.step(5)
action:[3.5, 6.80777]
reward:0.6784149940136968
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.9496   0.       6.80402  5.22089]
done:False
-------------------------
[154]>>[54]: env.step(1)
action:[0, 6.80402]
reward:-0.06610935531506312
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      42.7054   0.       0.
  0.       0.       0.       0.       6.88013  2.9671 ]
done:False
-------------------------
[154]>>[55]: env.step(3)
action:[0, 11.880130000000001]
reward:0.7731714477125047
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      46.6899   6.85842  1.01779]
done:False
-------------------------
[154]>>[56]: env.step(4)
action:[0, 4.85842]
reward:0.6007838462002333
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.24043 1.67716]
done:False
-------------------------
[154]>>[57]: env.step(3)
action:[0, 11.24043]
reward:0.7075814605491334
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.09796 1.75685]
done:False
-------------------------
[154]>>[58]: env.step(5)
action:[0, 6.09796]
reward:0.6058888162068045
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.99884 1.80959]
done:False
-------------------------
[154]>>[59]: env.step(4)
action:[0, 3.9988400000000004]
reward:0.5585023698180207
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.89379 1.85233]
done:False
-------------------------
[154]>>[60]: env.step(4)
action:[0, 3.89379]
reward:0.5000794431995172
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.15556 1.87843]
done:False
-------------------------
[154]>>[61]: env.step(4)
action:[0, 3.1555600000000004]
reward:0.47874465963704055
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.06404 1.89927]
done:False
-------------------------
[154]>>[62]: env.step(3)
action:[0, 10.06404]
reward:0.6021835851666218
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.95774 1.91886]
done:False
-------------------------
[154]>>[63]: env.step(3)
action:[0, 9.957740000000001]
reward:0.6853318728796961
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.11151 1.94007]
done:False
-------------------------
[154]>>[64]: env.step(3)
action:[0, 11.111509999999999]
reward:0.8521618875578154
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.19233 1.96853]
done:False
-------------------------
[154]>>[65]: env.step(4)
action:[0, 6.19233]
reward:0.7302671695397959
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.67571 2.00089]
done:False
-------------------------
[154]>>[66]: env.step(4)
action:[0, 5.67571]
reward:0.6748455942294167
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.03811 2.03023]
done:False
-------------------------
[154]>>[67]: env.step(4)
action:[0, 5.03811]
reward:0.6147976174753749
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.38325 2.05697]
done:False
-------------------------
[154]>>[68]: env.step(3)
action:[0, 11.38325]
reward:0.7215719316984956
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.25665 2.08255]
done:False
-------------------------
[154]>>[69]: env.step(3)
action:[0, 11.25665]
reward:0.7675626249460107
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.93466 2.11003]
done:False
-------------------------
[154]>>[70]: env.step(3)
action:[0, 11.934660000000001]
reward:0.9389840224151277
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.29137 2.14287]
done:False
-------------------------
[154]>>[71]: env.step(4)
action:[0, 7.291370000000001]
reward:0.9289384543324983
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2982   2.18297]
done:False
-------------------------
[154]>>[72]: env.step(4)
action:[0, 8.2982]
reward:0.9129596809671232
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.80326 2.22336]
done:False
-------------------------
[154]>>[73]: env.step(5)
action:[0, 9.80326]
reward:0.9305405437384524
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.69473 2.26282]
done:False
-------------------------
[154]>>[74]: env.step(4)
action:[0, 7.69473]
reward:0.8593169994001757
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.15195 2.30051]
done:False
-------------------------
[154]>>[75]: env.step(4)
action:[0, 7.151949999999999]
reward:0.8119836818712306
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.59658 2.33605]
done:False
-------------------------
[154]>>[76]: env.step(4)
action:[0, 6.596579999999999]
reward:0.7623448272835249
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.02576 2.36931]
done:False
-------------------------
[154]>>[77]: env.step(3)
action:[0, 13.02576]
reward:0.8664691313750167
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.92493 2.4016 ]
done:False
-------------------------
[154]>>[78]: env.step(3)
action:[0, 12.92493]
reward:0.8580136654337229
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.82517 2.43346]
done:False
-------------------------
[154]>>[79]: env.step(2)
action:[3.5, 7.82517]
reward:0.03216967067834786
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.00029 5.16461]
done:False
-------------------------
[154]>>[80]: env.step(3)
action:[3.5, 13.00029]
reward:0.9017183741572312
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.45784 6.36477]
done:False
-------------------------
[154]>>[81]: env.step(3)
action:[3.5, 13.45784]
reward:0.9928159150932603
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.75101 6.13644]
done:False
-------------------------
[154]>>[82]: env.step(4)
action:[3.5, 7.751010000000001]
reward:0.9782524552509481
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9477   6.09574]
done:False
-------------------------
[154]>>[83]: env.step(4)
action:[3.5, 8.9477]
reward:0.973059509189155
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.567    6.11716]
done:False
-------------------------
[154]>>[84]: env.step(4)
action:[3.5, 8.567]
reward:0.9592187520936571
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4461   6.15638]
done:False
-------------------------
[154]>>[85]: env.step(4)
action:[3.5, 8.4461]
reward:0.9267702104068798
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.97639 6.19706]
done:False
-------------------------
[154]>>[86]: env.step(4)
action:[3.5, 7.97639]
reward:0.8869173111499867
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.4916  6.23613]
done:False
-------------------------
[154]>>[87]: env.step(2)
action:[3.5, 9.4916]
reward:0.9049001065810012
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.383   6.27435]
done:False
-------------------------
[154]>>[88]: env.step(4)
action:[3.5, 7.382999999999999]
reward:0.8631929398804109
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.28714 6.31213]
done:False
-------------------------
[154]>>[89]: env.step(4)
action:[3.5, 7.287140000000001]
reward:0.8689374125267122
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.39616 6.3524 ]
done:False
-------------------------
[154]>>[90]: env.step(5)
action:[3.5, 9.39616]
reward:0.9128897491349262
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.52771 6.39074]
done:False
-------------------------
[154]>>[91]: env.step(4)
action:[3.5, 7.527710000000001]
reward:0.8479407711157612
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.02625 6.42788]
done:False
-------------------------
[154]>>[92]: env.step(4)
action:[3.5, 7.026249999999999]
reward:0.8037299938566589
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.50898 6.46298]
done:False
-------------------------
[154]>>[93]: env.step(4)
action:[3.5, 6.508979999999999]
reward:0.7572880447640493
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.97617 6.49595]
done:False
-------------------------
[154]>>[94]: env.step(4)
action:[3.5, 5.97617]
reward:0.7406904423043582
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.87572 6.52803]
done:False
-------------------------
[154]>>[95]: env.step(4)
action:[3.5, 5.87572]
reward:0.6984222121915573
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.31241 6.55837]
done:False
-------------------------
[154]>>[96]: env.step(3)
action:[3.5, 12.31241]
reward:0.806896243065817
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.23305 6.58777]
done:False
-------------------------
[154]>>[97]: env.step(4)
action:[3.5, 5.23305]
reward:0.6443872989878976
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.73372 6.61572]
done:False
-------------------------
[154]>>[98]: env.step(4)
action:[3.5, 4.73372]
reward:0.5948156498456818
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.1919  6.64152]
done:False
-------------------------
[154]>>[99]: env.step(4)
action:[3.5, 4.1919]
reward:0.5419716274970298
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.62791 6.66663]
done:False
-------------------------
[154]>>[100]: env.step(4)
action:[3.5, 3.62791]
reward:0.486811382266644
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.05015 6.68781]
done:False
-------------------------
[154]>>[101]: env.step(4)
action:[3.5, 3.0501500000000004]
reward:0.4687077230369847
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.96106 6.70807]
done:False
-------------------------
[154]>>[102]: env.step(3)
action:[3.5, 9.96106]
reward:0.5926575410129149
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.85628 6.72794]
done:False
-------------------------
[154]>>[103]: env.step(3)
action:[3.5, 9.85628]
reward:0.6782135699449743
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.03913 6.74922]
done:False
-------------------------
[154]>>[104]: env.step(4)
action:[3.5, 4.03913]
reward:0.5422052004068525
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.66917 6.77307]
done:False
-------------------------
[154]>>[105]: env.step(1)
action:[0, 5.66917]
reward:-0.15727739845295097
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.93012 4.85693]
done:False
-------------------------
[154]>>[106]: env.step(3)
action:[0, 10.930119999999999]
reward:0.685091476633467
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.86511 2.45478]
done:False
-------------------------
[154]>>[107]: env.step(3)
action:[0, 10.86511]
reward:0.7785123641759031
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.18817 3.47174]
done:False
-------------------------
[154]>>[108]: env.step(4)
action:[0, 5.18817]
reward:0.6562152855102532
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.90561 3.41151]
done:False
-------------------------
[154]>>[109]: env.step(3)
action:[0, 11.90561]
reward:0.7635089085431508
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.71498 3.39783]
done:False
-------------------------
[154]>>[110]: env.step(3)
action:[0, 11.71498]
reward:0.7507670325387453
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.58269 3.41948]
done:False
-------------------------
[154]>>[111]: env.step(1)
action:[0, 6.58269]
reward:0.6881109469859477
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.9935  3.44576]
done:False
-------------------------
[154]>>[112]: env.step(3)
action:[0, 11.993500000000001]
reward:0.7851471826020399
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.00071 3.47451]
done:False
-------------------------
[154]>>[113]: env.step(3)
action:[0, 12.00071]
reward:0.9006062372176231
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.69098 3.5054 ]
done:False
-------------------------
[154]>>[114]: env.step(3)
action:[0, 13.69098]
reward:1.0685884130046799
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9256   3.54573]
done:False
-------------------------
[154]>>[115]: env.step(5)
action:[0, 10.9256]
reward:1.0810750237985454
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.8266   3.59192]
done:False
-------------------------
[154]>>[116]: env.step(4)
action:[0, 9.8266]
reward:1.046938725270985
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 11.5328  3.639 ]
done:False
-------------------------
[154]>>[117]: env.step(4)
action:[0, 9.5328]
reward:1.0229573805535048
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.2151   3.68481]
done:False
-------------------------
[154]>>[118]: env.step(4)
action:[0, 9.2151]
reward:0.9971531936350884
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.8806   3.72928]
done:False
-------------------------
[154]>>[119]: env.step(3)
action:[0, 15.8806]
reward:1.0920372164108818
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.7736   3.77599]
done:False
-------------------------
[154]>>[120]: env.step(4)
action:[0, 8.7736]
reward:1.0234456415830446
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.4128   3.82059]
done:False
-------------------------
[154]>>[121]: env.step(3)
action:[0, 16.4128]
reward:1.199482706350358
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.5608   3.86904]
done:False
-------------------------
[154]>>[122]: env.step(4)
action:[0, 10.5608]
reward:1.1106646565797025
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.423    3.91959]
done:False
-------------------------
[154]>>[123]: env.step(3)
action:[0, 17.423000000000002]
reward:1.2045010200986979
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 12.4032  3.9697]
done:False
-------------------------
[154]>>[124]: env.step(4)
action:[0, 10.4032]
reward:1.1529534194916409
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.2072   4.02132]
done:False
-------------------------
[154]>>[125]: env.step(4)
action:[0, 11.2072]
reward:1.1607737808318275
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1472   4.07468]
done:False
-------------------------
[154]>>[126]: env.step(4)
action:[0, 11.1472]
reward:1.153020229650151
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.0224   4.12765]
done:False
-------------------------
[154]>>[127]: env.step(4)
action:[0, 11.0224]
reward:1.1436022653681126
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.8852   4.18009]
done:False
-------------------------
[154]>>[128]: env.step(4)
action:[0, 10.8852]
reward:1.1339921963852364
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.7492   4.23197]
done:False
-------------------------
[154]>>[129]: env.step(4)
action:[0, 10.7492]
reward:1.1289928762187502
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.6952   4.25257]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': 750.385, 'y': 4.25257, 'z': 0.568584}
.........................
** Rewards description :
count    129.000000
mean       0.745825
std        0.270082
min       -0.157277
25%        0.643582
50%        0.770089
75%        0.912890
max        1.204501
dtype: float64
#########################
[155]>> env.reset()
=========================
[155]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.145448515006589
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.468529 0.199818]
done:False
-------------------------
[155]>>[2]: env.step(0)
action:[-3.5, 0.468529]
reward:-0.6506305325085319
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        1.05211   0.0536365]
done:False
-------------------------
[155]>>[3]: env.step(3)
action:[-3.5, 6.05211]
reward:0.24132810089899973
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.36416  -0.490054]
done:False
-------------------------
[155]>>[4]: env.step(4)
action:[-3.5, 0.68208]
reward:0.24563245260969552
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.75921 -1.66126]
done:False
-------------------------
[155]>>[5]: env.step(3)
action:[-3.5, 7.7592099999999995]
reward:0.5116286638598164
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.33933 -3.45212]
done:False
-------------------------
[155]>>[6]: env.step(3)
action:[-3.5, 9.33933]
reward:0.6292992119873626
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.50311 -3.20768]
done:False
-------------------------
[155]>>[7]: env.step(3)
action:[-3.5, 10.50311]
reward:0.7518466905582232
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.7371   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.90087 -3.19149]
done:False
-------------------------
[155]>>[8]: env.step(1)
action:[0, 6.90087]
reward:-0.01780493790534643
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      43.835    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.52553 -1.00738]
done:False
-------------------------
[155]>>[9]: env.step(4)
action:[0, 5.52553]
reward:0.6196375300295571
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       39.1889    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.32643   0.694878]
done:False
-------------------------
[155]>>[10]: env.step(3)
action:[0, 11.32643]
reward:0.7037878193349341
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.7371    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.02392   0.411197]
done:False
-------------------------
[155]>>[11]: env.step(1)
action:[0, 6.02392]
reward:0.5975500974411365
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.3083    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.90585   0.380522]
done:False
-------------------------
[155]>>[12]: env.step(2)
action:[3.5, 5.90585]
reward:-0.1441998779508702
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      26.474   49.5105
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.04568  2.37725]
done:False
-------------------------
[155]>>[13]: env.step(2)
action:[3.5, 6.04568]
reward:0.60367202591891
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      23.1092   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.98224  4.75889]
done:False
-------------------------
[155]>>[14]: env.step(3)
action:[3.5, 10.982240000000001]
reward:0.6823318244537199
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.9157   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.81416  3.85336]
done:False
-------------------------
[155]>>[15]: env.step(3)
action:[3.5, 10.814160000000001]
reward:0.6594496918541282
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.7599   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.54316  3.9446 ]
done:False
-------------------------
[155]>>[16]: env.step(1)
action:[0, 5.54316]
reward:-0.18672845852520736
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.3561  34.3804   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.57069  2.22245]
done:False
-------------------------
[155]>>[17]: env.step(4)
action:[0, 3.57069]
reward:0.4321724888629288
observation:
[ 0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         9.50152    0.        31.8592     0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.36301   -0.0337268]
done:False
-------------------------
[155]>>[18]: env.step(3)
action:[0, 9.36301]
reward:0.513390191336951
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.63858   0.        0.       28.8782    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.96132   0.490762]
done:False
-------------------------
[155]>>[19]: env.step(5)
action:[0, 3.96132]
reward:0.46384173164570797
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        3.89081   0.
  0.        0.        0.       41.6222   25.4457    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.67069   0.517295]
done:False
-------------------------
[155]>>[20]: env.step(0)
action:[-3.5, 4.67069]
reward:-0.25536963226640885
observation:
[ 0.       0.       0.       4.67364  0.       0.       0.       0.
  0.       0.       0.       0.      38.807   22.4592   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.89067 -1.18885]
done:False
-------------------------
[155]>>[21]: env.step(4)
action:[-3.5, 2.445335]
reward:0.45164302285394314
observation:
[ 0.       0.       0.       0.       7.51469  0.       0.       0.
  0.       0.       0.       0.       0.       0.      20.1898   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.89316 -3.48079]
done:False
-------------------------
[155]>>[22]: env.step(3)
action:[-3.5, 9.89316]
reward:0.5647914367396685
observation:
[ 0.       0.       0.       0.       0.       9.12345  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      16.7862   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.50328 -2.90197]
done:False
-------------------------
[155]>>[23]: env.step(1)
action:[0, 4.50328]
reward:-0.2850099752367711
observation:
[ 0.       0.       0.       0.       0.       0.       0.      10.4204
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      30.3416  13.8889   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.54996 -1.34519]
done:False
-------------------------
[155]>>[24]: env.step(1)
action:[0, 4.54996]
reward:0.4683263448179754
observation:
[ 0.        0.        0.        0.       11.6158    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       27.912
 11.757     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.5812    0.996843]
done:False
-------------------------
[155]>>[25]: env.step(1)
action:[0, 4.5812]
reward:0.4316678301548628
observation:
[14.7283    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       24.8026    8.60873   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.10395   0.619461]
done:False
-------------------------
[155]>>[26]: env.step(3)
action:[0, 9.103950000000001]
reward:0.5115476311672459
observation:
[17.7159    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.8031    5.60284   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.00209   0.590437]
done:False
-------------------------
[155]>>[27]: env.step(1)
action:[0, 4.00209]
reward:-24.602919632763395
observation:
[19.0425    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.4652   40.5153    4.28634   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.8098    0.637841]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.9396, 'y': 0.637841, 'z': 0.569638}
.........................
** Rewards description :
count    27.000000
mean     -0.589395
std       4.812922
min     -24.602920
25%       0.063822
50%       0.463842
75%       0.600611
max       0.751847
dtype: float64
#########################
[156]>> env.reset()
=========================
[156]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.2027726676315036
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.15861  0.148826]
done:False
-------------------------
[156]>>[2]: env.step(3)
action:[0, 6.1586099999999995]
reward:0.3906208063991645
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.18911  0.196179]
done:False
-------------------------
[156]>>[3]: env.step(4)
action:[0, 1.594555]
reward:0.39726445754659856
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.41401  0.226387]
done:False
-------------------------
[156]>>[4]: env.step(3)
action:[0, 9.414010000000001]
reward:0.6264713291696835
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.44631  0.245857]
done:False
-------------------------
[156]>>[5]: env.step(3)
action:[0, 10.44631]
reward:0.7564455016696678
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.5336    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.97994   0.270576]
done:False
-------------------------
[156]>>[6]: env.step(3)
action:[0, 11.97994]
reward:0.9096096487626966
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.4336    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.83209   0.302822]
done:False
-------------------------
[156]>>[7]: env.step(3)
action:[0, 13.83209]
reward:0.9943973758716493
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.489     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.68255   0.340097]
done:False
-------------------------
[156]>>[8]: env.step(5)
action:[0, 9.68255]
reward:0.9681217507776851
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.9854   49.7983    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.306     0.380607]
done:False
-------------------------
[156]>>[9]: env.step(0)
action:[-3.5, 10.306]
reward:0.22413569864701
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.6477  42.7008   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.2443  -2.81323]
done:False
-------------------------
[156]>>[10]: env.step(5)
action:[-3.5, 10.2443]
reward:0.9641270170438562
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.9428   0.      35.434    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.1032  -2.93818]
done:False
-------------------------
[156]>>[11]: env.step(3)
action:[-3.5, 15.1032]
reward:1.0313663197290337
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.13799  0.       0.       0.
  0.      27.9698   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.95892 -2.99503]
done:False
-------------------------
[156]>>[12]: env.step(3)
action:[-3.5, 14.95892]
reward:1.0216438459886632
observation:
[ 0.       0.       0.       0.       0.       0.       6.99186  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.5958   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.83733 -2.9648 ]
done:False
-------------------------
[156]>>[13]: env.step(0)
action:[-3.5, 9.83733]
reward:0.9796052351351511
observation:
[ 0.       0.       0.      11.9884   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.152    0.      48.98     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.4474  -2.92273]
done:False
-------------------------
[156]>>[14]: env.step(5)
action:[-3.5, 10.4474]
reward:1.0380768351383336
observation:
[ 0.      19.3732   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.35355
 21.7717   0.      40.8017   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.2323  -2.87722]
done:False
-------------------------
[156]>>[15]: env.step(0)
action:[-3.5, 11.2323]
reward:1.0466970257067523
observation:
[ 0.      27.4475   0.       4.46494  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.9371
  0.       0.      32.3893   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.1774  -2.8311 ]
done:False
-------------------------
[156]>>[16]: env.step(4)
action:[-3.5, 9.1774]
reward:0.9473704501629866
observation:
[ 0.      35.091    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.83454  0.       0.       0.
  0.       0.      24.5809   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.1099  -2.78848]
done:False
-------------------------
[156]>>[17]: env.step(2)
action:[3.5, 10.1099]
reward:-0.5377338105544778
observation:
[ 0.         0.         0.         0.         0.        17.954
 41.0786     0.         0.         0.         0.         0.
  3.89667    0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 42.3328    18.6054     0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
 10.1078     0.0769228]
done:False
-------------------------
[156]>>[18]: env.step(1)
action:[0, 10.1078]
reward:-24.79741379579429
observation:
[ 0.       0.       0.       0.       0.       0.      18.8606  41.7349
  0.       3.07269  0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      41.7853  18.3798   0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.95797  1.9473 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 101.547, 'y': 1.9473, 'z': 0.570246}
.........................
** Rewards description :
count    18.000000
mean     -0.713135
std       6.025602
min     -24.797414
25%       0.392282
50%       0.928490
75%       0.990699
max       1.046697
dtype: float64
#########################
[157]>> env.reset()
=========================
[157]>>[1]: env.step(4)
action:[0, 7.9823]
reward:0.2619279306661869
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.1335   -0.536387]
done:False
-------------------------
[157]>>[2]: env.step(5)
action:[0, 1.1335]
reward:0.16200512371165537
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.63368  -0.742224]
done:False
-------------------------
[157]>>[3]: env.step(5)
action:[0, 1.63368]
reward:0.1739761565731871
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.65257  -0.719092]
done:False
-------------------------
[157]>>[4]: env.step(3)
action:[0, 6.65257]
reward:0.31309764293987563
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.09644  -0.210063]
done:False
-------------------------
[157]>>[5]: env.step(3)
action:[0, 7.096439999999999]
reward:0.4404619207745351
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.58735  0.207974]
done:False
-------------------------
[157]>>[6]: env.step(3)
action:[0, 8.58735]
reward:0.5845327062140977
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.09151  0.257047]
done:False
-------------------------
[157]>>[7]: env.step(3)
action:[0, 10.09151]
reward:0.6742673605680793
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      48.2473   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.92624  0.26854]
done:False
-------------------------
[157]>>[8]: env.step(1)
action:[0, 5.92624]
reward:0.6033162390374778
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       43.7721    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.00734   0.291382]
done:False
-------------------------
[157]>>[9]: env.step(5)
action:[0, 6.00734]
reward:0.5972966035172451
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.0233    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.90661   0.316496]
done:False
-------------------------
[157]>>[10]: env.step(0)
action:[-3.5, 5.90661]
reward:-0.14895227676004907
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      35.6784   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.98191 -1.82444]
done:False
-------------------------
[157]>>[11]: env.step(5)
action:[-3.5, 5.98191]
reward:0.5987740372954193
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      32.6922
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.9327  -3.99115]
done:False
-------------------------
[157]>>[12]: env.step(0)
action:[-3.5, 5.9327]
reward:0.584171602649504
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.4969   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.75037 -3.0862 ]
done:False
-------------------------
[157]>>[13]: env.step(5)
action:[-3.5, 5.75037]
reward:0.5561343992341157
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.5471  46.702    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.42467 -3.11789]
done:False
-------------------------
[157]>>[14]: env.step(1)
action:[0, 5.42467]
reward:-0.20836324505560944
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 20.7059  42.6944   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.31532 -3.10607]
done:False
-------------------------
[157]>>[15]: env.step(5)
action:[0, 5.31532]
reward:0.5326046893430237
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      17.0021
  0.      38.7541   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.22421 -3.07349]
done:False
-------------------------
[157]>>[16]: env.step(1)
action:[0, 5.22421]
reward:0.5239992650663654
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.4982
  0.      34.8832   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.13442 -3.04216]
done:False
-------------------------
[157]>>[17]: env.step(4)
action:[0, 3.1344200000000004]
reward:0.38350426961469736
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      10.538    0.      32.1559   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.85545 -1.60374]
done:False
-------------------------
[157]>>[18]: env.step(4)
action:[0, 1.927725]
reward:0.355204957199309
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        8.09077   0.
 46.6206   30.4401    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.8019    0.565354]
done:False
-------------------------
[157]>>[19]: env.step(0)
action:[-3.5, 3.8019]
reward:-0.38799791097493874
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.52747   0.        0.       43.8209   27.6528    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.41846   0.561709]
done:False
-------------------------
[157]>>[20]: env.step(0)
action:[-3.5, 3.41846]
reward:0.3437012495722058
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.70954  0.       0.       0.
  0.      41.3356  25.1596   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.28549  0.50864]
done:False
-------------------------
[157]>>[21]: env.step(0)
action:[-3.5, 3.28549]
reward:0.3501367641477309
observation:
[ 0.        0.        0.        0.        0.        4.09229   0.
  0.        0.        0.        0.        0.        0.       39.3111
 23.0171    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.39909  -0.660782]
done:False
-------------------------
[157]>>[22]: env.step(5)
action:[-3.5, 3.39909]
reward:0.33293463714560745
observation:
[ 0.       0.       6.16487  0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.734    0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.15616 -2.69374]
done:False
-------------------------
[157]>>[23]: env.step(2)
action:[3.5, 3.15616]
reward:-1.1766754549408311
observation:
[ 0.       0.       0.       0.       0.       7.45687  0.       0.
  0.       0.       0.       0.       0.       0.       0.      36.1203
 19.6187   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.09741 -3.11209]
done:False
-------------------------
[157]>>[24]: env.step(4)
action:[3.5, 1.548705]
reward:0.22448017765549166
observation:
[ 0.       0.       0.       0.       0.       0.       7.90001  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      34.3552  17.8738   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.2848  -2.30804]
done:False
-------------------------
[157]>>[25]: env.step(3)
action:[3.5, 7.284800000000001]
reward:0.36828409861891565
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        7.88003   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 33.0408   16.647     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.62651  -0.921192]
done:False
-------------------------
[157]>>[26]: env.step(1)
action:[0, 2.62651]
reward:-0.413509602524326
observation:
[ 0.        0.        0.        0.        0.        8.47141   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       31.3455
 15.1305    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.39358   0.641682]
done:False
-------------------------
[157]>>[27]: env.step(0)
action:[-3.5, 3.39358]
reward:-0.42761158010497674
observation:
[ 0.       10.6257    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.0127   12.8169    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.02643   0.633567]
done:False
-------------------------
[157]>>[28]: env.step(4)
action:[-3.5, 1.513215]
reward:0.2747745021382007
observation:
[ 0.       12.7636    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.8138   10.6138    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.90841   0.605588]
done:False
-------------------------
[157]>>[29]: env.step(5)
action:[-3.5, 2.90841]
reward:0.2948679603843478
observation:
[ 0.       14.9908    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.5484    8.34586   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.80705   0.615573]
done:False
-------------------------
[157]>>[30]: env.step(3)
action:[-3.5, 7.80705]
reward:0.42215828786677534
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       22.8248
  6.40725  42.6382    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       17.0356
  0.        3.17643  -0.448184]
done:False
-------------------------
[157]>>[31]: env.step(3)
action:[-3.5, 8.17643]
reward:0.5484412645985276
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       5.19498 21.6419   0.      40.7339   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      19.3777   0.       0.       4.71682 -2.84485]
done:False
-------------------------
[157]>>[32]: env.step(3)
action:[-3.5, 9.71682]
reward:0.6617689892092913
observation:
[ 0.       0.      23.2022   0.       0.       0.       0.       0.
  0.       0.       0.       2.83367  0.       0.       0.       0.
 18.098    0.       0.      36.837    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.84911 -3.09441]
done:False
-------------------------
[157]>>[33]: env.step(5)
action:[-3.5, 5.84911]
reward:0.6578748790762489
observation:
[ 0.      27.5875   0.       4.59709  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.833
  0.       0.      32.2526   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.76297 -2.87593]
done:False
-------------------------
[157]>>[34]: env.step(3)
action:[-3.5, 11.76297]
reward:0.7831753688057026
observation:
[ 0.      32.6916   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.48401  0.       0.
  0.       0.      27.0239   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.03019 -2.81455]
done:False
-------------------------
[157]>>[35]: env.step(0)
action:[-3.5, 7.03019]
reward:0.7679268120594225
observation:
[15.0168  38.3348   0.       0.       0.       0.       0.       0.
  0.       0.       6.48485  0.       0.       0.       0.       0.
  0.       0.      21.2911   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.99644 -2.7755 ]
done:False
-------------------------
[157]>>[36]: env.step(0)
action:[-3.5, 7.99644]
reward:0.7866698116752071
observation:
[44.2841   0.       0.       0.       0.       7.92087  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.2832   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.02173 -2.73935]
done:False
-------------------------
[157]>>[37]: env.step(2)
action:[3.5, 8.02173]
reward:-0.7055998438025908
observation:
[ 0.        0.        0.        0.        0.       25.8156   48.9442
 10.4166    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.4764   10.9809    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.12607  -0.127002]
done:False
-------------------------
[157]>>[38]: env.step(0)
action:[-3.5, 8.12607]
reward:-0.710733162070523
observation:
[ 0.      29.8111   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      31.6107   0.       0.
  0.      10.4548   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.02646  4.15214]
done:False
-------------------------
[157]>>[39]: env.step(2)
action:[3.5, 8.02646]
reward:-0.7367847541988836
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      25.784    0.       0.       0.
  0.       0.       8.44708  0.       0.       0.       0.       0.
  0.       0.       0.      35.9631   7.68061  4.42103]
done:False
-------------------------
[157]>>[40]: env.step(0)
action:[-3.5, 7.68061]
reward:-0.7507235909732294
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      20.4498   0.       0.       0.
  0.       0.       0.       0.       0.       0.       9.94474  0.
  0.       0.       0.      41.6255   7.57029  4.39788]
done:False
-------------------------
[157]>>[41]: env.step(0)
action:[-3.5, 7.57029]
reward:0.739990528334564
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      15.4622   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.8      0.       0.      47.2284   7.46737  4.41117]
done:False
-------------------------
[157]>>[42]: env.step(0)
action:[-3.5, 7.46737]
reward:0.731318011687269
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.9036   0.       0.       0.      11.1674   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      18.5247   0.      36.4816   7.37164  4.43606]
done:False
-------------------------
[157]>>[43]: env.step(5)
action:[-3.5, 7.37164]
reward:0.7308343114290167
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      44.2026   0.       0.       0.
  0.       0.       6.63659  0.       0.       0.       0.       0.
  0.       0.       0.       0.      21.9183   0.      41.0559   0.
  0.       0.       0.       0.       7.38881  2.11924]
done:False
-------------------------
[157]>>[44]: env.step(4)
action:[-3.5, 5.38881]
reward:-24.37564553422452
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      43.3902   0.       0.       0.       0.       3.21209  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      21.987   42.1312   0.       0.       0.
  0.       0.       0.       0.       6.42409 -1.54324]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 34}
{'x': 140.808, 'y': -1.54324, 'z': 0.567675}
.........................
** Rewards description :
count    44.000000
mean     -0.310863
std       3.745531
min     -24.375646
25%       0.084266
50%       0.361745
75%       0.597666
max       0.786670
dtype: float64
#########################
[158]>> env.reset()
=========================
[158]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.12036946536274407
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.168992 0.31388 ]
done:False
-------------------------
[158]>>[2]: env.step(3)
action:[0, 5.168992]
reward:0.20433181274310086
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.13524  0.424526]
done:False
-------------------------
[158]>>[3]: env.step(3)
action:[0, 6.13524]
reward:0.3885521375399004
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.16886  0.275914]
done:False
-------------------------
[158]>>[4]: env.step(1)
action:[0, 3.16886]
reward:0.3744788133341986
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.73329  0.227787]
done:False
-------------------------
[158]>>[5]: env.step(3)
action:[0, 8.73329]
reward:0.4951049261885161
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.88117  0.236805]
done:False
-------------------------
[158]>>[6]: env.step(3)
action:[0, 8.881170000000001]
reward:0.6191474434392039
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       49.8997    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.48093   0.256762]
done:False
-------------------------
[158]>>[7]: env.step(5)
action:[0, 5.48093]
reward:0.6417808746689302
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       45.2851    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.63643   0.281943]
done:False
-------------------------
[158]>>[8]: env.step(4)
action:[0, 4.63643]
reward:0.5407311607225991
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.8123    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.50049   0.306815]
done:False
-------------------------
[158]>>[9]: env.step(4)
action:[0, 3.50049]
reward:0.42188930221499943
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.1192    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.24965   0.327323]
done:False
-------------------------
[158]>>[10]: env.step(3)
action:[0, 9.249649999999999]
reward:0.526682517399301
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.9897    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.16313   0.344291]
done:False
-------------------------
[158]>>[11]: env.step(5)
action:[0, 4.16313]
reward:0.536536362716397
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.37      0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.56378   0.363521]
done:False
-------------------------
[158]>>[12]: env.step(5)
action:[0, 5.56378]
reward:0.6241556569267155
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       25.8007   48.6061    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.37767   0.388102]
done:False
-------------------------
[158]>>[13]: env.step(1)
action:[0, 6.37767]
reward:0.6343577467316212
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       21.0792   43.8457    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.31182   0.413816]
done:False
-------------------------
[158]>>[14]: env.step(4)
action:[0, 4.31182]
reward:0.5076118866062875
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.024     0.       39.7394    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.14891   0.436302]
done:False
-------------------------
[158]>>[15]: env.step(5)
action:[0, 5.14891]
reward:0.5156921519888183
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.2879    0.       35.9271    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.04484   0.456909]
done:False
-------------------------
[158]>>[16]: env.step(5)
action:[0, 5.04484]
reward:0.5067540390867222
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.67793  48.3501   32.1837    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.9545    0.477146]
done:False
-------------------------
[158]>>[17]: env.step(0)
action:[-3.5, 4.9545]
reward:-0.23406944842449284
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       7.60316  0.       0.       0.      29.0279   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.09655 -1.17571]
done:False
-------------------------
[158]>>[18]: env.step(3)
action:[-3.5, 10.09655]
reward:0.6114473057756573
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       7.79458  0.       0.       0.       0.      26.6356   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.07368 -3.58333]
done:False
-------------------------
[158]>>[19]: env.step(3)
action:[-3.5, 10.07368]
reward:0.6851314834762733
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.48505  0.       0.       0.       0.       0.       0.       0.
  0.      22.4198   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.07977 -2.85591]
done:False
-------------------------
[158]>>[20]: env.step(3)
action:[-3.5, 11.07977]
reward:0.8301073211815861
observation:
[ 0.       0.       0.       0.       8.77001  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 33.7406  17.2263   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.87749 -2.88629]
done:False
-------------------------
[158]>>[21]: env.step(0)
action:[-3.5, 7.87749]
reward:0.8532435631087774
observation:
[ 0.       0.      14.0106   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.8509   0.      46.6319   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.01675 -2.89   ]
done:False
-------------------------
[158]>>[22]: env.step(3)
action:[-3.5, 14.01675]
reward:0.9995559305584608
observation:
[ 0.      20.4771   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       4.35274  0.
 20.6542   0.      39.6328   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.71844 -2.86549]
done:False
-------------------------
[158]>>[23]: env.step(1)
action:[0, 9.71844]
reward:0.25889149308412085
observation:
[ 0.      27.9994   0.       4.94449  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.4337
  0.       0.      31.8219   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9422  -2.82721]
done:False
-------------------------
[158]>>[24]: env.step(5)
action:[0, 10.9422]
reward:1.0660489628179877
observation:
[ 0.        0.        0.       11.8077   34.929     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        5.38257   0.        0.
  0.       24.6728    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.5704    0.254691]
done:False
-------------------------
[158]>>[25]: env.step(4)
action:[0, 9.5704]
reward:0.9864390563165804
observation:
[ 0.        0.        0.        4.59847   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.7359   17.1201    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 42.6913   10.6219    0.631928]
done:False
-------------------------
[158]>>[26]: env.step(4)
action:[0, 8.6219]
reward:0.9619965230476462
observation:
[ 0.       11.7437    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       32.9322    0.        9.84996
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 27.5052   10.4756    0.788407]
done:False
-------------------------
[158]>>[27]: env.step(0)
action:[-3.5, 10.4756]
reward:-24.765308419759283
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      25.7707   0.
  0.       0.       2.53876  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.4231  19.1753   0.       0.      10.368   -2.09495]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 117.172, 'y': -2.09495, 'z': 0.570913}
.........................
** Rewards description :
count    27.000000
mean     -0.373642
std       4.883107
min     -24.765308
25%       0.405221
50%       0.536536
75%       0.663456
max       1.066049
dtype: float64
#########################
[159]>> env.reset()
=========================
[159]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.19611123552309553
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.07802  0.880554]
done:False
-------------------------
[159]>>[2]: env.step(3)
action:[0, 6.07802]
reward:0.3162490026547279
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.27914 1.44715]
done:False
-------------------------
[159]>>[3]: env.step(3)
action:[0, 7.27914]
reward:0.4486288974221789
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.64611 1.65474]
done:False
-------------------------
[159]>>[4]: env.step(3)
action:[0, 8.64611]
reward:0.5415613613005278
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.50897  0.268014]
done:False
-------------------------
[159]>>[5]: env.step(4)
action:[0, 2.254485]
reward:0.5235636271734327
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.87116  0.196532]
done:False
-------------------------
[159]>>[6]: env.step(3)
action:[0, 10.87116]
reward:0.7554708899482199
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.5067    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.85997   0.254459]
done:False
-------------------------
[159]>>[7]: env.step(4)
action:[0, 4.85997]
reward:0.5571359907450102
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.9527    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.66048   0.293436]
done:False
-------------------------
[159]>>[8]: env.step(2)
action:[3.5, 5.66048]
reward:-0.16648378678014708
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      38.2371   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.80971  2.08833]
done:False
-------------------------
[159]>>[9]: env.step(4)
action:[3.5, 3.80971]
reward:0.541858357021693
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      34.9199   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.72197  4.69515]
done:False
-------------------------
[159]>>[10]: env.step(3)
action:[3.5, 10.721969999999999]
reward:0.6582915587643614
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.9401   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.55043  3.74856]
done:False
-------------------------
[159]>>[11]: env.step(4)
action:[3.5, 3.5504300000000004]
reward:0.4373032652272989
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      27.4501   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.43352  3.86032]
done:False
-------------------------
[159]>>[12]: env.step(5)
action:[3.5, 4.43352]
reward:0.44917608356345945
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      24.1631   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.36452  3.91421]
done:False
-------------------------
[159]>>[13]: env.step(5)
action:[3.5, 4.36452]
reward:0.4398011501741522
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.94     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.26189  3.92553]
done:False
-------------------------
[159]>>[14]: env.step(3)
action:[3.5, 9.261890000000001]
reward:0.5281346135072131
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.7838   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.17906  3.93302]
done:False
-------------------------
[159]>>[15]: env.step(5)
action:[3.5, 4.17906]
reward:0.5361094335856923
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.1571   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.5542   3.94941]
done:False
-------------------------
[159]>>[16]: env.step(4)
action:[3.5, 3.5542]
reward:0.6339020110175198
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.37964 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.01153 3.97498]
done:False
-------------------------
[159]>>[17]: env.step(0)
action:[-3.5, 7.01153]
reward:-0.7386130171883002
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.85743  0.      43.615   27.5761   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.90847  1.73861]
done:False
-------------------------
[159]>>[18]: env.step(3)
action:[-3.5, 12.908470000000001]
reward:0.8611865571338898
observation:
[ 0.       0.       0.       0.       7.79572  0.       0.       0.
  0.       0.      42.4614  25.971    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.87612 -3.80614]
done:False
-------------------------
[159]>>[19]: env.step(4)
action:[-3.5, 5.87612]
reward:0.6682088373815633
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  8.93558  0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.1893   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.8972  -5.12736]
done:False
-------------------------
[159]>>[20]: env.step(0)
action:[-3.5, 6.8972]
reward:0.6844250977502959
observation:
[ 0.       0.       0.       0.       0.       8.9595   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.5974   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.86418 -2.48312]
done:False
-------------------------
[159]>>[21]: env.step(1)
action:[0, 6.86418]
reward:-0.08176738250000148
observation:
[ 0.        0.        0.        0.        0.        0.        0.
 11.5374    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       12.2562   48.4401    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.65051  -0.628634]
done:False
-------------------------
[159]>>[22]: env.step(3)
action:[0, 11.65051]
reward:0.750020320344259
observation:
[15.0492   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      24.3247   8.27157  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.58829  1.25062]
done:False
-------------------------
[159]>>[23]: env.step(5)
action:[0, 6.58829]
reward:-24.3309701296572
observation:
[ 0.      19.1721   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.327    0.       4.16138  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.73038  0.6508 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.9331, 'y': 0.6508, 'z': 0.57164}
.........................
** Rewards description :
count    23.000000
mean     -0.643074
std       5.175789
min     -24.330970
25%       0.376776
50%       0.528135
75%       0.646097
max       0.861187
dtype: float64
#########################
[160]>> env.reset()
=========================
[160]>>[1]: env.step(2)
action:[3.5, 0.0]
reward:-0.7462375354458298
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0439092 0.169182 ]
done:False
-------------------------
[160]>>[2]: env.step(3)
action:[3.5, 5.0439092]
reward:0.20642053453837228
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.19181  0.113939]
done:False
-------------------------
[160]>>[3]: env.step(3)
action:[3.5, 6.19181]
reward:0.3867676568706805
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.13222  0.780192]
done:False
-------------------------
[160]>>[4]: env.step(3)
action:[3.5, 8.13222]
reward:0.5089465075658874
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.21117 3.00062]
done:False
-------------------------
[160]>>[5]: env.step(3)
action:[3.5, 9.21117]
reward:0.6419085918452492
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.7056  4.21467]
done:False
-------------------------
[160]>>[6]: env.step(3)
action:[3.5, 10.7056]
reward:0.7384851113960613
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.284    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.66243  3.85005]
done:False
-------------------------
[160]>>[7]: env.step(5)
action:[3.5, 6.66243]
reward:0.7214093382663589
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.876    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.43459  3.82012]
done:False
-------------------------
[160]>>[8]: env.step(1)
action:[0, 7.43459]
reward:-0.021069341238203254
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      38.3375   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.34647  3.8289 ]
done:False
-------------------------
[160]>>[9]: env.step(5)
action:[0, 7.34647]
reward:0.7221005613164275
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      33.5401   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.27321  1.21314]
done:False
-------------------------
[160]>>[10]: env.step(3)
action:[0, 12.273209999999999]
reward:0.8156594915492439
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       28.8382    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.36941  -0.162537]
done:False
-------------------------
[160]>>[11]: env.step(2)
action:[3.5, 7.36941]
reward:-0.023570624089432002
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.731
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.32784  3.53373]
done:False
-------------------------
[160]>>[12]: env.step(2)
action:[3.5, 7.32784]
reward:0.7324547603026684
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 19.711   42.9533   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.42242  4.52096]
done:False
-------------------------
[160]>>[13]: env.step(0)
action:[-3.5, 7.42242]
reward:-0.7861844499573662
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.4339   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.13896  4.07114]
done:False
-------------------------
[160]>>[14]: env.step(3)
action:[-3.5, 12.13896]
reward:0.8026715970076799
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      10.3725  33.1934   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.21557  1.39814]
done:False
-------------------------
[160]>>[15]: env.step(3)
action:[-3.5, 12.21557]
reward:0.8191593283382064
observation:
[ 0.       0.       0.       0.       0.       0.       0.      11.4077
  0.       0.      32.0088   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.4345  -3.73592]
done:False
-------------------------
[160]>>[16]: env.step(3)
action:[-3.5, 12.4345]
reward:0.9789291422234765
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       9.89159  0.       0.       0.       0.
  0.      26.6691   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.78747 -5.90933]
done:False
-------------------------
[160]>>[17]: env.step(0)
action:[-3.5, 9.78747]
reward:0.9958509832118848
observation:
[ 0.       0.       0.       0.       0.       0.       6.84814  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      35.931   19.4697   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.7168  -2.2553 ]
done:False
-------------------------
[160]>>[18]: env.step(0)
action:[-3.5, 10.7168]
reward:1.0253045117860378
observation:
[ 0.       0.       0.      13.3231   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.6461  47.4362   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9571  -2.94265]
done:False
-------------------------
[160]>>[19]: env.step(2)
action:[3.5, 10.9571]
reward:-0.4752587706424305
observation:
[ 0.        0.        0.        0.        0.        0.        0.
 18.8555    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.5249    0.       40.693     4.53123   0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.8879    0.980686]
done:False
-------------------------
[160]>>[20]: env.step(3)
action:[3.5, 15.8879]
reward:1.094633098261271
observation:
[24.1101   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.46     0.       0.       0.
  0.       0.       0.       0.       7.02551  0.       0.       0.
  0.       0.       0.       0.      10.816    6.63609]
done:False
-------------------------
[160]>>[21]: env.step(2)
action:[3.5, 10.816]
reward:1.026593854169442
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  7.7967   0.      28.8799   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       9.27738
  0.       0.      31.279    0.      10.9532   3.8495 ]
done:False
-------------------------
[160]>>[22]: env.step(4)
action:[3.5, 8.9532]
reward:-24.053474748988656
observation:
[35.3985   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.72752 25.0602   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      13.2013  10.1529   4.1865 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 95.194, 'y': 4.1865, 'z': 0.565614}
.........................
** Rewards description :
count    22.000000
mean     -0.631295
std       5.261833
min     -24.053475
25%       0.035803
50%       0.721755
75%       0.818284
max       1.094633
dtype: float64
#########################
[161]>> env.reset()
=========================
[161]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.15254405054836923
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.553533 -0.161278]
done:False
-------------------------
[161]>>[2]: env.step(0)
action:[-3.5, 0.553533]
reward:-0.6859150450379651
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.613355 -0.479193]
done:False
-------------------------
[161]>>[3]: env.step(3)
action:[-3.5, 5.613355]
reward:0.18280148786317824
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.763978 -0.861078]
done:False
-------------------------
[161]>>[4]: env.step(3)
action:[-3.5, 5.763978]
reward:0.2975275220712541
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.12599 -1.87169]
done:False
-------------------------
[161]>>[5]: env.step(5)
action:[-3.5, 2.12599]
reward:0.36827672754885044
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.91612 -3.90444]
done:False
-------------------------
[161]>>[6]: env.step(3)
action:[-3.5, 8.91612]
reward:0.5671739145902553
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.77905 -5.10157]
done:False
-------------------------
[161]>>[7]: env.step(3)
action:[-3.5, 9.77905]
reward:0.6236920911986077
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.31761 -3.48684]
done:False
-------------------------
[161]>>[8]: env.step(3)
action:[-3.5, 10.31761]
reward:0.7233429499776108
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.54774 -3.3402 ]
done:False
-------------------------
[161]>>[9]: env.step(3)
action:[-3.5, 11.547740000000001]
reward:0.8295031085585387
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      44.2965   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.7517  -3.23931]
done:False
-------------------------
[161]>>[10]: env.step(1)
action:[0, 7.7517]
reward:0.06726177375474252
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.2095   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.52298 -3.18779]
done:False
-------------------------
[161]>>[11]: env.step(2)
action:[3.5, 8.52298]
reward:0.09966189255173374
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       32.495     0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.80271  -0.415949]
done:False
-------------------------
[161]>>[12]: env.step(4)
action:[3.5, 6.802709999999999]
reward:0.8128570842539542
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      29.8275   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.69651  5.47316]
done:False
-------------------------
[161]>>[13]: env.step(4)
action:[3.5, 6.69651]
reward:0.7298961631894869
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.4327
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.54448  5.54148]
done:False
-------------------------
[161]>>[14]: env.step(3)
action:[3.5, 12.54448]
reward:0.8259493999140739
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.5015  42.6826   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.45082  3.61461]
done:False
-------------------------
[161]>>[15]: env.step(4)
action:[3.5, 5.45082]
reward:0.7543691972825384
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      13.7804   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.19951  3.87159]
done:False
-------------------------
[161]>>[16]: env.step(1)
action:[0, 8.19951]
reward:0.10393279127119825
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       8.36326 47.2256  31.1568   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.94639  1.51745]
done:False
-------------------------
[161]>>[17]: env.step(3)
action:[0, 13.94639]
reward:0.9496506405085482
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        3.90208
  0.        0.        0.        0.        0.       25.0192    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.95289   0.182124]
done:False
-------------------------
[161]>>[18]: env.step(3)
action:[0, 13.95289]
reward:1.0145668289694894
observation:
[ 0.        0.        0.        5.86284   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.2254   18.0234    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.97472   0.452635]
done:False
-------------------------
[161]>>[19]: env.step(4)
action:[0, 7.97472]
reward:0.8579782412615847
observation:
[ 0.       12.854     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.7324   10.5258    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.0622    0.574411]
done:False
-------------------------
[161]>>[20]: env.step(4)
action:[0, 7.062200000000001]
reward:0.7739443657081877
observation:
[18.9813    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.5293   40.5771    4.34594   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.07389   0.622419]
done:False
-------------------------
[161]>>[21]: env.step(3)
action:[0, 13.07389]
reward:-24.1233787982981
observation:
[19.379    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      20.1302  40.1773   3.95495  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.06361  0.62596]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.0673, 'y': 0.62596, 'z': 0.572433}
.........................
** Rewards description :
count    21.000000
mean     -0.670208
std       5.389407
min     -24.123379
25%       0.152544
50%       0.623692
75%       0.812857
max       1.014567
dtype: float64
#########################
[162]>> env.reset()
=========================
[162]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.10737334645137331
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0143179 0.208831 ]
done:False
-------------------------
[162]>>[2]: env.step(3)
action:[0, 5.0143179]
reward:0.1076615249664213
observation:
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.0141642 0.219452 ]
done:False
-------------------------
[162]>>[3]: env.step(2)
action:[3.5, 0.0141642]
reward:-0.7168041706603743
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.384827 0.24154 ]
done:False
-------------------------
[162]>>[4]: env.step(3)
action:[3.5, 5.384827]
reward:0.20626530552455868
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.1047   0.449742]
done:False
-------------------------
[162]>>[5]: env.step(3)
action:[3.5, 6.1047]
reward:0.36566197714114346
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.88864 1.34999]
done:False
-------------------------
[162]>>[6]: env.step(3)
action:[3.5, 7.8886400000000005]
reward:0.5124855395429159
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.31813 3.61917]
done:False
-------------------------
[162]>>[7]: env.step(5)
action:[3.5, 4.31813]
reward:0.4787929041433718
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.77402 3.90109]
done:False
-------------------------
[162]>>[8]: env.step(2)
action:[3.5, 4.77402]
reward:0.4684324273971817
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.52655 3.73864]
done:False
-------------------------
[162]>>[9]: env.step(3)
action:[3.5, 9.52655]
reward:0.5519105857560864
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      47.1157   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.42496  3.75621]
done:False
-------------------------
[162]>>[10]: env.step(2)
action:[3.5, 4.42496]
reward:0.5021394670474323
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      43.5845   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.04951  3.78761]
done:False
-------------------------
[162]>>[11]: env.step(0)
action:[-3.5, 5.04951]
reward:-0.9689901147793827
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      40.4274   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.26978  1.93398]
done:False
-------------------------
[162]>>[12]: env.step(5)
action:[-3.5, 5.26978]
reward:0.5088196783752146
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      39.869    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.92513 -1.79842]
done:False
-------------------------
[162]>>[13]: env.step(4)
action:[-3.5, 2.462565]
reward:0.3163809584002004
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      39.0288   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.18464 -4.17331]
done:False
-------------------------
[162]>>[14]: env.step(4)
action:[-3.5, 1.59232]
reward:0.28474745174018473
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      37.1703
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.01131 -4.74463]
done:False
-------------------------
[162]>>[15]: env.step(5)
action:[-3.5, 3.01131]
reward:0.3047480137469688
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      35.0777   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.90339 -3.98984]
done:False
-------------------------
[162]>>[16]: env.step(2)
action:[3.5, 2.90339]
reward:-1.2037341022335009
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      33.4518   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.82556 -2.34428]
done:False
-------------------------
[162]>>[17]: env.step(2)
action:[3.5, 2.82556]
reward:0.271915181705681
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.6804    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.5452   -0.356834]
done:False
-------------------------
[162]>>[18]: env.step(5)
action:[3.5, 2.5452]
reward:0.25740689030871144
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      32.2629   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.4374   1.50238]
done:False
-------------------------
[162]>>[19]: env.step(2)
action:[3.5, 2.4374]
reward:0.23812842703600623
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      32.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.22881  3.3264 ]
done:False
-------------------------
[162]>>[20]: env.step(2)
action:[3.5, 2.22881]
reward:0.2350546578289366
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.1743   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.24349  4.66257]
done:False
-------------------------
[162]>>[21]: env.step(5)
action:[3.5, 2.24349]
reward:0.22817280421419892
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.8793   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.15602  5.38043]
done:False
-------------------------
[162]>>[22]: env.step(2)
action:[3.5, 2.15602]
reward:0.22080164055415197
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      28.3888   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.08826  5.40006]
done:False
-------------------------
[162]>>[23]: env.step(3)
action:[3.5, 7.08826]
reward:0.3193044562358536
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 26.9612   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.06448  4.77453]
done:False
-------------------------
[162]>>[24]: env.step(3)
action:[3.5, 7.06448]
reward:0.30647086306176113
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 25.6325   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.91141  4.11379]
done:False
-------------------------
[162]>>[25]: env.step(5)
action:[3.5, 1.91141]
reward:0.19804655625848788
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 24.2667  47.4538   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.87357  3.91652]
done:False
-------------------------
[162]>>[26]: env.step(5)
action:[3.5, 1.87357]
reward:0.19908244600101557
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      22.8548  46.0419   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.89556  3.88454]
done:False
-------------------------
[162]>>[27]: env.step(3)
action:[3.5, 6.89556]
reward:0.3362248692188451
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.3381  44.5307   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.32301  3.89417]
done:False
-------------------------
[162]>>[28]: env.step(3)
action:[3.5, 7.32301]
reward:0.4868403821687557
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      18.8584   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.12675  3.91978]
done:False
-------------------------
[162]>>[29]: env.step(3)
action:[3.5, 9.126750000000001]
reward:0.6434706588415136
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      14.8156   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.74787  3.94583]
done:False
-------------------------
[162]>>[30]: env.step(3)
action:[3.5, 10.747869999999999]
reward:0.7732949198254782
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.95574 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.14324 3.97213]
done:False
-------------------------
[162]>>[31]: env.step(3)
action:[3.5, 12.143239999999999]
reward:0.903168907969996
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.91883 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.69397 4.00461]
done:False
-------------------------
[162]>>[32]: env.step(3)
action:[3.5, 13.69397]
reward:-24.059980118383077
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 3.04123 0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.86747 4.00942]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 27}
{'x': 56.8638, 'y': 4.00942, 'z': 0.569997}
.........................
** Rewards description :
count    32.000000
mean     -0.519272
std       4.317861
min     -24.059980
25%       0.204470
50%       0.294748
75%       0.480805
max       0.903169
dtype: float64
#########################
[163]>> env.reset()
=========================
[163]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.4137449017929531
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.77133  0.207116]
done:False
-------------------------
[163]>>[2]: env.step(3)
action:[0, 8.771329999999999]
reward:0.5813744708397484
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.00353  0.224921]
done:False
-------------------------
[163]>>[3]: env.step(3)
action:[0, 10.00353]
reward:0.7103129616738058
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.44506  0.248037]
done:False
-------------------------
[163]>>[4]: env.step(3)
action:[0, 11.44506]
reward:0.8606420467799106
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.0943    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.23393   0.277649]
done:False
-------------------------
[163]>>[5]: env.step(3)
action:[0, 13.23393]
reward:0.9352849908652345
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.5782    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.90975   0.312722]
done:False
-------------------------
[163]>>[6]: env.step(3)
action:[0, 13.90975]
reward:0.9800769858645992
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.7643    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.43672   0.349484]
done:False
-------------------------
[163]>>[7]: env.step(4)
action:[0, 7.436719999999999]
reward:0.7949676162020316
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.2756   49.0841    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.28046   0.385008]
done:False
-------------------------
[163]>>[8]: env.step(3)
action:[0, 13.28046]
reward:0.8940638865048142
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.1544   42.9111    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.27267   0.418328]
done:False
-------------------------
[163]>>[9]: env.step(0)
action:[-3.5, 8.27267]
reward:0.1393320042024312
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.1807    0.       35.817     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.45367   0.456312]
done:False
-------------------------
[163]>>[10]: env.step(3)
action:[-3.5, 14.45367]
reward:1.0690235464772266
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       8.70727  0.       0.       0.      29.2428   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.7422  -2.55483]
done:False
-------------------------
[163]>>[11]: env.step(3)
action:[-3.5, 15.7422]
reward:1.1476421412405649
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.7498   0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.2244   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.7773  -2.95036]
done:False
-------------------------
[163]>>[12]: env.step(1)
action:[0, 11.7773]
reward:0.38053627612685204
observation:
[ 0.       0.       0.      12.8033   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 28.7785  12.2318  48.0358   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.4653  -2.94302]
done:False
-------------------------
[163]>>[13]: env.step(3)
action:[0, 17.4653]
reward:1.251712619142709
observation:
[ 0.       0.       0.      19.9554   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      19.549    0.      39.598    3.39544  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.3155   0.52635]
done:False
-------------------------
[163]>>[14]: env.step(4)
action:[0, 11.3155]
reward:-23.82449292835845
observation:
[ 0.        0.       20.5148    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       18.9083   39.0337
  0.        2.93658   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       13.3888    0.829734]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 80.0135, 'y': 0.829734, 'z': 0.569813}
.........................
** Rewards description :
count    14.000000
mean     -0.976127
std       6.583656
min     -23.824493
25%       0.455652
50%       0.827805
75%       0.968879
max       1.251713
dtype: float64
#########################
[164]>> env.reset()
=========================
[164]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.3321301257683221
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.74592  -0.337371]
done:False
-------------------------
[164]>>[2]: env.step(3)
action:[0, 7.74592]
reward:0.49343694769315105
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.1064   0.134214]
done:False
-------------------------
[164]>>[3]: env.step(5)
action:[0, 4.1064]
reward:0.4694678387753686
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.70678  0.259896]
done:False
-------------------------
[164]>>[4]: env.step(3)
action:[0, 9.70678]
reward:0.5929537714461944
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.9238   0.261599]
done:False
-------------------------
[164]>>[5]: env.step(1)
action:[0, 4.9238]
reward:0.5309688265372947
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.8583    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.30067   0.274989]
done:False
-------------------------
[164]>>[6]: env.step(3)
action:[0, 10.30067]
reward:0.6304091097476836
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       42.8878    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.27775   0.294991]
done:False
-------------------------
[164]>>[7]: env.step(5)
action:[0, 5.27775]
reward:0.5306798743520103
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      38.9701   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.2084   0.31633]
done:False
-------------------------
[164]>>[8]: env.step(5)
action:[0, 5.2084]
reward:0.5228530766140287
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.1205    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.1234    0.337586]
done:False
-------------------------
[164]>>[9]: env.step(5)
action:[0, 5.1234]
reward:0.5143817244979334
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       31.0921    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.03414   0.359734]
done:False
-------------------------
[164]>>[10]: env.step(0)
action:[-3.5, 5.03414]
reward:-0.22388636472219126
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      28.2135   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.20957 -1.45933]
done:False
-------------------------
[164]>>[11]: env.step(5)
action:[-3.5, 5.20957]
reward:0.5320260771082906
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      26.0553  48.1484
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.24307 -3.78568]
done:False
-------------------------
[164]>>[12]: env.step(1)
action:[0, 5.24307]
reward:-0.22353278648664088
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      22.4224   0.      44.6473   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.16196 -2.41978]
done:False
-------------------------
[164]>>[13]: env.step(4)
action:[0, 3.1619599999999997]
reward:0.48562973261574605
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 19.7884   42.572     0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.15136   0.770907]
done:False
-------------------------
[164]>>[14]: env.step(0)
action:[-3.5, 5.15136]
reward:-0.23356968579369153
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       16.216    39.0107    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.05385   0.922515]
done:False
-------------------------
[164]>>[15]: env.step(5)
action:[-3.5, 5.05385]
reward:0.498732680320851
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.6286   0.      36.6629   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.84807 -1.87914]
done:False
-------------------------
[164]>>[16]: env.step(0)
action:[-3.5, 4.84807]
reward:0.4983152560092921
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1422   0.       0.      34.1123
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.8941  -3.84745]
done:False
-------------------------
[164]>>[17]: env.step(5)
action:[-3.5, 4.8941]
reward:0.4833496734690077
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       9.99209
  0.       0.      30.6425   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.68886 -2.95466]
done:False
-------------------------
[164]>>[18]: env.step(0)
action:[-3.5, 4.68886]
reward:0.4682832114881236
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.71234  0.       0.       0.
  0.      27.2492   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.54592 -2.95365]
done:False
-------------------------
[164]>>[19]: env.step(3)
action:[-3.5, 9.545919999999999]
reward:0.5735085607508782
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       6.54171  0.       0.       0.       0.       0.       0.
  0.      23.6126   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.70549 -2.98398]
done:False
-------------------------
[164]>>[20]: env.step(5)
action:[-3.5, 4.70549]
reward:0.5084451218075954
observation:
[ 0.       0.       0.       0.       0.       0.       7.2353   0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.4903  19.9941   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.06133 -2.96349]
done:False
-------------------------
[164]>>[21]: env.step(0)
action:[-3.5, 5.06133]
reward:0.5149452040211551
observation:
[ 0.       0.       0.       0.       9.52072  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.7501  16.2265   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.057   -2.93852]
done:False
-------------------------
[164]>>[22]: env.step(1)
action:[0, 5.057]
reward:-0.2176457572291809
observation:
[ 0.       0.       0.       0.       0.       0.       0.      11.2865
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      29.2644  12.8162   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.28551 -1.19299]
done:False
-------------------------
[164]>>[23]: env.step(4)
action:[0, 3.2855100000000004]
reward:0.50052940892988
observation:
[ 0.       0.       0.      13.1231   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.2779  46.451   10.1991   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.31347  1.28621]
done:False
-------------------------
[164]>>[24]: env.step(3)
action:[0, 10.313469999999999]
reward:0.6128531434307237
observation:
[16.8679    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       22.6626   42.7083    6.45327   0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.03831   0.522823]
done:False
-------------------------
[164]>>[25]: env.step(5)
action:[0, 5.03831]
reward:-24.49332383482154
observation:
[19.0558    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       20.4478    0.       40.5014    4.27438   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.95512   0.655167]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 78.8997, 'y': 0.655167, 'z': 0.568657}
.........................
** Rewards description :
count    25.000000
mean     -0.603922
std       4.984890
min     -24.493324
25%       0.468283
50%       0.498733
75%       0.530680
max       0.630409
dtype: float64
#########################
[165]>> env.reset()
=========================
Retrying to reset environment!
[165]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.14517344632904156
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.465236 0.139753]
done:False
-------------------------
[165]>>[2]: env.step(3)
action:[0, 5.465236]
reward:0.2688555172951528
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.84772  0.173338]
done:False
-------------------------
[165]>>[3]: env.step(3)
action:[0, 6.84772]
reward:0.41546503516537847
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       3.33123  0.207985]
done:False
-------------------------
[165]>>[4]: env.step(3)
action:[0, 8.33123]
reward:0.536175221084459
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.51702  0.230242]
done:False
-------------------------
[165]>>[5]: env.step(5)
action:[0, 4.51702]
reward:0.5135492927075838
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.17489  0.250206]
done:False
-------------------------
[165]>>[6]: env.step(5)
action:[0, 5.17489]
reward:0.5260323588900623
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.3889    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.17332   0.271439]
done:False
-------------------------
[165]>>[7]: env.step(4)
action:[0, 3.1733200000000004]
reward:0.38886298957715787
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.1791    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.91326   0.289228]
done:False
-------------------------
[165]>>[8]: env.step(5)
action:[0, 3.91326]
reward:0.40366506773253397
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.2618    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.91528   0.304984]
done:False
-------------------------
[165]>>[9]: env.step(5)
action:[0, 3.91528]
reward:0.40690280487747854
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       38.1203    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.95577   0.321946]
done:False
-------------------------
[165]>>[10]: env.step(5)
action:[0, 3.95577]
reward:0.4105179640765958
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       35.1483    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.99146   0.338032]
done:False
-------------------------
[165]>>[11]: env.step(1)
action:[0, 3.99146]
reward:0.4138745481258955
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       32.1524    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.02511   0.354262]
done:False
-------------------------
[165]>>[12]: env.step(5)
action:[0, 4.02511]
reward:0.4170393392698496
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       29.1347    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.05687   0.370621]
done:False
-------------------------
[165]>>[13]: env.step(5)
action:[0, 4.05687]
reward:0.4200243865592978
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.0975   48.9049    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.08685   0.387105]
done:False
-------------------------
[165]>>[14]: env.step(5)
action:[0, 4.08685]
reward:0.4228432540752201
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       23.0436   45.8283    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.11519   0.403705]
done:False
-------------------------
[165]>>[15]: env.step(1)
action:[0, 4.11519]
reward:0.4255061089016109
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       19.9764   42.7312    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.14198   0.420418]
done:False
-------------------------
[165]>>[16]: env.step(5)
action:[0, 4.14198]
reward:0.42802366321808066
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       16.9013    0.       39.6147    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.16733   0.437236]
done:False
-------------------------
[165]>>[17]: env.step(0)
action:[-3.5, 4.16733]
reward:-0.29936493737052094
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.5736  36.8729   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.44975 -1.00711]
done:False
-------------------------
[165]>>[18]: env.step(4)
action:[-3.5, 2.224875]
reward:0.42296248198715425
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      13.546    0.       0.      34.8621   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.5822  -3.37031]
done:False
-------------------------
[165]>>[19]: env.step(0)
action:[-3.5, 4.5822]
reward:0.44270097474753456
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.6209   0.
  0.      47.867   31.4457   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.24452 -3.00754]
done:False
-------------------------
[165]>>[20]: env.step(4)
action:[-3.5, 2.12226]
reward:0.2822508666671149
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.84336  0.       0.
  0.      29.0535   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.84809 -2.99569]
done:False
-------------------------
[165]>>[21]: env.step(3)
action:[-3.5, 7.84809]
reward:0.41723030096727215
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       7.54188  0.       0.       0.       0.
  0.      26.8738   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.10355 -3.00411]
done:False
-------------------------
[165]>>[22]: env.step(0)
action:[-3.5, 3.10355]
reward:0.3618474636085721
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.64172  0.       0.       0.       0.       0.
  0.      24.3844   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.59111 -2.98458]
done:False
-------------------------
[165]>>[23]: env.step(3)
action:[-3.5, 8.59111]
reward:0.47661488597818674
observation:
[ 0.       0.       0.       0.       0.       0.       0.       6.67376
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      21.6612   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.67768 -2.96369]
done:False
-------------------------
[165]>>[24]: env.step(3)
action:[-3.5, 8.67768]
reward:0.4950268018985745
observation:
[ 0.       0.       0.       0.       0.       7.78876  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 35.373   18.8687   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.89406 -2.94833]
done:False
-------------------------
[165]>>[25]: env.step(0)
action:[-3.5, 3.89406]
reward:0.4355116464197738
observation:
[ 0.       0.       0.       0.       9.81349  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 32.3591  15.8329   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.32475 -2.93302]
done:False
-------------------------
[165]>>[26]: env.step(5)
action:[-3.5, 4.32475]
reward:0.4480751880144873
observation:
[ 0.       0.       0.      12.4558   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 12.6083   0.      48.4264   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       4.37762 -2.91581]
done:False
-------------------------
[165]>>[27]: env.step(4)
action:[-3.5, 2.18881]
reward:0.2967296219053398
observation:
[ 0.       0.      14.708    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 10.1026   0.      45.8573   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       3.00993 -2.90158]
done:False
-------------------------
[165]>>[28]: env.step(4)
action:[-3.5, 1.504965]
reward:0.22312011150482824
observation:
[ 0.       0.      16.3949   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.31537  0.      43.9997   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.2792  -2.89124]
done:False
-------------------------
[165]>>[29]: env.step(4)
action:[-3.5, 1.1396]
reward:0.2119827125571318
observation:
[ 0.       0.      18.0577   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.62493
 23.1171   0.      42.204    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.23531 -2.8815 ]
done:False
-------------------------
[165]>>[30]: env.step(3)
action:[-3.5, 7.23531]
reward:0.33523868116723043
observation:
[ 0.      19.6266   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       5.117
 21.5141   0.      40.5327   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.22579 -2.8725 ]
done:False
-------------------------
[165]>>[31]: env.step(0)
action:[-3.5, 2.22579]
reward:0.2328371848729875
observation:
[ 0.      21.2054   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       3.75569  0.       0.
 19.9284   0.      38.8677   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.21723 -2.86352]
done:False
-------------------------
[165]>>[32]: env.step(3)
action:[-3.5, 7.21723]
reward:0.33353275261663967
observation:
[ 0.      22.7908   0.       0.       0.       0.       0.       0.
  0.       0.       0.       2.75522  0.       0.       0.      18.3626
  0.       0.      37.2088   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.20907 -2.85456]
done:False
-------------------------
[165]>>[33]: env.step(5)
action:[-3.5, 2.20907]
reward:0.2311743402725551
observation:
[ 0.      24.3805   0.       0.       0.       0.       0.       2.5656
  0.       0.       0.       0.       0.       0.       0.      16.8203
  0.       0.      35.5559   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.20116 -2.84562]
done:False
-------------------------
[165]>>[34]: env.step(5)
action:[-3.5, 2.20116]
reward:0.240971775548998
observation:
[ 0.      26.0195   0.       0.       3.35159  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      15.2625
  0.       0.      33.8604   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.32255 -2.83649]
done:False
-------------------------
[165]>>[35]: env.step(4)
action:[-3.5, 1.161275]
reward:0.18233805145978443
observation:
[ 0.      27.465    0.       4.47974  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.9211
  0.       0.      32.3714   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.87141 -2.82833]
done:False
-------------------------
[165]>>[36]: env.step(5)
action:[-3.5, 1.87141]
reward:0.20738992663395983
observation:
[ 0.      28.8721   5.73498  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      12.6512   0.
  0.       0.      30.9264   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99668 -2.82056]
done:False
-------------------------
[165]>>[37]: env.step(4)
action:[-3.5, 0.99834]
reward:0.16388492606028368
observation:
[ 0.      30.1575   6.94377  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      11.5303   0.
  0.       0.      29.6098   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.69005 -2.81336]
done:False
-------------------------
[165]>>[38]: env.step(4)
action:[-3.5, 0.845025]
reward:0.14676287068916138
observation:
[ 0.      31.3008   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      10.5735   0.
  0.       0.      28.4413   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.52301 -2.807  ]
done:False
-------------------------
[165]>>[39]: env.step(5)
action:[-3.5, 1.52301]
reward:0.159941179582558
observation:
[ 0.      32.4879   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.63143  0.       0.
  0.       0.      27.2301   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.51152 -2.80045]
done:False
-------------------------
[165]>>[40]: env.step(2)
action:[3.5, 1.51152]
reward:-1.3409054133904363
observation:
[ 0.      33.596    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.81318  0.       0.
  0.       0.      26.1013   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.50423 -2.79435]
done:False
-------------------------
[165]>>[41]: env.step(2)
action:[3.5, 1.50423]
reward:0.19054799167802883
observation:
[ 0.       0.      34.6146   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       7.73507  0.
  0.       0.       0.       0.      25.0118   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.88474 -2.27635]
done:False
-------------------------
[165]>>[42]: env.step(2)
action:[3.5, 1.88474]
reward:0.20756838840036526
observation:
[ 0.       0.       0.       0.      35.4209   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  6.38542  0.       0.       0.       0.       0.      24.1341   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       1.99551 -1.21098]
done:False
-------------------------
[165]>>[43]: env.step(1)
action:[0, 1.99551]
reward:-0.5405576333672677
observation:
[ 0.         0.         0.         0.         0.        36.076
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  4.932      0.         0.         0.         0.        47.3413
 23.4994     0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.99053    0.0740028]
done:False
-------------------------
[165]>>[44]: env.step(4)
action:[0, 0.995265]
reward:0.218868866637227
observation:
[ 0.        0.       14.2949   37.3748    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  3.5051    0.        0.        0.        0.        0.        0.
 46.0378   22.2908    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.35497   0.774919]
done:False
-------------------------
[165]>>[45]: env.step(2)
action:[3.5, 2.35497]
reward:-25.472066602791962
observation:
[ 0.       0.       0.      15.1468  38.1456   0.       0.       0.
  0.       0.       0.       0.       0.       0.       2.65835  0.
  0.       0.       0.       0.       0.       0.      45.2858  21.6199
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       2.7368   1.25021]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 32}
{'x': 98.2532, 'y': 1.25021, 'z': 0.570164}
.........................
** Rewards description :
count    45.000000
mean     -0.305451
std       3.849694
min     -25.472067
25%       0.207568
50%       0.335239
75%       0.422843
max       0.536175
dtype: float64
#########################
[166]>> env.reset()
=========================
Retrying to reset environment!
Retrying to reset environment!
[166]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.19253593709511993
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.03481  -0.579965]
done:False
-------------------------
[166]>>[2]: env.step(3)
action:[0, 6.03481]
reward:0.28657689595113645
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.92322  -0.896468]
done:False
-------------------------
[166]>>[3]: env.step(3)
action:[0, 6.92322]
reward:0.4338566351937302
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.54635  -0.612564]
done:False
-------------------------
[166]>>[4]: env.step(3)
action:[0, 8.54635]
reward:0.5606702730706914
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 4.78553 0.20564]
done:False
-------------------------
[166]>>[5]: env.step(3)
action:[0, 9.78553]
reward:0.6608058028796315
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.8188  0.23088]
done:False
-------------------------
[166]>>[6]: env.step(3)
action:[0, 10.8188]
reward:0.7708427894048514
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.4958    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.09067   0.265605]
done:False
-------------------------
[166]>>[7]: env.step(1)
action:[0, 7.09067]
reward:0.785592592363872
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.685     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.23278   0.303558]
done:False
-------------------------
[166]>>[8]: env.step(5)
action:[0, 8.23278]
reward:0.8288566487749183
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.3761    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.57103   0.340125]
done:False
-------------------------
[166]>>[9]: env.step(3)
action:[0, 13.57103]
reward:0.9148341842002896
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.5879    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.51348   0.377582]
done:False
-------------------------
[166]>>[10]: env.step(3)
action:[0, 13.51348]
reward:0.9794404877688487
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.8862   43.6508    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        9.52577   0.413942]
done:False
-------------------------
[166]>>[11]: env.step(3)
action:[0, 14.52577]
reward:1.068648104601971
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.3373    0.       35.9777    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.7179    0.455097]
done:False
-------------------------
[166]>>[12]: env.step(3)
action:[0, 15.7179]
reward:1.1309256978611066
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  5.50361   0.        0.       43.7669   27.5943    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       11.487     0.500167]
done:False
-------------------------
[166]>>[13]: env.step(3)
action:[0, 16.487000000000002]
reward:1.1915785449559677
observation:
[ 0.        0.        0.        5.28472   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.846    18.658     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       12.3938    0.548199]
done:False
-------------------------
[166]>>[14]: env.step(0)
action:[-3.5, 12.3938]
reward:0.42907988814475306
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     10.2116  0.     45.9946  0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.     14.5478
 13.185  -2.7016]
done:False
-------------------------
[166]>>[15]: env.step(3)
action:[-3.5, 18.185000000000002]
reward:1.2529372994194754
observation:
[ 0.      23.5577   0.       0.       0.       0.       0.       0.
  0.       2.37168  0.       0.       0.       0.       0.      17.5166
  0.       0.      36.3717   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.1603  -2.71307]
done:False
-------------------------
[166]>>[16]: env.step(5)
action:[-3.5, 13.1603]
reward:1.2305204995003451
observation:
[ 0.      33.4907   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       8.86811  0.       0.
  0.       0.      26.2051   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.9705  -2.77922]
done:False
-------------------------
[166]>>[17]: env.step(5)
action:[-3.5, 13.9705]
reward:1.266454699089592
observation:
[44.0379   0.       0.       0.       0.       7.77154  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      15.5309   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.4898  -2.7385 ]
done:False
-------------------------
[166]>>[18]: env.step(4)
action:[-3.5, 12.4898]
reward:1.2045062898890504
observation:
[31.1048   0.      16.2018   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      29.0983   5.23274  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.6366  -2.68375]
done:False
-------------------------
[166]>>[19]: env.step(4)
action:[-3.5, 11.6366]
reward:-23.80882266251587
observation:
[33.8184  18.7364   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      26.3794   0.       0.       2.70347  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.5989  -2.6695 ]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 33}
{'x': 116.363, 'y': -2.6695, 'z': 0.570822}
.........................
** Rewards description :
count    19.000000
mean     -0.453693
std       5.666009
min     -23.808823
25%       0.497263
50%       0.828857
75%       1.161252
max       1.266455
dtype: float64
#########################
[167]>> env.reset()
=========================
[167]>>[1]: env.step(1)
action:[0, 13.5067]
reward:0.3103379968946164
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.348723 0.199656]
done:False
-------------------------
[167]>>[2]: env.step(3)
action:[0, 5.348723]
reward:0.24563988363940026
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.59264  0.203299]
done:False
-------------------------
[167]>>[3]: env.step(3)
action:[0, 6.59264]
reward:0.3841715607669478
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     2.9993 0.2123]
done:False
-------------------------
[167]>>[4]: env.step(3)
action:[0, 7.9993]
reward:0.5274375064445478
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.48559  0.227502]
done:False
-------------------------
[167]>>[5]: env.step(3)
action:[0, 9.48559]
reward:0.6559489438408337
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.82763  0.248406]
done:False
-------------------------
[167]>>[6]: env.step(3)
action:[0, 10.82763]
reward:0.7648572312162975
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       46.7414    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.00357   0.274478]
done:False
-------------------------
[167]>>[7]: env.step(4)
action:[0, 5.00357]
reward:0.5902602622235548
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.9448    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.0637    0.300685]
done:False
-------------------------
[167]>>[8]: env.step(4)
action:[0, 4.0637]
reward:0.5640421668763795
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       37.4738    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.95074   0.324913]
done:False
-------------------------
[167]>>[9]: env.step(4)
action:[0, 3.9507399999999997]
reward:0.48358575355706
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.3049    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        4.92775   0.347775]
done:False
-------------------------
[167]>>[10]: env.step(4)
action:[0, 2.463875]
reward:0.338691172663906
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       30.4164    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.46166   0.363833]
done:False
-------------------------
[167]>>[11]: env.step(4)
action:[0, 1.73083]
reward:0.26054064468881777
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       28.2715    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.67937   0.375681]
done:False
-------------------------
[167]>>[12]: env.step(5)
action:[0, 2.67937]
reward:0.28568956503226595
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       26.2525   49.0608    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.75115   0.386622]
done:False
-------------------------
[167]>>[13]: env.step(4)
action:[0, 1.375575]
reward:0.2670123489864251
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       24.163    46.9567    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.84752   0.397955]
done:False
-------------------------
[167]>>[14]: env.step(4)
action:[0, 1.42376]
reward:0.22694960210018045
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       22.3251   45.1035    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.34607   0.408098]
done:False
-------------------------
[167]>>[15]: env.step(3)
action:[0, 7.34607]
reward:0.36569885512255873
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.525    43.2858    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.57876   0.417844]
done:False
-------------------------
[167]>>[16]: env.step(4)
action:[0, 1.28938]
reward:0.2189387490638374
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       18.772    41.5122    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.28229   0.427502]
done:False
-------------------------
[167]>>[17]: env.step(5)
action:[0, 2.28229]
reward:0.24736993591261505
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       17.0499    0.       39.7656    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.38038   0.436904]
done:False
-------------------------
[167]>>[18]: env.step(3)
action:[0, 7.380380000000001]
reward:0.3707883227649551
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       15.221     0.       37.9044    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        2.63405   0.446882]
done:False
-------------------------
[167]>>[19]: env.step(3)
action:[0, 7.63405]
reward:0.4631392421563965
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       12.7273    0.       35.3509    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        3.74348   0.460369]
done:False
-------------------------
[167]>>[20]: env.step(4)
action:[0, 1.87174]
reward:0.45190616740713907
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        9.48862  48.151    31.9843    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.03993   0.478198]
done:False
-------------------------
[167]>>[21]: env.step(0)
action:[-3.5, 5.03993]
reward:-0.17514417898821655
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       7.39765  0.       0.      44.9026  28.5727   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.84985 -1.3963 ]
done:False
-------------------------
[167]>>[22]: env.step(3)
action:[-3.5, 10.84985]
reward:0.6969552810188007
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       7.66348  0.       0.       0.       0.       0.      25.5318
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.04862 -3.86591]
done:False
-------------------------
[167]>>[23]: env.step(4)
action:[-3.5, 4.04862]
reward:0.5105672208061447
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  6.65551  0.       0.       0.       0.       0.       0.       0.
  0.      21.5989   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.25316 -2.85931]
done:False
-------------------------
[167]>>[24]: env.step(3)
action:[-3.5, 10.253160000000001]
reward:0.6237401775390029
observation:
[ 0.       0.       0.       0.       8.3936   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 34.3529  17.8415   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       5.19973 -2.91793]
done:False
-------------------------
[167]>>[25]: env.step(3)
action:[-3.5, 10.199729999999999]
reward:0.6844616580793687
observation:
[ 0.       0.       0.      11.529    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.6996   0.      49.5359   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.03905 -2.9298 ]
done:False
-------------------------
[167]>>[26]: env.step(3)
action:[-3.5, 11.03905]
reward:0.7894258375444796
observation:
[ 0.       0.      15.9537   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.7794   0.      44.4834   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.30049 -2.90024]
done:False
-------------------------
[167]>>[27]: env.step(3)
action:[-3.5, 12.30049]
reward:0.892704282785307
observation:
[ 0.      21.5704   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       3.48105  0.       0.
 19.5661   0.      38.485    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.49726 -2.86398]
done:False
-------------------------
[167]>>[28]: env.step(3)
action:[-3.5, 13.49726]
reward:0.9669259945188848
observation:
[ 0.      28.08     5.01617  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      13.361
  0.       0.      31.7392   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.33364 -2.82671]
done:False
-------------------------
[167]>>[29]: env.step(5)
action:[-3.5, 9.33364]
reward:0.9142832839020583
observation:
[ 0.      35.4811   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.60879  0.       0.       0.
  0.       0.      24.1846   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.56447 -2.78612]
done:False
-------------------------
[167]>>[30]: env.step(3)
action:[-3.5, 14.56447]
reward:1.0004105566160755
observation:
[42.5396   0.       0.       0.       0.       0.       7.00965  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.0412   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.59513 -2.7475 ]
done:False
-------------------------
[167]>>[31]: env.step(0)
action:[-3.5, 9.59513]
reward:0.9573160815556205
observation:
[49.8735   0.       0.      12.1655   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       9.67559  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.1595  -2.70768]
done:False
-------------------------
[167]>>[32]: env.step(2)
action:[3.5, 10.1595]
reward:-0.5313001143947957
observation:
[ 0.       0.       0.       0.       0.       0.      32.7056  16.8545
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      27.7776   0.       0.       0.       5.84536  0.       0.
  0.       0.       0.       0.      10.1958   0.64239]
done:False
-------------------------
[167]>>[33]: env.step(3)
action:[3.5, 15.1958]
reward:1.0479962411709702
observation:
[ 0.      37.4684   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      25.528    0.
  0.       0.       0.       0.       0.      10.7217   0.       0.
  0.       0.       0.       0.      10.2079   6.66791]
done:False
-------------------------
[167]>>[34]: env.step(3)
action:[3.5, 15.2079]
reward:1.1136680596989477
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      17.9516   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.7722   0.       0.       0.
 44.4424   0.       0.       0.      11.3132   4.55788]
done:False
-------------------------
[167]>>[35]: env.step(1)
action:[0, 11.3132]
reward:0.37998886412872945
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      48.4327   0.       0.       0.      10.9787   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      19.0406   0.      36.9746  12.5717   4.60205]
done:False
-------------------------
[167]>>[36]: env.step(0)
action:[-3.5, 12.5717]
reward:0.43830348492729465
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       40.2619    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  3.9793    0.        0.        0.        0.        0.        0.
 25.2684    0.       45.0646    0.        0.        0.        0.
  0.       13.3115    0.280678]
done:False
-------------------------
[167]>>[37]: env.step(3)
action:[-3.5, 18.311500000000002]
reward:-23.735519972503834
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      39.0001   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       2.73935  0.       0.      26.3301  46.6282
  0.       0.       0.       0.      13.3639  -2.03384]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 34}
{'x': 145.076, 'y': -2.03384, 'z': 0.571431}
.........................
** Rewards description :
count    37.000000
mean     -0.146006
std       3.999898
min     -23.735520
25%       0.285690
50%       0.463139
75%       0.696955
max       1.113668
dtype: float64
#########################
[168]>> env.reset()
=========================
[168]>>[1]: env.step(3)
action:[0, 18.354100000000003]
reward:0.4636273606548925
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.06974  0.753182]
done:False
-------------------------
[168]>>[2]: env.step(3)
action:[0, 6.0697399999999995]
reward:0.3659514108420172
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 2.90101 1.37074]
done:False
-------------------------
[168]>>[3]: env.step(3)
action:[0, 7.901009999999999]
reward:0.5658670132964784
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 5.01554 1.17061]
done:False
-------------------------
[168]>>[4]: env.step(3)
action:[0, 10.01554]
reward:0.7332771178689901
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       6.762    0.267105]
done:False
-------------------------
[168]>>[5]: env.step(3)
action:[0, 11.762]
reward:0.82326329730202
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.1154    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.60742   0.279178]
done:False
-------------------------
[168]>>[6]: env.step(5)
action:[0, 7.60742]
reward:0.8376868073679551
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       40.7496    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.85614   0.301739]
done:False
-------------------------
[168]>>[7]: env.step(5)
action:[0, 8.85614]
reward:0.8582490770971786
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       34.1221    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.84584   0.339819]
done:False
-------------------------
[168]>>[8]: env.step(5)
action:[0, 8.84584]
reward:0.8514460780760797
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       27.5608    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.74822   0.376983]
done:False
-------------------------
[168]>>[9]: env.step(4)
action:[0, 6.74822]
reward:0.8112309549625449
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       20.6531   43.4152    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.68664   0.415325]
done:False
-------------------------
[168]>>[10]: env.step(1)
action:[0, 8.68664]
reward:0.8462953107931822
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       14.2305    0.       36.8928    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.71237   0.450642]
done:False
-------------------------
[168]>>[11]: env.step(3)
action:[0, 13.71237]
reward:0.9317647501928548
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.95539   0.       46.519    30.3502    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.73619   0.486006]
done:False
-------------------------
[168]>>[12]: env.step(0)
action:[-3.5, 8.73619]
reward:0.09293595901773755
observation:
[ 0.       0.       0.       0.       0.       6.10643  0.       0.
  0.       0.       0.       0.      24.8726   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.65074 -2.29197]
done:False
-------------------------
[168]>>[13]: env.step(1)
action:[0, 8.65074]
reward:0.08584440715756592
observation:
[ 0.       0.       0.       0.       0.       0.       0.       7.89052
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.022    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.5684  -3.15727]
done:False
-------------------------
[168]>>[14]: env.step(0)
action:[-3.5, 8.5684]
reward:0.07381151619675441
observation:
[ 0.       0.       0.      12.3286   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      12.7948  48.6052   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.41378 -2.97506]
done:False
-------------------------
[168]>>[15]: env.step(1)
action:[0, 8.41378]
reward:0.0701667461394282
observation:
[ 0.       0.      17.9557   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.73768
 23.2324   0.      42.3189   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.39955 -2.90205]
done:False
-------------------------
[168]>>[16]: env.step(3)
action:[0, 13.39955]
reward:0.9070994879024367
observation:
[ 0.      23.9473   0.       0.       0.       0.       0.       0.
  2.51777  0.       0.       0.       0.       0.       0.      17.2407
  0.       0.      36.0066   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.43923 -2.8554 ]
done:False
-------------------------
[168]>>[17]: env.step(5)
action:[0, 8.43923]
reward:0.8192645580228136
observation:
[ 0.        0.        0.        0.        5.46101  28.7003    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       11.28
  0.        0.       30.8486    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        8.38011  -0.222922]
done:False
-------------------------
[168]>>[18]: env.step(1)
action:[0, 8.38011]
reward:0.8153895996105975
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       5.5595   0.       0.
 49.1939  25.444    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      11.2221  34.2225   0.       8.33878  1.05606]
done:False
-------------------------
[168]>>[19]: env.step(5)
action:[0, 8.33878]
reward:0.8032910942434663
observation:
[40.7285    0.        0.        0.        0.        3.20513   0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       42.6982   19.0499    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 17.6786    8.17453   0.799081]
done:False
-------------------------
[168]>>[20]: env.step(5)
action:[0, 8.17453]
reward:0.7928325315344722
observation:
[46.7681    8.11422   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       36.6875    0.       13.2843
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 23.721     8.0654    0.794478]
done:False
-------------------------
[168]>>[21]: env.step(3)
action:[0, 13.0654]
reward:0.8835826574318464
observation:
[ 0.       13.9467    0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       30.6968    0.        0.
  7.96973   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 29.7674    8.16951   0.815703]
done:False
-------------------------
[168]>>[22]: env.step(3)
action:[0, 13.16951]
reward:0.9648388907675896
observation:
[20.4507    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       24.2003    0.
  0.        0.        0.        0.        0.        0.        4.88711
  0.        0.        0.        0.        0.        0.        0.
 36.3625    9.383     0.847695]
done:False
-------------------------
[168]>>[23]: env.step(3)
action:[0, 14.383]
reward:1.073200490151837
observation:
[28.0467    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       16.7682    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        9.3247    0.        0.
 44.0102   10.8298    0.887217]
done:False
-------------------------
[168]>>[24]: env.step(3)
action:[0, 15.8298]
reward:1.1625981061400212
observation:
[36.6738    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       48.6176    0.        0.
  8.81657   0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       17.3101
  0.       12.0246    0.933164]
done:False
-------------------------
[168]>>[25]: env.step(1)
action:[0, 12.0246]
reward:1.1464662624460846
observation:
[45.9483    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       39.3232    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.13053   0.        0.        0.        0.       26.361
  0.       12.6857    0.983086]
done:False
-------------------------
[168]>>[26]: env.step(3)
action:[0, 17.6857]
reward:1.2194475685500352
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 29.8218  0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.     12.3487  0.     35.7459
 12.6237  1.0344]
done:False
-------------------------
[168]>>[27]: env.step(5)
action:[0, 12.6237]
reward:1.143839590352309
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      20.419    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      21.3406  45.087   12.4891   1.08523]
done:False
-------------------------
[168]>>[28]: env.step(4)
action:[0, 10.4891]
reward:1.105967248132741
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      49.5007  11.129    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      30.4875  12.3599   1.13552]
done:False
-------------------------
[168]>>[29]: env.step(0)
action:[-3.5, 12.3599]
reward:0.37291664772112076
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       3.39148  0.       0.       0.      41.093    0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 38.9046   0.       0.       0.      12.1861  -2.23468]
done:False
-------------------------
[168]>>[30]: env.step(1)
action:[0, 12.1861]
reward:0.37162496003481493
observation:
[ 0.       0.       0.       0.      47.148    5.86608  0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      32.7519   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.207   -0.43027]
done:False
-------------------------
[168]>>[31]: env.step(1)
action:[0, 12.207]
reward:1.1230068104145285
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      24.3154
 43.339    0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      14.199    0.       0.      12.2259   1.75725]
done:False
-------------------------
[168]>>[32]: env.step(3)
action:[0, 17.2259]
reward:1.198102135552485
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 15.3215   0.      34.3001   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      23.2375  12.3315   1.40354]
done:False
-------------------------
[168]>>[33]: env.step(3)
action:[0, 17.3315]
reward:1.245910770015421
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       6.02982
  0.       0.       0.      24.8677   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      32.825   13.2324   1.38611]
done:False
-------------------------
[168]>>[34]: env.step(3)
action:[0, 18.2324]
reward:1.309032958164086
observation:
[ 0.       0.       5.38981  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.9123   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      43.2194  14.3338   1.42966]
done:False
-------------------------
[168]>>[35]: env.step(0)
action:[-3.5, 14.3338]
reward:0.53801516074319
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       4.25758  0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      16.0718  14.8512  -1.82268]
done:False
-------------------------
[168]>>[36]: env.step(0)
action:[-3.5, 14.8512]
reward:-23.706403110232614
observation:
[16.8154   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       3.5211   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.8416  -2.11829]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 37}
{'x': 237.901, 'y': -2.11829, 'z': 0.570845}
.........................
** Rewards description :
count    36.000000
mean      0.102818
std       4.096826
min     -23.706403
25%       0.519418
50%       0.830475
75%       1.081392
max       1.309033
dtype: float64
#########################
[169]>> env.reset()
=========================
[169]>>[1]: env.step(3)
action:[0, 19.7774]
reward:1.3324970723615073
observation:
[ 0.       0.      33.0417   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      15.3887  14.4806   1.61058]
done:False
-------------------------
[169]>>[2]: env.step(3)
action:[0, 19.480600000000003]
reward:1.354212632079947
observation:
[44.0237   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      25.8628  15.0737   1.57292]
done:False
-------------------------
[169]>>[3]: env.step(3)
action:[0, 20.073700000000002]
reward:1.3937161193701502
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      37.3591  15.9533   1.70129]
done:False
-------------------------
[169]>>[4]: env.step(3)
action:[0, 20.9533]
reward:1.4303282936798078
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      49.595   16.8337   1.77024]
done:False
-------------------------
[169]>>[5]: env.step(4)
action:[0, 14.8337]
reward:1.4061574102916987
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 17.617   1.8378]
done:False
-------------------------
[169]>>[6]: env.step(4)
action:[0, 15.617]
reward:1.3709322533119492
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.4595   1.90592]
done:False
-------------------------
[169]>>[7]: env.step(4)
action:[0, 14.459499999999998]
reward:1.307858384261201
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.251    1.96983]
done:False
-------------------------
[169]>>[8]: env.step(4)
action:[0, 13.251]
reward:1.234712643795385
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 14.0302  2.0286]
done:False
-------------------------
[169]>>[9]: env.step(4)
action:[0, 12.0302]
reward:1.2107332783066878
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.8701   2.08882]
done:False
-------------------------
[169]>>[10]: env.step(2)
action:[3.5, 13.8701]
reward:0.4772706345546358
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.7295   2.14468]
done:False
-------------------------
[169]>>[11]: env.step(4)
action:[3.5, 11.7295]
reward:1.1919541798512585
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.5902   2.19997]
done:False
-------------------------
[169]>>[12]: env.step(4)
action:[3.5, 11.5902]
reward:1.1204565949887229
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      12.3356   5.56653]
done:False
-------------------------
[169]>>[13]: env.step(4)
action:[3.5, 10.3356]
reward:1.0264273515529085
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.0706   5.63027]
done:False
-------------------------
[169]>>[14]: env.step(4)
action:[3.5, 9.0706]
reward:0.9981947591826008
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.9333   5.80944]
done:False
-------------------------
[169]>>[15]: env.step(4)
action:[3.5, 8.9333]
reward:0.9885654692970464
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.8148   5.87788]
done:False
-------------------------
[169]>>[16]: env.step(4)
action:[3.5, 8.8148]
reward:0.979266349285736
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6977   5.92406]
done:False
-------------------------
[169]>>[17]: env.step(5)
action:[3.5, 10.6977]
reward:1.0013122115724213
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.5762   5.96704]
done:False
-------------------------
[169]>>[18]: env.step(4)
action:[3.5, 8.5762]
reward:0.8836482828769443
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.29279 6.00647]
done:False
-------------------------
[169]>>[19]: env.step(4)
action:[3.5, 7.29279]
reward:0.7715129456888603
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.98169 6.04292]
done:False
-------------------------
[169]>>[20]: env.step(3)
action:[3.5, 12.98169]
reward:0.8620843454693128
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.87108 6.07498]
done:False
-------------------------
[169]>>[21]: env.step(3)
action:[3.5, 12.87108]
reward:0.8534540237177399
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.77145 6.10664]
done:False
-------------------------
[169]>>[22]: env.step(4)
action:[3.5, 5.77145]
reward:0.6334921052343991
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.45168 6.1347 ]
done:False
-------------------------
[169]>>[23]: env.step(3)
action:[3.5, 11.45168]
reward:0.7267093430858913
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.31118 6.1605 ]
done:False
-------------------------
[169]>>[24]: env.step(3)
action:[3.5, 11.31118]
reward:0.7653977330463402
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.89034 6.18639]
done:False
-------------------------
[169]>>[25]: env.step(3)
action:[3.5, 11.89034]
reward:0.924485832295096
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.08047 6.21885]
done:False
-------------------------
[169]>>[26]: env.step(3)
action:[3.5, 14.08047]
reward:1.0300256305614899
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.1928   6.25793]
done:False
-------------------------
[169]>>[27]: env.step(4)
action:[3.5, 8.1928]
reward:0.8661956356570786
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.12912 6.29692]
done:False
-------------------------
[169]>>[28]: env.step(3)
action:[3.5, 14.12912]
reward:0.9587221709480014
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.04785 6.33358]
done:False
-------------------------
[169]>>[29]: env.step(0)
action:[-3.5, 9.04785]
reward:-0.5891748871302562
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.58351 3.04741]
done:False
-------------------------
[169]>>[30]: env.step(1)
action:[0, 9.58351]
reward:0.16521772617295505
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.51618 -1.55564]
done:False
-------------------------
[169]>>[31]: env.step(3)
action:[0, 14.51618]
reward:0.9786112593279371
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.26205 2.09661]
done:False
-------------------------
[169]>>[32]: env.step(3)
action:[0, 14.26205]
reward:0.9731563147871812
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.23993 3.63668]
done:False
-------------------------
[169]>>[33]: env.step(4)
action:[0, 7.239929999999999]
reward:0.7859842050600611
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.20106 3.10891]
done:False
-------------------------
[169]>>[34]: env.step(3)
action:[0, 13.20106]
reward:0.8835742866862754
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.13547 3.05379]
done:False
-------------------------
[169]>>[35]: env.step(1)
action:[0, 8.13547]
reward:0.8244551248934646
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.53136 3.06416]
done:False
-------------------------
[169]>>[36]: env.step(5)
action:[0, 8.53136]
reward:0.8264185543888812
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.46092 3.09188]
done:False
-------------------------
[169]>>[37]: env.step(4)
action:[0, 6.46092]
reward:0.7178702222561554
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.4357  3.12185]
done:False
-------------------------
[169]>>[38]: env.step(4)
action:[0, 5.4357]
reward:0.6233944591048384
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.39944 3.14886]
done:False
-------------------------
[169]>>[39]: env.step(3)
action:[0, 11.39944]
reward:0.7219299254862115
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.25759 3.17603]
done:False
-------------------------
[169]>>[40]: env.step(3)
action:[0, 11.25759]
reward:0.7693477948304344
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.95975 3.20184]
done:False
-------------------------
[169]>>[41]: env.step(4)
action:[0, 4.95975]
reward:0.5979460245663923
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.17718 3.22843]
done:False
-------------------------
[169]>>[42]: env.step(3)
action:[0, 11.17718]
reward:0.7065247286311307
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.09913 3.25325]
done:False
-------------------------
[169]>>[43]: env.step(5)
action:[0, 6.09913]
reward:0.7317528191731777
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.71978 3.28045]
done:False
-------------------------
[169]>>[44]: env.step(4)
action:[0, 5.71978]
reward:0.6713896156903947
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 6.97978 3.31033]
done:False
-------------------------
[169]>>[45]: env.step(3)
action:[0, 11.97978]
reward:0.7925898308061834
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 7.11061 3.33854]
done:False
-------------------------
[169]>>[46]: env.step(3)
action:[0, 12.110610000000001]
reward:0.8793233481366807
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 8.34467 3.36958]
done:False
-------------------------
[169]>>[47]: env.step(3)
action:[0, 13.34467]
reward:0.9828761216619318
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 9.62209 3.4061 ]
done:False
-------------------------
[169]>>[48]: env.step(3)
action:[0, 14.62209]
reward:1.0664549591939765
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6572   3.44701]
done:False
-------------------------
[169]>>[49]: env.step(3)
action:[0, 15.6572]
reward:1.1564384263804142
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.9564   3.49594]
done:False
-------------------------
[169]>>[50]: env.step(3)
action:[0, 16.956400000000002]
reward:1.234258289486759
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      13.0949   3.54648]
done:False
-------------------------
[169]>>[51]: env.step(3)
action:[0, 18.094900000000003]
reward:1.3120770917593059
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      14.4359   3.60219]
done:False
-------------------------
[169]>>[52]: env.step(3)
action:[0, 19.4359]
reward:1.38500144679178
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 15.8747  3.6637]
done:False
-------------------------
[169]>>[53]: env.step(3)
action:[0, 20.8747]
reward:1.4262579632769965
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.721    3.72965]
done:False
-------------------------
[169]>>[54]: env.step(3)
action:[0, 21.721]
reward:1.4597836833214097
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.7197   3.79934]
done:False
-------------------------
[169]>>[55]: env.step(1)
action:[0, 17.7197]
reward:1.4482414262479324
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      18.2674   3.87214]
done:False
-------------------------
[169]>>[56]: env.step(4)
action:[0, 16.2674]
reward:1.423485990617097
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 17.7844  3.9448]
done:False
-------------------------
[169]>>[57]: env.step(4)
action:[0, 15.784400000000002]
reward:1.4136663491705717
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      17.6019   4.01642]
done:False
-------------------------
[169]>>[58]: env.step(4)
action:[0, 15.6019]
reward:1.3943334787503519
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
 17.0884  4.0863]
done:False
-------------------------
[169]>>[59]: env.step(4)
action:[0, 15.0884]
reward:1.3695510860187619
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.5562   4.15859]
done:False
-------------------------
[169]>>[60]: env.step(4)
action:[0, 14.5562]
reward:1.342015065714156
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      16.01     4.22408]
done:False
-------------------------
[169]>>[61]: env.step(4)
action:[0, 14.010000000000002]
reward:1.3173144104177896
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      15.5746   4.25387]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': 750.626, 'y': 4.25387, 'z': 0.569624}
.........................
** Rewards description :
count    61.000000
mean      0.998236
std       0.359634
min      -0.589175
25%       0.785984
50%       0.982876
75%       1.317314
max       1.459784
dtype: float64
#########################
[170]>> env.reset()
=========================
[170]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.10616875065750875
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.1992]
done:False
-------------------------
[170]>>[2]: env.step(3)
action:[0, 5.0]
reward:0.10616875065750875
observation:
[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
 0.     0.     0.     0.     0.     0.     0.     0.1992]
done:False
-------------------------
[170]>>[3]: env.step(3)
action:[0, 5.0]
reward:0.1353778658220917
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.348079 0.19966 ]
done:False
-------------------------
[170]>>[4]: env.step(3)
action:[0, 5.348079]
reward:0.2355738713290485
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.47     0.203135]
done:False
-------------------------
[170]>>[5]: env.step(3)
action:[0, 6.47]
reward:0.37100294694789304
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.86434  0.211877]
done:False
-------------------------
[170]>>[6]: env.step(3)
action:[0, 7.86434]
reward:0.5058298268800878
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.23761  0.226263]
done:False
-------------------------
[170]>>[7]: env.step(3)
action:[0, 9.23761]
reward:0.6296179549703736
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       5.53284  0.246055]
done:False
-------------------------
[170]>>[8]: env.step(3)
action:[0, 10.53284]
reward:0.7425624266014821
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       47.4061    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.76283   0.270948]
done:False
-------------------------
[170]>>[9]: env.step(5)
action:[0, 6.76283]
reward:0.7184622850915766
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       41.7179    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.36846   0.301559]
done:False
-------------------------
[170]>>[10]: env.step(5)
action:[0, 7.36846]
reward:0.7268336440713722
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       36.2093    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.33372   0.331388]
done:False
-------------------------
[170]>>[11]: env.step(3)
action:[0, 12.33372]
reward:0.8079218698922352
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      30.7701   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.24251  0.36089]
done:False
-------------------------
[170]>>[12]: env.step(5)
action:[0, 7.24251]
reward:0.7072884960011767
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       25.4494   48.2524    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.09338   0.389815]
done:False
-------------------------
[170]>>[13]: env.step(0)
action:[-3.5, 7.09338]
reward:-0.04770265625650838
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      21.5229  43.8503   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.06156 -1.91053]
done:False
-------------------------
[170]>>[14]: env.step(5)
action:[-3.5, 7.06156]
reward:0.7028275676888067
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 17.8732  39.4777   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.07685 -3.7584 ]
done:False
-------------------------
[170]>>[15]: env.step(3)
action:[-3.5, 12.07685]
reward:0.7697835831461871
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      13.158    0.
  0.      34.4492   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.76112 -3.14321]
done:False
-------------------------
[170]>>[16]: env.step(5)
action:[-3.5, 6.76112]
reward:0.6616930899530735
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.1652   0.       0.
  0.      29.4964   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.587   -3.04835]
done:False
-------------------------
[170]>>[17]: env.step(5)
action:[-3.5, 6.587]
reward:0.6534476521608821
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       6.69708  0.       0.       0.       0.       0.
  0.      24.6068   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.51825 -2.99648]
done:False
-------------------------
[170]>>[18]: env.step(3)
action:[-3.5, 11.51825]
reward:0.7383476285837024
observation:
[ 0.       0.       0.       0.       0.       0.       7.33175  0.
  0.       0.       0.       0.       0.       0.       0.       0.
 36.2734  19.7756   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.45734 -2.96042]
done:False
-------------------------
[170]>>[19]: env.step(0)
action:[-3.5, 6.45734]
reward:0.6422579408059149
observation:
[ 0.       0.       0.      10.7065   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 31.2259  14.6921   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.39879 -2.9284 ]
done:False
-------------------------
[170]>>[20]: env.step(1)
action:[0, 6.39879]
reward:-0.10464693506519973
observation:
[ 0.        0.        0.        0.        0.        0.        0.
 13.205     0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       10.5278   46.7024    0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.45538  -0.738553]
done:False
-------------------------
[170]>>[21]: env.step(3)
action:[0, 11.45538]
reward:0.7377171833727352
observation:
[ 0.      16.4803   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      22.8446   0.       6.87104  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.46422  1.42872]
done:False
-------------------------
[170]>>[22]: env.step(1)
action:[0, 6.46422]
reward:-24.371021602903504
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.       20.2613    0.        4.06528   0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
 19.2626    6.21756   0.523668]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 31}
{'x': 79.0248, 'y': 0.523668, 'z': 0.569888}
.........................
** Rewards description :
count    22.000000
mean     -0.628386
std       5.311090
min     -24.371022
25%       0.160427
50%       0.647853
75%       0.724741
max       0.807922
dtype: float64
#########################
[171]>> env.reset()
=========================
[171]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.20378858701259364
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.17091  0.914235]
done:False
-------------------------
[171]>>[2]: env.step(3)
action:[0, 6.17091]
reward:0.22790529985023614
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.17091 1.17197]
done:False
-------------------------
[171]>>[3]: env.step(3)
action:[0, 6.17091]
reward:0.23103143231332726
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.20896  0.776688]
done:False
-------------------------
[171]>>[4]: env.step(3)
action:[0, 6.20896]
reward:0.23167633284547456
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       1.2073   0.446016]
done:True
{'Occurred': False, 'col_1': 0, 'cal_2': 0}
{'x': -3.02618, 'y': 0.446016, 'z': 0.571398}
.........................
** Rewards description :
count    4.000000
mean     0.223600
std      0.013310
min      0.203789
25%      0.221876
50%      0.229468
75%      0.231193
max      0.231676
dtype: float64
#########################
[172]>> env.reset()
=========================
[172]>>[1]: env.step(3)
action:[0, 5.0]
reward:0.21828620007783806
observation:
[0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 0.      0.      0.      0.      0.      0.      0.      0.      0.
 1.34671 0.29808]
done:False
-------------------------
[172]>>[2]: env.step(3)
action:[0, 6.34671]
reward:0.36287845961712556
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       2.79324  0.235518]
done:False
-------------------------
[172]>>[3]: env.step(3)
action:[0, 7.79324]
reward:0.4912864597828652
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.06672  0.219934]
done:False
-------------------------
[172]>>[4]: env.step(3)
action:[0, 9.06672]
reward:0.5799365150432434
observation:
[0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       0.       0.       0.       0.
 0.       0.       0.       0.       4.91058  0.239185]
done:False
-------------------------
[172]>>[5]: env.step(3)
action:[0, 9.91058]
reward:0.6483142443528731
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       48.8742    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        5.61761   0.262443]
done:False
-------------------------
[172]>>[6]: env.step(4)
action:[0, 3.61761]
reward:0.6080878233192014
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       44.239     0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.64838   0.287849]
done:False
-------------------------
[172]>>[7]: env.step(5)
action:[0, 6.64838]
reward:0.6969091043812669
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       39.0764    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.09835   0.315863]
done:False
-------------------------
[172]>>[8]: env.step(5)
action:[0, 7.09835]
reward:0.7021804060678902
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       33.7748    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.0587    0.344638]
done:False
-------------------------
[172]>>[9]: env.step(5)
action:[0, 7.0587]
reward:0.6945496363860626
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      28.1976   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.96321  0.37493]
done:False
-------------------------
[172]>>[10]: env.step(5)
action:[0, 6.96321]
reward:0.6863556012065322
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       23.0494   45.8341    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.87422   0.402933]
done:False
-------------------------
[172]>>[11]: env.step(4)
action:[0, 4.87422]
reward:0.6417079700976878
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.       17.9874   40.7171    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.78712   0.430579]
done:False
-------------------------
[172]>>[12]: env.step(3)
action:[0, 11.78712]
reward:0.7708970142093508
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       13.0004    0.       35.6318    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.84936   0.458016]
done:False
-------------------------
[172]>>[13]: env.step(3)
action:[0, 11.84936]
reward:0.8251388119304008
observation:
[ 0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.83033   0.       46.3839   30.215     0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        7.61282   0.487059]
done:False
-------------------------
[172]>>[14]: env.step(0)
action:[-3.5, 7.61282]
reward:0.0416187810920553
observation:
[ 0.       0.       0.       0.       0.       0.       5.84223  0.
  0.       0.       0.       0.      25.1437   0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.18844 -1.91056]
done:False
-------------------------
[172]>>[15]: env.step(5)
action:[-3.5, 8.18844]
reward:0.8053915779011392
observation:
[ 0.       0.       0.       0.       0.       0.       0.       7.72314
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      19.8412   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.24236 -3.43495]
done:False
-------------------------
[172]>>[16]: env.step(0)
action:[-3.5, 8.24236]
reward:0.7914215211194756
observation:
[ 0.       0.       0.      11.4144   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 13.9064   0.      49.7291   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.02823 -3.02707]
done:False
-------------------------
[172]>>[17]: env.step(3)
action:[-3.5, 13.02823]
reward:0.8739050606764431
observation:
[ 0.       0.      16.6369   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  8.08241  0.      43.7462   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       8.03463 -2.92065]
done:False
-------------------------
[172]>>[18]: env.step(4)
action:[-3.5, 6.03463]
reward:0.6791997744920606
observation:
[ 0.      21.8008   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       3.32355  0.       0.
 19.341    0.      38.2451   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       7.00807 -2.86916]
done:False
-------------------------
[172]>>[19]: env.step(0)
action:[-3.5, 7.00807]
reward:0.6903295490887825
observation:
[ 0.      27.1585   0.       4.22263  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      14.2035
  0.       0.      32.6869   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.9177  -2.83301]
done:False
-------------------------
[172]>>[20]: env.step(0)
action:[-3.5, 6.9177]
reward:0.6822579203060276
observation:
[ 0.      32.1822   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       9.86846  0.       0.
  0.       0.      27.5418   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.82928 -2.80397]
done:False
-------------------------
[172]>>[21]: env.step(0)
action:[-3.5, 6.82928]
reward:0.6689075257459096
observation:
[ 0.      37.1222   0.       0.       0.       0.       0.       0.
  0.       0.       0.       6.83325  0.       0.       0.       0.
  0.       0.      22.5193   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.66846 -2.77645]
done:False
-------------------------
[172]>>[22]: env.step(5)
action:[-3.5, 6.66846]
reward:0.65564969410919
observation:
[41.9764   0.       0.       0.       0.       0.       6.78797  0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      17.6094   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.52784 -2.74977]
done:False
-------------------------
[172]>>[23]: env.step(1)
action:[0, 6.52784]
reward:-0.09315532520246861
observation:
[ 0.        0.        0.        0.        0.       45.6939    0.
  0.        7.63607   0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       37.7161   14.0013    0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        6.57926  -0.460138]
done:False
-------------------------
[172]>>[24]: env.step(3)
action:[0, 11.57926]
reward:0.7589004692480499
observation:
[49.6184  10.7098   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      33.9279   0.      10.9897   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      26.6482   6.73138  1.58065]
done:False
-------------------------
[172]>>[25]: env.step(1)
action:[0, 6.73138]
reward:0.6745263754387754
observation:
[31.4435  15.5785   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      29.0542   0.       0.       0.       6.77132
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       6.76982  0.88963]
done:False
-------------------------
[172]>>[26]: env.step(3)
action:[0, 11.76982]
reward:0.7827326676917563
observation:
[36.5917   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      23.9807   0.       0.       0.       0.
  0.       0.       0.       4.92887  0.       0.       0.       0.
  0.       0.       0.       0.       7.02216  0.87559]
done:False
-------------------------
[172]>>[27]: env.step(3)
action:[0, 12.02216]
reward:0.8493920100759071
observation:
[26.2487    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       18.5097    0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        7.84627   0.        0.
 42.2037    7.92395   0.886857]
done:False
-------------------------
[172]>>[28]: env.step(3)
action:[0, 12.92395]
reward:0.9414246817252389
observation:
[32.6496    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       12.4062
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.       13.4844    0.
 48.6327    9.08159   0.913564]
done:False
-------------------------
[172]>>[29]: env.step(3)
action:[0, 14.08159]
reward:1.0357836560683575
observation:
[40.4354    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       44.8466    0.        0.
  0.        0.        6.00303   0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.       20.9563
  0.       10.2863    0.954157]
done:False
-------------------------
[172]>>[30]: env.step(1)
action:[0, 10.2863]
reward:1.0040527210578292
observation:
[48.3276    0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       36.9403    0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        6.40187   0.        0.        0.
 28.7069   10.7228    0.996374]
done:False
-------------------------
[172]>>[31]: env.step(0)
action:[-3.5, 10.7228]
reward:0.25611823643237575
observation:
[ 0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     29.9741  0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.     35.3589  0.      0.      0.      0.
 10.6467 -2.0239]
done:False
-------------------------
[172]>>[32]: env.step(1)
action:[0, 10.6467]
reward:0.25213643400840535
observation:
[ 0.       0.       0.      42.6093   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.      22.7236   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6021  -1.67934]
done:False
-------------------------
[172]>>[33]: env.step(5)
action:[0, 10.6021]
reward:0.9949987741338641
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      16.3776   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.      49.3292   0.      10.4996   2.21164]
done:False
-------------------------
[172]>>[34]: env.step(0)
action:[-3.5, 10.4996]
reward:0.23030836451335035
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.6727  49.0837   0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      30.8571
  0.       0.       0.       0.      10.2929  -2.40372]
done:False
-------------------------
[172]>>[35]: env.step(0)
action:[-3.5, 10.2929]
reward:0.9617878236066622
observation:
[ 0.      38.009    0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  4.12357  0.       0.      41.9926   0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      10.0546  -2.44872]
done:False
-------------------------
[172]>>[36]: env.step(3)
action:[-3.5, 15.0546]
reward:1.0317713131835882
observation:
[45.4522   0.       0.       4.94189  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      34.6295   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       9.97766 -2.33972]
done:False
-------------------------
[172]>>[37]: env.step(2)
action:[3.5, 9.97766]
reward:-0.47984454883580874
observation:
[ 0.      12.3747   0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 26.8949   0.      44.97     0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.0586  -2.26108]
done:False
-------------------------
[172]>>[38]: env.step(0)
action:[-3.5, 11.0586]
reward:-0.41266646545452423
observation:
[20.9391   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
 18.5251   0.      36.3099   0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.8992  -2.19713]
done:False
-------------------------
[172]>>[39]: env.step(5)
action:[-3.5, 11.8992]
reward:1.095888723682326
observation:
[30.4025   0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       9.96833  0.
  0.       0.      26.821    0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.8346  -2.14173]
done:False
-------------------------
[172]>>[40]: env.step(1)
action:[0, 11.8346]
reward:0.34049090077407307
observation:
[ 0.       0.       0.      38.1885   0.       0.       0.       0.
  0.       0.       0.       0.       2.63447  0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.      19.5914
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.7588   1.05526]
done:False
-------------------------
[172]>>[41]: env.step(2)
action:[3.5, 11.7588]
reward:-24.66065390242645
observation:
[ 0.       0.      38.6943   0.       0.       0.       0.       0.
  0.       0.       0.       2.34147  0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.      19.1996   0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.      11.7583   1.37451]
done:True
{'Occurred': True, 'col_1': 23, 'cal_2': 36}
{'x': 222.674, 'y': 1.37451, 'z': 0.56832}
.........................
** Rewards description :
count    41.000000
mean     -0.015141
std       3.961837
min     -24.660654
25%       0.362878
50%       0.682258
75%       0.805392
max       1.095889
dtype: float64
#########################
[173]>> env.reset()
=========================
[173]>>[1]: env.step(2)
action:[3.5, 11.6778]
reward:-0.09992970756191155
observation:
[ 0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.       0.       0.      12.598    0.       0.       0.       0.
  0.       0.       0.       0.       0.       0.       0.       0.
  0.      47.9582   0.       0.       5.19965  4.44387]
done:False
-------------------------
Error!
